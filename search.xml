<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fpod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F-%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%88%A0%E9%99%A4%2F</url>
    <content type="text"><![CDATA[测试]]></content>
  </entry>
  <entry>
    <title><![CDATA[Jenkins快速搭建]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FJenkins%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[git 准备主: 192.168.43.101其他节点: 192.168.43.102, 192.168.43.103 安装过程省略 yum install -y git 主节点创建 git 用户 123456789101112131415161718192021[root@k8s01 ~]# useradd git[root@k8s01 ~]# passwd gitChanging password for user git.New password:Retype new password:passwd: all authentication tokens updated successfully.[root@k8s01 ~]# cat /etc/ssh/sshd_config | grep AuthorizedKeysFile # 查看免密登陆文件路径AuthorizedKeysFile .ssh/authorized_keys[root@k8s01 ~]# su - gitLast login: Sun Jan 10 01:34:27 CST 2021 on pts/0[git@k8s01 ~]$ pwd/home/git[git@k8s01 ~]$ mkdir .ssh &amp;&amp; chmod 700 .ssh/ &amp;&amp; touch .ssh/authorized_keys &amp;&amp; chmod 600 .ssh/authorized_keys[git@k8s01 ~]$ echo &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDn2Q62b5GthMIqnJb0E+N1pd/mhigDpL+t702SHhaxHrPvUY3QNC/1nLJFA2OkjYJIKAs5xlxlh8afRfcyMtApOJGqXA1swLSMK97+cH8cQXMjFTlKSoKL6qfi9l7q0XC56rLBwkXt+9U9JdaD8ruW3fdNn6VC24ocWvYbI/XpFPArB4u9nbgeko+oLFp0q+MBc33Ucp6mkrs3Ytsp5kxolgNEUIXz3/sqpKH4LXioMRAtSx3F3MjarZEUmAsH0hDUQBXLV+u3Zyd+4lXZA9ALwz1k2l/R9p58zyAufR8EvvgWCriZMLeCsZdtRDPwsjFaJ1Qo3HPwKZk08q5ClBTL root@k8s02&quot; &gt; .ssh/authorized_keys # 下一步操作生成的文件[git@k8s01 ~]$ mkdir repo/app.git/ &amp;&amp; cd repo/app.git/ &amp;&amp; git --bare init # 初始化镜像仓库 备节点设置免密 登录1234567891011121314151617181920212223242526272829303132[root@k8s02 test_git]# ssh-keygen -t rsa -f /root/.ssh/id_rsa -N &apos;&apos;Generating public/private rsa key pair.Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:ozomMf9cpuEe0xWbhecz4UDwmPkNlsdw27YuLlnmXVw root@k8s02The key&apos;s randomart image is:+---[RSA 2048]----+| ..o . || * * o || + O B o || o &amp; o .E|| S = * ...|| o o o o+ o|| + = + =.... || . ++ B o.... || o.+* .. |+----[SHA256]-----+[root@k8s02 test_git]# cat /root/.ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDn2Q62b5GthMIqnJb0E+N1pd/mhigDpL+t702SHhax HrPvUY3QNC/1nLJFA2OkjYJIKAs5xlxlh8afRfcyMtApOJGqXA1swLSMK97+cH8cQXMjFTlKSoKL6qfi 9l7q0XC56rLBwkXt+9U9JdaD8ruW3fdNn6VC24ocWvYbI/XpFPArB4u9nbgeko+oLFp0q+MBc33Ucp6m krs3Ytsp5kxolgNEUIXz3/sqpKH4LXioMRAtSx3F3MjarZEUmAsH0hDUQBXLV+u3Zyd+4lXZA9ALwz1k 2l/R9p58zyAufR8EvvgWCriZMLeCsZdtRDPwsjFaJ1Qo3HPwKZk08q5ClBTL root@k8s02[root@k8s02 test_git]# git clone git@192.168.43.101:/home/git/repo/app.gitCloning into &apos;app&apos;...warning: You appear to have cloned an empty repository.[root@k8s02 test_git]# ls -altotal 0drwxr-xr-x 3 root root 17 Jan 10 01:54 .dr-xr-x---. 5 root root 215 Jan 10 01:25 ..drwxr-xr-x 3 root root 18 Jan 10 01:54 app jenkins 安装jenkins 下载地址 : https://www.jenkins.io/download/ 当前使用的 centos 安装方法: 123sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo # 下载 repo 源sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key # 导入证书sudo yum install -y jenkins 详细过程12345678910111213[root@k8s01 ~]# sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo--2021-01-10 01:59:39-- https://pkg.jenkins.io/redhat-stable/jenkins.repoResolving pkg.jenkins.io (pkg.jenkins.io)... 151.101.110.133, 2a04:4e42:36::645Connecting to pkg.jenkins.io (pkg.jenkins.io)|151.101.110.133|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 85Saving to: ‘/etc/yum.repos.d/jenkins.repo’100%[=============================================================================================&gt;] 85 --.-K/s in 0s2021-01-10 01:59:43 (969 KB/s) - ‘/etc/yum.repos.d/jenkins.repo’ saved [85/85][root@k8s01 ~]# sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fansibble(%E8%A1%A5)%2F</url>
    <content type="text"><![CDATA[术语Ansible Playbooks：任务脚本，编排定义Ansible任务及的配置文件，由Ansible按序依次执行，通常是JSON格式的YML文件； Inventory：Ansible 管理主机清单； Modules：Ansible 执行命令功能模块，多数为内置的核心模块，也可自定义； Plugins：模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不太常用； API：供第三方程序调用的应用程序编程接口；]]></content>
  </entry>
  <entry>
    <title><![CDATA[harbor]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fharbor%2F</url>
    <content type="text"><![CDATA[前置条件docker docker-compose 443端口未被占用 域名: harbor.imwl.cf 证书存放路径 /etc/cert/harbor 默认账户密码 admin Harbor12345 (可以修改配置文件更改) 12345678910111213mkdir /etc/cert/harborwget https://github.com/goharbor/harbor/releases/download/v2.1.2/harbor-offline-installer-v2.1.2.tgztar -xzvf harbor-offline-installer-v2.1.2.tgzcd harborcp harbor.yml.tmpl harbor.yml # 修改域名以及 证书路径mkdir certs.d &amp;&amp; cd certs.dopenssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 3650 -out ca.crt # 生成秘钥和自签名证书openssl req -newkey rsa:4096 -nodes -sha256 -keyout harbor.imwl.cf.key -out harbor.imwl.cf.csr # 生成证书签名请求openssl x509 -req -days 365 -in harbor.imwl.cf.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out harbor.imwl.cf.crt # 生成服务器证书cp harbor.imwl.cf* /etc/cert/harborcd .../install.sh 不安全是因为使用的自签名，并非来自权威证书机构颁布 报错信息1234[root@k8s01 ~]# docker login harbor.imwl.cfUsername: imwlPassword:Error response from daemon: Get https://harbor.imwl.cf/v2/: x509: certificate is not valid for any names, but wanted to match harbor.imwl.cf 需要修改 /etc/docker/daemon.json 添加 insecure-registries12345678[root@k8s01 ~]# cat /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [&quot;https://1hdirfy9.mirror.aliyuncs.com&quot;], &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;], &quot;insecure-registries&quot;:[&quot;harbor.imwl.cf&quot;]&#125;systemctl restart docker 重新验证， ok 1234567[root@k8s01 ~]# docker login harbor.imwl.cf Username: adminPassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded 推送123456789101112[root@k8s01 ~]# docker images |grep pauseimwl/pause 3.2 80d28bedfe5d 10 months ago 683kB[root@k8s01 ~]# docker tag imwl/pause:3.2 harbor.imwl.cf/library/pause:3.2[root@k8s01 ~]# docker images |grep pauseimwl/pause 3.2 80d28bedfe5d 10 months ago 683kBharbor.imwl.cf/library/pause 3.2 80d28bedfe5d 10 months ago 683kB[root@k8s01 ~]# docker push harbor.imwl.cf/library/pause:3.2The push refers to repository [harbor.imwl.cf/library/pause]ba0dae6243cc: Pushed3.2: digest: sha256:4a1c4b21597c1b4415bdbecb28a3296c6b5e23ca4f9feeb599860a1dac6a0108 size: 526]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s-%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Kubernetes Sidecar设计模式比如使用Sidebar容器处理日志，可以让应用不用关心日志发送到哪里，仅输出到stdout就可以。容器的输出会被同一Pod中的SideCar辅助容器截取，并发送到日志聚合平台如（ElasticSearch）。这使得运行在Kubernetes中的微服务可以实现分布式链路跟踪（Distribute Tracing）等功能。 Operator模式kubernetes管理无状态应用使用的就是一个简单的Operator模式。核心就是声明式表示对象预期值，控制器会根据预期值不断调整实际值使得预期值等于实际值。处理有状态应用则比较复杂，需要自定义控制器来满足复杂的业务需求。 =====================================================================================================================================================2、k8s 的 pause 容器有什么用。是否可以去掉。每个Pod里运行着一个特殊的被称之为Pause的容器，其他容器则为业务容器，这些业务容器共享Pause容器的网络栈和Volume挂载卷，因此他们之间通信和数据交换更为高效，在设计时我们可以充分利用这一特性将一组密切相关的服务进程放入同一个Pod中。同一个Pod里的容器之间仅需通过localhost就能互相通信。kubernetes中的pause容器主要为每个业务容器提供以下功能：PID命名空间：Pod中的不同应用程序可以看到其他应用程序的进程ID。网络命名空间：Pod中的多个容器能够访问同一个IP和端口范围。IPC命名空间：Pod中的多个容器能够使用SystemV IPC或POSIX消息队列进行通信。UTS命名空间：Pod中的多个容器共享一个主机名；Volumes（共享存储卷）：Pod中的各个容器可以访问在Pod级别定义的Volumes。 =====================================================================================================================================================3、Kubernetes Pod 是什么?Pod是Kubernetes中最小的可部署和管理单元。一个Pod可以包含多个容器，这些容器往往是紧耦合的。一个Pod中的多个容器代表需要运行在同一个服务器上的多个进程。Pod就类似于一台服务器。比如，通过localhost每个容器可以访问它所在Pod中的其它容器。 为什么Kubernetes将Pod而不是单个容器作为最小可部署单元呢？尽管直接部署单个容器也许会更容易，但增加Pod这个新的抽象层会带来新的好处。容器是一个真实存在的实体，它代表一个具体的东西。这个“东西”可以是一个Docker容器，也可以是一个rkt容器。每种“东西”都有不同的用途。为了管理容器，Kubernetes需要更多的信息，比如重启策略（restart policy），它定义了当容器终止了时怎样重启容器；还有活性检测（liveness probe），它定义了如何从应用视角去检测容器中的进程是否活着，比如Web服务器进程是否能响应HTTP请求。 =====================================================================================================================================================4、一个经典 pod 的完整生命周期。Pending：Pod 定义正确，提交到 Master，但其包含的容器镜像还未完全创建。通常处在 Master 对 Pod 的调度过程中。ContainerCreating：Pod 的调度完成，被分配到指定 Node 上。处于容器创建的过程中。通常是在拉取镜像的过程中。Running：Pod 包含的所有容器都已经成功创建，并且成功运行起来。Successed：Pod 中所有容器都成功结束，且不会被重启。这是 Pod 的一种最终状态。Failed：Pod 中所有容器都结束，但至少一个容器以失败状态结束。这也是 Pod 的一种最终状态。Unknown： 由于一些原因，Pod 的状态无法获取，通常是与 Pod 通信时出错导致的。 =====================================================================================================================================================5、k8s 的 service 和 ep 是如何关联和相互影响的。api-server创建service对象，与service绑定的pod地址：称之为endpointskube-proxy监控service后端endpoint的动态变化，并且维护service和endpoint的映射关系 =====================================================================================================================================================6、详述kube-proxy原理，一个请求是如何经过层层转发落到某个pod上的整个过程。请求可能来自pod也可能来自外部。kube-proxy为集群提供service功能，相同功能的pods对外抽象为service，service可以实现反向代理和服务发现。可以分为iptables、ipvs和userspace模式。 具体有iptables实现在反向代理方面，kube-proxy默认使用rr算法实现客户端流量分发到后端的pod=====================================================================================================================================================7、如何在 Kubernetes 中实现负载均衡？Service会自带负载均衡的endpoint，ipvs或者iptables，ipvs的话性能好一点，iptables是概率的方式，不是很好用， =====================================================================================================================================================8、在生产中，你如何实现 Kubernetes 自动化？ 使用jenkins开发流水线或者使用shell脚本===================================================================================================================================================== 9、你如何扩展 Kubernetes 集群？ 看安装方式如果是adm直接生成token以及就可以让node加入集群中，master的话需要把配置全部scp至新的node节点,然后起来kubelet和proxy以及网络插件以后master授权=====================================================================================================================================================10、你能解释 Deployment、ReplicaSets、StatefulSets、Pod、CronJob 的不同用途吗？Cronjob跟linux的crtab是类似的可以做批处理Deployment具有上线部署、副本设定、滚动升级、回滚等功能RS的话他的功能被deployment包含了创建deployment控制器的时候他默认会自动来一个rsStatefulset有状态的控制器一般是做有状态的应用部署比如redis以及mysql或者zk这种的 Pod是集群的最小单元，=====================================================================================================================================================11、Kubernetes 如何处理持久性？ 可以使用pvc以及pv做持久化数据，可以自动也可以手动=====================================================================================================================================================12、服务和 ingress 的作用是什么？Ingress可以作为一个7层调度器，可以保存ssl证书，这样的话,从外部到ingress这一段用https通信，对pod使用http通信， 就不用让pod做ssl会话了，service的Nodeport是不具备这个功能的，而且ingress可以加一些比如nginx他自身的参数，我们也知道nginx还是很强大的=====================================================================================================================================================13、你何时会使用像 ConfigMap 或 secret 这样的东西？Configmap的话需要做配置统一的话会考虑用这个，通过修改configmap来做热加载或者重启pod让他生效，比如部署Prometheus的时候就用的configmap， Prometheus的自动发现功能还是很好用的，Secret的话一般是存储ssl证书的配置或者是存docker的镜像仓库凭证=====================================================================================================================================================14、Pod 亲和性作用是什么？ 可以根据pod亲和来让pod指定运行在那个node节点上比如pod和pod亲和比如pod和node亲和=====================================================================================================================================================15、你能举例说明何时使用 Init Container 么？ Init是初始化容器，为这个初始化一个环境，没有很用过这个=====================================================================================================================================================16、.在构建和管理生产集群时遇到的主要问题是什么？容器雪崩 =====================================================================================================================================================17、kubernetes包含几个组件。 各个组件的功能是什么。组件之间是如何交互的。kube-apiserver Kubernetes API，集群的统一入口，各组件协调者，以RESTful API提供接口 服务，所有对象资源的增删改查和监听操作都交给APIServer处理后再提交给Etcd存储。 kube-controller-manager 处理集群中常规后台任务，一个资源对应一个控制器，而ControllerManager 就是负责管理这些控制器的。 kube-scheduler 根据调度算法为新创建的Pod选择一个Node节点，可以任意部署,可以部署在 同一个节点上,也可以部署在不同的节点上。 etcd 分布式键值存储系统。用于保存集群状态数据，比如Pod、Service等对象信息。 kubelet kubelet是Master在Node节点上的Agent，管理本机运行容器的生命周期，比如创 建容器、Pod挂载数据卷、下载secret、获取容器和节点状态等工作。kubelet将每 个Pod转换成一组容器。这是一个代理服务，它在每个节点上运行，并使从服务器与主服务器通信。因此，Kubelet处理PodSpec中提供给它的容器的描述，并确保PodSpec中描述的容器运行正常。 kube-proxy 在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作。 docker或rocket 容器引擎，运行容器。 docker runtime=====================================================================================================================================================18、.k8s的pause容器有什么用。是否可以去掉。不可以生成每个pod的同时会生成pause，是一个pod的网络总入口 =====================================================================================================================================================19.k8s中的pod内几个容器之间的关系是什么。 共享网络命名空间=====================================================================================================================================================20、rc/rs功能是怎么实现的。详述从API接收到-一个创建rc/rs的请求,到最终在节点上创建pod的全过程,尽可能详细。另外,当-个pod失效时，kubernetes是如何发现并重启另一个pod的?用户创建的请求跟api交互 在认证授权通过之后，api会把数据写入etcd并联系scheduler，给他根据调度算法，查看每个节点状态确定往哪一个节点调度， 然后api与该节点的kubelet交互并把相关的数据写入etcd，kubelet调用底层的docker来根据配置清单创建容器=====================================================================================================================================================21.cgroup中的cpu有哪几种限制方式。 k8s是如何使用实现request和limit的。软硬也就是request和limit，预配值以及最大限制，实现的话还是转化为底层的docker，使用docker的限制方式实现的 =====================================================================================================================================================22、k8s日志收集日志采集的两种模式容器日志采集模式现在流行的方式有 SideCar模式和 Node模式，SideCar模式会占用大量资源，而Node模式需要智能的 logging agent 配合，而 log-pilot就是那个智能的agent log-pilot+elsearch+kibana 1、k8s使用daemonset类型的副本集，使每个节点运行一个 log-pilot 来收集日志，该日志会含有 k8s_container_name、k8s_pod、k8s_node_name、k8s_pod_namespace 等打标数据，输出到相应的 logstash 来做索引2、运行docker微服务的主机上运行一个 log-pilot 来收集日志，该日志会含有 docker_container、topic、index 等打标数据，输出到相应的 logstash 来做索引3、普通非容器程序的日志可以采用 filebeat 收集，日志中可以自定义标签和字段，输出到对应的 logstash 来做索引 1、k8s日志收集的三种方式（推荐使用第一种）1.1、在Node节点上部署loging agent(Daemonset)，将日志文件转发到后端存贮起来,kubectl logs 可以使用1.2、启动一个sidecar辅助容器，将日志文件重新输入到sidecar容器的stdout和sdterr上，不过这种方式默认kubectl logs 不可以使用，而且保存两份日志文件非常消耗硬盘资源1.3、通过一个sidecar辅助容器，直接把容器日志发送到远端的存储，部署简单，而且对主机访问友好，不过sidecar容易非常消耗资源，甚至会拖垮业务容器，而kubectl logs 不可以使用 2、docker日志量大的时候，这么去收集？日志量大的时候，直接输出到容器的stdout、stderr，容易吧日志的配额用满，最终导致日志被吞掉，解决办法是增加日志配额，一个是容器加上存储，把日志放到存储上。 =====================================================================================================================================================23、基于k8s的CI/CD =====================================================================================================================================================24、ingress-nginxingress暴露从集群外到集群内服务的HTTP或HTTPS路由。定义在ingress资源上的规则控制流量的路由。 必须具有 Ingress 控制器 才能满足 Ingress 的要求。 仅创建 Ingress 资源本身没有任何效果。你可能需要部署 Ingress 控制器，例如 ingress-nginx。 你可以从许多 Ingress 控制器 中进行选择。 一个ingress可以配置用于提供外部可访问的服务url、负载均衡流量、SSL终端和提供虚拟主机名配置。ingress controller负责实现通常使用负载均衡器(loadbalancer)入口（ingress）。但是它也可以配置你的边缘路由器或额外的前端来帮助处理流量。ingress不暴露任何端口或协议。将HTTP和HTTPS之外的服务公开到因特网通常使用类型是NodePort或loadbalance的service。 Ingress 配置为服务提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及提供基于名称的虚拟主机等能力。Ingress-controller 控制器通常负责通过负载均衡器来实现Ingress，尽管它也可以配置边缘路由器或其他前端来帮助处理流量。Ingress 不会公开任意端口或协议。 将HTTP和HTTPS以外的服务公开到Internet时，通常使用Service.Type=NodePort或Service.Type=LoadBalancer类型的服务。 Ingress 规则1、可选的 host2、路径列表 paths 路径类型： 2.1.ImplementationSpecific：对于这种路径类型，匹配方法取决于 IngressClass 2.2.Exact：精确匹配 URL 路径，且区分大小写 2.3.Prefix：基于以 / 分隔的 URL 路径前缀匹配。匹配区分大小写，并且对路径中的元素逐个完成3、backend服务 =====================================================================================================================================================25、Kubernetes之网络策略(Network Policy)如果希望在 IP 地址或端口层面（OSI 第 3 层或第 4 层）控制网络流量， 则你可以考虑为集群中特定应用使用 Kubernetes 网络策略（NetworkPolicy）。NetworkPolicy 是一种以应用为中心的结构，允许你设置如何允许 Pod 与网络上的各类网络“实体” （我们这里使用实体以避免过度使用诸如“端点”和“服务”这类常用术语， 这些术语在 Kubernetes 中有特定含义）通信。 默认情况下，Pod 是非隔离的，它们接受任何来源的流量。Pod 在被某 NetworkPolicy 选中时进入被隔离状态。 一旦名字空间中有 NetworkPolicy 选择了特定的 Pod，该 Pod 会拒绝该 NetworkPolicy 所不允许的连接。 必需字段：与所有其他的 Kubernetes 配置一样，NetworkPolicy 需要 apiVersion、 kind 和 metadata 字段。 spec： NetworkPolicy 规约 中包含了在一个名字空间中定义特定网络策略所需的所有信息。 podSelector：每个 NetworkPolicy 都包括一个 podSelector，它对该策略所 适用的一组 Pod 进行选择。示例中的策略选择带有 “role=db” 标签的 Pod。 空的 podSelector 选择名字空间下的所有 Pod。 policyTypes: 每个 NetworkPolicy 都包含一个 policyTypes 列表，其中包含 Ingress 或 Egress 或两者兼具。policyTypes 字段表示给定的策略是应用于 进入所选 Pod 的入站流量还是来自所选 Pod 的出站流量，或两者兼有。 如果 NetworkPolicy 未指定 policyTypes 则默认情况下始终设置 Ingress； 如果 NetworkPolicy 有任何出口规则的话则设置 Egress。 ingress: 每个 NetworkPolicy 可包含一个 ingress 规则的白名单列表。 每个规则都允许同时匹配 from 和 ports 部分的流量。示例策略中包含一条简单的规则： 它匹配某个特定端口，来自三个来源中的一个，第一个通过 ipBlock 指定，第二个通过 namespaceSelector 指定，第三个通过 podSelector 指定。 egress: 每个 NetworkPolicy 可包含一个 egress 规则的白名单列表。 每个规则都允许匹配 to 和 port 部分的流量。该示例策略包含一条规则， 该规则将指定端口上 的流量匹配到 10.0.0.0/24 中的任何目的地。=====================================================================================================================================================26、k8s监控prometheus——grafapull抓取metrice监控指标数据(Daemonset 部署Node Exporter工具)，保存到TSDB（influxDB或者OpenTSDB）pushgateWay允许被监控对象已push的方式向prometheus推送监控指标数据altermanager可以根据metrice信息灵活的设置短信，邮件告警grafana对外暴露和配置展现监控数据的可视化界面 matric数据包含1、宿主机的监控数据2、k8s组件的监控数据3、 promotheus获取监控数据的有pull和push两种模式1、pull拉取的数据时效性比push客户端推送差，采集到的监控数据没有及时得到更新，容易造成监控数据的丢失2、push模式增加服务实现的复杂度，不支持metrics数据采集自定义，比如高峰时间减少数据采集。 =====================================================================================================================================================27、dockerfile的基本指令from 制定基础镜像run 执行的指令workdir制定了当前目录cmd 指定容器的进程，这个是容器制作时运行的entrypoint 与cmd相同，这个hi容器运行时运行的env 容器的环境变量 add 吧外部的资源添加到容器镜像，类似copy=====================================================================================================================================================28、docker基本知识docker容器只是一个特殊进程，通过namespace 资源隔离，cgroup资源限定，rootfs操作系统包含的文件，配置和目录,并不包含内核，所以同一台服务器上的所有容器上面都是共享宿主机的内核，自己本身没有内核namespace;IPC PID MNT user UTS docker在镜像设计，引入层的概念，这个层就是用户dockerfile文件的每一行指令，也是每一个增量的rootfs文件，rootfs包含三层1、只读层2、init层 /etc/hosts /etc/resolv.conf3、可读写层 容器最主要的两部分1、静态容器镜像images2、动态容器运行时runtimes 容器编排的三种工具1、单机docker-compose， 部署harbor使用，而且在测试环境里也使用nginx——tomcat——mysql的时候使用过，2、docker公司自己的swarm，没有接触，一般学主流3、谷歌公司的k8s，是一个管理和编排容器的工具，而docker只是它最底层的一个容器运行时的实现 =====================================================================================================================================================29、k8s的架构masterkube-apiserver 入口kube-scheduler 负责调度kube-controller 负责容器编排etcd node组件包括 kubelet、 容器运行时以及 kube-proxy。 kubelet 负责通过CRI接口同容器运行时打交道，另外一个重要的功能是网络插件CNI和存储插件CSI为容器配置网络和持久化存储同一个po里面的容器共享一个网络命名空间，mount挂载数据卷，从而达到了高效交换信息的目的。 =====================================================================================================================================================30、网络概念1、Linux网络名词解释： 1.1、网络的命名空间： Linux在网络栈中引入网络命名空间，将独立的网络协议栈隔离到不同的命令空间中，彼此间无法通信；docker利用这一特性，实现不容器间的网络隔离。 1.2、Veth设备对： Veth设备对的引入是为了实现在不同网络命名空间的通信。 1.3、Iptables/Netfilter： Netfilter负责在内核中执行各种挂接的规则(过滤、修改、丢弃等)，运行在内核模式中； Iptables模式是在用户模式下运行的进程，负责协助维护内核中Netfilter的各种规则表； 通过二者的配合来实现整个Linux网络协议栈中灵活的数据包处理机制。 1.4、网桥： 网桥是一个二层网络设备,通过网桥可以将linux支持的不同的端口连接起来,并实现类似交换机那样的多对多的通信。 1.5、路由： Linux系统包含一个完整的路由功能，当IP层在处理数据发送或转发的时候，会使用路由表来决定发往哪里 在Kubernetes网络中存在两种IP（Pod IP和Service Cluster IP），Pod IP地址是实际存在于某个网卡(可以是虚拟设备)上的，Service Cluster IP它是一个虚拟IP 是由kube-proxy使用Iptables/ipvs规则重新定向到其本地端口，再均衡到后端Pod的。 2、kubernetes网络模型 2.1. 基础原则 每个Pod都拥有一个独立的IP地址，而且假定所有Pod都在一个可以直接连通的、扁平的网络空间中，不管是否运行在同一Node上都可以通过Pod的IP来访问。 k8s中Pod的IP是最小粒度IP。同一个Pod内所有的容器共享一个网络堆栈，该模型称为IP-per-Pod模型。 Pod由docker0实际分配的IP，Pod内部看到的IP地址和端口与外部保持一致。同一个Pod内的不同容器共享网络，可以通过localhost来访问对方的端口，类似同一个VM内的不同进程。 IP-per-Pod模型从端口分配、域名解析、服务发现、负载均衡、应用配置等角度看，Pod可以看作是一台独立的VM或物理机。 2.2. k8s对集群的网络要求 所有容器都可以不用NAT的方式同别的容器通信。 所有节点都可以在不同NAT的方式下同所有容器通信，反之亦然。 容器的地址和别人看到的地址是同一个地址。 学习参考文档：https://www.cnblogs.com/centos-python/articles/10869210.html =====================================================================================================================================================31、k8s之网络插件flannel及基于Calico的网络策略1.k8s网络通信 1.1.容器间通信: 同一个pod内的多个容器间的通信,通过lo即可实现; 1.2.pod之间的通信: pod ip pod ip,pod和pod之间不经过任何转换即可通信; 1.3.pod和service通信: pod ip cluster ip(即service ip)pod ip,它们通过iptables或ipvs实现通信,ipvs取代不了iptables,因为ipvs只能做负载均衡,而做不了nat转换; .Service与集群外部客户端的通信. 2、k8s靠CNI接口接入其他插件来实现网络通讯.目前比较流行的插件有flannet、callco、canel.这些插件使用的解决方案有如下方式: 2.1.虚拟网桥:虚拟网卡,多个容器共用一个虚拟网卡进行通信; 2.2.多路复用:MacVLAN,多个容器共用一个物理网卡进行通信; 2.3.硬件交换:SR-LOV,一个物理网卡可以虚拟出多个接口,这个性能最好. 3、CNI插件存放位置 cat /etc/cni/net.d/10-flannel.conflist 3.1、flanel只支持网络通讯,但是不支持网络策略; 3.2、callco网络通讯和网络策略都支持;canel:flanel+callco 3.3、可以部署flanel提供网络通讯,再部署一个callco只提供网络策略,而不用canel. 3.4、mtu:是指一种通信协议的某一层上面所能通过的最大数据包大小. 学习参考地址：https://www.cnblogs.com/fawaikuangtu123/p/11296382.html=====================================================================================================================================================32、K8s Service原理1、Service的工作方式有三种: 1.1、Userspace Client Pod要访问Server Pod时,它先将请求发给本机内核空间中的service规则，由它再将请求,转给监听在指定套接字上的kube-proxy，kube-proxy处理完请求， 并分发请求到指定Server Pod后,再将请求递交给内核空间中的service,由service将请求转给指定的Server Pod。 由于其需要来回在用户空间和内核空间交互通信，因此效率很差，接着就有了第二种方式. 1.2、iptables 此工作方式是直接由内核中的iptables规则，接受Client Pod的请求，并处理完成后，直接转发给指定ServerPod. 1.3、ipvs 它是直接有内核中的ipvs规则来接受Client Pod请求，并处理该请求,再有内核封包后，直接发给指定的Server Pod。 以上不论哪种，kube-proxy都通过watch的方式监控着kube-APIServer写入etcd中关于Pod的最新状态信息,它一旦检查到一个Pod资源被删除了 或 新建，它将立即将这些变化，反应再iptables 或 ipvs规则中，以便iptables和ipvs在调度Clinet Pod请求到Server Pod时，不会出现Server Pod不存在的情况。自k8s1.1以后,service默认使用ipvs规则，若ipvs没有被激活，则降级使用iptables规则. 但在1.1以前，service使用的模式默认为userspace. 2、service的类型有四种: 2.1、ExternalName: 用于将集群外部的服务引入到集群内部，在集群内部可直接访问来获取服务。 Pod—-&gt;SVC[externalName]——[SNAT]—–&gt;宿主机的物理网卡——&gt;物理网关—–&gt;Internat上提供服务的服务器. 注意: Service是externelName类型时, externalName必须是域名,而且此域名必须能被CoreDNS或CoreDNS能通过互联网上的根DNS解析出A记录. 2.2、ClusterIP： 用于为集群内Pod访问时,提供的固定访问地址,默认是自动分配地址,可使用ClusterIP关键字指定固定IP。 2.3、NodePort: 用于为集群外部访问Service后面Pod提供访问接入端口. 这种类型的service工作流程为:Client—–&gt;NodeIP:NodePort—–&gt;ClusterIP:ServicePort—–&gt;PodIP:ContainerPort LoadBalancer: 用于当K8s运行在一个云环境内时,若该云环境支持LBaaS,则此类型可自动触发创建一个软件负载均衡器用于对Service做负载均衡调度. 因为外部所有Client都访问一个NodeIP,该节点的压力将会很大, 而LoadBalancer则可解决这个问题。 而且它还直接动态监测后端Node是否被移除或新增了，然后动态更新调度的节点数。 3、什么是Headless Service？ 所谓headless service指: 没有ClusterIP的service, 它仅有一个service name.这个服务名解析得到的不是service的集群IP，而是Pod的IP,当其它人访问该service时， 将直接获得Pod的IP,进行直接访问。Headless Service类似于“普通”服务，但没有群集IP。此服务使您可以直接访问pod，而无需通过代理访问它。 学习参考文档：https://www.cnblogs.com/wn1m/p/11288131.html===================================================================================================================================================== 感谢观哥]]></content>
  </entry>
  <entry>
    <title><![CDATA[基本数据结构-python实现]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2F%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84python%2F</url>
    <content type="text"><![CDATA[SingleLinkList.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495class SingleNode: def __init__(self, item): self.item = item self.next = None class SingleLinkList: def __init__(self): self._head = None def is_empty(self): return self._head == None def length(self): current = self._head count = 0 while current != None: count += 1 current = current.next return count def travel(self): current = self._head while current != None: print(current.item) current = current.next print(&quot;&quot;) def add(self, item): node = SingleNode(item) node.next = self._head self._head = node def append(self, item): node = SingleNode(item) if self.is_empty(): self._head = node else: current = self._head while current.next != None: current = current.next current.next = node def insert(self, pos, item): if pos &lt;=0: self.add(item) elif pos &gt;(self.length() -1): self.append(item) else: node = SingleNode(item) count = 0 pre = self._head while count &lt; (pos-1): count += 1 pre = pre.next node.next = pre.next pre.next = node def search(self,item): current = self._head while current != None: if current.item == item: return True current = current.next return False def remove(self, item): current = self._head pre = None while current != None: if current.item == item: if not pre: self._head = current.next else: pre.next = current.next break else: pre = current current = current.next if __name__ == &quot;__main__&quot;: ll = SingleLinkList() ll.add(1) ll.add(2) ll.append(3) ll.insert(2, 4) print(&quot;length:&quot;,ll.length()) ll.travel() print(ll.search(3)) print(ll.search(5)) ll.remove(1) print(&quot;length:&quot;,ll.length()) ll.travel() list_stack.py1234567891011121314151617181920212223242526272829303132333435363738394041class Stack(object): &quot;&quot;&quot;栈&quot;&quot;&quot; def __init__(self): self.items = [] def is_empty(self): &quot;&quot;&quot;判断是否为空&quot;&quot;&quot; return self.items == [] def push(self, item): &quot;&quot;&quot;加入元素&quot;&quot;&quot; self.items.append(item) def pop(self): &quot;&quot;&quot;弹出元素&quot;&quot;&quot; self.items.pop() def peek(self): &quot;&quot;&quot;返回栈顶元素&quot;&quot;&quot; return self.items[len(self.items) - 1] def size(self): &quot;&quot;&quot;返回栈的大小&quot;&quot;&quot; return len(self.items)if __name__ == &quot;__main__&quot;: def test(): print(stack.size()) print(stack.peek()) stack.pop() stack = Stack() stack.push(&quot;hello&quot;) stack.push(&quot;world&quot;) stack.push(&quot;itcast&quot;) test() test() test() list_queue.py123456789101112131415161718192021222324252627282930313233class Queue(object): &quot;&quot;&quot;队列&quot;&quot;&quot; def __init__(self): self.items = [] def is_empty(self): return self.items == [] def enqueue(self, item): return self.items.insert(0, item) def dequeue(self): return self.items.pop() def size(self): return len(self.items)if __name__ == &quot;__main__&quot;: def test(): print(q.size()) print(q.dequeue()) q = Queue() q.enqueue(&quot;hello&quot;) q.enqueue(&quot;world&quot;) q.enqueue(&quot;itcast&quot;) test() test() test() list_Deque.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Deque(object): &quot;&quot;&quot;双端队列&quot;&quot;&quot; def __init__(self): self.items = [] def is_empty(self): &quot;&quot;&quot;判断队列是否为空&quot;&quot;&quot; return self.items == [] def add_front(self, item): &quot;&quot;&quot;在队头添加元素&quot;&quot;&quot; return self.items.insert(0, item) def add_rear(self, item): &quot;&quot;&quot;在队尾添加元素&quot;&quot;&quot; return self.items.append(item) def remove_front(self): &quot;&quot;&quot;从队头删除元素&quot;&quot;&quot; return self.items.pop(0) def remove_rear(self): &quot;&quot;&quot;从队尾删除元素&quot;&quot;&quot; return self.items.pop() def size(self): &quot;&quot;&quot;返回队列大小&quot;&quot;&quot; return len(self.items)if __name__ == &quot;__main__&quot;: deque = Deque() print(deque.size()) print(deque.is_empty()) deque.add_front(1) deque.add_front(2) deque.add_rear(3) deque.add_rear(4) print(deque.size()) deque.remove_front() print(deque.items) deque.remove_rear() print(deque.items)]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[一般算法]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2F%E4%B8%80%E8%88%AC%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[递归递归： 把大规模的问题转化为规模小的相同的子问题来解决。递归主体和 一个终止条件 因为大问题 和小问题 的解决方法往往是同一个方法，所以产生函数调用自身的情况。 一个终止条件 （防止产生无限递归） 分治分治： 把大规模，高难度的问题转化为 若干个小规模，低难度的小问题，最后再将小问题的答案合并 数据有序，预期时间复杂度带有 logn。通过小问题的答案合并原问题的答案。 可以采用分治法 排序排序： 让一组无序的数据变成有序的过程 排序最暴力的方法， 冒泡排序，选择排序，插入排序 O（n**2） 归并排序 O(nlogn)，需要开辟额外的空间 空间复杂度 O(N)快速排序 平均 O(nlogn), 最坏的时间复杂度 O(n**2) 动态规划]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基本数据结构]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2F%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[数组数组将元素以一种不规则的顺序进行排列，在内存中是连续存放。数据可以通过索引值直接取得。 数组只需记录头部的第一个数据位置，然后累加空间位置即可。 数组的操作新增 在 数组最后新增一个元素， 对原数据无影响。 插入时间复杂度 O(1) 在 数组中间某一个位置新增一个元素，会对插入后面的数据产生影响， 后面的元素位置要依次后挪一个位置 。 插入时间复杂度 O(n) 删除1 .在 数组最后删除一个元素， 对原数据无影响。 删除时间复杂度 O(1) 在 数组中间某一个位置删除一个元素，会对删除后面的数据产生影响， 后面的元素位置要依次前挪一个位置 。 删除时间复杂度 O(n) 查找 基于位置，以索引查找 时间复杂度 O(1) 查找具体数值，eg： 查找元素为 9 是否出现过。 需要遍历 时间复杂度 O(n) 虽然 很多操作被封装， 但时间复杂度不会改变 （因为python 封装的 函数底层可能是 c，所以一般执行效率会高一点） 数组的长度是固定的，申请时就已在内存空间开辟了若干空间，扩容一般 有一定规则扩容 链表可以 用指针充分利用内存空间。数组想从分利用空间只能选择顺序存储，而且不插入删除数据。 线性表线性表： n 个数据元素的有序排列，最常用的就是 链式表达 链表：存储的数据元素也叫结点，一个结点存储的就是一条数据记录。一般头指针指向第一个结点，最后一个结点的指针因为没有下一个节点，所以是个空指针 结点的结构包括两个部分: 具体的数据值 指向下一个结点的指针 单链表: 只能由上一个结点的 指针 指向下一个结点，反过来不行 循环链表: 将单链表的最后一个元素的指针指向第一个元素 双向链表： 新增一个结点的指针，除了有指向下一个元素的指针，也有指向上一个元素的指针 双向循环链表： 双向链表和循环链表 结合，将双向链表最后一个元素的指针指向第一个元素，第一个指针也指向最后一个元素 链表的增删查, p 为 当前结点，b 为下一个结点 新增：s 为待插入的结点， 只需要将s 的指针 指向 p的目标b ，p的指针指向s 12s.next = p.next(即指向 b)p.next = s （即指向 b） 删除： 只需要 将 p 的指针指向 下下个结点 （即b 指向的结点） 1p.next = p.next.next 查找： 1.按位置序号来查找 2.按具体的数值查找 查询第 n 个元素： 从头开始，遍历到第 n 个元素 查询值为 x: 从头开始,判断结点的值是否为 x，直到把所有节点遍历完 链表优缺点： 优点: 新增和删除（但也会伴随着查找） 缺点：查找 链表: 数据元素个数不确定, 需要经常添加删除 数组: 数据元素个数确定，删除插入操作不多。 需要以位置查找 栈栈是一种特殊的线性表，不同的地方体现在增和删操作。栈的数据结点必须后进先出 后进: 栈的数据新增只能在最后一个结点进行 先出: 栈的数据删除也只能在最后一个节点进行 栈降低了操作的灵活性，但处理一端的新增和删除数据的问题效率更高 表尾用来输入数据，通常叫做栈顶 （top）, 表头就是栈底（bottom） 栈的基本操作 新增：入栈 push 删除：出栈 pop 栈分为： 顺序栈，链栈 顺序栈：借助数组实现 链栈： 借助链表实现 顺序栈一般会把数组的首元素存在栈底，最后一个元素放在栈顶，定义一个 top 指针来指示栈顶元素在 数组中的位置。只有一个元素，top =0。 top =-1 表示空栈。如果定义了最大容量 StackSize，则 top 必须小于 StackSize。 新增： 将元素放在栈顶，top +1 删除： 删除元素， top - 1 查找： 类似于线性表链栈 栈顶放在单链表的头部，不需要头部指针。需要增加指向 栈顶的 top 指针。 新增： 新结点的指针指向 原栈顶，top指向新的结点 删除： 将 top 指针指向 顶元素的 next 指针 查找： 类似于线性表 栈： 限制版的线性表，先进后出，新增删除时间复杂度 O(1)，而查找 时间复杂度 O(n) 队列队列也是一种特殊的线性表，不同的地方体现在增和删操作。队列的数据结点先进先出 先进: 队列的数据新增只能在最后一个结点进行 先出: 队列的数据删除只能在第一个节点进行 队列分为： 顺序队列，链队列 顺序队列：借助数组实现 链队列： 借助链表实现 一个队列 依赖队头（front） 和 队尾 （rear） 两个指针进行唯一确定 顺序队列实现一个有 k 个元素的顺序队列，需要建立一个长度 比 k 大的数组，以便把所有的队列元素存储在数组中。 新增： 利用 rear 指针在队尾新增一个元素 O(1) 删除： 利用 front 指针删除 下标为 0 的元素，然后队列中所有元素都向前移动一个位置。 O(n) 时间复杂度高 删除： 通过移动指针的方式删除数据，不移动剩余元素。（会产生数组越界，需要开辟足够大的内存空间保证不会越界） 越界： 循环队列上面的两种删除方法都不太好，可以通过循环队列 解决数据越界问题待补充 链队列单链表增加 front 和 rear 指针。 front 指针头结点。头结点不存储数据，只用来标识辅助。 新增： 将新结点 s 设置为队尾结点，然后 rear 指向 s. 删除： 找到头结点的后继，删除这个后继结点（头结点不存储数据），删除最后一个有效数据后，让rear 也指向头结点。 头结点存在意义： 防止 最后一个有效数据结点删除后， front 和 rear 指针变成野指针。 总结 循环队列： 可以确定队列长度的最大值 链式队列： 无法确定队列长度 队列类似于 排队买票场景，可以使用队列来处理相似问题 哈希哈希表的设计采用了函数映射的思想，将记录的存储位置与记录的关键字关联起来。这样的设计方式，能够快速定位到想要查找的记录，而且不需要与表中存在的记录的关键字比较后再来进行查找1234567张一：155555555张二：166666666张三：177777777张四：188888888 借助哈希表的思路，构建姓名到地址的映射函数“地址 = f (姓名)”。这样，我们就可以通过这个函数直接计算出”张四“的存储位置，在 O(1) 时间复杂度内就可以完成数据的查找 假如对上面的例子采用的 Hash 函数为，姓名的每个字的拼音开头大写字母的 ASCII 码之和。即：1234567address (张一) = ASCII (Z) + ASCII (Y) = 90 + 89 = 179；address (张二) = ASCII (Z) + ASCII (E) = 90 + 69 = 159；address (张三) = ASCII (Z) + ASCII (S) = 90 + 83 = 173；address (张四) = ASCII (Z) + ASCII (S) = 90 + 83 = 173； 我们发现这个哈希函数存在一个非常致命的问题，那就是 f ( 张三) 和 f (张四) 都是 173。这种现象称作哈希冲突，是需要在设计哈希函数时进行规避的 从本质上来看，哈希冲突只能尽可能减少，不能完全避免。这是因为，输入数据的关键字是个开放集合。只要输入的数据量够多、分布够广，就完全有可能发生冲突的情况。因此，哈希表需要设计合理的哈希函数，并且对冲突有一套处理机制。 哈希表查找的细节过程是：对于给定的 key，通过哈希函数计算哈希地址 H (key)。 如果哈希地址对应的值为空，则查找不成功。 反之，则查找成功。 虽然哈希表查找的细节过程还比较麻烦，但因为一些高级语言的黑盒化处理，开发者并不需要实际去开发底层代码，只要调用相关的函数就可以了。 哈希表在我们平时的数据处理操作中有着很多独特的优点，不论哈希表中有多少数据，查找、插入、删除只需要接近常量的时间，即 O(1）的时间级 哈希表中的数据是没有顺序概念的，所以不能以一种固定的方式（比如从小到大）来遍历其中的元素。在数据处理顺序敏感的问题时，选择哈希表并不是个好的处理方法。同时，哈希表中的 key 是不允许重复的，在重复性非常高的数据中，哈希表也不是个好的选择]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s-Operator]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s-Operator%2F</url>
    <content type="text"><![CDATA[Operator在 Kubernetes 中，管理“有状态应用”是一个比较复杂的过程，尤其是编写 Pod 模板的时候，总有一种 “在 YAML 文件里编程序”的感觉，让人很不舒服。 而在 Kubernetes 生态中，还有一个相对更加灵活和编程友好的管理“有状态应用”的解决方案，它就是：Operator。 Etcd Operator 示例1234567891011121314151617181920212223242526272829303132333435[root@k8s01 ~]# git clone https://github.com/coreos/etcd-operator[root@k8s01 ~]# cd etcd-operator/[root@k8s01 etcd-operator]# example/rbac/create_role.shCreating role with ROLE_NAME=etcd-operator, NAMESPACE=defaultWarning: rbac.authorization.k8s.io/v1beta1 ClusterRole is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleclusterrole.rbac.authorization.k8s.io/etcd-operator createdCreating role binding with ROLE_NAME=etcd-operator, ROLE_BINDING_NAME=etcd-operator, NAMESPACE=defaultWarning: rbac.authorization.k8s.io/v1beta1 ClusterRoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleBindingclusterrolebinding.rbac.authorization.k8s.io/etcd-operator created[root@k8s01 etcd-operator]# kubectl create -f example/deployment.yaml # 因为使用的 v1.20, 所以需要修改文件，见最后error: unable to recognize &quot;example/deployment.yaml&quot;: no matches for kind &quot;Deployment&quot; in version &quot;extensions/v1beta1&quot;[root@k8s01 etcd-operator]# kubectl apply -f example/deployment.yaml # 创建 Etcd Operatordeployment.apps/etcd-operator created[root@k8s01 etcd-operator]# kubectl get pods |grep etcdetcd-operator-646cbffdb6-rwhl6 1/1 Running 0 6m28s [root@k8s01 etcd-operator]# kubectl get crd |grep etcd # 有一个 crd 被创建出来etcdclusters.etcd.database.coreos.com 2021-01-05T17:04:06Z[root@k8s01 etcd-operator]# kubectl apply -f example/example-etcd-cluster.yaml # 编写一个 EtcdCluster 的 YAML 文件[root@k8s01 etcd-operator]# kubectl get podsNAME READY STATUS RESTARTS AGEetcd-operator-646cbffdb6-rwhl6 1/1 Running 0 32mexample-etcd-cluster-5hrtljjplq 1/1 Running 0 2m39sexample-etcd-cluster-n5x8pbzfzv 1/1 Running 0 7m20sexample-etcd-cluster-vwz9wcsxcf 1/1 Running 0 5m11s Operator 的工作原理，实际上是利用了 Kubernetes 的自定义 API 资源（CRD），来描述我们想要部署的“有状态应用”；然后在自定义控制器里，根据自定义 API 对象的变化，来完成具体的部署和运维工作。 Kubernetes 里添加了一个名叫 EtcdCluster 的自定义资源类型。而 Etcd Operator 本身，就是这个自定义资源类型对应的自定义控制器。 补example/deployment.yaml123456789101112131415161718192021222324252627282930apiVersion: apps/v1kind: Deploymentmetadata: name: etcd-operatorspec: replicas: 1 selector: matchLabels: name: etcd-operator template: metadata: labels: name: etcd-operator spec: containers: - name: etcd-operator image: quay.io/coreos/etcd-operator:v0.9.4 command: - etcd-operator # Uncomment to act for resources in all namespaces. More information in doc/user/clusterwide.md #- -cluster-wide env: - name: MY_POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name etcdclusters.etcd.database.coreos.com 如果有 API 组（Group）是etcd.database.coreos.com、API 资源类型（Kind）是“EtcdCluster”的 YAML 文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394[root@k8s01 etcd-operator]# kubectl describe crd etcdclusters.etcd.database.coreos.comName: etcdclusters.etcd.database.coreos.comNamespace:Labels: &lt;none&gt;Annotations: &lt;none&gt;API Version: apiextensions.k8s.io/v1Kind: CustomResourceDefinitionMetadata: Creation Timestamp: 2021-01-05T17:04:06Z Generation: 1 Managed Fields: API Version: apiextensions.k8s.io/v1beta1 Fields Type: FieldsV1 fieldsV1: f:spec: f:conversion: .: f:strategy: f:group: f:names: f:kind: f:listKind: f:plural: f:shortNames: f:singular: f:preserveUnknownFields: f:scope: f:version: f:versions: f:status: f:storedVersions: Manager: etcd-operator Operation: Update Time: 2021-01-05T17:04:06Z API Version: apiextensions.k8s.io/v1 Fields Type: FieldsV1 fieldsV1: f:status: f:acceptedNames: f:kind: f:listKind: f:plural: f:shortNames: f:singular: f:conditions: Manager: kube-apiserver Operation: Update Time: 2021-01-05T17:04:06Z Resource Version: 75878 UID: 2eaa1a5d-e086-413e-873a-bf6d3de062ddSpec: Conversion: Strategy: None Group: etcd.database.coreos.com # 标识 Names: Kind: EtcdCluster # 标识 List Kind: EtcdClusterList Plural: etcdclusters Short Names: etcd Singular: etcdcluster Preserve Unknown Fields: true Scope: Namespaced Versions: Name: v1beta2 # 版本 Served: true Storage: trueStatus: Accepted Names: Kind: EtcdCluster List Kind: EtcdClusterList Plural: etcdclusters Short Names: etcd Singular: etcdcluster Conditions: Last Transition Time: 2021-01-05T17:04:06Z Message: spec.preserveUnknownFields: Invalid value: true: must be false Reason: Violations Status: True Type: NonStructuralSchema Last Transition Time: 2021-01-05T17:04:06Z Message: no conflicts found Reason: NoConflicts Status: True Type: NamesAccepted Last Transition Time: 2021-01-05T17:04:06Z Message: the initial names have been accepted Reason: InitialNamesAccepted Status: True Type: Established Stored Versions: v1beta2Events: &lt;none&gt; example/example-etcd-cluster.yaml123456789101112[root@k8s01 etcd-operator]# cat example/example-etcd-cluster.yamlapiVersion: &quot;etcd.database.coreos.com/v1beta2&quot; # 使用的 api ，上文中的 Group/Versions kind: &quot;EtcdCluster&quot; # 资源类型，上文定义的 kindmetadata: name: &quot;example-etcd-cluster&quot; ## Adding this annotation make this cluster managed by clusterwide operators ## namespaced operators ignore it # annotations: # etcd.database.coreos.com/scope: clusterwidespec: size: 3 version: &quot;3.2.13&quot;]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s-GPU管理与Device Plugin机制]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s-gpu%2F</url>
    <content type="text"><![CDATA[GPU管理对于云的用户来说，在 GPU 的支持上，他们最基本的诉求其实非常简单：只要在 Pod 的 YAML 里面，声明某容器需要的 GPU 个数，那么 Kubernetes 创建的容器里就应该出现对应的 GPU 设备，以及它对应的驱动目录 。 以 NVIDIA 的 GPU 设备为例，上面的需求就意味着当用户的容器被创建之后，这个容器里必须出现如下两部分设备和目录： GPU 设备，比如 /dev/nvidia0 （该器启动时的 Devices 参数） GPU 驱动目录，比如 /usr/local/nvidia/* （该容器启动时的 Volume 参数 ） 在 Kubernetes 的 GPU 支持的实现里，kubelet 实际上就是将上述两部分内容，设置在了创建该容器的 CRI （Container Runtime Interface）参数里面。这样，等到该容器启动之后，对应的容器里就会出现 GPU 设备和驱动的路径了。 不过，Kubernetes 在 Pod 的 API 对象里，并没有为 GPU 专门设置一个资源类型字段，而是使用了一种叫作 Extended Resource（ER）的特殊字段来负责传递 GPU 的信息. 12345678910111213apiVersion: v1kind: Podmetadata: name: cuda-vector-addspec: restartPolicy: OnFailure containers: - name: cuda-vector-add image: &quot;k8s.gcr.io/cuda-vector-add:v0.1&quot; resources: limits: nvidia.com/gpu: 1 这个 Pod 声明了自己要使用一个 NVIDIA 类型的 GPU, kube-scheduler 里面，它其实并不关心这个字段的具体含义，只会在计算的时候，一律将调度器里保存的该类型资源的可用量，直接减去 Pod 声明的数值即可。所以说，Extended Resource，其实是 Kubernetes 为用户设置的一种对自定义资源的支持。 添加自定义资源的数据，必须使用 PATCH API 来对该 Node 对象进行更新，加上你的自定义资源的数量。这个 PATCH 操作，可以简单地使用 curl 命令来发起，如下所示：12345678910111213141516171819202122# 启动 Kubernetes 的客户端 proxy，这样你就可以直接使用 curl 来跟 Kubernetes 的API Server 进行交互了$ kubectl proxy# 执行 PACTH 操作$ curl --header &quot;Content-Type: application/json-patch+json&quot; \--request PATCH \--data &apos;[&#123;&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/status/capacity/nvidia.com/gpu&quot;, &quot;value&quot;: &quot;1&quot;&#125;]&apos; \http://localhost:8001/api/v1/nodes/&lt;your-node-name&gt;/status# 执行后， Node 的 Status 变成了如下所示的内容， 它就能够在缓存里记录下 node-1 上的nvidia.com/gpu类型的资源的数量是 1apiVersion: v1kind: Node...Status: Capacity: cpu: 2 memory: 2049008Ki nvidia.com/gpu: 1 Device Plugin机制在 Kubernetes 的 GPU 支持方案里，你并不需要真正去做上述关于 Extended Resource 的这些操作。在 Kubernetes 中，对所有硬件加速设备进行管理的功能，都是由一种叫作 Device Plugin 的插件来负责的。这其中，当然也就包括了对该硬件的 Extended Resource 进行汇报的逻辑。 首先，对于每一种硬件设备，都需要有它所对应的 Device Plugin 进行管理，这些 Device Plugin，都通过 gRPC 的方式，同 kubelet 连接起来。以 NVIDIA GPU 为例，它对应的插件叫作NVIDIA GPU device plugin。这个 Device Plugin 会通过一个叫作 ListAndWatch 的 API，定期向 kubelet 汇报该 Node 上 GPU 的列表。比如，在我们的例子里，一共有三个 GPU（GPU0、GPU1 和 GPU2）。这样，kubelet 在拿到这个列表之后，就可以直接在它向 APIServer 发送的心跳里，以 Extended Resource 的方式，加上这些 GPU 的数量，比如nvidia.com/gpu=3。所以说，用户在这里是不需要关心 GPU 信息向上的汇报流程的。需要注意的是，ListAndWatch 向上汇报的信息，只有本机上 GPU 的 ID 列表，而不会有任何关于 GPU 设备本身的信息。而且 kubelet 在向 API Server 汇报的时候，只会汇报该 GPU 对应的 Extended Resource 的数量。当然，kubelet 本身，会将这个 GPU 的 ID 列表保存在自己的内存里，并通过 ListAndWatch API 定时更新。而当一个 Pod 想要使用一个 GPU 的时候，它只需要像我在本文一开始给出的例子一样，在 Pod 的 limits 字段声明nvidia.com/gpu: 1。那么接下来，Kubernetes 的调度器就会从它的缓存里，寻找 GPU 数量满足条件的 Node，然后将缓存里的 GPU 数量减 1，完成 Pod 与 Node 的绑定。这个调度成功后的 Pod 信息，自然就会被对应的 kubelet 拿来进行容器操作。而当 kubelet 发现这个 Pod 的容器请求一个 GPU 的时候，kubelet 就会从自己持有的 GPU 列表里，为这个容器分配一个 GPU。此时，kubelet 就会向本机的 Device Plugin 发起一个 Allocate() 请求。这个请求携带的参数，正是即将分配给该容器的设备 ID 列表。当 Device Plugin 收到 Allocate 请求之后，它就会根据 kubelet 传递过来 目前 Kubernetes 本身的 Device Plugin 的设计，实际上能覆盖的场景是非常单一的，属于“可用”但是“不好用”的状态。并且， Device Plugin 的 API 本身的可扩展性也不是很好]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s-api]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s-api%2F</url>
    <content type="text"><![CDATA[简介 123apiVersion: batch/v2alpha1kind: CronJob... CronJob : 这个 API 对象的资源类型（Resource）， batch : 它的组（Group）， (Pod、Node 等，是不需要 Group 的（即：它们的 Group 是’’）) v2alpha1 : 就是它的版本（Version）。 创建一个 /apis/batch/v2alpha1 下的 CronJob 对象。 发起了创建 CronJob 的 POST 请求, YAML 的信息提交给 APIServer APIServer 的第一个功能，就是过滤这个请求，并完成一些前置性的工作，(授权、超时处理、审计等) 进入 MUX 和 Routes(APIServer 完成 URL 和 Handler 绑定的场所)。找到对应的 CronJob 类型定义. 根据这个 CronJob 类型定义，使用用户提交的 YAML 文件里的字段，创建一个 CronJob 对象。(APIServer 会进行一个 Convert 工作，即：把用户提交的 YAML 文件，转换成一个叫作 Super Version 的对象(是该 API 资源类型所有版本的字段全集)。这样用户提交的不同版本的 YAML 文件，就都可以用这个 Super Version 对象来进行处理了。接下来，APIServer 会先后进行 Admission() 和 Validation()(验证是否合法) 操作。这个被验证过的 API 对象，都保存在了 APIServer 里一个叫作 Registry 的数据结构中。最后，APIServer 会把验证过的 API 对象转换成用户最初提交的版本，进行序列化操作，并调用 Etcd 的 API 把它保存起来。 Custom Resource DefinitionCRD 的全称是 Custom Resource Definition。顾名思义，它指的就是，允许用户在 Kubernetes 中添加一个跟 Pod、Node 类似的、新的 API 资源类型，即：自定义 API 资源。 示例为 Kubernetes 添加一个名叫 Network 的 API 资源类型。它的作用是，一旦用户创建一个 Network 对象，那么 Kubernetes 就应该使用这个对象定义的网络参数，调用真实的网络插件，比如 Neutron 项目，为用户创建一个真正的“网络”。这样，将来用户创建的 Pod，就可以声明使用这个“网络”了。 example-network.yaml 12345678apiVersion: samplecrd.k8s.io/v1kind: Networkmetadata: name: example-networkspec: cidr: &quot;192.168.0.0/16&quot; gateway: &quot;192.168.0.1&quot; 这个 YAML 文件，就是一个具体的“自定义 API 资源”实例，也叫 CR（Custom Resource)。而为了能够让 Kubernetes 认识这个 CR，需要让 Kubernetes 明白这个 CR 的宏观定义是什么，也就是 CRD（Custom Resource Definition）。 network-crd.yaml123456789101112apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: networks.samplecrd.k8s.iospec: group: samplecrd.k8s.io version: v1 names: kind: Network # CR 的资源类型 plural: networks # 复数 scope: Namespaced # 属于 Namespace 的对象，类似于 Pod 以上 Kubernetes 就能够认识和处理所有声明了 API 类型是 samplecrd.k8s.io/v1/network 的 YAML 文件了。需要让 Kubernetes “认识”这种 YAML 文件里描述的“网络”部分，比如“cidr”（网段），“gateway”（网关）这些字段的含义.(需要写代码了) 创建出这样一个自定义 API 对象，我们只是完成了 Kubernetes 声明式 API 的一半工作。接下来的另一半工作是：为这个 API 对象编写一个自定义控制器（Custom Controller）。这样， Kubernetes 才能根据 Network API 对象的“增、删、改”操作，在真实环境中做出相应的响应。比如，“创建、删除、修改”真正的 Neutron 网络。 以后详细看吧]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[cri]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fcri%2F</url>
    <content type="text"><![CDATA[cri : 容器运行时接口 cri 带来的好处： 将 kubelet 和与 容器运行时 解耦 解放 kubelet 的负担 kubelet 调用下层容器（eg: docker）运行的执行过程，是通过 CRI 的 gPRC 接口间接执行的 cricri 接口可以分为两部分 容器运行时服务 RuntimeService, 主要负责管理 Pod 和容器生命周期，eg:创建，删除，查询容器 镜像服务 ImageService ， 主要负责 容器镜像的生命周期管理， eg: 拉取，删除，查询镜像]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s安全]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E5%AE%89%E5%85%A8%E4%B8%8E%E6%81%A2%E5%A4%8D%2C%2F</url>
    <content type="text"><![CDATA[k8s 安全性Kubernetes 的安全性归纳为了以下四个方面： Infrastructure（基础设施） : 主要包括网络、存储、物理机、操作系统，等等 Kubernetes 集群自身 Containers（容器）及其运行时 Applications（业务应用） 措施1. 集群版本更新及 CVE 漏洞时刻关注社区 Kubernetes 的版本更新，以及披露的 CVE 漏洞，及时地把 CVE 的修复方案变更到你的集群中去。 同时你需要保证跟社区的版本不要太脱节，跟社区保持 1 到 2 个大版本的差异 2. 保护好 Etcd 集群Etcd 中保存着整个 Kubernetes 集群中最重要的数据，比如 Pod 信息、Secret、Token 等。一旦这些数据遭到攻击，造成的影响面非常巨大。我们必须确保 Etcd 集群的安全。 对于部署 Etcd 集群的各个节点，我们应该被授予最小的访问权限，同时还要尽量避免这些节点被用作其他用途。由于 Etcd 对数据的读写要求很高，这里磁盘最好是 SSD 类型。 Etcd 集群要配置双向 TLS 认证（mTLS），用于 Etcd 各个节点之间的通信。同时 APIServer 对 Etcd 集群的访问最好也要基于 mTLS。通过 Kubeadm 搭建出来的集群，默认已经采取这种配置方式。 3. 限制对 Kubernetes APIServer 的访问APIServer 是整个 Kubernetes 的大脑，及流量入口，所有的数据都在此进行交互。Kubernetes 的安全机制也都是围绕着保护 APIServer 进行设计的，正如我们第 18 讲介绍的认证（Authentication）、鉴权（Authorization）和准入控制（Admission Control），这三大机制保护了 APIServer 的安全。 显而易见，APIServer 也必须得使用 TLS 进行通信，尽量不要开启不安全的 HTTP 方式，尤其是在云上的环境中，切记一定要关闭，你可以通过–insecure-port=0参数来关闭。 同时要避免使用 AlwaysAllow 这种鉴权模式，这种模式会允许所有请求。一般来说，我建议这么配置鉴权模式，即–authorization-mode=RBAC,Node。RBAC（基于角色的访问控制）会将传入的用户/组与一组绑定到角色的权限进行匹配。这些权限将 HTTP 请求的动作（GET，POST，DELETE）和 Kubernetes 内部各种资源对象，比如 Pod、Service 或者 Node，在命名空间或者集群范围内有机地结合起来，你可以回顾我们第 18 讲的内容，这里不再赘述。 4. 减少集群的端口暴露当然你还需要尽可能减少集群的端口暴露。如下是 Kubernetes 各组件需要的端口，在使用的时候，可以限制只允许固定节点对这些端口的访问。 5. 限制对 Kubelet 的访问Kubelet 上运行着我们的业务容器，同时还暴露了 10250 端口，可以用来查询容器，支持容器 exec，获取容器日志等功能。因此在生产级别的集群，我们要启用 Kubelet 身份验证和授权，同时关闭匿名访问–anonymous-auth=false。 6. 开启审计能力APIServer 支持对所有的请求进行审计（Audit），你可以通过–audit-log-path来指定用来写入审计事件的日志文件路径，默认是不指定的。通过这个开启审计能力，再结合 RBAC，我们可以对整个集群的请求访问进行详细的监控和分析。 这个审计功能提供了与安全相关的，按时间顺序排列的记录集，每一个请求都会有对应的审计事件，记录着： 发生了什么？ 什么时候发生的？ 谁触发的？ 活动发生在哪个（些）对象上？ 在哪观察到的？ 它从哪触发的？ 活动的后续处理行为是什么？ 通过这些审计事件，集群管理员可以很容易地分析出集群内的安全风险，以采取应对策略。 7. 通过 namespace 进行隔离通过 namespace 来隔离工作负载和数据，比如区分不用的用户，不同的业务场景，以及一些关键的业务。你可以通过对这些 namespace 内的资源设置一些 RBAC 的规则，来进一步增强安全性。 8. 使用网络策略进行限制Kubernetes 提供了基于 namespace 的网络策略（Network Policy），可以允许和限制不同 namespace 中的 Pod 互访。 网络策略通过网络插件来实现，所以你要使用这种能力，要选择支持 NetworkPolicy 的网络解决方案，比如 Calico、Cilium、Weave 等。 9. 容器镜像安全容器的运行依赖容器的镜像，保证镜像安全是最基本的。要避免使用一些未知来源的镜像，同时自己构建镜像的时候，要使用安全的、确知的、官方的基础镜像。 同时，要定期地对镜像进行漏洞扫描，你可以使用 harbor-scanner-aqua、Clair 等工具对你的镜像中心、镜像进行扫描，来查找已知的漏洞。 除此之外，我们还要限制特权容器，避免在容器镜像中使用 root 用户，防止特权升级。 10. 应用程序的安全性应用程序自身的安全性也很重要。如果你的应用程序要暴露给集群外部，可以使用入口控制器（Ingress Controller），比如 Nginx。 应用容器也要使用 TLS 进行通信，包括跟入口控制器之间的通信。不需要定期扫描源代码及依赖项，查找是否有新漏洞，还要持续测试你的应用程序，查看是否会受到攻击，比如 SQL 注入，DDoS 攻击等。 工具检测https://github.com/aquasecurity/kube-bench 能帮助你排查 95% Kubernetes 集群的配置风险 备份恢复master 节点 在 Master 节点上，我们运行着 Etcd 集群以及 Kubernetes 控制面的几大组件，比如 kube-apiserver、kube-controller-manager、kube-scheduler 和 cloud-controller-manager（可选）等。 在这些组件中，除了 Etcd，其他都是无状态的服务。只要保证 Etcd 的数据正常，其他几个组件不管出现什么问题，我们都可以通过重启或者新建实例来解决，并不会受到任何影响。因此我们只需要备份 Etcd 中的数据。 node 节点主要对数据文件备份 eg: pv 备份etcd 备份1234567891011121314151617181920212223242526272829303132# 0. 数据备份ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \--cacert=/etc/kubernetes/pki/etcd/ca.crt \--key=/etc/kubernetes/pki/etcd/peer.key \--cert=/etc/kubernetes/pki/etcd/peer.crt \snapshot save ./new.snapshot.db# 1. 查看 etcd 集群的节点ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \ --cacert=/etc/kubernetes/pki/etcd/ca.crt \ --cert=/etc/kubernetes/pki/etcd/peer.crt \ --key=/etc/kubernetes/pki/etcd/peer.key \member list# 2. 停止所有节点上的 etcd！（注意是所有！！）## 如果是 static pod，可以听过如下的命令进行 stop## 如果是 systemd 管理的，可以通过 systemctl stop etcdmv /etc/kubernetes/manifests/etcd.yaml /etc/kubernetes/# 3. 数据清理## 依次在每个节点上，移除 etcd 数据rm -rf /var/lib/etcd# 4. 数据恢复## 依次在每个节点上，恢复 etcd 旧数据## 里面的 name，initial-advertise-peer-urls，initial-cluster=controlplane## 等参数，可以从 etcd pod 的 yaml 文件中获取到。ETCDCTL_API=3 etcdctl snapshot restore ./old.snapshot.db \--data-dir=/var/lib/etcd \--name=controlplane \--initial-advertise-peer-urls=https://172.17.0.18:2380 \--initial-cluster=controlplane=https://172.17.0.18:2380# 5. 恢复 etcd 服务## 依次在每个节点上，拉起 etcd 服务mv /etc/kubernetes/etcd.yaml /etc/kubernetes/manifests/systemctl restart kubelet 如果你的 Etcd 集群是运行在 Kubernetes 集群中的，你可以通过以下的定时 Job (CronJob) 来帮你自动化、周期性（如下的 YAML 文件中会每分钟对 Etcd 进行一次备份）地备份 Etcd 的数据 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: batch/v1beta1kind: CronJobmetadata: name: backup namespace: kube-systemspec: # activeDeadlineSeconds: 100 schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: backup # Same image as in /etc/kubernetes/manifests/etcd.yaml image: k8s.gcr.io/etcd:3.2.24 env: - name: ETCDCTL_API value: &quot;3&quot; command: [&quot;/bin/sh&quot;] args: [&quot;-c&quot;, &quot;etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key snapshot save /backup/etcd-snapshot-$(date +%Y-%m-%d_%H:%M:%S_%Z).db&quot;] volumeMounts: - mountPath: /etc/kubernetes/pki/etcd name: etcd-certs readOnly: true - mountPath: /backup name: backup restartPolicy: OnFailure hostNetwork: true volumes: - name: etcd-certs hostPath: path: /etc/kubernetes/pki/etcd type: DirectoryOrCreate - name: backup hostPath: path: /data/backup type: DirectoryOrCreate PV 备份对于 PV 来讲，备份就比较麻烦了。Kubernetes 自身不提供存储能力，它依赖各个存储插件对存储进行管理和使用。因此对于存储的备份操作，尤其是 PV 的备份操作，我们需要依赖各个云提供商的 API 来做 snapshot。 但是上述对于 Etcd 和 PV 的备份操作并不是很方便，我推荐你通过Velero来备份 Kubernetes。Velero 功能强大，但是操作起来很简单，它可以帮你做到以下 3 点： 对 Kubernets 集群做备份和恢复。 对集群进行迁移。 对集群的配置和对象进行复制，比如复制到其他的开发和测试集群中去。 而且 Velero 还提供针对单个 Namespace 进行备份的能力，如果你只想备份某些关键的业务和数据，这是一个十分方便的功能。]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s优先级调度]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E4%BC%98%E5%85%88%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[优先级和抢占机制，解决的是 Pod 调度失败时该怎么办的问题。 正常情况下，当一个 Pod 调度失败后，它就会被暂时“搁置”起来，直到 Pod 被更新，或者集群状态发生变化，调度器才会对这个 Pod 进行重新调度。 当一个高优先级的 Pod 调度失败后，该 Pod 并不会被“搁置”，而是会“挤走”某个 Node 上的一些低优先级的 Pod 。这样就可以保证这个高优先级 Pod 的调度成功 优先级提高集群的资源利用率最常见的做法就是采用优先级的方案。 通过给 Pod 设置高优先级，让其比其他 Pod 显得更为重要，通过这种“插队”的方式优先获得调度器的调度 PriorityClassKubernetes 在初始化的时候就自带了两个 PriorityClasses 1234[root@k8s01 ~]# kubectl get priorityclassNAME VALUE GLOBAL-DEFAULT AGEsystem-cluster-critical 2000000000 false 24dsystem-node-critical 2000001000 false 24d 这是两个公共的优先级类，主要用来确保 Kubernetes 系统的关键组件或者关键插件总是能够优先被调度，比如 coredns 等。 我们在定义这样一个 PriorityClass 对象的时候，名字不可以包含 system- 这个前缀。且不能高于这里的 HighestUserDefinablePriority 的， 即 1000000000 （10 亿）。1234// HighestUserDefinablePriority is the highest priority for user defined priority classes. Priority values larger than 1 billion are reserved for Kubernetes system use.HighestUserDefinablePriority = int32(1000000000)// SystemCriticalPriority is the beginning of the range of priority values for critical system components.SystemCriticalPriority = 2 * HighestUserDefinablePriority 自定义PriorityClass high-priority.yaml1234567apiVersion: scheduling.k8s.io/v1 # 使用的 API 版本是 scheduling.k8s.io/v1。这个对象是个集群级别的定义，并不属于任何 namespace，可以被全局使用kind: PriorityClassmetadata: name: high-priorityvalue: 1000000globalDefault: false # 是否将该 PriorityClass 的数值作为默认值，并将其应用在所有未设置 priorityClassName 的 Pod 上(新增 Pod ，之前的存量pod优先级默认为 0). 整个 Kubernetes 集群中只能存在一个 globalDefault 设为 true 的 PriorityClass 对象。description: &quot;This priority class should be used for XYZ service pods only.&quot; low-priority.yaml123456apiVersion: scheduling.k8s.io/v1kind: PriorityClassmetadata: name: low-priorityvalue: 1000globalDefault: false 应用这两个优先级 123456789[root@k8s01 ~]# kubectl apply -f low-priority.yamlpriorityclass.scheduling.k8s.io/low-priority created[root@k8s01 ~]# kubectl apply -f high-priority.yamlpriorityclass.scheduling.k8s.io/high-priority created[root@k8s01 ~]# kubectl get priorityclass | grep -v systemNAME VALUE GLOBAL-DEFAULT AGEhigh-priority 1000000 false 69slow-priority 1000 false 90s nginx-low-priority.yaml 1234567891011121314151617apiVersion: v1kind: Podmetadata: name: nginx-low-pcspec: containers: - name: nginx image: nginx:1.7.9 imagePullPolicy: IfNotPresent resources: requests: memory: &quot;64Mi&quot; cpu: &quot;2400m&quot; # 因为是4核，总数 4000, 2400 超过 4000 一半 limits: memory: &quot;128Mi&quot; cpu: &quot;2500m&quot; priorityClassName: low-priority #使用低优先级 nginx-high-priority.yaml 1234567891011121314151617apiVersion: v1kind: Podmetadata: name: nginx-high-pcspec: containers: - name: nginx image: nginx:1.7.9 imagePullPolicy: IfNotPresent resources: requests: memory: &quot;64Mi&quot; cpu: &quot;2400m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;2500m&quot; priorityClassName: high-priority #使用高优先级 应用上面两个 pod 12345678910111213141516171819202122[root@k8s01 ~]# cat /proc/cpuinfo | grep &apos;model name&apos; | wc -l4 # 4 核[root@k8s01 ~]# kubectl apply -f nginx-low-priority.yamlpod/nginx-low-pc created[root@k8s01 ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-low-pc 1/1 Running 0 4m33s[root@k8s01 ~]# kubectl apply -f nginx-high-priority.yamlpod/nginx-high-pc created# 调度器会尝试寻找一个节点，通过移除一个或者多个比该 Pod 的优先级低的 Pod， 尝试使目标 Pod 可以被调度。 (当前 k8s01，k8s03节点已设置不能被调度)# kubectl taint nodes k8s01 node-role.kubernetes.io/master=:NoSchedule# kubectl taint nodes k8s03 node-role.kubernetes.io/master=:NoSchedule[root@k8s01 ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-high-pc 0/1 Pending 0 7snginx-low-pc 0/1 Terminating 0 87s # 低优先级的被挤占[root@k8s01 ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-high-pc 1/1 Running 0 12s 非抢占式并不希望 Pod 被驱逐掉，只是希望可以优先调度 preemptionPolicy.yaml12345678apiVersion: scheduling.k8s.io/v1kind: PriorityClassmetadata: name: high-priority-nonpreemptingvalue: 1000000preemptionPolicy: Never globalDefault: falsedescription: &quot;This priority class will not cause other pods to be preempted.&quot; kube-scheduler 的抢占能力是通过 disablePreemption 这个参数来控制的，该标志默认为 false ( 不建议使用) 123456apiVersion: kubescheduler.config.k8s.io/v1alpha1kind: KubeSchedulerConfigurationalgorithmSource: provider: DefaultProvider...disablePreemption: true 集群管理员可以为特定用户创建特定优先级级别，来防止他们恶意使用高优先级的 PriorityClass。 补当 Pod 里的每一个 Container 都同时设置了 requests 和 limits，并且 requests 和 limits 值相等的时候(或者只有 limits )，这个 Pod 就属于 Guaranteed 类别 Pod 不满足 Guaranteed 的条件，但至少有一个 Container 设置了 requests。那么这个 Pod 就会被划分到 Burstable 类别 Pod 既没有设置 requests，也没有设置 limits，那么它的 QoS 类别就是 BestEffort QoS 划分的主要应用场景，是当宿主机资源紧张的时候，kubelet 对 Pod 进行 Eviction（即资源回收）时需要用到的。 默认值1234memory.available&lt;100Minodefs.available&lt;10%nodefs.inodesFree&lt;5%imagefs.available&lt;15% 可自行配置1kubelet --eviction-hard=imagefs.available&lt;10%,memory.available&lt;500Mi,nodefs.available&lt;5%,nodefs.inodesFree&lt;5% --eviction-soft=imagefs.available&lt;30%,nodefs.available&lt;10% --eviction-soft-grace-period=imagefs.available=2m,nodefs.available=2m --eviction-max-pod-grace-period=600 建议将 DaemonSet 的 Pod 都设置为 Guaranteed 的 QoS 类型。否则，一旦 DaemonSet 的 Pod 被回收，它又会立即在原宿主机上被重建出来，这就使得前面资源回收的动作，完全没有意义了]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s-高可用]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E4%B8%AD%E7%9A%84%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[Garbage Collector 即垃圾回收，通常简称 GC,在 Kubelet 中非常重要，它不仅可以清理无用的容器，还可以清理未使用的镜像以达到节省空间的目的。(清理的这些容器都是 Kubernetes 自己创建的容器) 主要分为镜像回收 和容器回收 配置文件 12345678910111213141516171819202122232425262728293031323334[root@k8s01 system]# find / |grep kubeadm/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/from_repo/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/reason/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/releasever/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/var_uuid/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/var_contentdir/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/var_infra/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/command_line/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/checksum_type/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/checksum_data/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/origin_url/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/from_repo_revision/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/from_repo_timestamp/var/lib/yum/yumdb/k/a447ee9308ee530f64582f36692a50045a987853-kubeadm-1.18.6-0-x86_64/installed_by/var/lib/kubelet/kubeadm-flags.env/usr/bin/kubeadm/usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf # 配置文件[root@k8s01 system]# cat /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf # 默认配置# Note: This dropin only works with kubeadm and kubelet v1.11+[Service]Environment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&quot;Environment=&quot;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&quot;# This is a file that &quot;kubeadm init&quot; and &quot;kubeadm join&quot; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamicallyEnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.EnvironmentFile=-/etc/sysconfig/kubeletExecStart=ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS ## 在这个后面附加参数# 生效# systemctl daemon-reload # systemctl restart kubelet 镜像回收 image-gc-high-threshold：磁盘使用率上限，有效范围 [0-100]，默认 85 image-gc-low-threshold：磁盘使用率下限，有效范围 [0-100]，默认 80 minimum-image-ttl-duration：镜像最短应该生存的年龄，默认 2 分钟 对镜像的 GC 操作，就是逐个删除最久最少使用（Least Recently Used）的镜像 容器回收--minimum-container-ttl-duration 表示已停止的容器在被清理之前最小的存活时间，默认值是 1 分钟，即容器停止超过 1 分钟才会被标记可被 GC 清理； --maximum-dead-containers-per-container 表示一个 Pod 内可以保留的已停止的容器数量，默认值是 2。Kubernetes 是以 Pod 为单位进行容器管理的。有时候 Pod 内运行失败的容器，比如容器自身的问题，或者健康检查失败，会被 kubelet 自动重启，这将产生一些停止的容器； --maximum-dead-containers 表示在本节点上可以保留的已停止容器的最大数量，默认值是240。毕竟这些容器也会消耗额外的磁盘空间，所以超过这个上限阈值后，就会触发 Kubelet 的 GC 操作，来帮你自动清理这些已停止的容器，释放磁盘空间。 关闭容器的 GC 操作，只需要将 --minimun-container-ttl-duration 设置为0，把 --maximum-dead-containers-per-container 和--maximum-dead-containers 都设置为负数即可。 在有些场景中，容器的日志需要保留在本地，如果直接清理掉这些容器会丢失日志。 强烈建议你将 --maximum-dead-containers-per-container 设置为一个足够大的值，以便每个容器至少有一个退出的实例]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker原理]]></title>
    <url>%2Fdocker%2Fdocker%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[容器技术原理容器，其实是一种特殊的进程而已。容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的 Docker 是利用 Linux 的 Namespace 、Cgroups 和联合文件系统三大机制来保证实现的， 所以它的原理是使用 Namespace 做主机名、网络、PID 等资源的隔离，使用 Cgroups 对进程或者进程组做资源（例如：CPU、内存等）的限制，联合文件系统用于镜像构建和容器运行环境. 一个“容器”，实际上是一个由 Linux Namespace、Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。 一个正在运行的 Linux 容器，其实可以被“一分为二”地看待： 一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs，这一部分我们称为“容器镜像”（Container Image），是容器的静态视图； 一个由 Namespace+Cgroups 构成的隔离环境，这一部分我们称为“容器运行时”（Container Runtime），是容器的动态视图。 rootfs 里面打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用和它运行所需要的所有依赖，都被封装在一起。 Namespace基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：隔离得不彻底。 Namespace 是 Linux 内核的一项功能，该功能对内核资源进行隔离，使得容器中的进程都可以在单独的命名空间中运行，并且只可以访问当前容器命名空间的资源。Namespace 可以隔离进程 ID、主机名、用户 ID、文件名、网络访问和进程间通信等相关资源。 Docker 主要用到以下五种命名空间。 pid namespace：用于隔离进程 ID。 net namespace：隔离网络接口，在虚拟的 net namespace 内用户可以拥有自己独立的 IP、路由、端口等。 mnt namespace：文件系统挂载点隔离。 ipc namespace：信号量,消息队列和共享内存的隔离。 uts namespace：主机名和域名的隔离 CgroupsCgroups 是一种 Linux 内核功能，可以限制和隔离进程的资源使用情况（CPU、内存、磁盘 I/O、网络等）。在容器的实现中，Cgroups 通常用来限制容器的 CPU 和内存等资源的使用。 cgroups 限制了固定几种资源的使用不会超限，但是它既不能隔离被共享的硬件比如 L3 cache,也不能有效地防止容器逃逸的问题123456789$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 100000 ## CPU period $ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 20000 ## 这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。 cgroup 可以实现资源的限制，但不能保证资源的使用 联合文件系统联合文件系统，又叫 UnionFS，是一种通过创建文件层进程操作的文件系统，因此，联合文件系统非常轻快。Docker 使用联合文件系统为容器提供构建层，使得容器可以实现写时复制以及镜像的分层构建和存储。常用的联合文件系统有 AUFS、Overlay 和 Devicemapper 等。 Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。容器镜像是只读的，如果要修改必须通过 copy-on-write机制把文件复制到只读层才行 我现在有两个目录 A 和 B，它们分别有两个文件： 123456789$ tree.├── A│ ├── a│ └── x└── B ├── b └── x 使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上： 12345678910$ mkdir C$ mount -t aufs -o dirs=./A:./B none ./C$ tree ./C./C├── a├── b└── x 对于 AuFS 来说，它最关键的目录结构在 /var/lib/docker 路径下的 diff 目录：/var/lib/docker/aufs/diff/&lt;layer_id&gt; Docker 重要组件 containerd : containerd通过 containerd-shim 启动并管理 runC，可以说containerd真正管理了容器的生命周期。 containerd-shim ctr docker docker-init docker-proxy dockerd runc : 是一个用来运行容器的轻量级工具，是真正用来运行容器的。]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s自动伸缩]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E8%87%AA%E5%8A%A8%E4%BC%B8%E7%BC%A9%2F</url>
    <content type="text"><![CDATA[HPAPod 水平自动伸缩（Horizontal Pod Autoscaler，HPA） 可以根据应用的 CPU 利用率, 内存占用率等 水位信息，动态地增加或者减少 Pod 副本数量。 使用 HPA 时，要提前部署好 metrics-server. (也可以直接使用 Custom Metrics 来执行用户指定的扩展策略，这里的整个过程都是非常灵活和可定制的。) 补Kubernetes 里的 Custom Metrics 机制，也是借助 Aggregator APIServer 扩展机制来实现的。这里的具体原理是，当你把 Custom Metrics APIServer 启动之后，Kubernetes 里就会出现一个叫作 custom.metrics.k8s.io 的 API。而当你访问这个 URL 时，Aggregator 就会把你的请求转发给 Custom Metrics APIServer 。（详细待补充）1234567891011121314151617181920212223242526272829303132333435363738wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.7/components.yaml （需要修改）[root@k8s01 ~]# kubectl apply -f components.yamlclusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader createdclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator createdrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader createdWarning: apiregistration.k8s.io/v1beta1 APIService is deprecated in v1.19+, unavailable in v1.22+; use apiregistration.k8s.io/v1 APIServiceapiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io createdserviceaccount/metrics-server createddeployment.apps/metrics-server createdservice/metrics-server createdclusterrole.rbac.authorization.k8s.io/system:metrics-server createdclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created[root@k8s01 ~]# kubectl get deploy -n kube-system metrics-serverNAME READY UP-TO-DATE AVAILABLE AGEmetrics-server 1/1 1 1 26s# 创建 deployment[root@k8s01 ~]# kubectl apply -f myapp-deploy-hpa.yamldeployment.apps/nginx-deployment created# 暴露服务[root@k8s01 ~]# kubectl expose deployment/myapp-deployment -n demoservice/myapp-deployment exposed[root@k8s01 ~]# kubectl get svc -n demoNAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdemo myapp-deployment ClusterIP 10.104.238.121 &lt;none&gt; 80/TCP 7s[root@k8s01 ~]# kubectl get endpoints -n demo # 获取endpoints 对象NAME ENDPOINTS AGEmyapp-deployment 10.104.238.121:80 20s# 创建 hpa[root@k8s01 ~]# kubectl autoscale deploy myapp-deployment -n demo --cpu-percent=50 --min=1 --max=10horizontalpodautoscaler.autoscaling/myapp-deployment autoscaled myapp-deploy-hpa.yaml1234567891011121314151617181920212223242526272829apiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deployment namespace: demospec: selector: matchLabels: app: myapp usage: hpa replicas: 1 template: metadata: labels: app: myapp usage: hpa spec: containers: - name: myapp image: imwl/myapp:v1 ports: - containerPort: 80 resources: requests: # 里我们把quota设置得小一点，方便做压力测试 memory: &quot;64Mi&quot; cpu: &quot;250m&quot; limits: memory: &quot;128Mi&quot; cpu: &quot;500m&quot; components.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: system:aggregated-metrics-reader labels: rbac.authorization.k8s.io/aggregate-to-view: &quot;true&quot; rbac.authorization.k8s.io/aggregate-to-edit: &quot;true&quot; rbac.authorization.k8s.io/aggregate-to-admin: &quot;true&quot;rules:- apiGroups: [&quot;metrics.k8s.io&quot;] resources: [&quot;pods&quot;, &quot;nodes&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: metrics-server:system:auth-delegatorroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:auth-delegatorsubjects:- kind: ServiceAccount name: metrics-server namespace: kube-system---apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: metrics-server-auth-reader namespace: kube-systemroleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: extension-apiserver-authentication-readersubjects:- kind: ServiceAccount name: metrics-server namespace: kube-system---apiVersion: apiregistration.k8s.io/v1beta1kind: APIServicemetadata: name: v1beta1.metrics.k8s.iospec: service: name: metrics-server namespace: kube-system group: metrics.k8s.io version: v1beta1 insecureSkipTLSVerify: true groupPriorityMinimum: 100 versionPriority: 100---apiVersion: v1kind: ServiceAccountmetadata: name: metrics-server namespace: kube-system---apiVersion: apps/v1kind: Deploymentmetadata: name: metrics-server namespace: kube-system labels: k8s-app: metrics-serverspec: selector: matchLabels: k8s-app: metrics-server template: metadata: name: metrics-server labels: k8s-app: metrics-server spec: serviceAccountName: metrics-server volumes: # mount in tmp so we can safely use from-scratch images and/or read-only containers - name: tmp-dir emptyDir: &#123;&#125; containers: - name: metrics-server image: imwl/metrics-server:v0.3.7 # 修改 imagePullPolicy: IfNotPresent args: - /metrics-server - --cert-dir=/tmp - --secure-port=4443 - --kubelet-insecure-tls ## 增加 - --kubelet-preferred-address-types=InternalDNS,InternalIP,ExternalDNS,ExternalIP,Hostname ## 增加 ports: - name: main-port containerPort: 4443 protocol: TCP securityContext: readOnlyRootFilesystem: true runAsNonRoot: true runAsUser: 1000 volumeMounts: - name: tmp-dir mountPath: /tmp nodeSelector: kubernetes.io/os: linux---apiVersion: v1kind: Servicemetadata: name: metrics-server namespace: kube-system labels: kubernetes.io/name: &quot;Metrics-server&quot; kubernetes.io/cluster-service: &quot;true&quot;spec: selector: k8s-app: metrics-server ports: - port: 443 protocol: TCP targetPort: main-port---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: system:metrics-serverrules:- apiGroups: - &quot;&quot; resources: - pods - nodes - nodes/stats - namespaces - configmaps verbs: - get - list - watch---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: system:metrics-serverroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:metrics-serversubjects:- kind: ServiceAccount name: metrics-server namespace: kube-system 验证 hpa开三个窗口 用压测工具ApacheBench 进行压力测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@k8s01 ~]# kubectl run demo-benchmark --image httpd:2.4.46-alpine -n demo -it shIf you don&apos;t see a command prompt, try pressing enter./usr/local/apache2 # ab -n 50000 -c 500 -s 60 http://10.104.238.121/This is ApacheBench, Version 2.3 &lt;$Revision: 1879490 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking 10.104.238.121 (be patient)Completed 5000 requestsCompleted 10000 requestsCompleted 15000 requestsCompleted 20000 requestsCompleted 25000 requestsCompleted 30000 requestsCompleted 35000 requestsCompleted 40000 requestsCompleted 45000 requestsCompleted 50000 requestsFinished 50000 requestsServer Software: nginx/1.12.2Server Hostname: 10.104.238.121Server Port: 80Document Path: /Document Length: 65 bytesConcurrency Level: 500Time taken for tests: 75.398 secondsComplete requests: 50000Failed requests: 0Total transferred: 14800000 bytesHTML transferred: 3250000 bytesRequests per second: 663.15 [#/sec] (mean)Time per request: 753.976 [ms] (mean)Time per request: 1.508 [ms] (mean, across all concurrent requests)Transfer rate: 191.69 [Kbytes/sec] receivedConnection Times (ms) min mean[+/-sd] median maxConnect: 0 741 478.4 1003 3013Processing: 0 7 24.2 1 1645Waiting: 0 7 24.1 1 1644Total: 0 748 471.2 1004 3214Percentage of the requests served within a certain time (ms) 50% 1004 66% 1004 75% 1005 80% 1005 90% 1006 95% 1006 98% 1008 99% 1013 100% 3214 (longest request)/usr/local/apache2 # hpa 的信息如下 12345678910[root@k8s01 ~]# kubectl get hpa -n demo -wNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGEmyapp-deployment Deployment/myapp-deployment 0%/50% 1 10 1 21mmyapp-deployment Deployment/myapp-deployment 72%/50% 1 10 1 21mmyapp-deployment Deployment/myapp-deployment 72%/50% 1 10 2 22mmyapp-deployment Deployment/myapp-deployment 64%/50% 1 10 2 22mmyapp-deployment Deployment/myapp-deployment 64%/50% 1 10 3 23mmyapp-deployment Deployment/myapp-deployment 0%/50% 1 10 3 23mmyapp-deployment Deployment/myapp-deployment 0%/50% 1 10 3 28mmyapp-deployment Deployment/myapp-deployment 0%/50% 1 10 1 28m deployment 信息如下 12345678910111213141516[root@k8s01 ~]# kubectl get deploy -n demo -wNAME READY UP-TO-DATE AVAILABLE AGEmyapp-deployment 1/1 1 1 1smyapp-deployment 1/2 1 1 3m43smyapp-deployment 1/2 1 1 3m43smyapp-deployment 1/2 1 1 3m43smyapp-deployment 1/2 2 1 3m43smyapp-deployment 2/2 2 2 4m4smyapp-deployment 2/3 2 2 4m44smyapp-deployment 2/3 2 2 4m44smyapp-deployment 2/3 2 2 4m44smyapp-deployment 2/3 3 2 4m44smyapp-deployment 3/3 3 3 4m46s # 很长一段时间才降下来，防止意外myapp-deployment 3/1 3 3 10mmyapp-deployment 3/1 3 3 10mmyapp-deployment 1/1 1 1 10m Cluster AutoscalerCA 主要用来监听（watch）集群中未被调度的 Pod （即 Pod 暂时由于某些调度策略、抑或资源不满足，导致无法被成功调度），然后确定是否可以通过增加节点资源来解决无法调度的问题。 如果可以的话，就会调用对应的 cloud provider 接口，向集群中增加新的节点。当然 CA 在创建新的节点资源前，也会尝试是否可以将正在运行的一部分 Pod “挤压”到某些节点上，从而让这些未被调度的 Pod 可以被调度，如果可行的话，CA 会将这些 Pod 进行驱逐 后续除了 HPA 和 CA 以外，还有 Vertical Pod Autoscaler (VPA)可以帮我们确定 Pod 中合适的 CPU 和 Memory 区间。在实际使用的时候，注意千万不要同时使用 HPA 和 VPA，以免造成异常。 使用 HPA 的时候，也尽量对 Deployment 这类对象进行操作，避免对 ReplicaSet 操作。毕竟 ReplicaSet 由 Deployment 管理着，一旦 Deployment 更新了，旧的 ReplicaSet 会被新的 ReplicaSet 替换掉。]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ansible安装k8s高可用集群(二进制)]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fansible%E5%AE%89%E8%A3%85k8s%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4(%E4%BA%8C%E8%BF%9B%E5%88%B6)%2F</url>
    <content type="text"><![CDATA[环境准备当前 192.168.43.10[1:3] 是 master 节点 ，192.168.43.10[4:5] 是 node 节点。每个节点都需要安装 python。1git clone https://github.com/itswl/kubeasz.git 修改 ansible 中 hosts 文件，修改后如下。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# &apos;etcd&apos; cluster should have odd member(s) (1,3,5,...)# variable &apos;NODE_NAME&apos; is the distinct name of a member in &apos;etcd&apos; cluster[etcd]192.168.43.101 NODE_NAME=etcd1192.168.43.102 NODE_NAME=etcd2192.168.43.103 NODE_NAME=etcd3192.168.43.104 NODE_NAME=etcd4192.168.43.105 NODE_NAME=etcd5# master node(s)[kube-master]192.168.43.101192.168.43.102192.168.43.103# work node(s)[kube-node]192.168.43.104192.168.43.105# [optional] harbor server, a private docker registry# &apos;NEW_INSTALL&apos;: &apos;yes&apos; to install a harbor server; &apos;no&apos; to integrate with existed one# &apos;SELF_SIGNED_CERT&apos;: &apos;no&apos; you need put files of certificates named harbor.pem and harbor-key.pem in directory &apos;down&apos;[harbor]192.168.43.102 HARBOR_DOMAIN=&quot;harbor.yourdomain.com&quot; NEW_INSTALL=no SELF_SIGNED_CERT=yes# [optional] loadbalance for accessing k8s from outside[ex-lb]#192.168.43.106 LB_ROLE=backup EX_APISERVER_VIP=192.168.43.100 EX_APISERVER_PORT=8443#192.168.43.107 LB_ROLE=backup EX_APISERVER_VIP=192.168.43.100 EX_APISERVER_PORT=8443#192.168.43.108 LB_ROLE=master EX_APISERVER_VIP=192.168.43.100 EX_APISERVER_PORT=8443# [optional] ntp server for the cluster[chrony]192.168.43.101[all:vars]# --------- Main Variables ---------------# Cluster container-runtime supported: docker, containerdCONTAINER_RUNTIME=&quot;docker&quot;# Network plugins supported: calico, flannel, kube-router, cilium, kube-ovnCLUSTER_NETWORK=&quot;flannel&quot;# Service proxy mode of kube-proxy: &apos;iptables&apos; or &apos;ipvs&apos;PROXY_MODE=&quot;ipvs&quot;# K8S Service CIDR, not overlap with node(host) networkingSERVICE_CIDR=&quot;10.68.0.0/16&quot;# Cluster CIDR (Pod CIDR), not overlap with node(host) networkingCLUSTER_CIDR=&quot;172.20.0.0/16&quot;# NodePort RangeNODE_PORT_RANGE=&quot;20000-40000&quot;# Cluster DNS DomainCLUSTER_DNS_DOMAIN=&quot;cluster.local.&quot;# -------- Additional Variables (don&apos;t change the default value right now) ---# Binaries Directorybin_dir=&quot;/opt/kube/bin&quot;# CA and other components cert/key Directoryca_dir=&quot;/etc/kubernetes/ssl&quot;# Deploy Directory (kubeasz workspace)base_dir=&quot;/etc/ansible&quot; 安装执行以下命令123456789101112131415# 分步安装ansible-playbook 01.prepare.ymlansible-playbook 02.etcd.ymlansible-playbook 03.docker.ymlansible-playbook 04.kube-master.ymlansible-playbook 05.kube-node.ymlansible-playbook 06.network.ymlansible-playbook 07.cluster-addon.yml# 一步安装#ansible-playbook 90.setup.yml[可选]对集群所有节点进行操作系统层面的安全加固 ansible-playbook roles/os-harden/os-harden.yml 详情请参考os-harden项目 https://github.com/dev-sec/ansible-os-hardening# 卸载ansible-playbook 99.clean.yml 遇到问题，定位查日志等解决 安装完成后12345678910111213141516171819202122232425[root@k8s01 ansible]# kubectl get nodeNAME STATUS ROLES AGE VERSION192.168.43.101 Ready,SchedulingDisabled master 2m17s v1.18.3192.168.43.102 Ready,SchedulingDisabled master 2m18s v1.18.3192.168.43.103 Ready,SchedulingDisabled master 2m18s v1.18.3192.168.43.104 Ready node 97s v1.18.3192.168.43.105 Ready node 96s v1.18.3[root@k8s01 ansible]# kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-65dbdb44db-d7tpb 1/1 Running 0 62skube-system dashboard-metrics-scraper-545bbb8767-zpmfw 1/1 Running 0 43skube-system kube-flannel-ds-amd64-7f45j 1/1 Running 0 83skube-system kube-flannel-ds-amd64-hp74d 1/1 Running 0 83skube-system kube-flannel-ds-amd64-lfnqc 1/1 Running 0 83skube-system kube-flannel-ds-amd64-wcpgm 1/1 Running 0 83skube-system kube-flannel-ds-amd64-zqgk4 1/1 Running 0 83skube-system kubernetes-dashboard-65665f84db-h5tzk 1/1 Running 0 43skube-system metrics-server-869ffc99cd-8l9lk 1/1 Running 0 59s[root@k8s01 ansible]# kubectl get svc --all-namespacesNAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEdefault kubernetes ClusterIP 10.68.0.1 &lt;none&gt; 443/TCP 22mkube-system dashboard-metrics-scraper ClusterIP 10.68.99.51 &lt;none&gt; 8000/TCP 19mkube-system kube-dns ClusterIP 10.68.0.2 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 20mkube-system kubernetes-dashboard NodePort 10.68.78.245 &lt;none&gt; 443:39370/TCP 19mkube-system metrics-server ClusterIP 10.68.252.186 &lt;none&gt; 443/TCP 20m 安装记录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245[root@k8s01 ansible]# ansible-playbook 90.setup.yml[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see detailsPLAY [kube-master,kube-node,etcd,ex-lb,chrony] ******************************************************************************************************************TASK [Gathering Facts] ******************************************************************************************************************************************ok: [192.168.43.105]ok: [192.168.43.104]ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.101]TASK [chrony : yum 卸载 ntp] **************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.103]changed: [192.168.43.102]changed: [192.168.43.101]TASK [安装 chrony] ************************************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.105]ok: [192.168.43.101]ok: [192.168.43.103]ok: [192.168.43.102]TASK [配置 chrony server] *****************************************************************************************************************************************ok: [192.168.43.101]TASK [启动 chrony server] *****************************************************************************************************************************************changed: [192.168.43.101]TASK [配置 chrony client] *****************************************************************************************************************************************ok: [192.168.43.102]ok: [192.168.43.104]ok: [192.168.43.103]ok: [192.168.43.105]TASK [启动 chrony client] *****************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.102]changed: [192.168.43.105]changed: [192.168.43.103]PLAY [localhost] ************************************************************************************************************************************************TASK [Gathering Facts] ******************************************************************************************************************************************ok: [localhost]TASK [deploy : prepare some dirs] *******************************************************************************************************************************ok: [localhost] =&gt; (item=/etc/ansible/.cluster/ssl)ok: [localhost] =&gt; (item=/etc/ansible/.cluster/backup)TASK [deploy : 本地设置 bin 目录权限] ***********************************************************************************************************************************ok: [localhost]TASK [deploy : 读取ca证书stat信息] ************************************************************************************************************************************ok: [localhost]TASK [deploy : 删除原有kubeconfig] **********************************************************************************************************************************ok: [localhost]TASK [deploy : 准备kubectl使用的admin证书签名请求] *************************************************************************************************************************ok: [localhost]TASK [deploy : 创建admin证书与私钥] ************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置集群参数] ******************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置客户端认证参数] ***************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置上下文参数] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 选择默认上下文] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 准备kube-proxy 证书签名请求] *****************************************************************************************************************************ok: [localhost]TASK [deploy : 创建 kube-proxy证书与私钥] ******************************************************************************************************************************changed: [localhost]TASK [deploy : 设置集群参数] ******************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置客户端认证参数] ***************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置上下文参数] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 选择默认上下文] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 准备kube-controller-manager 证书签名请求] ****************************************************************************************************************ok: [localhost]TASK [deploy : 创建 kube-controller-manager证书与私钥] *****************************************************************************************************************changed: [localhost]TASK [deploy : 设置集群参数] ******************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置认证参数] ******************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置上下文参数] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 选择默认上下文] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 准备kube-scheduler 证书签名请求] *************************************************************************************************************************ok: [localhost]TASK [deploy : 创建 kube-scheduler证书与私钥] **************************************************************************************************************************changed: [localhost]TASK [deploy : 设置集群参数] ******************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置认证参数] ******************************************************************************************************************************************changed: [localhost]TASK [deploy : 设置上下文参数] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 选择默认上下文] *****************************************************************************************************************************************changed: [localhost]TASK [deploy : 本地创建 easzctl 工具的软连接] *****************************************************************************************************************************ok: [localhost]TASK [deploy : ansible 控制端创建 kubectl 软链接] ***********************************************************************************************************************ok: [localhost]TASK [deploy : 注册变量以判断是否容器化运行ansible控制端] ************************************************************************************************************************changed: [localhost]TASK [deploy : ansible 控制端写入环境变量$PATH] **************************************************************************************************************************changed: [localhost]TASK [deploy : ansible 控制端添加 kubectl 自动补全] **********************************************************************************************************************changed: [localhost]TASK [deploy : pip install netaddr] *****************************************************************************************************************************ok: [localhost]PLAY [kube-master,kube-node,etcd] *******************************************************************************************************************************TASK [prepare : 删除centos/redhat默认安装] ****************************************************************************************************************************changed: [192.168.43.105] =&gt; (item=firewalld)changed: [192.168.43.104] =&gt; (item=firewalld)changed: [192.168.43.102] =&gt; (item=firewalld)changed: [192.168.43.103] =&gt; (item=firewalld)changed: [192.168.43.101] =&gt; (item=firewalld)changed: [192.168.43.105] =&gt; (item=python-firewall)changed: [192.168.43.104] =&gt; (item=python-firewall)changed: [192.168.43.102] =&gt; (item=python-firewall)changed: [192.168.43.103] =&gt; (item=python-firewall)changed: [192.168.43.101] =&gt; (item=python-firewall)changed: [192.168.43.105] =&gt; (item=firewalld-filesystem)changed: [192.168.43.104] =&gt; (item=firewalld-filesystem)changed: [192.168.43.102] =&gt; (item=firewalld-filesystem)changed: [192.168.43.103] =&gt; (item=firewalld-filesystem)changed: [192.168.43.101] =&gt; (item=firewalld-filesystem)TASK [prepare : 安装基础软件包] ****************************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 临时关闭 selinux] ***********************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.101]TASK [prepare : 永久关闭 selinux] ***********************************************************************************************************************************ok: [192.168.43.102]ok: [192.168.43.104]ok: [192.168.43.103]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 禁止rsyslog获取journald日志1] *************************************************************************************************************************ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.104]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 禁止rsyslog获取journald日志2] *************************************************************************************************************************ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.104]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 重启rsyslog服务] ************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.105]changed: [192.168.43.104]changed: [192.168.43.103]changed: [192.168.43.101]TASK [prepare : 禁用系统 swap] **************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.101]TASK [prepare : 删除fstab swap 相关配置] ******************************************************************************************************************************ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.104]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 转换内核版本为浮点数] *************************************************************************************************************************************ok: [192.168.43.101]ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.104]ok: [192.168.43.105]TASK [prepare : 设置 nf_conntrack_ipv4 模块名] ***********************************************************************************************************************ok: [192.168.43.101]ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.104]ok: [192.168.43.105]TASK [prepare : 加载内核模块] *****************************************************************************************************************************************ok: [192.168.43.105] =&gt; (item=br_netfilter)ok: [192.168.43.104] =&gt; (item=br_netfilter)ok: [192.168.43.103] =&gt; (item=br_netfilter)ok: [192.168.43.102] =&gt; (item=br_netfilter)ok: [192.168.43.101] =&gt; (item=br_netfilter)ok: [192.168.43.104] =&gt; (item=ip_vs)ok: [192.168.43.105] =&gt; (item=ip_vs)ok: [192.168.43.103] =&gt; (item=ip_vs)ok: [192.168.43.102] =&gt; (item=ip_vs)ok: [192.168.43.104] =&gt; (item=ip_vs_rr)ok: [192.168.43.105] =&gt; (item=ip_vs_rr)ok: [192.168.43.103] =&gt; (item=ip_vs_rr)ok: [192.168.43.102] =&gt; (item=ip_vs_rr)ok: [192.168.43.105] =&gt; (item=ip_vs_wrr)ok: [192.168.43.101] =&gt; (item=ip_vs)ok: [192.168.43.104] =&gt; (item=ip_vs_wrr)ok: [192.168.43.103] =&gt; (item=ip_vs_wrr)ok: [192.168.43.102] =&gt; (item=ip_vs_wrr)ok: [192.168.43.105] =&gt; (item=ip_vs_sh)ok: [192.168.43.104] =&gt; (item=ip_vs_sh)ok: [192.168.43.102] =&gt; (item=ip_vs_sh)ok: [192.168.43.103] =&gt; (item=ip_vs_sh)ok: [192.168.43.101] =&gt; (item=ip_vs_rr)ok: [192.168.43.105] =&gt; (item=nf_conntrack_ipv4)ok: [192.168.43.104] =&gt; (item=nf_conntrack_ipv4)ok: [192.168.43.102] =&gt; (item=nf_conntrack_ipv4)ok: [192.168.43.103] =&gt; (item=nf_conntrack_ipv4)ok: [192.168.43.101] =&gt; (item=ip_vs_wrr)ok: [192.168.43.101] =&gt; (item=ip_vs_sh)ok: [192.168.43.101] =&gt; (item=nf_conntrack_ipv4)TASK [prepare : 启用systemd自动加载模块服务] ******************************************************************************************************************************ok: [192.168.43.103]ok: [192.168.43.104]ok: [192.168.43.102]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 增加内核模块开机加载配置] ***********************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.102]ok: [192.168.43.105]ok: [192.168.43.103]ok: [192.168.43.101]TASK [prepare : 设置系统参数] *****************************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 生效系统参数] *****************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.104]changed: [192.168.43.103]changed: [192.168.43.105]changed: [192.168.43.101]TASK [prepare : 创建 systemd 配置目录] ********************************************************************************************************************************ok: [192.168.43.102]ok: [192.168.43.104]ok: [192.168.43.103]ok: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 设置系统 ulimits] ***********************************************************************************************************************************ok: [192.168.43.105]ok: [192.168.43.104]ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.101]TASK [prepare : 把SCTP列入内核模块黑名单] *********************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.102]ok: [192.168.43.105]ok: [192.168.43.103]ok: [192.168.43.101]TASK [prepare some dirs] ****************************************************************************************************************************************ok: [192.168.43.102] =&gt; (item=/opt/kube/bin)ok: [192.168.43.103] =&gt; (item=/opt/kube/bin)ok: [192.168.43.104] =&gt; (item=/opt/kube/bin)ok: [192.168.43.105] =&gt; (item=/opt/kube/bin)ok: [192.168.43.101] =&gt; (item=/opt/kube/bin)changed: [192.168.43.102] =&gt; (item=/etc/kubernetes/ssl)changed: [192.168.43.103] =&gt; (item=/etc/kubernetes/ssl)changed: [192.168.43.104] =&gt; (item=/etc/kubernetes/ssl)changed: [192.168.43.105] =&gt; (item=/etc/kubernetes/ssl)ok: [192.168.43.102] =&gt; (item=/root/.kube)ok: [192.168.43.105] =&gt; (item=/root/.kube)ok: [192.168.43.104] =&gt; (item=/root/.kube)ok: [192.168.43.103] =&gt; (item=/root/.kube)changed: [192.168.43.101] =&gt; (item=/etc/kubernetes/ssl)ok: [192.168.43.101] =&gt; (item=/root/.kube)TASK [prepare : 分发证书工具 CFSSL] ***********************************************************************************************************************************ok: [192.168.43.104] =&gt; (item=cfssl)ok: [192.168.43.102] =&gt; (item=cfssl)ok: [192.168.43.103] =&gt; (item=cfssl)ok: [192.168.43.105] =&gt; (item=cfssl)ok: [192.168.43.105] =&gt; (item=cfssl-certinfo)ok: [192.168.43.101] =&gt; (item=cfssl)ok: [192.168.43.104] =&gt; (item=cfssl-certinfo)ok: [192.168.43.102] =&gt; (item=cfssl-certinfo)ok: [192.168.43.103] =&gt; (item=cfssl-certinfo)ok: [192.168.43.104] =&gt; (item=cfssljson)ok: [192.168.43.105] =&gt; (item=cfssljson)ok: [192.168.43.102] =&gt; (item=cfssljson)ok: [192.168.43.103] =&gt; (item=cfssljson)ok: [192.168.43.101] =&gt; (item=cfssl-certinfo)ok: [192.168.43.101] =&gt; (item=cfssljson)TASK [prepare : 写入环境变量$PATH] ************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.101]TASK [prepare : 分发证书相关] *****************************************************************************************************************************************changed: [192.168.43.104] =&gt; (item=admin.pem)changed: [192.168.43.102] =&gt; (item=admin.pem)changed: [192.168.43.105] =&gt; (item=admin.pem)changed: [192.168.43.103] =&gt; (item=admin.pem)changed: [192.168.43.104] =&gt; (item=admin-key.pem)changed: [192.168.43.105] =&gt; (item=admin-key.pem)changed: [192.168.43.102] =&gt; (item=admin-key.pem)changed: [192.168.43.103] =&gt; (item=admin-key.pem)changed: [192.168.43.101] =&gt; (item=admin.pem)changed: [192.168.43.104] =&gt; (item=ca.pem)changed: [192.168.43.105] =&gt; (item=ca.pem)changed: [192.168.43.102] =&gt; (item=ca.pem)changed: [192.168.43.103] =&gt; (item=ca.pem)changed: [192.168.43.104] =&gt; (item=ca-key.pem)changed: [192.168.43.105] =&gt; (item=ca-key.pem)changed: [192.168.43.102] =&gt; (item=ca-key.pem)changed: [192.168.43.103] =&gt; (item=ca-key.pem)changed: [192.168.43.104] =&gt; (item=ca-config.json)changed: [192.168.43.105] =&gt; (item=ca-config.json)changed: [192.168.43.102] =&gt; (item=ca-config.json)changed: [192.168.43.103] =&gt; (item=ca-config.json)changed: [192.168.43.101] =&gt; (item=admin-key.pem)changed: [192.168.43.101] =&gt; (item=ca.pem)changed: [192.168.43.101] =&gt; (item=ca-key.pem)changed: [192.168.43.101] =&gt; (item=ca-config.json)TASK [prepare : 添加 kubectl 命令自动补全] ******************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.104]changed: [192.168.43.105]ok: [192.168.43.101]TASK [prepare : 分发 kubeconfig配置文件] ******************************************************************************************************************************ok: [192.168.43.101]changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.102]changed: [192.168.43.103]TASK [prepare : 分发 kube-proxy.kubeconfig配置文件] *******************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [prepare : 分发 kube-controller-manager.kubeconfig配置文件] ******************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [prepare : 分发 kube-scheduler.kubeconfig配置文件] ***************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]PLAY [etcd] *****************************************************************************************************************************************************TASK [etcd : prepare some dirs] *********************************************************************************************************************************ok: [192.168.43.101] =&gt; (item=/opt/kube/bin)ok: [192.168.43.102] =&gt; (item=/opt/kube/bin)ok: [192.168.43.104] =&gt; (item=/opt/kube/bin)ok: [192.168.43.103] =&gt; (item=/opt/kube/bin)ok: [192.168.43.105] =&gt; (item=/opt/kube/bin)ok: [192.168.43.104] =&gt; (item=/etc/kubernetes/ssl)ok: [192.168.43.101] =&gt; (item=/etc/kubernetes/ssl)ok: [192.168.43.102] =&gt; (item=/etc/kubernetes/ssl)ok: [192.168.43.103] =&gt; (item=/etc/kubernetes/ssl)ok: [192.168.43.105] =&gt; (item=/etc/kubernetes/ssl)changed: [192.168.43.104] =&gt; (item=/etc/etcd/ssl)changed: [192.168.43.102] =&gt; (item=/etc/etcd/ssl)changed: [192.168.43.101] =&gt; (item=/etc/etcd/ssl)changed: [192.168.43.105] =&gt; (item=/etc/etcd/ssl)changed: [192.168.43.103] =&gt; (item=/etc/etcd/ssl)changed: [192.168.43.104] =&gt; (item=/var/lib/etcd)changed: [192.168.43.102] =&gt; (item=/var/lib/etcd)changed: [192.168.43.105] =&gt; (item=/var/lib/etcd)changed: [192.168.43.101] =&gt; (item=/var/lib/etcd)changed: [192.168.43.103] =&gt; (item=/var/lib/etcd)TASK [下载etcd二进制文件] **********************************************************************************************************************************************ok: [192.168.43.104] =&gt; (item=etcd)ok: [192.168.43.105] =&gt; (item=etcd)ok: [192.168.43.102] =&gt; (item=etcd)ok: [192.168.43.103] =&gt; (item=etcd)ok: [192.168.43.101] =&gt; (item=etcd)ok: [192.168.43.105] =&gt; (item=etcdctl)ok: [192.168.43.104] =&gt; (item=etcdctl)ok: [192.168.43.103] =&gt; (item=etcdctl)ok: [192.168.43.102] =&gt; (item=etcdctl)ok: [192.168.43.101] =&gt; (item=etcdctl)TASK [etcd : 分发证书相关] ********************************************************************************************************************************************ok: [192.168.43.101] =&gt; (item=ca.pem)ok: [192.168.43.104] =&gt; (item=ca.pem)ok: [192.168.43.103] =&gt; (item=ca.pem)ok: [192.168.43.102] =&gt; (item=ca.pem)ok: [192.168.43.105] =&gt; (item=ca.pem)ok: [192.168.43.104] =&gt; (item=ca-key.pem)ok: [192.168.43.105] =&gt; (item=ca-key.pem)ok: [192.168.43.102] =&gt; (item=ca-key.pem)ok: [192.168.43.101] =&gt; (item=ca-key.pem)ok: [192.168.43.103] =&gt; (item=ca-key.pem)ok: [192.168.43.104] =&gt; (item=ca-config.json)ok: [192.168.43.105] =&gt; (item=ca-config.json)ok: [192.168.43.103] =&gt; (item=ca-config.json)ok: [192.168.43.102] =&gt; (item=ca-config.json)ok: [192.168.43.101] =&gt; (item=ca-config.json)TASK [创建etcd证书请求] ***********************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.101]changed: [192.168.43.103]changed: [192.168.43.102]TASK [创建 etcd证书和私钥] *********************************************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [创建etcd的systemd unit文件] ************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [开机启用etcd服务] ***********************************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.104]changed: [192.168.43.103]changed: [192.168.43.105]TASK [开启etcd服务] *************************************************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [etcd : 以轮询的方式等待服务同步完成] ************************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.105]changed: [192.168.43.104]PLAY [kube-master,kube-node] ************************************************************************************************************************************TASK [获取是否已经安装docker] *******************************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.104]changed: [192.168.43.102]changed: [192.168.43.105]changed: [192.168.43.103]TASK [docker : 获取是否已经安装containerd] ******************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.104]changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.105]TASK [获取docker版本信息] *********************************************************************************************************************************************changed: [192.168.43.101]TASK [转换docker版本信息为浮点数] *****************************************************************************************************************************************ok: [192.168.43.101]ok: [192.168.43.102]ok: [192.168.43.103]ok: [192.168.43.104]ok: [192.168.43.105]TASK [docker : debug info] **************************************************************************************************************************************ok: [192.168.43.101] =&gt; &#123; &quot;DOCKER_VER&quot;: &quot;19.03&quot;&#125;ok: [192.168.43.102] =&gt; &#123; &quot;DOCKER_VER&quot;: &quot;19.03&quot;&#125;ok: [192.168.43.103] =&gt; &#123; &quot;DOCKER_VER&quot;: &quot;19.03&quot;&#125;ok: [192.168.43.104] =&gt; &#123; &quot;DOCKER_VER&quot;: &quot;19.03&quot;&#125;ok: [192.168.43.105] =&gt; &#123; &quot;DOCKER_VER&quot;: &quot;19.03&quot;&#125;TASK [准备docker相关目录] *********************************************************************************************************************************************ok: [192.168.43.101] =&gt; (item=/opt/kube/bin)ok: [192.168.43.103] =&gt; (item=/opt/kube/bin)ok: [192.168.43.104] =&gt; (item=/opt/kube/bin)ok: [192.168.43.102] =&gt; (item=/opt/kube/bin)ok: [192.168.43.105] =&gt; (item=/opt/kube/bin)changed: [192.168.43.101] =&gt; (item=/etc/docker)changed: [192.168.43.104] =&gt; (item=/etc/docker)changed: [192.168.43.105] =&gt; (item=/etc/docker)changed: [192.168.43.103] =&gt; (item=/etc/docker)changed: [192.168.43.102] =&gt; (item=/etc/docker)TASK [下载 docker 二进制文件(&gt;= 18.09.x)] ******************************************************************************************************************************ok: [192.168.43.104] =&gt; (item=containerd)ok: [192.168.43.105] =&gt; (item=containerd)ok: [192.168.43.102] =&gt; (item=containerd)ok: [192.168.43.101] =&gt; (item=containerd)ok: [192.168.43.103] =&gt; (item=containerd)ok: [192.168.43.105] =&gt; (item=containerd-shim)ok: [192.168.43.104] =&gt; (item=containerd-shim)ok: [192.168.43.102] =&gt; (item=containerd-shim)ok: [192.168.43.103] =&gt; (item=containerd-shim)ok: [192.168.43.101] =&gt; (item=containerd-shim)ok: [192.168.43.104] =&gt; (item=docker-init)ok: [192.168.43.105] =&gt; (item=docker-init)ok: [192.168.43.103] =&gt; (item=docker-init)ok: [192.168.43.102] =&gt; (item=docker-init)ok: [192.168.43.101] =&gt; (item=docker-init)ok: [192.168.43.104] =&gt; (item=runc)ok: [192.168.43.105] =&gt; (item=runc)ok: [192.168.43.102] =&gt; (item=runc)ok: [192.168.43.103] =&gt; (item=runc)ok: [192.168.43.101] =&gt; (item=runc)ok: [192.168.43.105] =&gt; (item=docker)ok: [192.168.43.103] =&gt; (item=docker)ok: [192.168.43.104] =&gt; (item=docker)ok: [192.168.43.102] =&gt; (item=docker)ok: [192.168.43.101] =&gt; (item=docker)ok: [192.168.43.104] =&gt; (item=ctr)ok: [192.168.43.105] =&gt; (item=ctr)ok: [192.168.43.102] =&gt; (item=ctr)ok: [192.168.43.103] =&gt; (item=ctr)ok: [192.168.43.101] =&gt; (item=ctr)ok: [192.168.43.104] =&gt; (item=dockerd)ok: [192.168.43.105] =&gt; (item=dockerd)ok: [192.168.43.103] =&gt; (item=dockerd)ok: [192.168.43.102] =&gt; (item=dockerd)ok: [192.168.43.101] =&gt; (item=dockerd)ok: [192.168.43.104] =&gt; (item=docker-proxy)ok: [192.168.43.105] =&gt; (item=docker-proxy)ok: [192.168.43.102] =&gt; (item=docker-proxy)ok: [192.168.43.103] =&gt; (item=docker-proxy)ok: [192.168.43.101] =&gt; (item=docker-proxy)TASK [docker命令自动补全] *********************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [docker国内镜像加速] *********************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [docker : flush-iptables] **********************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.103]TASK [创建docker的systemd unit文件] **********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [开机启用docker 服务] ********************************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.105]changed: [192.168.43.104]TASK [开启docker 服务] **********************************************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]changed: [192.168.43.103]changed: [192.168.43.102]changed: [192.168.43.101]TASK [轮询等待docker服务运行] *******************************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.103]TASK [配置 docker 命令软链接] ******************************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.104]changed: [192.168.43.103]changed: [192.168.43.105]TASK [下载 docker-tag] ********************************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.105]ok: [192.168.43.102]ok: [192.168.43.101]ok: [192.168.43.103]PLAY [kube-master] **********************************************************************************************************************************************TASK [下载 kube-master 二进制] ***************************************************************************************************************************************ok: [192.168.43.102] =&gt; (item=kube-apiserver)ok: [192.168.43.103] =&gt; (item=kube-apiserver)ok: [192.168.43.101] =&gt; (item=kube-apiserver)ok: [192.168.43.102] =&gt; (item=kube-controller-manager)ok: [192.168.43.103] =&gt; (item=kube-controller-manager)ok: [192.168.43.101] =&gt; (item=kube-controller-manager)ok: [192.168.43.103] =&gt; (item=kube-scheduler)ok: [192.168.43.102] =&gt; (item=kube-scheduler)ok: [192.168.43.101] =&gt; (item=kube-scheduler)ok: [192.168.43.103] =&gt; (item=kubectl)ok: [192.168.43.102] =&gt; (item=kubectl)ok: [192.168.43.101] =&gt; (item=kubectl)TASK [kube-master : 创建 kubernetes 证书签名请求] ***********************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-master : 创建 kubernetes 证书和私钥] ************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [kube-master : 创建 aggregator proxy证书签名请求] ******************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [kube-master : 创建 aggregator-proxy证书和私钥] *******************************************************************************************************************changed: [192.168.43.103]changed: [192.168.43.101]changed: [192.168.43.102]TASK [kube-master : 替换 kubeconfig 的 apiserver 地址] ***************************************************************************************************************changed: [192.168.43.102] =&gt; (item=/root/.kube/config)ok: [192.168.43.101] =&gt; (item=/root/.kube/config)changed: [192.168.43.103] =&gt; (item=/root/.kube/config)changed: [192.168.43.102] =&gt; (item=/etc/kubernetes/kube-controller-manager.kubeconfig)ok: [192.168.43.101] =&gt; (item=/etc/kubernetes/kube-controller-manager.kubeconfig)changed: [192.168.43.103] =&gt; (item=/etc/kubernetes/kube-controller-manager.kubeconfig)ok: [192.168.43.101] =&gt; (item=/etc/kubernetes/kube-scheduler.kubeconfig)changed: [192.168.43.102] =&gt; (item=/etc/kubernetes/kube-scheduler.kubeconfig)changed: [192.168.43.103] =&gt; (item=/etc/kubernetes/kube-scheduler.kubeconfig)TASK [kube-master : 创建 master 服务的 systemd unit 文件] **************************************************************************************************************changed: [192.168.43.101] =&gt; (item=kube-apiserver.service)changed: [192.168.43.102] =&gt; (item=kube-apiserver.service)changed: [192.168.43.103] =&gt; (item=kube-apiserver.service)changed: [192.168.43.102] =&gt; (item=kube-controller-manager.service)changed: [192.168.43.101] =&gt; (item=kube-controller-manager.service)changed: [192.168.43.103] =&gt; (item=kube-controller-manager.service)changed: [192.168.43.102] =&gt; (item=kube-scheduler.service)changed: [192.168.43.101] =&gt; (item=kube-scheduler.service)changed: [192.168.43.103] =&gt; (item=kube-scheduler.service)TASK [kube-master : enable master 服务] ***************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [kube-master : 启动 master 服务] *******************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [kube-master : 以轮询的方式等待master服务启动完成] ***********************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [创建kube-node 相关目录] *****************************************************************************************************************************************changed: [192.168.43.101] =&gt; (item=/var/lib/kubelet)changed: [192.168.43.102] =&gt; (item=/var/lib/kubelet)changed: [192.168.43.103] =&gt; (item=/var/lib/kubelet)changed: [192.168.43.103] =&gt; (item=/var/lib/kube-proxy)changed: [192.168.43.101] =&gt; (item=/var/lib/kube-proxy)changed: [192.168.43.102] =&gt; (item=/var/lib/kube-proxy)changed: [192.168.43.101] =&gt; (item=/etc/cni/net.d)changed: [192.168.43.103] =&gt; (item=/etc/cni/net.d)changed: [192.168.43.102] =&gt; (item=/etc/cni/net.d)TASK [kube-node : 下载 kubelet,kube-proxy 二进制和基础 cni plugins] *****************************************************************************************************ok: [192.168.43.103] =&gt; (item=kubectl)ok: [192.168.43.102] =&gt; (item=kubectl)ok: [192.168.43.101] =&gt; (item=kubectl)ok: [192.168.43.101] =&gt; (item=kubelet)ok: [192.168.43.102] =&gt; (item=kubelet)ok: [192.168.43.103] =&gt; (item=kubelet)ok: [192.168.43.101] =&gt; (item=kube-proxy)ok: [192.168.43.102] =&gt; (item=kube-proxy)ok: [192.168.43.103] =&gt; (item=kube-proxy)ok: [192.168.43.102] =&gt; (item=bridge)ok: [192.168.43.103] =&gt; (item=bridge)ok: [192.168.43.101] =&gt; (item=bridge)ok: [192.168.43.102] =&gt; (item=host-local)ok: [192.168.43.103] =&gt; (item=host-local)ok: [192.168.43.101] =&gt; (item=host-local)ok: [192.168.43.102] =&gt; (item=loopback)ok: [192.168.43.103] =&gt; (item=loopback)ok: [192.168.43.101] =&gt; (item=loopback)TASK [kube-node : 替换 kubeconfig 的 apiserver 地址] *****************************************************************************************************************ok: [192.168.43.102]ok: [192.168.43.101]ok: [192.168.43.103]TASK [kube-node : 准备kubelet 证书签名请求] *****************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 创建 kubelet 证书与私钥] *****************************************************************************************************************************changed: [192.168.43.103]changed: [192.168.43.101]changed: [192.168.43.102]TASK [kube-node : 设置集群参数] ***************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 设置客户端认证参数] ************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 设置上下文参数] **************************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [kube-node : 选择默认上下文] **************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 准备 cni配置文件] ***********************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 注册变量 TMP_VER] *********************************************************************************************************************************changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]TASK [kube-node : 获取 kubernetes 主版本号] ***************************************************************************************************************************ok: [192.168.43.101]ok: [192.168.43.102]ok: [192.168.43.103]TASK [kube-node : debug info] ***********************************************************************************************************************************ok: [192.168.43.101] =&gt; &#123; &quot;KUBE_VER&quot;: &quot;1.18&quot;&#125;ok: [192.168.43.102] =&gt; &#123; &quot;KUBE_VER&quot;: &quot;1.18&quot;&#125;ok: [192.168.43.103] =&gt; &#123; &quot;KUBE_VER&quot;: &quot;1.18&quot;&#125;TASK [kube-node : 创建kubelet的配置文件] *******************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 创建kubelet的systemd unit文件] *********************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 开机启用kubelet 服务] *******************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 开启kubelet 服务] *********************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [kube-node : 替换 kube-proxy.kubeconfig 的 apiserver 地址] ******************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]ok: [192.168.43.101]TASK [kube-node : 创建kube-proxy 服务文件] ****************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [kube-node : 开机启用kube-proxy 服务] ****************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [kube-node : 开启kube-proxy 服务] ******************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [kube-node : 轮询等待kubelet启动] ********************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]FAILED - RETRYING: 轮询等待node达到Ready状态 (8 retries left).FAILED - RETRYING: 轮询等待node达到Ready状态 (8 retries left).FAILED - RETRYING: 轮询等待node达到Ready状态 (8 retries left).FAILED - RETRYING: 轮询等待node达到Ready状态 (7 retries left).TASK [kube-node : 轮询等待node达到Ready状态] ****************************************************************************************************************************changed: [192.168.43.103]FAILED - RETRYING: 轮询等待node达到Ready状态 (7 retries left).changed: [192.168.43.102]changed: [192.168.43.101]TASK [kube-node : 设置node节点role] *********************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]TASK [Making master nodes SchedulingDisabled] *******************************************************************************************************************changed: [192.168.43.103]changed: [192.168.43.102]changed: [192.168.43.101]TASK [Setting master role name] *********************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]PLAY [kube-node] ************************************************************************************************************************************************TASK [创建kube-node 相关目录] *****************************************************************************************************************************************changed: [192.168.43.104] =&gt; (item=/var/lib/kubelet)changed: [192.168.43.105] =&gt; (item=/var/lib/kubelet)changed: [192.168.43.104] =&gt; (item=/var/lib/kube-proxy)changed: [192.168.43.105] =&gt; (item=/var/lib/kube-proxy)changed: [192.168.43.104] =&gt; (item=/etc/cni/net.d)changed: [192.168.43.105] =&gt; (item=/etc/cni/net.d)TASK [kube-node : 下载 kubelet,kube-proxy 二进制和基础 cni plugins] *****************************************************************************************************ok: [192.168.43.104] =&gt; (item=kubectl)ok: [192.168.43.105] =&gt; (item=kubectl)ok: [192.168.43.104] =&gt; (item=kubelet)ok: [192.168.43.105] =&gt; (item=kubelet)ok: [192.168.43.104] =&gt; (item=kube-proxy)ok: [192.168.43.105] =&gt; (item=kube-proxy)ok: [192.168.43.104] =&gt; (item=bridge)ok: [192.168.43.105] =&gt; (item=bridge)ok: [192.168.43.104] =&gt; (item=host-local)ok: [192.168.43.105] =&gt; (item=host-local)ok: [192.168.43.104] =&gt; (item=loopback)ok: [192.168.43.105] =&gt; (item=loopback)TASK [kube-node : 安装 haproxy] ***********************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.105]TASK [kube-node : 创建haproxy配置目录] ********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 修改centos的haproxy.service] *********************************************************************************************************************ok: [192.168.43.105]ok: [192.168.43.104]TASK [kube-node : 配置 haproxy] ***********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : daemon-reload for haproxy.service] ************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 开机启用haproxy服务] ********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 停止haproxy服务] **********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 开启haproxy服务] **********************************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]TASK [kube-node : 替换 kubeconfig 的 apiserver 地址] *****************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 准备kubelet 证书签名请求] *****************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 创建 kubelet 证书与私钥] *****************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 设置集群参数] ***************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 设置客户端认证参数] ************************************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]TASK [kube-node : 设置上下文参数] **************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 选择默认上下文] **************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 准备 cni配置文件] ***********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 注册变量 TMP_VER] *********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 获取 kubernetes 主版本号] ***************************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.105]TASK [kube-node : debug info] ***********************************************************************************************************************************ok: [192.168.43.104] =&gt; &#123; &quot;KUBE_VER&quot;: &quot;1.18&quot;&#125;ok: [192.168.43.105] =&gt; &#123; &quot;KUBE_VER&quot;: &quot;1.18&quot;&#125;TASK [kube-node : 创建kubelet的配置文件] *******************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 创建kubelet的systemd unit文件] *********************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 开机启用kubelet 服务] *******************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 开启kubelet 服务] *********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 替换 kube-proxy.kubeconfig 的 apiserver 地址] ******************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 创建kube-proxy 服务文件] ****************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 开机启用kube-proxy 服务] ****************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 开启kube-proxy 服务] ******************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [kube-node : 轮询等待kubelet启动] ********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]FAILED - RETRYING: 轮询等待node达到Ready状态 (8 retries left).FAILED - RETRYING: 轮询等待node达到Ready状态 (8 retries left).FAILED - RETRYING: 轮询等待node达到Ready状态 (7 retries left).TASK [kube-node : 轮询等待node达到Ready状态] ****************************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]TASK [kube-node : 设置node节点role] *********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]PLAY [kube-master,kube-node] ************************************************************************************************************************************TASK [创建flannel 相关目录] *******************************************************************************************************************************************ok: [192.168.43.102] =&gt; (item=/etc/cni/net.d)ok: [192.168.43.103] =&gt; (item=/etc/cni/net.d)ok: [192.168.43.104] =&gt; (item=/etc/cni/net.d)ok: [192.168.43.101] =&gt; (item=/etc/cni/net.d)ok: [192.168.43.105] =&gt; (item=/etc/cni/net.d)ok: [192.168.43.102] =&gt; (item=/opt/kube/images)ok: [192.168.43.104] =&gt; (item=/opt/kube/images)ok: [192.168.43.103] =&gt; (item=/opt/kube/images)ok: [192.168.43.105] =&gt; (item=/opt/kube/images)ok: [192.168.43.101] =&gt; (item=/opt/kube/images)changed: [192.168.43.102] =&gt; (item=/opt/kube/kube-system)changed: [192.168.43.104] =&gt; (item=/opt/kube/kube-system)changed: [192.168.43.105] =&gt; (item=/opt/kube/kube-system)changed: [192.168.43.103] =&gt; (item=/opt/kube/kube-system)changed: [192.168.43.101] =&gt; (item=/opt/kube/kube-system)TASK [配置 flannel DaemonSet yaml文件] ******************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.101]TASK [下载flannel cni plugins] ************************************************************************************************************************************ok: [192.168.43.105] =&gt; (item=bridge)ok: [192.168.43.104] =&gt; (item=bridge)ok: [192.168.43.102] =&gt; (item=bridge)ok: [192.168.43.101] =&gt; (item=bridge)ok: [192.168.43.103] =&gt; (item=bridge)ok: [192.168.43.105] =&gt; (item=flannel)ok: [192.168.43.104] =&gt; (item=flannel)ok: [192.168.43.102] =&gt; (item=flannel)ok: [192.168.43.101] =&gt; (item=flannel)ok: [192.168.43.103] =&gt; (item=flannel)ok: [192.168.43.105] =&gt; (item=host-local)ok: [192.168.43.104] =&gt; (item=host-local)ok: [192.168.43.102] =&gt; (item=host-local)ok: [192.168.43.101] =&gt; (item=host-local)ok: [192.168.43.103] =&gt; (item=host-local)ok: [192.168.43.105] =&gt; (item=loopback)ok: [192.168.43.104] =&gt; (item=loopback)ok: [192.168.43.102] =&gt; (item=loopback)ok: [192.168.43.103] =&gt; (item=loopback)ok: [192.168.43.101] =&gt; (item=loopback)ok: [192.168.43.105] =&gt; (item=portmap)ok: [192.168.43.104] =&gt; (item=portmap)ok: [192.168.43.102] =&gt; (item=portmap)ok: [192.168.43.103] =&gt; (item=portmap)ok: [192.168.43.101] =&gt; (item=portmap)TASK [检查是否已下载离线flannel镜像] ***************************************************************************************************************************************changed: [192.168.43.101]TASK [flannel : 尝试推送离线docker 镜像（若执行失败，可忽略）] *********************************************************************************************************************ok: [192.168.43.104] =&gt; (item=pause.tar)ok: [192.168.43.102] =&gt; (item=pause.tar)ok: [192.168.43.105] =&gt; (item=pause.tar)ok: [192.168.43.101] =&gt; (item=pause.tar)ok: [192.168.43.103] =&gt; (item=pause.tar)ok: [192.168.43.104] =&gt; (item=flannel_v0.12.0-amd64.tar)ok: [192.168.43.102] =&gt; (item=flannel_v0.12.0-amd64.tar)ok: [192.168.43.105] =&gt; (item=flannel_v0.12.0-amd64.tar)ok: [192.168.43.103] =&gt; (item=flannel_v0.12.0-amd64.tar)ok: [192.168.43.101] =&gt; (item=flannel_v0.12.0-amd64.tar)TASK [获取flannel离线镜像推送情况] ****************************************************************************************************************************************changed: [192.168.43.102]changed: [192.168.43.101]changed: [192.168.43.103]changed: [192.168.43.104]changed: [192.168.43.105]TASK [导入 flannel的离线镜像（若执行失败，可忽略）] *******************************************************************************************************************************changed: [192.168.43.104] =&gt; (item=pause.tar)changed: [192.168.43.102] =&gt; (item=pause.tar)changed: [192.168.43.103] =&gt; (item=pause.tar)changed: [192.168.43.105] =&gt; (item=pause.tar)changed: [192.168.43.101] =&gt; (item=pause.tar)changed: [192.168.43.104] =&gt; (item=flannel_v0.12.0-amd64.tar)changed: [192.168.43.105] =&gt; (item=flannel_v0.12.0-amd64.tar)changed: [192.168.43.102] =&gt; (item=flannel_v0.12.0-amd64.tar)changed: [192.168.43.103] =&gt; (item=flannel_v0.12.0-amd64.tar)changed: [192.168.43.101] =&gt; (item=flannel_v0.12.0-amd64.tar)TASK [运行 flannel网络] *********************************************************************************************************************************************changed: [192.168.43.101]TASK [flannel : 删除默认cni配置] **************************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]changed: [192.168.43.101]changed: [192.168.43.103]changed: [192.168.43.102]FAILED - RETRYING: 轮询等待flannel 运行，视下载镜像速度而定 (15 retries left).FAILED - RETRYING: 轮询等待flannel 运行，视下载镜像速度而定 (15 retries left).FAILED - RETRYING: 轮询等待flannel 运行，视下载镜像速度而定 (15 retries left).FAILED - RETRYING: 轮询等待flannel 运行，视下载镜像速度而定 (15 retries left).FAILED - RETRYING: 轮询等待flannel 运行，视下载镜像速度而定 (15 retries left).TASK [轮询等待flannel 运行，视下载镜像速度而定] *********************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.101]changed: [192.168.43.102]changed: [192.168.43.103]changed: [192.168.43.105]PLAY [kube-node] ************************************************************************************************************************************************TASK [cluster-addon : 在 node 节点创建相关目录] **************************************************************************************************************************ok: [192.168.43.104] =&gt; (item=/opt/kube/kube-system)ok: [192.168.43.105] =&gt; (item=/opt/kube/kube-system)TASK [cluster-addon : 准备 DNS的部署文件] ******************************************************************************************************************************changed: [192.168.43.104] =&gt; (item=kubedns)changed: [192.168.43.105] =&gt; (item=kubedns)changed: [192.168.43.104] =&gt; (item=coredns)changed: [192.168.43.105] =&gt; (item=coredns)TASK [cluster-addon : 获取所有已经创建的POD信息] ***************************************************************************************************************************changed: [192.168.43.104]TASK [cluster-addon : 获取已下载离线镜像信息] ******************************************************************************************************************************changed: [192.168.43.104]TASK [cluster-addon : 尝试推送离线coredns镜像（若执行失败，可忽略）] ***************************************************************************************************************ok: [192.168.43.104]ok: [192.168.43.105]TASK [cluster-addon : 获取coredns离线镜像推送情况] ************************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [cluster-addon : 导入coredns的离线镜像（若执行失败，可忽略）] ****************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [cluster-addon : 创建coredns部署] ******************************************************************************************************************************changed: [192.168.43.104]TASK [cluster-addon : 尝试推送离线 metrics-server镜像（若执行失败，可忽略）] *******************************************************************************************************ok: [192.168.43.105]ok: [192.168.43.104]TASK [cluster-addon : 获取metrics-server离线镜像推送情况] *****************************************************************************************************************changed: [192.168.43.105]changed: [192.168.43.104]TASK [cluster-addon : 导入 metrics-server的离线镜像（若执行失败，可忽略）] ********************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [cluster-addon : 创建 metrics-server部署] **********************************************************************************************************************changed: [192.168.43.104]TASK [cluster-addon : 尝试推送离线 dashboard 镜像（若执行失败，可忽略）] ***********************************************************************************************************ok: [192.168.43.104] =&gt; (item=dashboard_v2.0.1.tar)ok: [192.168.43.105] =&gt; (item=dashboard_v2.0.1.tar)ok: [192.168.43.104] =&gt; (item=metrics-scraper_v1.0.4.tar)ok: [192.168.43.105] =&gt; (item=metrics-scraper_v1.0.4.tar)TASK [cluster-addon : 获取dashboard离线镜像推送情况] **********************************************************************************************************************changed: [192.168.43.104]changed: [192.168.43.105]TASK [cluster-addon : 导入 dashboard 的离线镜像（docker）] ***************************************************************************************************************changed: [192.168.43.104] =&gt; (item=dashboard_v2.0.1.tar)changed: [192.168.43.105] =&gt; (item=dashboard_v2.0.1.tar)changed: [192.168.43.104] =&gt; (item=metrics-scraper_v1.0.4.tar)changed: [192.168.43.105] =&gt; (item=metrics-scraper_v1.0.4.tar)TASK [cluster-addon : 创建 dashboard部署] ***************************************************************************************************************************changed: [192.168.43.104]PLAY RECAP ******************************************************************************************************************************************************192.168.43.101 : ok=104 changed=69 unreachable=0 failed=0 skipped=143 rescued=0 ignored=0192.168.43.102 : ok=101 changed=70 unreachable=0 failed=0 skipped=131 rescued=0 ignored=0192.168.43.103 : ok=101 changed=70 unreachable=0 failed=0 skipped=131 rescued=0 ignored=0192.168.43.104 : ok=111 changed=76 unreachable=0 failed=0 skipped=125 rescued=0 ignored=0192.168.43.105 : ok=106 changed=71 unreachable=0 failed=0 skipped=125 rescued=0 ignored=0localhost : ok=35 changed=23 unreachable=0 failed=0 skipped=4 rescued=0 ignored=0]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[常见服务安装]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2F%E5%B8%B8%E8%A7%81%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[promethous12345git clone https://github.com/prometheus-operator/kube-prometheus.gitgit checkout release-0.6 # v1.18 支持版本kubectl create -f manifests/setupuntil kubectl get servicemonitors --all-namespaces ; do date; sleep 1; echo &quot;&quot;; donekubectl create -f manifests/ helm 安装 promethous1234567891011121314151617181920212223242526272829303132333435# helm repo add 添加一个 Helm repohelm repo add prometheus-community https://prometheus-community.github.io/helm-chartshelm repo listNAME URLprometheus-community https://prometheus-community.github.io/helm-chartshelm repo update# 创建一个名为monitor的 namespacekubectl create ns monitorhelm install prometheus-stack prometheus-community/kube-prometheus-stack -n monitor kubectl --namespace monitor get pods -l &quot;release=prometheus-stack&quot;kubectl get all -n monitorkubectl port-forward -n monitor prometheus-prometheus-stack-kube-prom-prometheus-0 9090kubectl port-forward -n monitor prometheus-stack-grafana-5b6dd6b5fb-rtp6z 3000kubectl get deploy -n monitor prometheus-stack-grafana -o yamlkubectl get secret prometheus-stack-grafana -n monitor -o jsonpath=&apos;&#123;.data&#125;&apos;$ kubectl get secret prometheus-stack-grafana -n monitor -o jsonpath=&apos;&#123;.data.admin-user&#125;&apos; | base64 --decodeadmin$ kubectl get secret prometheus-stack-grafana -n monitor -o jsonpath=&apos;&#123;.data.admin-password&#125;&apos; | base64 --decodeprom-operatorkubectl port-forward -n monitor prometheus-stack-kube-state-metrics-c7c69c8c9-bhgjv 8080 dashboard12345678910111213141516171819202122232425https://github.com/kubernetes/dashboard wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yamlkubectl apply -f recommended.yaml## 赋予 cluster-admin 权限cat &gt; dashboard-adminuser.yaml &lt;&lt;EOFapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard-admin namespace: kube-systemroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-adminsubjects:- kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboardEOFkubectl apply -f dashboard-adminuser.yaml]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[监控告警]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2F%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[常见的监控数据类型主要分为两大类： 应用级别的数据 ：主要了解应用自身的一些监控指标 eg: cpu 使用率，内存使用率，请求失败率等 集群级别的数据 ：主要了解自身的运行状况，节点的 cpu,内存，网络吞吐等指标及时了解 kubelet 的负载情况，k8s 各组件的状态 运行过程中, k8s 产生的各种 event 数据，以及 deployment,sts,daemonset,pod 等状态，资源请求，调用和 API 延迟等数据指标也是必须要收集的 常见的监控数据收集工具 cAdvisor : v1.12 版本已移除 hapster ： 通过 cAdvisor 收集汇总的各种性能数据，做自动伸缩 （Autoscale） 所依赖的组件，已被废除，使用 metrics-server 来替换 metrics-server ： 集群范围内的监控数据聚合工具。 (可以通过标准的 Kubernetes API 来访问到这些监控数据) kube-state-metrics : 可以监听 kube-apiserver 中的数据，并生成有关资源对象的新的状态指标，eg: deployment ，Node, Pod （和 metrics-server 的最大区别） node-export : Prometheus 的一个 export, 可以获取到节点级别的监控指标 Promtheus + Grafana : 推荐方案 Prometheus Prometheus 项目工作的核心，是使用 Pull （抓取）的方式去搜集被监控对象的 Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，以便后续可以按照时间进行检索。 有了这套核心监控机制， Prometheus 剩下的组件就是用来配合这套机制的运行。 Pushgateway : 可以允许被监控对象以 Push 的方式向 Prometheus 推送 Metrics 数据。 Alertmanager : 则可以根据 Metrics 信息灵活地设置报警。 Grafana : 前台界面，对外暴露出、可以灵活配置的监控数据可视化界面。 补 kubeadm 部署默认开启 12http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/namespaces/&lt;namespace-name&gt;/pods/&lt;pod-name&gt; Kubernetes 的 API Server 开启了 Aggregator 模式之后，你再访问 apis/metrics.k8s.io/v1beta1 的时候，实际上访问到的是一个叫作 kube-aggregator 的代理。而 kube-apiserver，正是这个代理的一个后端；而 Metrics Server，则是另一个后端。在这个机制下，你还可以添加更多的后端给这个 kube-aggregator。所以 kube-aggregator 其实就是一个根据 URL 选择具体的 API 后端的代理服务器。通过这种方式，我们就可以很方便地扩展 Kubernetes 的 API 了。]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s安装-三主两工作节点-kubeadm]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E5%AE%89%E8%A3%85kubeadm%E4%B8%89%E4%B8%BB%2F</url>
    <content type="text"><![CDATA[请结合 k8s简介与安装 操作 准备条件VIP 192.168.43.100| 主机名 | IP | 角色 || —— | ———— | —— || k8s01 | 192.168.43.101 | master || k8s02 | 192.168.43.102 | worker || k8s03 | 192.168.43.103 | worker || k8s04 | 192.168.43.104 | master || k8s05 | 192.168.43.105 | master | 前置条件与单 master 相同 所有节点执行123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 根据规划设置主机名hostnamectl set-hostname &lt;hostname&gt;# 在master添加hostscat &gt;&gt; /etc/hosts &lt;&lt; EOF192.168.43.100 k8s-vip master.k8s.io192.168.43.101 k8s01 k8s01.k8s.io 192.168.43.102 k8s02 k8s02.k8s.io192.168.43.103 k8s03 k8s03.k8s.io192.168.43.104 k8s04 k8s04.k8s.io192.168.43.105 k8s05 k8s05.k8s.ioEOF## 所有节点执行以下内容#!/bin/sh#关闭防火墙systemctl disable --now firewalldsetenforce 0sed -i &apos;s/enforcing/disabled/&apos; /etc/selinux/config#关闭swap分区swapoff -ased -i.bak &apos;s/^.*centos-swap/#&amp;/g&apos; /etc/fstab#优化系统cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOFnet.ipv4.ip_forward = 1net.bridge.bridge-nf-call-iptables = 1net.bridge.bridge-nf-call-ip6tables = 1fs.may_detach_mounts = 1vm.overcommit_memory=1vm.panic_on_oom=0fs.inotify.max_user_watches=89100fs.file-max=52706963fs.nr_open=52706963net.ipv4.tcp_keepalive_time = 600net.ipv4.tcp.keepaliv.probes = 3net.ipv4.tcp_keepalive_intvl = 15net.ipv4.tcp.max_tw_buckets = 36000net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp.max_orphans = 327680net.ipv4.tcp_orphan_retries = 3net.ipv4.tcp_syncookies = 1net.ipv4.tcp_max_syn_backlog = 16384net.ipv4.ip_conntrack_max = 65536net.ipv4.tcp_max_syn_backlog = 16384net.ipv4.top_timestamps = 0net.core.somaxconn = 16384EOF#立即生效sysctl --system#配置阿里云的base和epel源mv /etc/yum.repos.d/* /tmpcurl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repocurl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo#安装dnf工具yum install dnf -ydnf makecache#安装ntpdate工具dnf install ntpdate -y#同步阿里云时间ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtimentpdate ntp.aliyun.com 安装1. Haproxy+Keepalived配置高可用VIP在 三个 master 节点安装1dnf install -y keepalived haproxy 2. 配置 Keepalived 服务k8s0112345678910111213141516171819202122232425262728293031323334cat &gt; /etc/keepalived/keepalived.conf &lt;&lt;EOF ! Configuration File for keepalivedglobal_defs &#123; router_id k8s&#125;vrrp_script check_haproxy &#123; script &quot;killall -0 haproxy&quot; interval 3 weight -2 fall 10 rise 2&#125;vrrp_instance VI_1 &#123; state MASTER # 主节点 interface ens33 # 当前用的 ens33 网卡 virtual_router_id 51 priority 100 # 优先级配置 k8s01 100 k8s04 99 k8s05 98 advert_int 2 authentication &#123; auth_type PASS auth_pass K8SHA_KA_AUTH &#125; virtual_ipaddress &#123; # VIP 192.168.43.100 &#125; track_script &#123; check_kubernetes # 集群检查脚本 &#125;&#125;EOF k8s04 和 k8s05 12345678910111213141516171819202122232425262728293031323334cat &gt; /etc/keepalived/keepalived.conf &lt;&lt;EOF ! Configuration File for keepalivedglobal_defs &#123; router_id k8s&#125;vrrp_script check_haproxy &#123; script &quot;killall -0 haproxy&quot; interval 3 weight -2 fall 10 rise 2&#125;vrrp_instance VI_1 &#123; state BACKUP # 主节点 interface ens33 # 当前用的 ens33 网卡 virtual_router_id 51 priority 100 # 优先级配置 k8s01 100 k8s04 99 k8s05 98 advert_int 2 authentication &#123; auth_type PASS auth_pass K8SHA_KA_AUTH &#125; virtual_ipaddress &#123; # VIP 192.168.43.100 &#125; track_script &#123; check_kubernetes # 集群检查脚本 &#125;&#125;EOF 3. 配置健康检测脚本/etc/keepalived/check_kubernetes.sh123456789101112131415161718192021222324cat &gt; /etc/keepalived/check_kubernetes.sh &lt;&lt;EOF #!/bin/bashfunction chech_kubernetes() &#123; for ((i=0;i&lt;5;i++));do apiserver_pid_id=$(pgrep kube-apiserver) if [[ ! -z $apiserver_pid_id ]];then return else sleep 2 fi apiserver_pid_id=0 done&#125;# 1:running 0:stoppedcheck_kubernetesif [[ $apiserver_pid_id -eq 0 ]];then /usr/bin/systemctl stop keepalived exit 1else exit 0fiEOF 4. 配置 haproxy三台 master 节点的配置均相同，配置中声明了后端代理的三个 master 节点服务器，指定了 haproxy 运行的端口为 16443 等，因此 16443 端口为集群的入口/etc/haproxy/haproxy.cfg 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475cat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOF#---------------------------------------------------------------------# Global settings#---------------------------------------------------------------------global # to have these messages end up in /var/log/haproxy.log you will # need to: # 1) configure syslog to accept network log events. This is done # by adding the &apos;-r&apos; option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats#---------------------------------------------------------------------# common defaults that all the &apos;listen&apos; and &apos;backend&apos; sections will# use if not designated in their block#--------------------------------------------------------------------- defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000#---------------------------------------------------------------------# kubernetes apiserver frontend which proxys to the backends#--------------------------------------------------------------------- frontend kubernetes-apiserver mode tcp bind *:16443 option tcplog default_backend kubernetes-apiserver #---------------------------------------------------------------------# round robin balancing between the various backends#---------------------------------------------------------------------backend kubernetes-apiserver mode tcp balance roundrobin server k8s01.k8s.io 192.168.43.101:6443 check server k8s04.k8s.io 192.168.43.104:6443 check server k8s05.k8s.io 192.168.43.105:6443 check#---------------------------------------------------------------------# collection haproxy statistics message#---------------------------------------------------------------------listen stats bind *:1080 stats auth admin:awesomePassword stats refresh 5s stats realm HAProxy\ Statistics stats uri /admin?statsEOF 5. 设置开机启动并检查是否正常1234567~]# systemctl enable --now keepalived haproxy~]# systemctl restart keepalived haproxy~]# systemctl status keepalived haproxy ~]# ping 192.168.43.100 #检测一下是否通PING 192.168.43.100 (192.168.43.100) 56(84) bytes of data.64 bytes from 192.168.43.100: icmp_seq=1 ttl=64 time=0.778 ms64 bytes from 192.168.43.100: icmp_seq=2 ttl=64 time=0.339 ms 6. 修改初始化文件~]# kubeadm config print init-defaults &gt; kubeadm-init.yaml # 需要修改 修改后如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.43.100 # 主节点IP bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: k8s01 taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0s certSANs: - k8s01 - k8s04 - k8s05 - master.k8s.io - 192.168.43.100 # VIP - 192.168.43.101 - 192.168.43.104 - 192.168.43.105 - 127.0.0.1apiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrolPlaneEndpoint: &quot;master.k8s.io:16443&quot;controllerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: v1.18.0networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 10.244.0.0/16 # 添加pod网段scheduler: &#123;&#125;---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs # 默认调度方式 IPVS 7 在master1节点执行1234567891011121314151617181920212223242526272829$ kubeadm init --config kubeadm_init.yaml |tee kubeadm_init.log# 节选[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of control-plane nodes by copying certificate authoritiesand service account keys on each node and then running the following as root: kubeadm join master.k8s.io:16443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:8904c82ab09f67fca54cd8137412d5ad917548604326e952edeedb5165facf87 \ --control-planeThen you can join any number of worker nodes by running the following on each as root:kubeadm join master.k8s.io:16443 --token abcdef.0123456789abcdef \ --discovery-token-ca-cert-hash sha256:8904c82ab09f67fca54cd8137412d5ad917548604326e952edeedb5165facf87 按照提示配置环境变量，使用 kubectl 工具： 123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 8. 安装集群网络从官方地址获取到 calico 的 yaml ，在 k8s01上执行 12345678910111213141516171819202122232425[root@k8s01 ~]# kubectl create -f calico.yamlconfigmap/calico-config createdcustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org createdclusterrole.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers createdclusterrole.rbac.authorization.k8s.io/calico-node createdclusterrolebinding.rbac.authorization.k8s.io/calico-node createddaemonset.apps/calico-node createdserviceaccount/calico-node createddeployment.apps/calico-kube-controllers createdserviceaccount/calico-kube-controllers created 9. 其他节点加入集群9.1 复制密钥及相关文件从 k8s01 复制密钥及相关文件到 k8s04 , k8s05 1234567891011ssh root@192.168.43.104 mkdir -p /etc/kubernetes/pki/etcdssh root@192.168.43.105 mkdir -p /etc/kubernetes/pki/etcdscp /etc/kubernetes/admin.conf root@192.168.43.104:/etc/kubernetesscp /etc/kubernetes/admin.conf root@192.168.43.105:/etc/kubernetes scp /etc/kubernetes/pki/&#123;ca.*,sa.*,front-proxy-ca.*&#125; root@192.168.43.104:/etc/kubernetes/pkiscp /etc/kubernetes/pki/&#123;ca.*,sa.*,front-proxy-ca.*&#125; root@192.168.43.105:/etc/kubernetes/pkiscp /etc/kubernetes/pki/etcd/ca.* root@192.168.43.104:/etc/kubernetes/pki/etcd scp /etc/kubernetes/pki/etcd/ca.* root@192.168.43.105:/etc/kubernetes/pki/etcd 9.2 其他 master 加入集群执行在 k8s01 上 init 后输出的 join 命令,需要带上参数 --control-plane 表示把 master 控制节点加入集群 12345678kubeadm join master.k8s.io:16443 --token abcdef.0123456789abcdef \--discovery-token-ca-cert-hash sha256:8904c82ab09f67fca54cd8137412d5ad917548604326e952edeedb5165facf87 \--control-planemkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 9.3 加入Kubernetes Node向集群添加新 worker 节点，执行在 kubeadm init 输出的 kubeadm join 命令： 12kubeadm join master.k8s.io:16443 --token abcdef.0123456789abcdef \--discovery-token-ca-cert-hash sha256:8904c82ab09f67fca54cd8137412d5ad917548604326e952edeedb5165facf87 检查状态 12345678910111213141516171819202122232425262728293031323334[root@k8s01 ~]# kubectl get nodeNAME STATUS ROLES AGE VERSIONk8s01 Ready master 6m15s v1.18.6k8s02 Ready &lt;none&gt; 71s v1.18.6k8s03 Ready &lt;none&gt; 62s v1.18.6k8s04 Ready master 2m2s v1.18.6k8s05 Ready master 118s v1.18.6[root@k8s01 ~]# kubectl get pods --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-76d4774d89-4s2zk 1/1 Running 0 4m15skube-system calico-node-bnc6s 1/1 Running 0 2m17skube-system calico-node-j4mjd 1/1 Running 0 86skube-system calico-node-rmzrb 1/1 Running 5 4m15skube-system calico-node-tspg2 1/1 Running 0 2m12skube-system calico-node-vnnv8 1/1 Running 0 77skube-system coredns-7ff77c879f-bst6d 1/1 Running 0 6m16skube-system coredns-7ff77c879f-gjnnm 1/1 Running 0 6m16skube-system etcd-k8s01 1/1 Running 0 6m22skube-system etcd-k8s04 1/1 Running 0 2m15skube-system etcd-k8s05 1/1 Running 0 2m1skube-system kube-apiserver-k8s01 1/1 Running 0 6m22skube-system kube-apiserver-k8s04 1/1 Running 0 2m17skube-system kube-apiserver-k8s05 1/1 Running 0 2m11skube-system kube-controller-manager-k8s01 1/1 Running 1 6m22skube-system kube-controller-manager-k8s04 1/1 Running 0 2m17skube-system kube-controller-manager-k8s05 1/1 Running 0 2m11skube-system kube-proxy-287zs 1/1 Running 0 2m17skube-system kube-proxy-5lqd8 1/1 Running 0 6m15skube-system kube-proxy-5thjh 1/1 Running 0 86skube-system kube-proxy-7vbmf 1/1 Running 0 77skube-system kube-proxy-wthx6 1/1 Running 0 2m12skube-system kube-scheduler-k8s01 1/1 Running 1 6m22skube-system kube-scheduler-k8s04 1/1 Running 0 2m16skube-system kube-scheduler-k8s05 1/1 Running 0 2m11s 10. 测试kubernetes集群在 Kubernetes 集群中创建一个pod，验证是否正常运行： 123456789101112131415161718192021222324252627[root@k8s01 ~]# kubectl create deployment nginx --image=imwl/myappdeployment.apps/nginx created[root@k8s01 ~]# kubectl expose deployment nginx --port=80 --type=NodePortservice/nginx exposed[root@k8s01 ~]# kubectl get pod,svcNAME READY STATUS RESTARTS AGEpod/nginx-7cffc8d665-wzlvx 1/1 Running 0 26sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 7m37sservice/nginx NodePort 10.107.221.225 &lt;none&gt; 80:32713/TCP 16s[root@k8s01 ~]# curl 192.168.43.100:32713Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;[root@k8s01 ~]#[root@k8s01 ~]# kubectl create deployment nginx --image=imwl/myappdeployment.apps/nginx created[root@k8s01 ~]# kubectl expose deployment nginx --port=80 --type=NodePortservice/nginx exposed[root@k8s01 ~]# kubectl get pod,svcNAME READY STATUS RESTARTS AGEpod/nginx-7cffc8d665-wzlvx 1/1 Running 0 26sNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 7m37sservice/nginx NodePort 10.107.221.225 &lt;none&gt; 80:32713/TCP 16s[root@k8s01 ~]# curl 192.168.43.100:32713Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt; # 验证 OK 访问地址：http://192.168.43.100:32713]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[日志收集]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2F%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[日志的需求 系统各组件的日志 ： eg: kubelet、kube-proxy,docker 等日志 容器化运行的应用程序自身日志 ： eg: Nginx 的运行日志 k8s 内部各种 Event ： eg: kubctl create pod 后，kubectl describe pod *** 的pod 的 Event信息 日志系统Kubernetes 的日志系统在设计的时候，必须得独立于节点和 Pod 的生命周期，且保证日志数据可以实时采集到服务端，即完全独立于 Kubernetes 系统，使用自己的后端存储和查询工具 日志收集方式一般有如下 四种方案来做日志收集： 直接在应用程序中将日志信息推送到采集后端； （不推荐, 耦合严重。本身已有完善日志处理系统的公司可以采用） 在节点上运行一个 Agent 来采集节点级别的日志； （使用 daemonset，比较常用，但只适合 容器内应用日志是标准输出场景，即应用把日志 输出的 stdout 和 stderr） 3.当容器的日志只能输出到某些文件里的时候，我们可以通过一个 sidecar 容器把这些日志文件重新输出到 sidecar 的 stdout 和 stderr 上，这样就能够继续使用第一种方案了; (Sidecar 容器读取日志文件，并重定向到自己的标准输出。会增加额外开销,cpu 内存，磁盘空间等，大规模集群，这些开销不可忽视，所以非特殊情况，一般推荐二和四) 通过一个 sidecar 容器，直接把应用的日志文件发送到远程存储里面去。也就是相当于把方案二里的 logging agent，放在了应用 Pod 里。（应用还可以直接把日志输出到固定的文件里而不是 stdout，logging-agent 还可以使用 fluentd，后端存储还可以是 ElasticSearch。只不过， fluentd 的输入源，变成了应用的日志文件。一般来说，我们会把 fluentd 的输入源配置保存在一个 ConfigMap 里） sidecar 指的就是我们可以在一个 Pod 中，启动一个辅助容器，来完成一些独立于主进程（主容器）之外的工作。 推荐方式使用 EFK 进行日志收集和管理，通过 Fluentd 将日志导入到 Elasticsearch 中，然后通过 Kibana 查看所有的日志 yaml 文件Pod 只有一个容器，它会把日志输出到容器里的 /var/log/1.log 和 2.log 这两个文件里 log_to_file.yaml1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log; echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 因为非 stdout 和 stderr, kubectl logs 命令是看不到应用的任何日志的。所以方案二不能使用。使用方案三 ： Pod 添加两个 sidecar 容器，分别将上述两个日志文件里的内容重新以 stdout 和 stderr 的方式输出出来 tail -f 123456789101112131415161718192021222324252627282930313233343536373839apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log; echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-log-1 # 此容器将主容器的 /var/log/1.log 通过 tail 输出到 stdout 和 stderr image: busybox args: [/bin/sh, -c, &apos;tail -n+1 -f /var/log/1.log&apos;] volumeMounts: - name: varlog mountPath: /var/log - name: count-log-2 image: busybox args: [/bin/sh, -c, &apos;tail -n+1 -f /var/log/2.log&apos;] volumeMounts: - name: varlog mountPath: /var/log volumes: - name: varlog emptyDir: &#123;&#125; 方案四 fluentd-from-config.yaml12345678910111213141516171819202122232425apiVersion: v1kind: ConfigMapmetadata: name: fluentd-configdata: fluentd.conf: | &lt;source&gt; type tail format none path /var/log/1.log pos_file /var/log/1.log.pos tag count.format1 &lt;/source&gt; &lt;source&gt; type tail format none path /var/log/2.log pos_file /var/log/2.log.pos tag count.format2 &lt;/source&gt; &lt;match **&gt; type google_cloud &lt;/match&gt; 声明一个 Fluentd 容器作为 sidecar，专门负责将应用生成的 1.log 和 2.log 转发到 ElasticSearch 当中. 12345678910111213141516171819202122232425262728293031323334353637383940apiVersion: v1kind: Podmetadata: name: counterspec: containers: - name: count image: busybox args: - /bin/sh - -c - &gt; i=0; while true; do echo &quot;$i: $(date)&quot; &gt;&gt; /var/log/1.log; echo &quot;$(date) INFO $i&quot; &gt;&gt; /var/log/2.log; i=$((i+1)); sleep 1; done volumeMounts: - name: varlog mountPath: /var/log - name: count-agent image: k8s.gcr.io/fluentd-gcp:1.30 env: - name: FLUENTD_ARGS value: -c /etc/fluentd-config/fluentd.conf volumeMounts: - name: varlog mountPath: /var/log - name: config-volume mountPath: /etc/fluentd-config volumes: - name: varlog emptyDir: &#123;&#125; - name: config-volume configMap: name: fluentd-config 这个 sidecar 容器很可能会消耗较多的资源，甚至拖垮应用容器。并且，由于日志还是没有输出到 stdout 上，所以你通过 kubectl logs 是看不到任何日志输出的。]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s图]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[课程内容介绍.png 概述特性和架构组件.png 核心概念.png k8s集群搭建（平台规划和搭建方式介绍）.png 搭建k8s集群（kubeadm方式）.png 搭建k8s集群（二进制方式）.png 搭建k8s集群总结.png 命令行工具kubectl.png yaml文件说明.png 快速编写yaml文件.png 1-Pod实现机制-共享网络.png 2-Pod实现机制-共享存储.png Pod.png Pod镜像拉取策略.png Pod资源限制.png Pod重启策略.png Pod健康检查.png 创建Pod流程.png 1-Pod调度-节点亲和性.png Pod调度-节点选择器.png Pod调度-污点和污点容忍.png Controller控制器（deployment）.png Service.png controller.png 配置管理-secret.png 配置管理-configMap.png k8s集群安全机制.png k8s集群安全机制-rbac实现鉴权.png ingress.png 集群监控平台.png helm（概述）.png helm（快速部署应用）.png helm（自己创建chart）.png helm（chart模板）.png 部署项目流程介绍.png 部署java项目.png 搭建高可用的集群.png 搭建高可用的集群.png 持久存储-nfs.png 持久存储-pv和pvc.png yaml文件字段说明.png yaml文件示例.png 共享存储示例yaml.png 污点容忍.png 来源于 尚硅谷的教程]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[helm]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fhelm%2F</url>
    <content type="text"><![CDATA[helmhelm 通过打包的方式，支持发布的版本管理和控制，很大程度上简化了 Kubernetes 应用的部署和管理. Helm 本质就是让 K8s 的应用管理（Deployment,Service 等 ) 可配置，能动态生成。通过动态生成 K8s 资源清单文件（deployment.yaml，service.yaml 等）。然后调用 Kubectl 自动执行 K8s 资源部署 Helm 是官方提供的类似于 YUM 的包管理器，是部署环境的流程封装。Helm 有两个重要的概念：chart 和 release chart 是创建一个应用的信息集合，包括各种 Kubernetes 对象的配置模板、参数定义、依赖关系、文档说明等。chart 是应用部署的自包含逻辑单元。可以将 chart 想象成 apt、yum 中的软件安装包 release 是 chart 的运行实例，代表了一个正在运行的应用。当 chart 被安装到 Kubernetes 集群，就生成一个 release。chart 能够多次安装到同一个集群，每次安装都是一个 release Helm 包含两个组件：Helm 客户端和 Tiller 服务器 (Tiller 在 helm 3.0 以上版本被遗弃)，有关内容删除。 helm 部署1234ntpdate ntp1.aliyun.comwget https://get.helm.sh/helm-v3.3.1-linux-amd64.tar.gz # 当前最新版 v3.3.1tar -zxvf helm-*-linux-amd64.tar.gzmv linux-amd64/helm /usr/local/bin/ 12345678910## helm 自定义模板$ mkdir ./hello-world$ cd ./hello-world# 创建自描述文件 Chart.yaml , 这个文件必须有 name 和 version 定义$ cat &lt;&lt;&apos;EOF&apos; &gt; ./Chart.yamlname: hello-worldversion: 1.0.0EOF 当前文件夹下，创建模板文件，用于生成 Kubernetes 资源清单（manifests）./templates/service.yaml123456789101112apiVersion: v1kind: Servicemetadata: name: hello-worldspec: type: NodePort ports: - port: 80 targetPort: 80 protocol: TCP selector: app: hello-world ./templates/deployment.yaml1234567891011121314151617181920apiVersion: apps/v1kind: Deploymentmetadata: name: hello-worldspec: replicas: 1 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world spec: containers: - name: hello-world image: &#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125; ports: - containerPort: 80 protocol: TCP 配置体现在配置文件 values.yaml ./values.yaml123image: repository: imwl/myapp tag: &apos;v2&apos; 目录结构12345678910[root@k8s01 ~]# cd hello-world/[root@k8s01 hello-world]# tree.├── Chart.yaml├── templates│ ├── deployment.yaml│ └── service.yaml└── values.yaml1 directory, 4 files 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 使用命令 helm install RELATIVE_PATH_TO_CHART 创建一次Release [root@k8s01 hello-world]# helm install --name-template hello .[root@k8s01 hello-world]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEShello-world-6768f995d8-tzw8x 1/1 Running 0 45s 172.18.235.154 k8s03 &lt;none&gt; &lt;none&gt;[root@k8s01 hello-world]# curl 172.18.235.154Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;# 在 values.yaml 中的值可以被部署 release 时用到的参数 --values YAML_FILE_PATH 或 --setkey1=value1, key2=value2 覆盖掉[root@k8s01 hello-world]# helm install --set image.tag=&apos;v1&apos; --name-template hello .NAME: helloLAST DEPLOYED: Mon Aug 31 21:44:42 2020NAMESPACE: defaultSTATUS: deployedREVISION: 1TEST SUITE: None[root@k8s01 hello-world]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEShello-world-7cb76c9f4d-lhbw8 1/1 Running 0 19s 172.18.235.167 k8s03 &lt;none&gt; &lt;none&gt;[root@k8s01 hello-world]# curl 172.18.235.167Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;# 升级版本[root@k8s01 hello-world]# vi values.yaml # 改为v3[root@k8s01 hello-world]# helm upgrade -f values.yaml hello .Release &quot;hello&quot; has been upgraded. Happy Helming!NAME: helloLAST DEPLOYED: Mon Aug 31 21:47:00 2020NAMESPACE: defaultSTATUS: deployedREVISION: 2TEST SUITE: None[root@k8s01 hello-world]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEShello-world-7d845997d-fc86w 1/1 Running 0 20s 172.18.235.164 k8s03 &lt;none&gt; &lt;none&gt;[root@k8s01 hello-world]# curl 172.18.235.164Hello MyApp | Version: v3 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;# 回滚[root@k8s01 hello-world]# helm history helloREVISION UPDATED STATUS CHART APP VERSION DESCRIPTION1 Mon Aug 31 21:44:42 2020 superseded hello-world-1.0.0 Install complete2 Mon Aug 31 21:47:00 2020 deployed hello-world-1.0.0 Upgrade complete[root@k8s01 hello-world]# helm rollback hello 1Rollback was a success! Happy Helming![root@k8s01 hello-world]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEShello-world-7cb76c9f4d-6zgcb 1/1 Running 0 16s 172.18.235.170 k8s03 &lt;none&gt; &lt;none&gt;[root@k8s01 hello-world]# curl 172.18.235.170Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;[root@k8s01 hello-world]### 删除[root@k8s01 hello-world]# helm uninstall hello (--keep-history 保存)release &quot;hello&quot; uninstalled Debug使用模板动态生成 K8s 资源清单，非常需要能提前预览生成的结果。使用 --dry-run --debug 选项来打印出生成的清单文件内容，而不执行部署 1helm install --generate-name --dry-run --debug --set image.tag=latest .]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s-高可用]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[修改证书为 10 年apiservice 默认为 1 年，一般正常升级不用去修改。修改为10年可参考谷歌资料 12345678910111213[root@k8s01 kubernetes-dashboard]# openssl x509 -in apiserver.crt -text -noout^C[root@k8s01 kubernetes-dashboard]# cd ~[root@k8s01 ~]# cd /etc/kubernetes/pki/[root@k8s01 pki]# openssl x509 -in apiserver.crt -text -nooutCertificate: Data: Version: 3 (0x2) Serial Number: 4701217366037256467 (0x413e14494a8c5913) Signature Algorithm: sha256WithRSAEncryption Issuer: CN=kubernetes Validity Not Before: Jul 27 17:34:14 2020 GMT Not After : Jul 27 17:34:14 2021 GMT ## 可以看到为 1 年期限 ###]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s安全]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[机制说明Kubernetes 作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。API Server 是集群内部各个组件通信的中介，也是外部控制的入口。所以 Kubernetes 的安全机制基本就是围绕保护 API Server 来设计的。 Kubernetes 使用了认证（Authentication）、鉴权（Authorization）、准入控制（AdmissionControl）三步来保证 API Server 的安全 Authentication 认证方式 HTTP Token 认证：通过一个 Token 来识别合法用户 (HTTP Token 的认证是用一个很长的特殊编码方式的并且难以被模仿的字符串 - Token 来表达客户的一种方式。Token 是一个很长的很复杂的字符串，每一个 Token 对应一个用户名存储在 API Server 能访问的文件中。当客户端发起 API 调用请求时，需要在 HTTP Header 里放入 Token) HTTP Base 认证：通过用户名+密码的方式认证 (用户名+：+密码用 BASE64 算法进行编码后的字符串放在 HTTP Request 中的 HeatherAuthorization 域里发送给服务端，服务端收到后进行编码，获取用户名及密码) 最严格的 HTTPS 证书认证：基于 CA 根证书签名的客户端身份认证方式 一般用 HTTPS 证书认证 HTTPS 证书认证 需要认证的节点 两种类型 Kubenetes 组件对 API Server 的访问：kubectl、Controller Manager、Scheduler、kubelet、kube-proxy Kubernetes 管理的 Pod 对容器的访问：Pod（dashborad 也是以 Pod 形式运行） 安全性说明 Controller Manager、Scheduler 与 API Server 在同一台机器，所以直接使用 API Server 的非安全端口访问，--insecure-bind-address=127.0.0.1 kubectl、kubelet、kube-proxy 访问 API Server 就都需要证书进行 HTTPS 双向认证 证书颁发 手动签发：通过 k8s 集群的跟 ca 进行签发 HTTPS 证书 自动签发：kubelet 首次访问 API Server 时，使用 token 做认证，通过后，Controller Manager 会为 kubelet 生成一个证书，以后的访问都是用证书做认证了 kubeconfigkubeconfig 文件包含集群参数（CA证书、API Server 地址），客户端参数（上面生成的证书和私钥），集群 context 信息（集群名称、用户名）。Kubenetes 组件通过启动时指定不同的 kubeconfig 文件可以切换到不同的集群 ServiceAccountPod 中的容器访问 API Server。因为 Pod 的创建、销毁是动态的，所以要为它手动生成证书就不可行了。Kubenetes 使用了 Service Account 解决 Pod 访问 API Server 的认证问题 Secret 与 SA 的关系Kubernetes 设计了一种资源对象叫做 Secret，分为两类，一种是用于 ServiceAccount 的 service-account-token，另一种是用于保存用户自定义保密信息的 Opaque。ServiceAccount 中用到包含三个部分：Token、ca.crt、namespace 1. token 是使用 API Server 私钥签名的 JWT。用于访问 API Server 时，Server端认证 ca.crt，根证书。用于 Client 端验证 API Server 发送的证书 namespace, 标识这个service-account-token 的作用域名空间 1kubectl get secret --all-namespaceskubectl describe secret default-token-5gm9r --namespace=kube-syste 默认情况下，每个 namespace 都会有一个 ServiceAccount，如果 Pod 在创建时没有指定 ServiceAccount，就会使用 Pod 所属的 namespace 的 ServiceAccount Authorization上面认证过程，只是确认通信的双方都确认了对方是可信的，可以相互通信。而鉴权是确定请求方有哪些资源的权限。 API Server 目前支持以下几种授权策略（通过 API Server 的启动参数 --authorization-mode 设置） AlwaysDeny：表示拒绝所有的请求，一般用于测试 AlwaysAllow：允许接收所有请求，如果集群不需要授权流程，则可以采用该策略 ABAC（Attribute-Based Access Control）：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制 Webbook：通过调用外部 REST 服务对用户进行授权 RBAC（Role-Based Access Control)：基于角色的访问控制，现行默认规则 一般只用RBAC RBAC 授权模式RBAC（Role-Based Access Control）基于角色的访问控制，在 Kubernetes 1.5 中引入，现行版本成为默认标准。相对其它访问控制方式，拥有以下优势： 对集群中的资源和非资源均拥有完整的覆盖 整个 RBAC 完全由几个 API 对象完成，同其它 API 对象一样，可以用 kubectl 或 API 进行操作 可以在运行时进行调整，无需重启 API Server RBAC 的 API 资源对象说明RBAC 引入了 4 个新的顶级资源对象：Role、ClusterRole、RoleBinding、ClusterRoleBinding，4 种对象类型均可以通过 kubectl 与 API 操作 Role：角色，它其实是一组规则，定义了一组对 Kubernetes API 对象的操作权限。 Subject：被作用者，既可以是“人”，也可以是“机器”，也可以是你在 Kubernetes 里定义的“用户”。 RoleBinding：定义了“被作用者”和“角色”的绑定关系。而这三个概念，其实就是整个 RBAC 体系的核心所在。 需要注意的是 Kubenetes 并不会提供用户管理，那么 User、Group、ServiceAccount 指定的用户又是从哪里来的呢？ Kubenetes 组件（kubectl、kube-proxy）或是其他自定义的用户在向 CA 申请证书时，需要提供一个证书请求文件 1234567891011121314151617181920&#123; &quot;CN&quot;: &quot;admin&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;HangZhou&quot;, &quot;L&quot;: &quot;XS&quot;, &quot;O&quot;: &quot;system:masters&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;## hosts&quot;: []表示所有主机 API Server 会把客户端证书的 CN 字段作为 User，把 names.O 字段作为Group` kubelet 使用 TLS Bootstaping 认证时，API Server 可以使用 Bootstrap Tokens 或者 Token authenticationfile 验证=token，无论哪一种，Kubenetes 都会为 token 绑定一个默认的 User 和 GroupPod 使用 ServiceAccount 认证时，service-account-token 中的 JWT 会保存 User 信息有了用户信息，再创建一对角色/角色绑定(集群角色/集群角色绑定)资源对象，就可以完成权限绑定了。 Role and ClusterRole在 RBAC API 中，Role 表示一组规则权限，权限只会增加(累加权限)，不存在一个资源一开始就有很多权限而通过 RBAC 对其进行减少的操作；Role 可以定义在一个 namespace 中，如果想要跨 namespace 则可以创建 ClusterRole 。 123456789kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: default name: pod-readerrules:- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group resources: [&quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] ClusterRole 具有与 Role 相同的权限角色控制能力，不同的是 ClusterRole 是集群级别的，ClusterRole 可以用于: 集群级别的资源控制( 例如 node 访问权限 ) 非资源型 endpoints( 例如/healthz访问 ) 所有命名空间资源控制(例如 pods ) 123456789kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: # &quot;namespace&quot; omitted since ClusterRoles are not namespaced name: secret-readerrules:- apiGroups: [&quot;&quot;] resources: [&quot;secrets&quot;] verbs: [&quot;get&quot;,&quot;watch&quot;,&quot;list&quot;] RoleBinding and ClusterRoleBindingRoloBinding 可以将角色中定义的权限授予用户或用户组，RoleBinding 包含一组权限列表(subjects)，权限列表中包含有不同形式的待授予权限资源类型(users, groups, or service accounts)；RoloBinding 同样包含对被 Bind 的 Role 引用；RoleBinding 适用于某个命名空间内授权，而 ClusterRoleBinding 适用于集群范围内的授权 将 default 命名空间的 pod-reader Role 授予 jane 用户，此后 jane 用户在 default 命名空间中将具有 pod-reader 的权限 12345678910111213kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: read-pods namespace: defaultsubjects:- kind: User name: jane apiGroup: rbac.authorization.k8s.ioroleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io RoleBinding 同样可以引用 ClusterRole 来对当前 namespace 内用户、用户组或 ServiceAccount 进行授权，这种操作允许集群管理员在整个集群内定义一些通用的 ClusterRole，然后在不同的 namespace 中使用 RoleBinding 来引用 例如，以下 RoleBinding 引用了一个 ClusterRole，这个 ClusterRole 具有整个集群内对 secrets 的访问权限；但是其授权用户 dave 只能访问 development 空间中的 secrets (因为 RoleBinding 定义在 development 命名空间) 1234567891011121314# This role binding allows &quot;dave&quot; to read secrets in the &quot;development&quot; namespace.kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: read-secrets namespace: development # This only grants permissions within the &quot;development&quot; namespace.subjects: - kind: User name: dave apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 使用 ClusterRoleBinding 可以对整个集群中的所有命名空间资源权限进行授权；以下 ClusterRoleBinding 样例展示了授权 manager 组内所有用户在全部命名空间中对 secrets 进行访问 12345678910111213# This cluster role binding allows anyone in the &quot;manager&quot; group to read secrets in any namespace.kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: read-secrets-globalsubjects:- kind: Group name: manager apiGroup: rbac.authorization.k8s.ioroleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io ResourcesKubernetes 集群内一些资源一般以其名称字符串来表示，这些字符串一般会在 API 的 URL 地址中出现；同时某些资源也会包含子资源，例如 logs 资源就属于 pods 的子资源，API 中 URL 样例如下 1GET /api/v1/namespaces/&#123;namespace&#125;/pods/&#123;name&#125;/log 如果要在 RBAC 授权模型中控制这些子资源的访问权限，可以通过 / 分隔符来实现，以下是一个定义 pods 资源 logs 访问权限的 Role 定义样例 123456789kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: default name: pod-and-pod-logs-readerrules:- apiGroups: [&quot;&quot;] resources: [&quot;pods/log&quot;] verbs: [&quot;get&quot;,&quot;list&quot;] to SubjectsRoleBinding 和 ClusterRoleBinding 可以将 Role 绑定到 Subjects；Subjects 可以是 groups、users 或者 service accountsSubjects 中 Users 使用字符串表示，它可以是一个普通的名字字符串，如 alice；也可以是 email 格式的邮箱地址，如 `wangyanglinux@163.com；甚至是一组字符串形式的数字ID。但是Users的前缀system`: 是系统保留的，集群管理员应该确保普通用户不会使用这个前缀 格式 Groups 书写格式与 Users 相同，都为一个字符串，并且没有特定的格式要求；同样 system: 前缀为系统保留。 实践：创建一个用户只能管理 dev 空间123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990$ mkdir cert$ cd cert$ cat &lt;&lt;&apos;EOF&apos; &gt; devuser-csr.json&#123; &quot;CN&quot;: &quot;devuser&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ]&#125;EOF# 下载证书生成工具wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64mv cfssl_linux-amd64 /usr/local/bin/cfsslwget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64mv cfssljson_linux-amd64 /usr/local/bin/cfssljsonwget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfochmod a+x /usr/local/bin/*[root@k8s01 cert]# cfssl gencert -ca=/etc/kubernetes/pki/ca.crt -ca-key=/etc/kubernetes/pki/ca.key -profile=kubernetes /root/cert/devuser-csr.json | cfssljson -bare devuser2020/08/31 22:35:34 [INFO] generate received request2020/08/31 22:35:34 [INFO] received CSR2020/08/31 22:35:34 [INFO] generating key: rsa-20482020/08/31 22:35:34 [INFO] encoded CSR2020/08/31 22:35:34 [INFO] signed certificate with serial number 4854766599168946027405930534974868297593658910322020/08/31 22:35:34 [WARNING] This certificate lacks a &quot;hosts&quot; field. This makes it unsuitable forwebsites. For more information see the Baseline Requirements for the Issuance and Managementof Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);specifically, section 10.2.3 (&quot;Information Requirements&quot;).[root@k8s01 cert]# tree.├── devuser.csr├── devuser-csr.json├── devuser-key.pem└── devuser.pem0 directories, 4 files# 设置集群参数export KUBE_APISERVER=&quot;https://192.168.43.101:6443&quot;kubectl config set-cluster kubernetes \--certificate-authority=/etc/kubernetes/pki/ca.crt \--embed-certs=true \--server=$&#123;KUBE_APISERVER&#125; \--kubeconfig=devuser.kubeconfig# 设置客户端认证参数kubectl config set-credentials devuser \--client-certificate=/root/cert/devuser.pem \--client-key=/root/cert/devuser-key.pem \--embed-certs=true \--kubeconfig=devuser.kubeconfig# 设置上下文参数kubectl config set-context kubernetes \--cluster=kubernetes \--user=devuser \--namespace=dev \--kubeconfig=devuser.kubeconfig# role binding[root@k8s01 cert]# kubectl create namespace devnamespace/dev created[root@k8s01 cert]# kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev # 在 dev 下是 admin 角色[root@k8s01 cert]# mkdir /home/devuser/.kube/[root@k8s01 cert]# mv devuser.kubeconfig /home/devuser/.kube/config[root@k8s01 cert]# chown devuser:devuser -R /home/devuser # 切到 devuser # 设置默认上下文su - devusercd .kubekubectl config use-context kubernetes --kubeconfig=config## namespace dev 就是 devuser 的 default AdmissionControl准入控制是 API Server 的插件集合，通过添加不同的插件，实现额外的准入控制规则。甚至于 API Server 的一些主要的功能都需要通过 Admission Controllers 实现，比如 ServiceAccount 官方文档上有一份针对不同版本的准入控制器推荐列表，其中最新的 1.14 的推荐列表是：1NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota 列举几个插件的功能： NamespaceLifecycle：防止在不存在的 namespace 上创建对象，防止删除系统预置 namespace，删除 namespace 时，连带删除它的所有资源对象。 LimitRanger：确保请求的资源不会超过资源所在 Namespace 的 LimitRange 的限制。 ServiceAccount：实现了自动化添加 ServiceAccount。 ResourceQuota：确保请求的资源不会超过资源的 ResourceQuota 限制。 Role-RoleBinding-ServiceAccount.yaml 是最常用的123456789101112131415161718192021222324252627282930313233343536373839404142434445# 大多数时候，我们其实都不太使用“用户”这个功能，而是直接使用 Kubernetes 里的“内置用户”apiVersion: v1kind: ServiceAccountmetadata: namespace: mynamespace name: example-sa---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: namespace: mynamespace name: example-rolerules:- apiGroups: [&quot;&quot;] resources: [&quot;pods&quot;] verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] # verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: example-rolebinding namespace: mynamespacesubjects:- kind: ServiceAccount name: example-sa namespace: mynamespaceroleRef: kind: Role name: example-role apiGroup: rbac.authorization.k8s.io---# 用户的 Pod，就可以声明使用这个 ServiceAccount 了apiVersion: v1kind: Podmetadata: namespace: mynamespace name: sa-token-testspec: containers: - name: nginx image: nginx:1.7.9 serviceAccountName: example-sa 123456789101112131415161718192021# 一个 ServiceAccount，在 Kubernetes 里对应的“用户”的名字是：system:serviceaccount:&lt;Namespace名字&gt;:&lt;ServiceAccount名字&gt;# 它对应的内置“用户组”的名字，就是：system:serviceaccounts:&lt;Namespace名字&gt;# 这个 Role 的权限规则，作用于 mynamespace 里的所有 ServiceAccount 这就用到了“用户组”的概念subjects:- kind: Group name: system:serviceaccounts:mynamespace apiGroup: rbac.authorization.k8s.io# 作用于整个系统里的所有 ServiceAccount subjects:- kind: Group name: system:serviceaccounts apiGroup: rbac.authorization.k8s.io]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Volume补]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FVolume%E8%A1%A5%2F</url>
    <content type="text"><![CDATA[Local Persistent VolumeKubernetes 能够直接使用宿主机上的本地磁盘目录，而不依赖于远程存储服务，来提供“持久化”的容器 Volume。 比于正常的 PV，一旦这些节点宕机且不能恢复时，Local Persistent Volume 的数据就可能丢失,使用 Local Persistent Volume 的应用必须具备数据备份和恢复的能力，允许你把这些数据定时备份在其他位置。 难点： 如何把本地磁盘抽象成 PV () 保证 Pod 始终能被正确地调度到它所请求的 Local Persistent Volume 所在的节点上 不应该把一个宿主机上的目录当作 PV 使用。这种本地目录的存储行为完全不可控，它所在的磁盘随时都可能被应用写满，甚至造成整个宿主机宕机. 最好一块额外挂载在宿主机的磁盘或者块设备。（“一个 PV 一块盘”） 调度器就必须能够知道所有节点与 Local Persistent Volume 对应的磁盘的关联关系，然后根据这个信息来调度 Pod。（“在调度的时候考虑 Volume 分布”） 示例 在名叫 node-1 的宿主机上创建一个挂载点，比如 /mnt/disks；然后，用几个 RAM Disk 来模拟本地磁盘 1234567# 在node-1上执行$ mkdir /mnt/disks$ for vol in vol1 vol2 vol3; do mkdir /mnt/disks/$vol mount -t tmpfs $vol /mnt/disks/$voldone 为这些本地磁盘定义对应的 PV 12345678910111213141516171819202122apiVersion: v1kind: PersistentVolumemetadata: name: example-pvspec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage # 对应 local: path: /mnt/disks/vol1 nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node-1 创建一个 StorageClass 来描述这个 PV 123456kind: StorageClassapiVersion: storage.k8s.io/v1metadata: name: local-storage # 对应provisioner: kubernetes.io/no-provisioner # Local Persistent Volume 目前尚不支持 Dynamic ProvisioningvolumeBindingMode: WaitForFirstConsumer # 延迟绑定 原本实时发生的 PVC 和 PV 的绑定过程，就被延迟到了 Pod 第一次调度的时候在调度器中进行 创建 PVC，apply 后还不会绑定 ，pending 状态 123456789101112kind: PersistentVolumeClaimapiVersion: v1metadata: name: example-local-claimspec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: local-storage # 对应 编写一个 Pod 来声明使用这个 PVC 12345678910111213141516171819kind: PodapiVersion: v1metadata: name: example-pv-podspec: volumes: - name: example-pv-storage persistentVolumeClaim: claimName: example-local-claim # pvc name containers: - name: example-pv-container image: nginx ports: - containerPort: 80 name: &quot;http-server&quot; volumeMounts: - mountPath: &quot;/usr/share/nginx/html&quot; name: example-pv-storage 删除流程： 删除使用这个 PV 的 Pod 从宿主机移除本地磁盘（比如，umount 它） 删除 PVC 删除 PV 如果不按照这个流程的话，这个 PV 的删除就会失败 csiCSI 的设计思想，把插件的职责从“两阶段处理”，扩展成了 Provision、Attach 和 Mount 三个阶段。 Provision 等价于“创建磁盘” Attach 等价于“挂载磁盘到虚拟机” Mount 等价于“将该磁盘格式化后，挂载在 Volume 的宿主机目录上”。 12345678kind: StorageClassapiVersion: storage.k8s.io/v1metadata: name: do-block-storage namespace: kube-system annotations: storageclass.kubernetes.io/is-default-class: &quot;true&quot; # 使用这个 StorageClass 作为默认的持久化存储提供者provisioner: com.digitalocean.csi.dobs # 使用 com.digitalocean.csi.dobs 的 CSI 插件处理这个 StorageClass 相关的所有操作 具体用到了再看吧]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PV-PVC(statefulset示例)]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FPV-PVC(statefulset%E7%A4%BA%E4%BE%8B)%2F</url>
    <content type="text"><![CDATA[PersistentVolume（PV）是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。 PersistentVolumeClaim（PVC）是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或只读多次模式挂载） 静态 pv集群管理员创建一些 PV。它们带有可供群集用户使用的实际存储的细节。它们存在于 Kubernetes API 中，可用于消费 动态当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim 时，集群可能会尝试动态地为 PVC 创建卷。此配置基于 StorageClasses：PVC 必须请求 [存储类]，并且管理员必须创建并配置该类才能进行动态创建。声明该类为””可以有效地禁用其动态配置要启用基于存储级别的动态存储配置，集群管理员需要启用 API server 上的 DefaultStorageClass [准入控制器]。例如，通过确保 DefaultStorageClass 位于 API server 组件的 --admission-control 标志，使用逗号分隔的有序值列表中，可以完成此操作 StorageClass 对象的作用，其实就是创建 PV 的模板。 PV 的属性。比如，存储类型、Volume 的大小等等。 创建这种 PV 需要用到的存储插件。比如，Ceph 等等。 动态 PV 工作的过程: 首先我们定义了一个 StorageClass。当用户创建好 Pod 以后，指定了 PVC，这个时候 Kubernetes 就会根据 StorageClass 中定义的 Provisioner 来调用对应的 plugin 来创建 PV。PV 创建成功后，跟 PVC 进行绑定，挂载到 Pod 中使用。12345678910111213141516171819apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: fast-rbd-sc annotation: storageclass.kubernetes.io/is-default-class: &quot;true&quot;provisioner: kubernetes.io/rbd # 必填项，用来指定volume plugin来创建PV的物理资源,内置parameters: # 一些参数 monitors: 10.16.153.105:6789 adminId: kube adminSecretName: ceph-secret adminSecretNamespace: kube-system pool: kube userId: kube userSecretName: ceph-secret-user userSecretNamespace: default fsType: ext4 imageFormat: &quot;2&quot; imageFeatures: &quot;layering&quot; 绑定master 中的控制环路监视新的 PVC，寻找匹配的 PV（如果可能），并将它们绑定在一起。如果为新的 PVC 动态调配 PV，则该环路将始终将该 PV 绑定到 PVC。否则，用户总会得到他们所请求的存储，但是容量可能超出要求的数量。一旦 PV 和 PVC 绑定后，PersistentVolumeClaim绑定是排他性的，不管它们是如何绑定的。 PVC 跟PV 绑定是一对一的映射 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: claim1spec: accessModes: - ReadWriteOnce storageClassName: fast-rbd-sc # PVC 所要使用的 StorageClass resources: requests: storage: 30Gi 集群开启名叫 DefaultStorageClass 的 Admission Plugin，它就会为 PVC 和 PV 自动添加一个默认的 StorageClass；否则，PVC 的 storageClassName 的值就是“”，这也意味着它只能够跟 storageClassName 也是“”的 PV 进行绑定。 PVC : Pod 想要使用的持久化存储的属性，比如存储的大小、读写权限等。 PV : 一个具体的 Volume 的属性，比如 Volume 的类型、挂载目录、远程存储服务器地址等。 StorageClass : 充当 PV 的模板。并且，只有同属于一个 StorageClass 的 PV 和 PVC，才可以绑定在一起。也可以动态创建 PV 。持久化卷声明的保护PVC保护的目的是确保由 pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话可能会导致数据丢失.当启用 PVC 保护 alpha 功能时，如果用户删除了一个 pod 正在使用的 PVC，则该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 pod 使用 PV 访问模式PersistentVolume可以以资源提供者支持的任何方式挂载到主机上。 ReadWriteOnce—— 该卷可以被单个节点以读/写模式挂载 RWO ReadOnlyMany —— 该卷可以被多个节点以只读模式挂载 ROX ReadWriteMany —— 该卷可以被多个节点以读/写模式挂载 RWX 回收策略 Retain（保留）——手动回收 Recycle（回收）——基本擦除（rm -rf /thevolume/*） Delete（删除）——关联的存储资产（例如 AWS EBS、GCE PD、Azure Disk 和 OpenStack Cinder 卷）将被删除当前 只有 NFS(已不支持) 和 HostPath 支持回收策略。AWS EBS、GCE PD、Azure Disk 和 Cinder 卷支持删除策略 状态卷可以处于以下的某种状态 Pending 表示目前该 PV 在后端存储系统中还没创建完成； Available（可用）——一块空闲资源还没有被任何声明绑定 Bound（已绑定）——卷已经被声明绑定 Released（已释放）——声明被删除，但是资源还未被集群重新声明 Failed（失败）——该卷的自动回收失败 命令行会显示绑定到 PV 的 PVC 的名称 对于 PVC 来说，也有如下三种状态： Pending 表示还未绑定任何 PV； Bound 表示已经和某个 PV 进行了绑定； Lost 表示关联的 PV 失联。 持久化演示说明 - NFS 安装 NFS 服务器eg: 在 三个 节点上安装1234567yum install -y nfs-common nfs-utils rpcbindmkdir /nfsdatachmod 666 /nfsdatachown nfsnobody /nfsdataecho &quot;/nfsdata *(rw,no_root_squash,no_all_squash,sync)&quot; &gt;&gt; /etc/exportssystemctl start rpcbindsystemctl start nfs k8s02,k8s03操作 测试 NFS 是否成功1234567891011121314151617[root@k8s02 ~]# showmount -e 192.168.43.101Export list for 192.168.43.101:/nfsdata *[root@k8s02 ~]# mkdir /testnfs/[root@k8s02 ~]# mount -t nfs 192.168.43.101:/nfsdata /testnfs/[root@k8s02 ~]# df -h #节选Filesystem Size Used Avail Use% Mounted on192.168.43.101:/nfsdata 17G 3.9G 14G 23% /testnfs $ umount /testnfs/umount.nfs4: /testnfs: device is busy$ cd ~$ umount /testnfs/$ rm -rf /testnfs/ 部署 PV123456789101112131415apiVersion: v1kind: PersistentVolumemetadata: name: pv0003spec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain # 回收策略 storageClassName: nfs # 类名称 PV 和 PVC 的 storageClassName 字段必须一样 nfs: path: /nfsdata server: 192.168.43.101 eg:12345[root@k8s01 ~]# kubectl apply -f pv-example.yamlpersistentvolume/pv0003 created[root@k8s01 ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv0003 5Gi RWO Retain Available nfs 35s 创建服务并使用 PVC 一个典型、完整可用的 StatefulSet 通常由三个组件构成： Headless Service 、 StatefulSet 和 volumeClaimTemplate 。其中，Headless Service 用于为 Pod 资源标识符生成可解析的 DNS 资源记录，StatefulSet 用于管控 Pod 资源，volumeClaimTemplate 则基于静态或动态的PV供给方式为Pod资源提供专有且固定的存储。 StatefulSet-example.yaml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647apiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx---apiVersion: apps/v1kind: StatefulSet # 使用 StatefulSet 必须先建立一个 无头服务metadata: name: webspec: selector: matchLabels: app: nginx serviceName: &quot;nginx&quot; replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 name: web volumeMounts: - name: www # 与下面对应 mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: [&quot;ReadWriteOnce&quot;] storageClassName: &quot;nfs&quot; # PV 和 PVC 的 storageClassName 字段必须一样 resources: requests: storage: 1Gi 因为只能绑定 1个 PV1234567891011121314[root@k8s01 ~]# kubectl apply -f StatefulSet-example.yamlservice/nginx createdstatefulset.apps/web created[root@k8s01 ~]# kubectl get pod # 有序部署 0，1，2 (0完成后才部署1)NAME READY STATUS RESTARTS AGEweb-0 1/1 Running 0 12sweb-1 0/1 Pending 0 10s # 一直处于 Pending 状态## 节选，发现绑定不了 PVEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 28s (x3 over 101s) default-scheduler running &quot;VolumeBinding&quot; filter plugin for pod &quot;web-1&quot;: pod has unbound immediate PersistentVolumeClaims pv-example-more.yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263apiVersion: v1kind: PersistentVolumemetadata: name: pv01spec: capacity: storage: 2Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain # 回收策略 storageClassName: nfs # 类名称 nfs: path: /nfsdata01 server: 192.168.43.101---apiVersion: v1kind: PersistentVolumemetadata: name: pv02spec: capacity: storage: 1Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain # 回收策略 storageClassName: test # 类名称 nfs: path: /nfsdata02 server: 192.168.43.101---apiVersion: v1kind: PersistentVolumemetadata: name: pv03spec: capacity: storage: 1Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain # 回收策略 storageClassName: nfs # 类名称 nfs: path: /nfsdata03 server: 192.168.43.101---apiVersion: v1kind: PersistentVolumemetadata: name: pv04spec: capacity: storage: 1Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain # 回收策略 storageClassName: nfs # 类名称 nfs: path: /nfsdata04 server: 192.168.43.101 123456789101112131415161718192021222324252627[root@k8s01 ~]# mkdir /nfsdata&#123;01,02,03,04&#125;root@k8s01 ~]# kubectl apply -f pv-example-more.yamlpersistentvolume/pv01 createdpersistentvolume/pv02 createdpersistentvolume/pv03 createdpersistentvolume/pv04 created[root@k8s01 ~]# chmod 666 /nfsdata&#123;01,02,03,04&#125;[root@k8s01 ~]# chown nfsnobody /nfsdata&#123;01,02,03,04&#125;[root@k8s01 ~]# kubectl describe pod web-0 # 报错 因为 没执行 echo &quot;/nfsdata01 *(rw,no_root_squash,no_all_squash,sync)&quot; &gt;&gt; /etc/exports## systemctl restart rpcbind## systemctl restart nfs## 节选Events: Type Reason Age From Message ---- ------ ---- ---- -------Mounting command: systemd-runMounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/6c4be93c-fb32-4891-821e-817a7853c4c5/volumes/kubernetes.io~nfs/pv01 --scope -- mount -t nfs 192.168.43.101:/nfsdata01 /var/lib/kubelet/pods/6c4be93c-fb32-4891-821e-817a7853c4c5/volumes/kubernetes.io~nfs/pv01Output: Running scope as unit run-51115.scope.mount.nfs: access denied by server while mounting 192.168.43.101:/nfsdata01 Warning FailedMount 55s kubelet, k8s03 MountVolume.SetUp failed for volume &quot;pv01&quot; : mount failed: exit status 32Mounting command: systemd-runMounting arguments: --description=Kubernetes transient mount for /var/lib/kubelet/pods/6c4be93c-fb32-4891-821e-817a7853c4c5/volumes/kubernetes.io~nfs/pv01 --scope -- mount -t nfs 192.168.43.101:/nfsdata01 /var/lib/kubelet/pods/6c4be93c-fb32-4891-821e-817a7853c4c5/volumes/kubernetes.io~nfs/pv01Output: Running scope as unit run-51258.scope.mount.nfs: access denied by server while mounting 192.168.43.101:/nfsdata01 Warning FailedScheduling 25s (x2 over 25s) default-scheduler running &quot;VolumeBinding&quot; filter plugin for pod &quot;web-0&quot;: pod has unbound immediate PersistentVolumeClaims Normal Scheduled 23s default-scheduler Successfully assigned default/web-0 to k8s03 12345678910111213141516[root@k8s01 ~]# kubectl get pod # 有序部署 0，1，2NAME READY STATUS RESTARTS AGEweb-0 1/1 Running 0 10sweb-1 1/1 Running 0 7sweb-2 1/1 Running 0 3s[root@k8s01 ~]# kubectl get pvcNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGEwww-web-0 Bound pv01 2Gi RWO nfs 65swww-web-1 Bound pv03 2Gi RWO nfs 62swww-web-2 Bound pv04 2Gi RWO nfs 58s[root@k8s01 ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv01 2Gi RWO Retain Bound default/www-web-0 nfs 3m58spv02 2Gi RWO Retain Available test 3m58spv03 2Gi RWO Retain Bound default/www-web-1 nfs 3m58spv04 2Gi RWO Retain Bound default/www-web-2 nfs 3m58s 123456789101112131415161718192021222324252627282930313233[root@k8s01 ~]# kubectl get pod # 有序删除 2，1，0web-2 1/1 Terminating 0 9sweb-1 1/1 Terminating 0 11sweb-0 0/1 Terminating 0 13s[root@k8s01 ~]# kubectl edit pv pv01Edit cancelled, no changes made.[root@k8s01 ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv01 2Gi RWO Retain Bound default/www-web-0 nfs 11mpv02 2Gi RWO Retain Available test 11mpv03 2Gi RWO Retain Bound default/www-web-1 nfs 11mpv04 2Gi RWO Retain Bound default/www-web-2 nfs 11m[root@k8s01 ~]# kubectl edit pv pv01## 删除以下字段解除绑定 claimRef: apiVersion: v1 kind: PersistentVolumeClaim name: www-web-0 namespace: default resourceVersion: &quot;322074&quot; uid: 9cb4adcc-01ba-4a4f-9bf0-205bcb3a9b9epersistentvolume/pv01 edited[root@k8s01 ~]# kubectl get pvNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEpv01 2Gi RWO Retain Available nfs 12mpv02 2Gi RWO Retain Available test 12mpv03 2Gi RWO Retain Bound default/www-web-1 nfs 12mpv04 2Gi RWO Retain Bound default/www-web-2 nfs 12m 关于 StatefulSet 匹配 Pod name ( 网络标识 ) 的模式为：$(statefulset名称)-$(序号)，比如上面的示例：web-0，web-1，web-2 StatefulSet 为每个 Pod 副本创建了一个 DNS 域名，这个域名的格式为： $(podname).(headless servername)，也就意味着服务间是通过Pod域名来通信而非 Pod IP，因为当 Pod 所在 Node 发生故障时， Pod 会被飘移到其它 Node 上，Pod IP 会发生变化，但是 Pod 域名不会有变化 StatefulSet 使用 Headless 服务来控制 Pod 的域名，这个域名的 FQDN 为：$(servicename).$(namespace).svc.cluster.local，其中，cluster.local 指的是集群的域名 根据 volumeClaimTemplates，为每个 Pod 创建一个 pvc，pvc 的命名规则匹配模式：(volumeClaimTemplates.name)-(pod_name)，比如上面的 volumeMounts.name=www， Podname=web-[0-2]，因此创建出来的 PVC 是 www-web-0、www-web-1、www-web-2 删除 Pod 不会删除其 pvc，手动删除 pvc 将自动释放 pv 1234567891011121314151617181920212223242526[root@k8s01 /]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESweb-0 1/1 Running 0 5m31s 172.18.235.136 k8s03 &lt;none&gt; &lt;none&gt;web-1 1/1 Running 0 5m29s 172.18.235.145 k8s03 &lt;none&gt; &lt;none&gt;web-2 1/1 Running 0 5m27s 172.18.235.146 k8s03 &lt;none&gt; &lt;none&gt;[root@k8s01 /]# curl 172.18.235.136 # 因为权限为 666 访问 拒绝，设置为 777&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.7.9&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@k8s01 /]# curl 172.18.235.136 test # pv01 对应的 k8s 上 /nfsdata01/index.html[root@k8s01 /]# kubectl delete pod web-0pod &quot;web-0&quot; deleted[root@k8s01 /]# kubectl get pod -o wide # web-0 自动重新生成， ip会变，文件不变NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESweb-0 1/1 Running 0 4s 172.18.235.155 k8s03 &lt;none&gt; &lt;none&gt;web-1 1/1 Running 0 19m 172.18.235.145 k8s03 &lt;none&gt; &lt;none&gt;web-2 1/1 Running 0 19m 172.18.235.146 k8s03 &lt;none&gt; &lt;none&gt;[root@k8s01 /]# curl 172.18.235.155test 123456789101112[root@k8s01 /]# kubectl exec web-2 -it -- /bin/bashroot@web-2:/# ping web-0.nginx # Pod 域名不会有变化PING web-0.nginx.default.svc.cluster.local (172.18.235.155): 48 data bytes56 bytes from 172.18.235.136: icmp_seq=0 ttl=63 time=0.075 ms56 bytes from 172.18.235.136: icmp_seq=1 ttl=63 time=0.113 ms56 bytes from 172.18.235.155: icmp_seq=2 ttl=63 time=0.082 ms56 bytes from 172.18.235.155: icmp_seq=0 ttl=63 time=0.075 ms56 bytes from 172.18.235.155: icmp_seq=1 ttl=63 time=0.113 ms56 bytes from 172.18.235.155: icmp_seq=2 ttl=63 time=0.082 ms^C--- web-0.nginx.default.svc.cluster.local ping statistics ---3 packets transmitted, 3 packets received, 0% packet lossround-trip min/avg/max/stddev = 0.075/0.090/0.113/0.000 ms 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@k8s01 /]# kubectl get pod -o wide --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESdefault web-0 1/1 Running 0 11m 172.18.235.155 k8s03 &lt;none&gt; &lt;none&gt;default web-1 1/1 Running 0 31m 172.18.235.145 k8s03 &lt;none&gt; &lt;none&gt;default web-2 1/1 Running 0 31m 172.18.235.146 k8s03 &lt;none&gt; &lt;none&gt;ingress-nginx nginx-ingress-controller-5bb8fb4bb6-lwlw7 1/1 Running 6 8d 172.18.235.189 k8s03 &lt;none&gt; &lt;none&gt;kube-system calico-kube-controllers-76d4774d89-rltpc 1/1 Running 18 30d 172.18.73.123 k8s01 &lt;none&gt; &lt;none&gt;kube-system calico-node-5xqsz 1/1 Running 19 35d 192.168.43.103 k8s03 &lt;none&gt; &lt;none&gt;kube-system calico-node-cwv6n 1/1 Running 156 35d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system calico-node-pfpr4 1/1 Running 17 35d 192.168.43.102 k8s02 &lt;none&gt; &lt;none&gt;kube-system coredns-7ff77c879f-7frh7 1/1 Running 20 35d 172.18.73.121 k8s01 &lt;none&gt; &lt;none&gt;kube-system coredns-7ff77c879f-hlzpn 1/1 Running 19 35d 172.18.73.122 k8s01 &lt;none&gt; &lt;none&gt;kube-system etcd-k8s01 1/1 Running 19 35d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-apiserver-k8s01 1/1 Running 22 35d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-controller-manager-k8s01 1/1 Running 20 35d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-hmlxx 1/1 Running 18 35d 192.168.43.103 k8s03 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-nh96k 1/1 Running 17 35d 192.168.43.102 k8s02 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-x57zq 1/1 Running 19 35d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-scheduler-k8s01 1/1 Running 20 35d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;[root@k8s01 /]# dig -t A nginx.default.svc.cluster.local. @172.18.73.121 # `StatefulSet` 使用 `Headless` 服务来控制 `Pod` 的域名，这个域名的 `FQDN` 为：`$(servicename).$(namespace).svc.cluster.local`，其中，`cluster.local` 指的是集群的域名 172.18.73.121 是 coreDns的ip; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-16.P2.el7_8.6 &lt;&lt;&gt;&gt; -t A nginx.default.svc.cluster.local. @172.18.73.121;; global options: +cmd;; Got answer:;; WARNING: .local is reserved for Multicast DNS;; You are currently testing what happens when an mDNS query is leaked to DNS;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 44346;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; WARNING: recursion requested but not available;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;nginx.default.svc.cluster.local. IN A;; ANSWER SECTION:nginx.default.svc.cluster.local. 30 IN A 172.18.235.145nginx.default.svc.cluster.local. 30 IN A 172.18.235.146nginx.default.svc.cluster.local. 30 IN A 172.18.235.155;; Query time: 37 msec;; SERVER: 172.18.73.121#53(172.18.73.121);; WHEN: Mon Aug 31 18:20:00 EDT 2020;; MSG SIZE rcvd: 201[root@k8s01 ~]# nslookup nginx.default.svc.cluster.local. 172.18.73.121 # 同上Server: 172.18.73.121Address: 172.18.73.121#53Name: nginx.default.svc.cluster.localAddress: 172.18.235.145Name: nginx.default.svc.cluster.localAddress: 172.18.235.146Name: nginx.default.svc.cluster.localAddress: 172.18.235.155 Statefulset的启停顺序 有序部署：部署StatefulSet时，如果有多个Pod副本，它们会被顺序地创建（从0到N-1）并且，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态。 有序删除：当Pod被删除时，它们被终止的顺序是从N-1到0。 有序扩展：当对Pod执行扩展操作时，与部署一样，它前面的Pod必须都处于Running和Ready状态。 StatefulSet使用场景 稳定的持久化存储，即 Pod 重新调度后还是能访问到相同的持久化数据，基于 PVC 来实现。 稳定的网络标识符，即 Pod 重新调度后其 PodName 和 HostName 不变。 有序部署，有序扩展，基于 init containers 来实现。 有序收缩。]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Volume]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FVolume%2F</url>
    <content type="text"><![CDATA[Volume容器销毁时，保存在容器内部文件系统中的数据会被清除，为了持久化保存容器数据，可以使用 Kubernetes Volum。 Volum 生命周期独立于容器， Pod 中容器可能销毁重建，但 Volume 会被保留。 emptyDir一个 emptyDir Volume 是 Host 上的一个空目录。 emptyDir Volume 对容器是持久的。但 Pod 从节点删除时，Volume 的内容也会被删除。容器销毁而 Pod 还在，则 Volume 不受影响。 emptyDir Volume 的生命周期与 Pod 一致。 emptyDir 的用法有： 暂存空间，例如用于基于磁盘的合并排序 用作长时间计算崩溃恢复时的检查点 Web服务器容器提供数据时，保存内容管理器容器提取的文件 emptyDir-example.yaml123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: nginx:1.7.9 name: test-container01 volumeMounts: - mountPath: /cache name: cache-volume - name: test-container02 image: busybox:1.32.0 imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;sleep 3600&quot;] volumeMounts: - mountPath: /test name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; 12345678910111213141516171819202122232425262728[root@k8s01 ~]# kubectl apply -f emptyDir-example.yamlpod/test-pd created[root@k8s01 ~]# kubectl get podNAME READY STATUS RESTARTS AGEtest-pd 2/2 Running 0 3s[root@k8s01 ~]# kubectl exec test-pd -c test-container01 -it -- /bin/bash # 进入test-container01 下的/cache 目录root@test-pd:/# cd cache/root@test-pd:/cache# date &gt;&gt; index.txtroot@test-pd:/cache# cat index.txtMon Aug 31 17:03:13 UTC 2020### 新开一个窗口[root@k8s01 ~]# kubectl exec test-pd -c test-container02 -it -- /bin/sh # 进入test-container02 下的 /test 目录/ # cd test/test # ls # 发现与 test-container01 下的 /cache 目录 文件内容相同index.txt/test # cat index.txtMon Aug 31 17:03:13 UTC 2020/test # date &gt;&gt; index.txt/test # cat index.txtMon Aug 31 17:03:13 UTC 2020Mon Aug 31 17:05:43 UTC 2020### 第一个窗口root@test-pd:/cache# cat index.txt # 内容也同步更新Mon Aug 31 17:03:13 UTC 2020Mon Aug 31 17:05:43 UTC 2020 hostPathhostPath Volume 将 DOcker Host 文件系统中已经存在的目录 mount 给 Pod 的容器。一般不会使用，因为增加了 Pod 与节点的耦合，限制了 Pod 的使用。不过 那些需要访问 k8s, Docker 内部数据的应用则需要使用 hostPath。 eg: kube-apisrver、kube-controller-manager等 kubectl edit --namespace=kube-system pod kube-apiserver-k8s-master 查看 kube-apiserver Pod 的配置。 Pod 销毁，hostPath 对应的目录还会保留。 但 Host 崩溃，hostPath 就无法访问了。 使用这种卷类型是请注意 因为：由于每个节点上的文件都不同，具有相同配置（例如从 podTemplate 创建的）的 pod 在不同节点上的行为可能会有所不同 当 Kubernetes 按照计划添加资源感知调度时，将无法考虑 hostPath 使用的资源 在底层主机上创建的文件或目录只能由 root 写入。您需要在特权容器中以 root 身份运行进程，或修改主机上的文件权限以便写入 hostPath 卷 hostPath-example.yaml123456789101112131415161718apiVersion: v1kind: Podmetadata: name: test-pdspec: containers: - image: nginx:1.7.9 name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume hostPath: # directory location on host path: /data # this field is optional type: Directory 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@k8s01 ~]# kubectl apply -f hostPath-example.yamlpod/test-pd02 created[root@k8s01 ~]# kubectl get pod # 一直处于 ContainerCreatingNAME READY STATUS RESTARTS AGEtest-pd 2/2 Running 0 19mtest-pd02 0/1 ContainerCreating 0 16s[root@k8s01 ~]# kubectl describe pod test-pd02 # 查看日志，发现是因为 k8s03上没有 /data 目录[root@k8s03 ~]# mkdir /data[root@k8s01 ~]# kubectl describe pod test-pd02 # 节选Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 4m42s default-scheduler Successfully assigned default/test-pd02 to k8s03 Warning FailedMount 3m38s (x8 over 4m41s) kubelet, k8s03 MountVolume.SetUp failed for volume &quot;test-volume&quot; : hostPath type check failed: /data is not a directory Warning FailedMount 2m39s kubelet, k8s03 Unable to attach or mount volumes: unmounted volumes=[test-volume], unattached volumes=[test-volume default-token-rr77c]: timed out waiting for the condition Normal Pulled 2m26s kubelet, k8s03 Container image &quot;nginx:1.7.9&quot; already present on machine Normal Created 2m26s kubelet, k8s03 Created container test-container Normal Started 2m26s kubelet, k8s03 Started container test-container[root@k8s01 ~]# kubectl exec test-pd02 -it -- /bin/bash root@test-pd02:/# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin selinux srv sys test-pd tmp usr varroot@test-pd02:/# cd test-pd/root@test-pd02:/test-pd# date &gt;&gt; index.txtroot@test-pd02:/test-pd# cat index.txtMon Aug 31 17:25:09 UTC 2020[root@k8s03 ~]# cat /data/index.txt # /data 下已有 index.txt 文件，内容相同Mon Aug 31 17:25:09 UTC 2020[root@k8s03 ~]# date &gt;&gt; /data/index.txt # /data/index.txt 写入[root@k8s03 ~]# cat /data/index.txtMon Aug 31 17:25:09 UTC 2020Mon Aug 31 13:27:03 EDT 2020root@test-pd02:/test-pd# cat index.txt # 容器内也是相同内容Mon Aug 31 17:25:09 UTC 2020Mon Aug 31 13:27:03 EDT 2020[root@k8s01 ~]# kubectl delete pod test-pd02 # 删除 Podpod &quot;test-pd02&quot; deleted[root@k8s03 ~]# cat /data/index.txt # 文件还在 k8s03 节点存在Mon Aug 31 17:25:09 UTC 2020Mon Aug 31 13:27:03 EDT 2020 补当一个 Pod 调度到一个节点上之后，kubelet 就要负责为这个 Pod 创建它的 Volume 目录。默认情况下，kubelet 为 Volume 创建的目录是如下所示的一个宿主机上的路径： 1/var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt; 接下来，kubelet 要做的操作就取决于 Volume 类型。 eg: 远程磁盘 attach ： 将远程磁盘挂载到 pod 所在 node 节点上 （nfs 等不在远程的，可以直接执行第二步）（nodeName，即宿主机的名字。） mount : 格式化此磁盘，然后将它挂载到宿主机的指定挂载点 (dir，即 Volume 的宿主机目录) 1234567891011# 过程类似于：# 第一步$ gcloud compute instances attach-disk &lt;虚拟机名字&gt; --disk &lt;远程磁盘名字&gt;# 第二步# 通过lsblk命令获取磁盘设备ID$ sudo lsblk# 格式化成ext4格式$ sudo mkfs.ext4 -m 0 -F -E lazy_itable_init=0,lazy_journal_init=0,discard /dev/&lt;磁盘设备ID&gt;# 挂载到挂载点$ sudo mkdir -p /var/lib/kubelet/pods/&lt;Pod的ID&gt;/volumes/kubernetes.io~&lt;Volume类型&gt;/&lt;Volume名字&gt;]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ansible简介]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fansible%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[ansible 安装1. git安装123git clone git://github.com/ansible/ansible.git --recursive cd ./ansible source ./hacking/env-setup 2. yum/apt 安装1yum/apt install ansible 3. pip 安装1234yum install python3-pip python3-develyum install gcc glibc-devel zibl-devel rpm-bulid openssl-devel pip3 install --upgrade pip3 pip3 install ansible --upgrade 确认安装1234567root@DESKTOP-R0OV00O:/etc/ansible# ansible --versionansible 2.9.6 config file = /etc/ansible/ansible.cfg configured module search path = [&apos;/root/.ansible/plugins/modules&apos;, &apos;/usr/share/ansible/plugins/modules&apos;] ansible python module location = /usr/lib/python3/dist-packages/ansible executable location = /usr/bin/ansible python version = 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0] ansible 相关文件123/etc/ansible/ansible.cfg 主配置文件，配置ansible工作特性 /etc/ansible/hosts 主机清单 /etc/ansible/roles/ 存放角色的目录 ansible.cfg 详解1234567891011121314[defaults] inventory = /etc/ansible/hosts # 主机列表配置文件 library = /usr/share/my_modules/ # 库⽂件存放目录 remote_tmp = $HOME/.ansible/tmp #临时py命令文件存放在远程主机目录 # 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY 文件local_tmp = $HOME/.ansible/tmp # 本机的临时命令执目录 forks = 5 # 默认并发数 sudo_user = root # 默认sudo 用户 ask_sudo_pass = True #每次执行ansible命令是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False # 检查对应服务器的host_key，默认 True, 建议使用 False log_path=/var/log/ansible.log #日志文件路径，建议启用module_name = command #默认模块，可以修改为shell模块 inventory 主机清单示例123456789101112131415161718192021222324252627[k8s]192.168.43.10[1:5] # 即为 192.168.43.101,192.168.43.102,192.168.43.103,192.168.43.104,192.168.43.105[k8s_master]192.168.43.101192.168.43.104192.168.43.105[k8s_node]192.168.43.102192.168.43.103[vps]tj.imwl.ml:8822 # 加端口号 api.imwl.ga [password]192.168.43.10[1:5] ansible_ssh_user=root ansible_ssh_pass=12345678 # 账号密码# vars 是固定关键字写法[k8s_node:vars] ansible_ssh_user=root ansible_ssh_pass=12345678[vps:vars]ansible_ssh_user=rootansible_ssh_pass=123456 ansile 主要命令12345678910/usr/bin/ansible 主程序，临时命令执行工具 /usr/bin/ansible-config /usr/bin/ansible-connection /usr/bin/ansible-console 基于Console界面与用户交互的执行工具/usr/bin/ansible-doc 查看配置文档，模块功能查看工具 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-inventory /usr/bin/ansible-playbook 定制自动化任务，编排剧本⼯具 /usr/bin/ansible-pull 远程执行命令的工具 /usr/bin/ansible-vault 文件加密工具 ansible 命令执行过程 加载自己的配置文件默认/etc/ansible/ansible.cfg 加载自己对应的模块文件，如：command 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 给文件+x执行 执行并返回结果 删除临时py文件，退出 实战配置无秘登录192.168.100[1:200]1234567#!/bin/bash ssh-keygen -f /root/.ssh/id_rsa -P &apos;&apos; NET=192.168.100 export SSHPASS=password for IP in &#123;1..200&#125;;do sshpass -e ssh-copy-id $NET.$IP done Playbook核心元素Hosts : 执行的远程主机列表 Tasks : 任务集 Variables : 内置变量或自定义变量在playbook中调用 Templates : 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers和notify结合使用 : 由特定条件触发的操作，满足条件方才执行，否则不执行 tag : 标签, 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断 templetesrolesroles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中，并可以便捷地include它们的一种机制。角色一般用于基于主机构建服务的场景 每个角色，以特定的层级目录结构进行组织 roles目录结构：playbook.ymlroles/ project/ tasks/ files/ vars/ templates/ handlers/ default/ meta/ Roles各目录作用：roles/project : 项目名称 roles/project/:项目名称,有以下子目录 files/：存放由copy或script模块等调用的文件 templates/：template模块查找所需要模板文件的目录 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件；其它的文件需要在此文件中通过include进行包含 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件，其它文件需在此文件中通过include进行包含 default/：设定默认变量时使用此目录中的main.yml文件，比vars的优先级低 roles的目录结构 nginx-role.yml roles/ └──nginx ├──files │ └──main.yml ├──tasks │ ├──groupadd.yml │ ├──install.yml │ ├──main.yml │ ├──restart.yml │ └──useradd.yml └──vars └──main.yml role 测试#nginx-role.yml hosts:websrvsremote_user:rootroles: -{role:nginx,tags:[‘nginx’,’web’],when:ansible_distribution_major_version==”6“} -{role:httpd,tags:[‘httpd’,’web’]}-{role:mysql,tags:[‘mysql’,’db’]} -{role:mariadb,tags:[‘mariadb’,’db’]} ansible-playbook –tags=”nginx,httpd,mysql” nginx-role.yml]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[secret]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fsecret%2F</url>
    <content type="text"><![CDATA[Secret 存在意义Secret 解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者 Pod Spec中。Secret 可以以 Volume 或者环境变量的方式使用. Secret 有三种类型 Service Account：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中 Opaque：base64 编码格式的 Secret，用来存储密码、密钥等 # 也可用别的加密方式 kubernetes.io/dockerconfigjson：用来存储私有 docker registry 的认证信息 Service AccountService Account 用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中 示例12345678910111213141516171819202122232425262728293031323334[root@k8s01 storage]# kubectl run nginx --image nginx:1.7.9pod/nginx created[root@k8s01 storage]# kubectl get podsNAME READY STATUS RESTARTS AGEmy-nginx-test-59bf4fc6f8-4xsdz 1/1 Running 0 6m8snginx 1/1 Running 0 14stest-pod 0/1 Completed 0 55mtest-pod02 0/1 Completed 0 44mtest-pod03 0/1 Completed 0 35m[root@k8s01 storage]# kubectl exec nginx -it -- ls /run/secrets/kubernetes.io/serviceaccountca.crt namespace token[root@k8s01 storage]# kubectl exec nginx -it -- cat /run/secrets/kubernetes.io/serviceaccount/ca.crt-----BEGIN CERTIFICATE-----MIICyDCCAbCgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTIwMDcyNzE3MzQxNFoXDTMwMDcyNTE3MzQxNFowFTETMBEGA1UEAxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMOGz5wpcDPU642BeC/fj6IHUatrxJIu0xyvhXfK9NAA6qKenl0qiiKIWD2grSg6X8led0CRJuslM+WGnq6d68G6NMZ3/MDpPwgXM0k4MttYyfo3mngBmtvEbFryoKoeulkqVSszYmNozsffjniH+tAEp7yitM5U0YrrnQFGozpiz2mQ+2RTvIBG0YOrQ1xjTnDWVSk+zqsNwpsCR18ebd1rrewatW0QZxOs1yGjNmNv+4lXodHLPKwUUewHRNnZn3vSjTf1cz77F0RHtel6bmZ8uhQ+SzpL6lT3/eykJvtGrIEpp1Vg2AfHU9Hc6IP3WYMlMG88R8kjgjRaAMz8khMCAwEAAaMjMCEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBALi84N2GXQ6Qs3X3SKHfBumNJzb1sK38r0+w34r+Gzlr+kRictSyv/wTc8KUHTUGXaGCRyrZOWmreDhA7ilRNN6OzRCpTgaI9bSWbgVbszroXPg12arri+ixytW1iZAZj0FIqi8v0oyIH6YIAS+U5d8npAy9FyWBnzfg0StMjyLmh5f3pUQoxWNWRy5YOYGWZSsAhqBD3dNg+2Uor69Q0fmyJC1yrZlsUDYl4A70KWKNXfTtiRs6JfB3N9haWxmnkliC7sJ8A6bjAhgrVJYpEBThNdikhLeJhX8fCW/EyGeYNc3qPbrzza++sIZ5acSKKsX4I/vbhaqhVI/LYb9Imc4=-----END CERTIFICATE-----[root@k8s01 storage]# kubectl exec nginx -it -- cat /run/secrets/kubernetes.io/serviceaccount/tokeneyJhbGciOiJSUzI1NiIsImtpZCI6InZoTHNXRWwtZWU0NmswNnNvV3c0YWlyYVpZLUNaWm9sMWY5OGhzSkxveFUifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tcnI3N2MiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImNjNzUwZGVjLTY4ZTYtNDcxYi1hMmVmLWZhZjFiMDYxYzFhZCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.UJYnr8KaB59ZF0wefTnh-3W3b20ftBBSw-46ghkl20aWVeK7pFxwjlcCWgp_3dG2jHn9dHtWa1DTemr05rpse0Xu_C029sJ4NlYSIwfR3lZ_K3lOuei6svAg2Aal_M5F8RdlcAvVvHn6TDEEH1VViM1-0uYQNF3p88vCKVFAkbRxQj6b-viAXeF1rlmLSgcB3qpU_xpKtFTqTJ6VvMQEw90eC2RwIxNhQgZPnNaeQsanoOlPC9DRkLPeA_ZYdys-e1_me3Gm5NeYsCBAbyfofufQ3BLMkXw0bfpiWK4VesfX-9Z7p1t3tKxYCZrsLIuSuj-O7Sc5qef89lwxYvcfKw[root@k8s01 storage]# kubectl exec nginx -it -- cat /run/secrets/kubernetes.io/serviceaccount/namespacedefault Opaque Secret创建说明Opaque 类型的数据是一个 map 类型，要求 value 是 base64 编码格式： 123456[root@k8s01 storage]# echo -n &quot;admin&quot; | base64 # 加密，并不牢靠YWRtaW4=[root@k8s01 storage]# echo -n &quot;password&quot; | base64cGFzc3dvcmQ=[root@k8s01 storage]# echo -n &quot;cGFzc3dvcmQ=&quot; | base64 -d # 解密password secrets.yaml12345678apiVersion: v1kind: Secretmetadata: name: mysecrettype: Opaquedata: password: cGFzc3dvcmQ= username: YWRtaW4= 123456[root@k8s01 storage]# kubectl apply -f secrets.yamlsecret/mysecret created[root@k8s01 storage]# kubectl get secretNAME TYPE DATA AGEdefault-token-rr77c kubernetes.io/service-account-token 3 32dmysecret Opaque 2 5s 使用方式 将 Secret 挂载到 Volume 中 Secret-Volume.yaml123456789101112131415161718apiVersion: v1kind: Podmetadata: labels: name: seret-test name: seret-testspec: volumes: - name: secrets secret: secretName: mysecret containers: - image: nginx:1.7.9 name: db volumeMounts: - name: secrets mountPath: &quot;/etc/secrets&quot; readOnly: true 12345678910111213[root@k8s01 storage]# kubectl apply -f Secret-Volume.yamlpod/seret-test created[root@k8s01 storage]# kubectl get podNAME READY STATUS RESTARTS AGEseret-test 1/1 Running 0 43s[root@k8s01 storage]# kubectl exec seret-test -it -- /bin/bashroot@seret-test:/# cd /etc/secrets/root@seret-test:/etc/secrets# lspassword usernameroot@seret-test:/etc/secrets# cat password # 已解密passwordroot@seret-test:/etc/secrets# cat usernameadmin 将 Secret 导出到环境变量中test-secert-deployment.yaml123456789101112131415161718192021222324252627282930apiVersion: apps/v1kind: Deploymentmetadata: name: pod-deploymentspec: replicas: 2 selector: matchLabels: app: pod-deployment template: metadata: labels: app: pod-deployment spec: containers: - name: pod-1 image: nginx:1.7.9 ports: - containerPort: 80 env: - name: TEST_USER valueFrom: secretKeyRef: name: mysecret key: username - name: TEST_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password 12345678910[root@k8s01 storage]# kubectl apply -f test-secert-deplyment.yamldeployment.apps/pod-deployment created[root@k8s01 storage]# kubectl get podNAME READY STATUS RESTARTS AGEpod-deployment-c97f4b999-2q4t9 1/1 Running 0 2m32spod-deployment-c97f4b999-6nnx8 1/1 Running 0 2m32sseret-test 1/1 Running 0 6m49s[root@k8s01 storage]# kubectl exec pod-deployment-c97f4b999-2q4t9 -it -- /bin/bash root@pod-deployment-c97f4b999-2q4t9:/# echo $TEST_USER $TEST_PASSWORD # 查看环境变量admin password kubernetes.io/dockerconfigjson123456789101112131415161718192021222324[root@k8s01 storage]# docker pull imwl/test:0.14 # 我自己的私有镜像 不登录 pull 失败Error response from daemon: pull access denied for imwl/test, repository does not exist or may require &apos;docker login&apos;: denied: requested access to the resource is denied[root@k8s01 storage]# docker login # 登录Login with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one.Username: imwlPassword:WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded[root@k8s01 storage]# docker pull imwl/test:0.14 # 登录后可 pull 成功0.14: Pulling from imwl/testdc65f448a2e2: Pull completeDigest: sha256:97b496724012eee3df3421edb2ab6edcd6115e42b8060c24ba06b51da466e0ddStatus: Downloaded newer image for imwl/test:0.14docker.io/imwl/test:0.14[root@k8s01 storage]# docker rmi imwl/test:0.14 # 删除镜像Untagged: imwl/test:0.14Untagged: imwl/test@sha256:97b496724012eee3df3421edb2ab6edcd6115e42b8060c24ba06b51da466e0ddDeleted: sha256:69c1c6c58124c56456a22c92a2e2125c9abc744f6acde379f5039779becbcc29Deleted: sha256:ce8168f123378f7e04b085c9672717013d1d28b2aa726361bb132c1c64fe76ac[root@k8s01 storage]# docker logout # 退出登录Removing login credentials for https://index.docker.io/v1/ 使用 Kuberctl 创建 docker registry 认证的 secret 123kubectl create secret docker-registry myregistrykey --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAILsecret &quot;myregistrykey&quot; created. 在创建 Pod 的时候，通过 imagePullSecrets 来引用刚创建的 myregistrykey pod-dockerconfigjson.yaml12345678910apiVersion: v1kind: Podmetadata: name: foospec: containers: - name: foo image: imwl/test:0.14 imagePullSecrets: - name: myregistrykey 1234567891011[root@k8s01 storage]# kubectl create secret docker-registry myregistrykey --docker-username=imwl --docker-password=********** --docker-email=imwl@live.comsecret/myregistrykey created[root@k8s01 storage]# lsconfigMap secrets.yaml special-config.yaml test-pod02.yaml test-pod.yamlenv-config.yaml Secret-Volume.yaml test04.yaml test-pod03.yaml test-secert-deplyment.yaml[root@k8s01 storage]# vi pod-dockerconfigjson.yaml[root@k8s01 storage]# kubectl apply -f pod-dockerconfigjson.yamlpod/foo created[root@k8s01 storage]# kubectl get pod # 可以看到镜像已被下载NAME READY STATUS RESTARTS AGEfoo 0/1 Completed 2 79s]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[configMap]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FconfigMap%2F</url>
    <content type="text"><![CDATA[configMapConfigMap : 许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。ConfigMap API : 给我们提供了向容器中注入配置信息的机制，可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象 ConfigMap 的创建使用目录创建123456789101112131415161718192021222324252627282930313233343536373839404142$ mkdir configMap$ echo &quot;enemies=alienslives=3enemies.cheat=trueenemies.cheat.level=noGoodRottensecret.code.passphrase=UUDDLRLRBABASsecret.code.allowed=truesecret.code.lives=30&quot; &gt; configMap/game.properties$ echo &quot;color.good=purplecolor.bad=yellowallow.textmode=truehow.nice.to.look=fairlyNice&quot; &gt; configMap/ui.properties[root@k8s01 storage]# kubectl create configmap game-config --from-file=configMap/configmap/game-config created[root@k8s01 storage]# kubectl describe cm game-configName: game-configNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Data====game.properties:----enemies=alienslives=3enemies.cheat=trueenemies.cheat.level=noGoodRottensecret.code.passphrase=UUDDLRLRBABASsecret.code.allowed=truesecret.code.lives=30ui.properties:----color.good=purplecolor.bad=yellowallow.textmode=truehow.nice.to.look=fairlyNiceEvents: &lt;none&gt; --from-file 指定目录下的所有文件都会被用在 ConfigMap 里面创建一个键值对， 键的名字就是文件名，值就是文件的内容 使用文件创建只要指定为一个文件就可以从单个文件中创建 ConfigMap12345678910111213141516171819202122232425262728293031323334353637[root@k8s01 storage]# kubectl create configmap game-config-2 --from-file=configMap/game.properties --from-file=configMap/ui.propertiesconfigmap/game-config-2 created[root@k8s01 storage]# kubectl get configmaps game-config-2 -o yamlapiVersion: v1data: game.properties: | enemies=aliens lives=3 enemies.cheat=true enemies.cheat.level=noGoodRotten secret.code.passphrase=UUDDLRLRBABAS secret.code.allowed=true secret.code.lives=30 ui.properties: | color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNicekind: ConfigMapmetadata: creationTimestamp: &quot;2020-08-27T15:59:05Z&quot; managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: &#123;&#125; f:game.properties: &#123;&#125; f:ui.properties: &#123;&#125; manager: kubectl operation: Update time: &quot;2020-08-27T15:59:05Z&quot; name: game-config-2 namespace: default resourceVersion: &quot;235477&quot; selfLink: /api/v1/namespaces/default/configmaps/game-config-2 uid: c283cbf9-1eeb-49d8-8a1e-999099f4e97f --from-file 这个参数可以使用多次，你可以使用两次分别指定上个实例中的那两个配置文件，效果就跟指定整个目录是一样的 使用字面值创建使用文字值创建，利用--from-literal 参数传递配置信息，该参数可以使用多次，格式如下123456789101112131415161718192021222324252627282930313233343536373839404142[root@k8s01 storage]# kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charmconfigmap/special-config created[root@k8s01 storage]# kubectl get configmaps special-config -o yamlapiVersion: v1data: special.how: very special.type: charmkind: ConfigMapmetadata: creationTimestamp: &quot;2020-08-27T16:00:02Z&quot; managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:data: .: &#123;&#125; f:special.how: &#123;&#125; f:special.type: &#123;&#125; manager: kubectl operation: Update time: &quot;2020-08-27T16:00:02Z&quot; name: special-config namespace: default resourceVersion: &quot;235621&quot; selfLink: /api/v1/namespaces/default/configmaps/special-config uid: 7ab83245-87dc-41eb-be95-584d68ed259e[root@k8s01 storage]# kubectl describe cm special-configName: special-configNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Data====special.how:----veryspecial.type:----charmEvents: &lt;none&gt;[root@k8s01 storage 1234[root@k8s01 storage]# kubectl delete cm --allconfigmap &quot;game-config&quot; deletedconfigmap &quot;game-config-2&quot; deletedconfigmap &quot;special-config&quot; deleted Pod 中使用 ConfigMap使用 ConfigMap 来替代环境变量special-config.yaml12345678apiVersion: v1kind: ConfigMapmetadata: name: special-config namespace: defaultdata: special.how: very special.type: charm env-config.yaml1234567apiVersion: v1kind: ConfigMapmetadata: name: env-config namespace: defaultdata: log_level: INFO test-pod01.yaml123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: test-pod01spec: containers: - name: test-container image: nginx:1.7.9 command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;env&quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: - configMapRef: name: env-config restartPolicy: Never 12345678910111213141516171819202122232425262728[root@k8s01 storage]# kubectl apply -f special-config.yamlconfigmap/special-config created[root@k8s01 storage]# kubectl apply -f env-config.yamlconfigmap/env-config created[root@k8s01 storage]# kubectl logs test-pod # 已读取 configMapKUBERNETES_PORT=tcp://10.96.0.1:443KUBERNETES_SERVICE_PORT=443NGINX_SVC_SERVICE_HOST=10.109.24.218HOSTNAME=test-podHOME=/rootNGINX_SVC_PORT=tcp://10.109.24.218:80NGINX_SVC_SERVICE_PORT=80SPECIAL_TYPE_KEY=charm # charmNGINX_SVC_PORT_80_TCP_ADDR=10.109.24.218NGINX_SVC_PORT_80_TCP_PORT=80NGINX_SVC_PORT_80_TCP_PROTO=tcpKUBERNETES_PORT_443_TCP_ADDR=10.96.0.1NGINX_VERSION=1.7.9-1~wheezyPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binKUBERNETES_PORT_443_TCP_PORT=443KUBERNETES_PORT_443_TCP_PROTO=tcpNGINX_SVC_PORT_80_TCP=tcp://10.109.24.218:80SPECIAL_LEVEL_KEY=very # verylog_level=INFO # INFOKUBERNETES_SERVICE_PORT_HTTPS=443KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443KUBERNETES_SERVICE_HOST=10.96.0.1PWD=/ 用 ConfigMap 设置命令行参数test-pod02.yaml123456789101112131415161718192021apiVersion: v1kind: Podmetadata: name: test-pod02spec: containers: - name: test-container image: nginx:1.7.9 command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)&quot;] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never 12345678[root@k8s01 storage]# kubectl apply -f test-pod02.yamlpod/test-pod02 created[root@k8s01 storage]# kubectl get podNAME READY STATUS RESTARTS AGEtest-pod 0/1 Completed 0 10mtest-pod02 0/1 Completed 0 13s[root@k8s01 storage]# kubectl logs test-pod02very charm 通过数据卷插件使用ConfigMap在数据卷里面使用这个 ConfigMap，有不同的选项。最基本的就是将文件填入数据卷，在这个文件中，键就是文件名，键值就是文件内容test_pod03.yaml1234567891011121314151617apiVersion: v1kind: Podmetadata: name: test-pod03spec: containers: - name: test-container image: nginx:1.7.9 command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;sleep 600s&quot;] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never 12345[root@k8s01 storage]# kubectl exec test-pod03 -it -- /bin/bashroot@test-pod03:/# cat /etc/config/special.how # 文件名very # 文件内容root@test-pod03:/# cat /etc/config/special.typecharm ConfigMap 的热更新test04.yaml12345678910111213141516171819202122232425262728293031323334apiVersion: v1kind: ConfigMapmetadata: name: log-config namespace: defaultdata: log_level: INFO---apiVersion: apps/v1kind: Deploymentmetadata: name: my-nginx-testspec: replicas: 1 selector: matchLabels: run: my-nginx template: metadata: labels: run: my-nginx spec: containers: - name: my-nginx image: nginx:1.7.9 ports: - containerPort: 80 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: log-config 1234[root@k8s01 storage]# kubectl get pods -l run=my-nginx -o=name|cut -d &quot;/&quot; -f2my-nginx-test-59bf4fc6f8-lg2s2[root@k8s01 storage]# kubectl exec `kubectl get pods -l run=my-nginx -o=name|cut -d &quot;/&quot; -f2` -it -- cat /etc/config/log_levelINFO # 文件 /etc/config/log_level 的值为 INFO 修改 ConfigMap123456[root@k8s01 storage]# kubectl edit configmap log-config # 修改log_level的值为DEBUG等待大概 10 秒钟时间，再次查看环境变量的值configmap/log-config edited[root@k8s01 storage]# kubectl exec `kubectl get pods -l run=my-nginx -o=name|cut -d &quot;/&quot; -f2` -it -- cat /etc/config/log_levelINFO # 刚开始没变[root@k8s01 storage]# kubectl exec `kubectl get pods -l run=my-nginx -o=name|cut -d &quot;/&quot; -f2` -it -- cat /etc/config/log_levelDEBUG # 后来变成 DEBUG ConfigMap 更新后滚动更新 Pod更新 ConfigMap 目前并不会触发相关 Pod 的滚动更新，可以通过修改 pod annotations 的方式强制触发滚动更新123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384[root@k8s01 storage]# kubectl describe deployment my-nginx-testName: my-nginx-testNamespace: defaultCreationTimestamp: Thu, 27 Aug 2020 13:07:56 -0400Labels: &lt;none&gt;Annotations: deployment.kubernetes.io/revision: 1Selector: run=my-nginxReplicas: 1 desired | 1 updated | 1 total | 1 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: run=my-nginx Containers: my-nginx: Image: nginx:1.7.9 Port: 80/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: /etc/config from config-volume (rw) Volumes: config-volume: Type: ConfigMap (a volume populated by a ConfigMap) Name: log-config Optional: falseConditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: my-nginx-test-59bf4fc6f8 (1/1 replicas created)Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 37s deployment-controller Scaled up replica set my-nginx-test-59bf4fc6f8 to 1[root@k8s01 storage]# kubectl patch deployment my-nginx-test --patch &apos;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;:&#123;&quot;version/config&quot;: &quot;20200826&quot; &#125;&#125;&#125;&#125;&#125;&apos;deployment.apps/my-nginx-test patched[root@k8s01 storage]# kubectl describe deployment my-nginx-testName: my-nginx-testNamespace: defaultCreationTimestamp: Thu, 27 Aug 2020 12:50:33 -0400Labels: &lt;none&gt;Annotations: deployment.kubernetes.io/revision: 2Selector: run=my-nginxReplicas: 1 desired | 1 updated | 1 total | 1 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: run=my-nginx Annotations: version/config: 20200826 Containers: my-nginx: Image: nginx:1.7.9 Port: 80/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: /etc/config from config-volume (rw) Volumes: config-volume: Type: ConfigMap (a volume populated by a ConfigMap) Name: log-config Optional: falseConditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: my-nginx-test-74f5cf4498 (1/1 replicas created)Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 15m deployment-controller Scaled up replica set my-nginx-test-59bf4fc6f8 to 1 Normal ScalingReplicaSet 3m21s deployment-controller Scaled up replica set my-nginx-test-74f5cf4498 to 1 Normal ScalingReplicaSet 3m18s deployment-controller Scaled down replica set my-nginx-test-59bf4fc6f8 to 0 这个例子里我们在 .spec.template.metadata.annotations 中添加 version/config，每次通过修改 version/config 来触发滚动更新 ！！！更新 ConfigMap 后： 使用该 ConfigMap 挂载的 Env 不会同步更新 使用该 ConfigMap 挂载的 Volume 中的数据需要一段时间（实测大概10秒）才能同步更新]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据管理]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2F%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[数据管理Volume容器销毁时，保存在容器内部文件系统中的数据会被清除，为了持久化保存容器数据，可以使用 Kubernetes Volum。 Volum 生命周期独立于容器， Pod 中容器可能销毁重建，但 Volume 会被保留。 emptyDir一个 emptyDir Volume 是 Host 上的一个空目录。 emptyDir Volume 对容器是持久的。但 Pod 从节点删除时，Volume 的内容也会被删除。容器销毁而 Pod 还在，则 Volume 不受影响。 emptyDir Volume 的生命周期与 Pod 一致。 hostPathhostPath Volume将DOcker Host 文件系统中已经存在的目录 mount 给 Pod 的容器。一般不会使用，因为增加了 Pod 与节点的耦合，限制了 Pod 的使用。不过 那些需要访问 k8s, Docker 内部数据的应用则需要使用 hostPath。 eg: kube-apisrver、kube-controller-manager等 kubectl edit --namespace=kube-system pod kube-apiserver-k8s-master 查看 kube-apiserver Pod 的配置。 Pod 销毁，hostPath 对应的目录还会保留。 但 Host 崩溃，hostPath 就无法访问了。 ### 外部 Storage Provider这些 Volume 最大特点就是不依赖 Kubernetes . Volume 的底层基础设施由独立存储系统管理，与Kubernetes 集群分离。数据持久化后，即使整个 Kubernetes 奔溃也不受损。 也要考虑到 可靠性，可用性，和可扩展性 PersistentVolume &amp; PersistentVolumeClaimPV 是外部存储系统中的一块存储空间，由管理员创建维护。PV 具有持久性，生命周期独立于 Pod。PVC 是对 PV 的申请。PVC 通常由普通用户创建和维护。需要为 Pod 分配存储资源时，用户可以创建一个 PVC,指明存储资源的容量大小和访问模式等信息，Kubernetes 会查找并提供满足条件的 PV. PV 与 PVC 的关系，类似于 Node 和 Pod. Secret &amp; ConfigmapSecretSecret 会以密文的方式存储数据，避免了直接在配置文件中保存敏感性息。Secret 会以 Volume 的形式被 mount 到 Pod ，容器可以通过文件的方式使用 Secret 中的敏感数据，此外，容器也可以环境变量的方式使用这些数据。 ConfigmapConfigmap 与 Secret 类似，主要是存储一些非敏感信息。数据以明文方式存放。]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Scheduler]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FScheduler%2F</url>
    <content type="text"><![CDATA[简介Scheduler 是 kubernetes 的调度器，是为一个新创建出来的 Pod，寻找一个最合适的节点（Node）。调度器对一个 Pod 调度成功，实际上就是将它的 spec.nodeName 字段填上调度结果的节点名字 听起来非常简单，但有很多要考虑的问题：(这一块可以很复杂，也可以不关注使用默认) 公平：如何保证每个节点都能被分配资源资源 高效利用：集群所有资源最大化被使用 效率：调度的性能要好，能够尽快地对大批量的 pod 完成调度工作 灵活：允许用户根据自己的需求控制调度的逻辑 Sheduler 是作为单独的程序运行的，启动之后会一直坚挺 API Server，获取 PodSpec.NodeName 为空的 pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上 调度过程调度分为几个部分： 首先是过滤掉不满足条件的节点，这个过程称为 predicate （预选） 然后对通过的节点按照优先级排序，这个是 priority （优选） 最后从中选择优先级最高的节点。 如果中间任何一步骤有错误，就直接返回错误 Predicate 有一系列的算法可以使用： PodFitsResources：节点上剩余的资源是否大于 pod 请求的资源 PodFitsHost：如果 pod 指定了 NodeName，检查节点名称是否和 NodeName 匹配 PodFitsHostPorts：节点上已经使用的 port 是否和 pod 申请的 port 冲突 PodSelectorMatches：过滤掉和 pod 指定的 label 不匹配的节点 NoDiskConflict：已经 mount 的 volume 和 pod 指定的 volume 不冲突，除非它们都是只读 如果在 predicate 过程中没有合适的节点，pod会一直在 pending 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续 priorities 过程：按照优先级大小对节点排序 优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括： LeastRequestedPriority：通过计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高。换句话说，这个优先级指标倾向于资源使用比例更低的节点 BalancedResourceAllocation：节点上 CPU 和 Memory 使用率越接近，权重越高。这个应该和上面的一起使用，不应该单独使用 ImageLocalityPriority：倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高通过算法对所有的优先级项目和权重进行计算，得出最终的结果自定义调度器 除了 kubernetes 自带的调度器，也可以编写自己的调度器。通过 spec:schedulername 参数指定调度器的名字，可以为 pod 选择某个调度器进行调度。比如下面的 pod 选择 my-scheduler 进行调度，而不是默认的 default-scheduler： 1234567891011apiVersion: v1kind: Podmetadata: name: annotation-second-scheduler labels: name: multischeduler-examplespec: schedulername: my-scheduler containers: - name: pod-with-second-annotation-container image: gcr.io/google_containers/pause:2.0 Kubernetes 调度部分进行性能优化的一个最根本原则，就是尽最大可能将集群信息 Cache 化，以便从根本上提高 Predicate 和 Priority 调度算法的执行效率。 节点亲和性（pod与node的亲和性）pod.spec.nodeAffinity 关键字 preferredDuringSchedulingIgnoredDuringExecution（优先执行计划）：软策略 requiredDuringSchedulingIgnoredDuringExecution（要求执行计划）：硬策略 键值运算关系: In：label 的值在某个列表中 NotIn：label 的值不在某个列表中 Gt：label 的值大于某个值 Lt：label 的值小于某个值 Exists：某个 label 存在 DoesNotExist：某个 label 不存在 12345[root@k8s01 ~]# kubectl get node --show-labels # 查看标签 -L env,beta.kubernetes.io/archNAME STATUS ROLES AGE VERSION LABELSk8s01 Ready master 29d v1.18.6 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s01,kubernetes.io/os=linux,node-role.kubernetes.io/master=k8s02 Ready &lt;none&gt; 29d v1.18.6 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s02,kubernetes.io/os=linuxk8s03 Ready &lt;none&gt; 29d v1.18.6 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s03,kubernetes.io/os=linux requiredDuringSchedulingIgnoredDuringExecution节点硬策略。排除 k8s02，只能在 k8s03 上运行required_pod_example.yaml12345678910111213141516171819apiVersion: v1kind: Podmetadata: name: required labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: nginx:1.7.9 affinity: #亲和性 nodeAffinity: #node亲和性 requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn #键值运算关系 ，NotIn:label的值不在某个列表中 values: - k8s02 12345[root@k8s01 Scheduler]# kubectl apply -f required_pod_example.yamlpod/affinity created[root@k8s01 Scheduler]# kubectl get pod -o wide # 多次运行都只会在 k8s03 ，因为 k8s01 master 默认打上了污点 # kubectl taint nodes --all node-role.kubernetes.io/master- 让k8s01 节点也能调度NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESaffinity 1/1 Running 0 11s 172.18.235.181 k8s03 &lt;none&gt; &lt;none&gt; preferredDuringSchedulingIgnoredDuringExecution节点软策略。优先选择 k8s03 节点prefer_pod_example.yaml12345678910111213141516171819202122apiVersion: v1kind: Podmetadata:name: prefer labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: nginx:1.7.9 affinity: #亲和性 nodeAffinity: #node亲和性 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 #权重，权重越大越亲和(多个软策略的情况) preference: matchExpressions: - key: kubernetes.io/hostname operator: In values: - k8s03 合体1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: prefer_require labels: app: node-affinity-podspec: containers: - name: with-node-affinity image: nginx:1.7.9 affinity: #亲和性 nodeAffinity: #node亲和性 requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: NotIn #键值运算关系 ，NotIn:label的值不在某个列表中 values: - k8s02 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 #权重，权重越大越亲和(多个软策略的情况) preference: matchExpressions: - key: kubernetes.io/hostname operator: In values: - k8s03 Pod 亲和性（pod与pod之间的亲和性）pod.spec.affinity.podAffinity/podAntiAffinity pod-Affinity.yaml12345678910111213141516171819202122232425262728293031apiVersion: v1kind: Podmetadata: name: pod-3 labels: app: pod-3spec: containers: - name: pod-3 image: nginx:1.7.9 affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: # 硬策略 app=nginx - labelSelector: matchExpressions: - key: app operator: In values: - nginx topologyKey: kubernetes.io/hostname podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 podAffinityTerm: labelSelector: matchExpressions: - key: app operator: In values: - pod-2 topologyKey: kubernetes.io/hostname 1234567891011121314151617181920[root@k8s01 ~]# kubectl apply -f podAffinity.yamlpod/pod-3 created[root@k8s01 ~]# kubectl get pod -o wide # 硬策略没有匹配到， Pending 状态NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx 1/1 Running 1 24h 172.18.235.138 k8s03 &lt;none&gt; &lt;none&gt;pod-3 0/1 Pending 0 4s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;[root@k8s01 ~]# kubectl get pod --show-labels # 查看标签NAME READY STATUS RESTARTS AGE LABELSnginx 1/1 Running 1 24h run=nginxpod-3 0/1 Pending 0 57s app=pod-3[root@k8s01 ~]# kubectl label pod nginx app=nginx --overwrite=true # 打上标签,强制覆盖 kubectl label pod nginx app=nginx - 删除标签pod/nginx labeled[root@k8s01 ~]# kubectl get pod --show-labelsNAME READY STATUS RESTARTS AGE LABELSnginx 1/1 Running 1 24h app=nginx,run=nginxpod-3 1/1 Running 0 2m56s app=pod-3[root@k8s01 ~]# kubectl get pod -o wide # 已经Running 并且和 app=nginx 在同一 node 上NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx 1/1 Running 1 24h 172.18.235.138 k8s03 &lt;none&gt; &lt;none&gt;pod-3 1/1 Running 0 3m1s 172.18.235.136 k8s03 &lt;none&gt; &lt;none&gt; 指定调度节点1. Pod.spec.nodeName将 Pod 直接调度到指定的 Node 节点上，会跳过 Scheduler 的调度策略，该匹配规则是强制匹配. pod_k8s03.yaml1234567891011121314151617181920apiVersion: apps/v1kind: Deploymentmetadata: name: mywebspec: replicas: 7 selector: matchLabels: app: myweb template: metadata: labels: app: myweb spec: nodeName: k8s03 # 指定 Node 节点 containers: - name: myweb image: nginx:1.7.9 ports: - containerPort: 80 1234567891011[root@k8s01 Scheduler]# kubectl apply -f pod_k8s03.yamldeployment.apps/myweb created[root@k8s01 Scheduler]# kubectl get pod -o wide # 全在 k8s03 节点NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyweb-8678fd58f8-8l2fc 1/1 Running 0 59s 172.18.235.187 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-h46zk 1/1 Running 0 59s 172.18.235.183 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-p9jtj 1/1 Running 0 59s 172.18.235.186 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rrjhn 1/1 Running 0 59s 172.18.235.188 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rxtfh 1/1 Running 0 59s 172.18.235.189 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-t6snp 1/1 Running 0 59s 172.18.235.185 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-w8xsm 1/1 Running 0 59s 172.18.235.184 k8s03 &lt;none&gt; &lt;none&gt; 2. Pod.spec.nodeSelector通过 kubernetes 的 label-selector 机制选择节点，由调度器调度策略匹配 label，而后调度 Pod 到目标节点，该匹配规则属于强制约束 pod_select_k8s03.yaml123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: myweb02spec: replicas: 5 selector: matchLabels: app: myweb template: metadata: labels: app: myweb spec: nodeSelector: disk: ssd # 标签 containers: - name: myweb image: nginx:1.7.9 ports: - containerPort: 80 12345678910111213141516[root@k8s01 Scheduler]# kubectl apply -f pod_select_k8s02.yamldeployment.apps/myweb02 created[root@k8s01 Scheduler]# kubectl get pod -o wide # 还是pending 状态，因为 disk=ssd 的标签还没打上NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyweb-8678fd58f8-8l2fc 1/1 Running 0 8m50s 172.18.235.187 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-h46zk 1/1 Running 0 8m50s 172.18.235.183 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-p9jtj 1/1 Running 0 8m50s 172.18.235.186 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rrjhn 1/1 Running 0 8m50s 172.18.235.188 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rxtfh 1/1 Running 0 8m50s 172.18.235.189 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-t6snp 1/1 Running 0 8m50s 172.18.235.185 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-w8xsm 1/1 Running 0 8m50s 172.18.235.184 k8s03 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-85r2l 0/1 Pending 0 26s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-cllsk 0/1 Pending 0 26s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-clmhd 0/1 Pending 0 26s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-j8cwt 0/1 Pending 0 26s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-nm4jc 0/1 Pending 0 26s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt; 1234567891011121314151617[root@k8s01 Scheduler]# kubectl label node k8s02 disk=ssd # node k8s02 打上标签 disk=ssdnode/k8s02 labeled[root@k8s01 Scheduler]# kubectl get pod -o wide # 已在 k8s02 上 Running NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyweb-8678fd58f8-8l2fc 1/1 Running 0 13m 172.18.235.187 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-h46zk 1/1 Running 0 13m 172.18.235.183 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-p9jtj 1/1 Running 0 13m 172.18.235.186 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rrjhn 1/1 Running 0 13m 172.18.235.188 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rxtfh 1/1 Running 0 13m 172.18.235.189 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-t6snp 1/1 Running 0 13m 172.18.235.185 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-w8xsm 1/1 Running 0 13m 172.18.235.184 k8s03 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-85r2l 1/1 Running 0 5m12s 172.18.236.176 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-cllsk 1/1 Running 0 5m12s 172.18.236.180 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-clmhd 1/1 Running 0 5m12s 172.18.236.179 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-j8cwt 1/1 Running 0 5m12s 172.18.236.177 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-nm4jc 1/1 Running 0 5m12s 172.18.236.178 k8s02 &lt;none&gt; &lt;none&gt; Taint 和 Toleration (污点与容忍度)节点亲和性，是 pod 的一种属性（偏好或硬性要求），它使 pod被吸引到一类特定的节点。 Taint 则相反，它使节点能够排斥一类特定的 pod. Taint 和 toleration 相互配合，可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个 taint ，这表示对于那些不能容忍这些 taint 的 pod，是不会被该节点接受的。如果将 toleration 应用于 pod 上，则表示这些 pod 可以（但不要求）被调度到具有匹配 taint 的节点上。 Taint使用 kubectl taint 命令可以给某个 Node 节点设置污点，Node 被设置上污点之后就和 Pod 之间存在了一种相斥的关系，可以让 Node 拒绝 Pod 的调度执行，甚至将 Node 已经存在的 Pod 驱逐出去 每个污点的组成如下 key=value:effect 每个污点有一个 key 和 value 作为污点的标签，其中 value 可以为空，effect 描述污点的作用。当前 taint effect 支持如下三个选项： NoSchedule: 新的不能容忍的 pod 不能再调度过来，但是老的运行在 node 上不受影响 NoExecute：新的不能容忍的 pod 不能调度过来，老的 pod 也会被驱逐 PreferNoSchedule：尽量避免将 pod 分配到该节点 污点的设置、查看和去除查看污点 : kubectl describe node k8s0112345678[root@k8s01 Scheduler]# kubectl describe node k8s01 ## 节选Taints: node-role.kubernetes.io/master:NoSchedule # master 默认打上 NoScheduleUnschedulable: falseLease: HolderIdentity: k8s01 AcquireTime: &lt;unset&gt; RenewTime: Wed, 26 Aug 2020 12:25:00 -0400 设置污点 : kubectl taint nodes k8s02 key1=value1:NoExecute 去除污点 : kubectl taint nodes node1 key1=value1:NoSchedule- 当有多 master 时，为了防止资源浪费，可以如下设置 12kubectl taint nodes k8s01 node-role.kubernetes.io/master=:NoSchedule- # 去除 NoSchedule 污点kubectl taint nodes k8s01 node-role.kubernetes.io/master=:PreferNoSchedule # 打上 PreferNoSchedule 污点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@k8s01 Scheduler]# kubectl taint nodes k8s02 key1=value1:NoExecute # 设置污点 k8s02 上的 pod 将驱逐node/k8s02 tainted[root@k8s01 Scheduler]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyweb-8678fd58f8-8l2fc 1/1 Running 0 27m 172.18.235.187 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-h46zk 1/1 Running 0 27m 172.18.235.183 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-p9jtj 1/1 Running 0 27m 172.18.235.186 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rrjhn 1/1 Running 0 27m 172.18.235.188 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rxtfh 1/1 Running 0 27m 172.18.235.189 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-t6snp 1/1 Running 0 27m 172.18.235.185 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-w8xsm 1/1 Running 0 27m 172.18.235.184 k8s03 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-28kk2 0/1 Pending 0 4s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-85r2l 0/1 Terminating 0 18m 172.18.236.176 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-cllsk 0/1 Terminating 0 18m 172.18.236.180 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-clmhd 0/1 Terminating 0 18m &lt;none&gt; k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-ggq22 0/1 Pending 0 4s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-j8cwt 0/1 Terminating 0 18m 172.18.236.177 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-mw98x 0/1 Pending 0 4s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-nm4jc 0/1 Terminating 0 18m 172.18.236.178 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-rwqzk 0/1 Pending 0 4s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-sxrtx 0/1 Pending 0 4s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;[root@k8s01 Scheduler]# kubectl get pod -o wide # 但是这个pod 固定了 k8s02NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyweb-8678fd58f8-8l2fc 1/1 Running 0 27m 172.18.235.187 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-h46zk 1/1 Running 0 27m 172.18.235.183 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-p9jtj 1/1 Running 0 27m 172.18.235.186 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rrjhn 1/1 Running 0 27m 172.18.235.188 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rxtfh 1/1 Running 0 27m 172.18.235.189 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-t6snp 1/1 Running 0 27m 172.18.235.185 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-w8xsm 1/1 Running 0 27m 172.18.235.184 k8s03 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-28kk2 0/1 Pending 0 39s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-ggq22 0/1 Pending 0 39s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-mw98x 0/1 Pending 0 39s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-rwqzk 0/1 Pending 0 39s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-sxrtx 0/1 Pending 0 39s &lt;none&gt; &lt;none&gt; &lt;none&gt; &lt;none&gt;[root@k8s01 Scheduler]# kubectl taint nodes k8s02 key1=value1:NoExecute- # 去除污点node/k8s02 untainted[root@k8s01 Scheduler]# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyweb-8678fd58f8-8l2fc 1/1 Running 0 28m 172.18.235.187 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-h46zk 1/1 Running 0 28m 172.18.235.183 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-p9jtj 1/1 Running 0 28m 172.18.235.186 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rrjhn 1/1 Running 0 28m 172.18.235.188 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-rxtfh 1/1 Running 0 28m 172.18.235.189 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-t6snp 1/1 Running 0 28m 172.18.235.185 k8s03 &lt;none&gt; &lt;none&gt;myweb-8678fd58f8-w8xsm 1/1 Running 0 28m 172.18.235.184 k8s03 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-28kk2 1/1 Running 0 68s 172.18.236.182 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-ggq22 1/1 Running 0 68s 172.18.236.185 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-mw98x 1/1 Running 0 68s 172.18.236.181 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-rwqzk 1/1 Running 0 68s 172.18.236.183 k8s02 &lt;none&gt; &lt;none&gt;myweb02-77589bcf45-sxrtx 1/1 Running 0 68s 172.18.236.184 k8s02 &lt;none&gt; &lt;none&gt; Toleration设置了污点的 Node 将根据 taint 的 effect：NoSchedule、PreferNoSchedule、NoExecute 和 Pod 之间产生互斥的关系，Pod 将在一定程度上不会被调度到 Node 上。但我们可以在 Pod 上设置容忍 ( Toleration ) ，意思是设置了容忍的 Pod 将可以容忍污点的存在，可以被调度到存在污点的 Node 上。 pod-Toleration.yaml12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployspec: replicas: 10 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 tolerations: #containers同级 - key: &quot;key1&quot; #能容忍的污点key operator: &quot;Equal&quot; #Equal等于表示key=value ， Exists不等于，表示当值不等于下面value正常 value: &quot;value1&quot; #值 effect: &quot;NoExecute&quot; #effect策略，见上面 tolerationSeconds: 3600 #原始的pod多久驱逐，注意只有effect: &quot;NoExecute&quot;才能设置，不然报错 123456789101112131415161718[root@k8s01 ~]# kubectl taint nodes k8s02 key1=value1:NoExecute # k8s02打上污点node/k8s02 tainted[root@k8s01 ~]# kubectl apply -f pod-Toleration.yaml # 能容忍 key1=value1:NoExecute 这个污点deployment.apps/nginx-deploy created[root@k8s01 ~]# kubectl get pod -o wide # 所以 k8s02 节点也有 pod NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx 1/1 Running 1 24h 172.18.235.138 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-78svq 1/1 Running 0 20s 172.18.235.145 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-8kzgb 1/1 Running 0 20s 172.18.236.142 k8s02 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-8l5wc 1/1 Running 0 20s 172.18.235.144 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-977fg 1/1 Running 0 20s 172.18.235.146 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-c7xv5 1/1 Running 0 20s 172.18.235.143 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-dtlbn 1/1 Running 0 20s 172.18.235.147 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-hfvl6 1/1 Running 0 20s 172.18.235.141 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-hw5m2 1/1 Running 0 20s 172.18.235.142 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-rpqqq 1/1 Running 0 20s 172.18.235.148 k8s03 &lt;none&gt; &lt;none&gt;nginx-deploy-785cc8f568-vtpwl 1/1 Running 0 20s 172.18.236.140 k8s02 &lt;none&gt; &lt;none&gt;pod-3 1/1 Running 0 18m 172.18.235.136 k8s03 &lt;none&gt; &lt;none&gt;]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ingress]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fingress%2F</url>
    <content type="text"><![CDATA[Ingress 简介k8s 暴露服务 可以通过 LoadBalance service, NodePort service, Ingress。 Ingress 目前只工作在 7层网络 Ingress : 其实就是一组基于 DNS 名称或 URL 路径把请求转发至指定的service资源的规则。(将 nginx 配置抽象出来 成为 ingress 对象，不用修改 配置文件，直接改yaml 文件然后创建/更新就可以了) Ingress Controller : 其实是一个可以根据 Ingress 对象和被代理后端 Service 的变化，来自动进行更新的 Nginx 负载均衡器。 Ingress Controller 会根据 Ingress 对象定义的内容，生成 一份对应的 nginx 配置文件，并使用这个配置文件 启动一个 nginx 服务。一旦 Ingress 对象被更新， Ingress Controller 就会更新这个配置文件。 安装 ingress-control1234567891011121314151617181920212223[root@k8s01 ~]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.40.1/deploy/static/provider/baremetal/deploy.yaml## 需要修改 deploy.yaml , 镜像 imwl/ingress-nginx-controller:v0.40.1（同步的官方镜像）。也可以固定 NodePort 的端口[root@k8s01 ~]# kubectl apply -f deploy.yamlnamespace/ingress-nginx createdserviceaccount/ingress-nginx createdconfigmap/ingress-nginx-controller createdclusterrole.rbac.authorization.k8s.io/ingress-nginx createdclusterrolebinding.rbac.authorization.k8s.io/ingress-nginx createdrole.rbac.authorization.k8s.io/ingress-nginx createdrolebinding.rbac.authorization.k8s.io/ingress-nginx createdservice/ingress-nginx-controller-admission createdservice/ingress-nginx-controller createddeployment.apps/ingress-nginx-controller createdvalidatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission createdserviceaccount/ingress-nginx-admission createdclusterrole.rbac.authorization.k8s.io/ingress-nginx-admission createdclusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission createdrole.rbac.authorization.k8s.io/ingress-nginx-admission createdrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission createdjob.batch/ingress-nginx-admission-create createdjob.batch/ingress-nginx-admission-patch created Ingress HTTP 代理访问test-Ingress01.yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152apiVersion: apps/v1kind: Deploymentmetadata: name: myapp namespace: defaultspec: replicas: 3 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp image: imwl/myapp:v2 ports: - name: http containerPort: 80---apiVersion: v1kind: Servicemetadata: name: myapp02 namespace: defaultspec: selector: app: myapp ports: - targetPort: 80 port: 80---apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: example-ingress annotations: kubernetes.io/ingress.class: &quot;nginx&quot; nginx.ingress.kubernetes.io/rewrite-target: /spec: rules: - host: master.k8s.com http: paths: - path: / backend: serviceName: myapp02 servicePort: 80 Ingress HTTPS 代理访问创建证书，以及 cert 存储方式12openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj&quot;/CN=nginxsvc/O=nginxsvc&quot;kubectl create secret tls tls-secret --key tls.key --cert tls.crt deployment、Service、Ingress Yaml 文件 1234567891011121314151617apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: nginx-testspec: tls: - host: - master.k8s01.com secretName: tls-secret rules: - host: master.k8s01.com http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 Nginx 进行 BasicAuth123yum -y install httpdhtpasswd -c auth fookubectl create secret generic basic-auth --from-file=auth 123456789101112131415161718apiVersion: extensions/v1beta1kind: Ingressmetadata: name: ingress-with-auth annotations: nginx.ingress.kubernetes.io/auth-type: basic nginx.ingress.kubernetes.io/auth-secret: basic-auth nginx.ingress.kubernetes.io/auth-realm: &apos;Authentication Required - foo&apos;spec: rules: - host: foo2.bar.com http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 Nginx 进行重写123456789101112131415apiVersion: extensions/v1beta1kind: Ingressmetadata: name: nginx-test annotations: nginx.ingress.kubernetes.io/rewrite-target: http://foo.bar.com:31795/hostname.htmspec: rules: - host: foo10.bar.com http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s网络详解]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fservice-k8s%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[浅谈容器网络直接使用宿主机网络启动一个 nginx, 直接使用宿主机网络1[root@k8s01 service]# docker run -d --net=host --name nginx-host nginx 这个容器启动后，直接监听的就是宿主机的 80 端口。像这样直接使用宿主机网络栈的方式，虽然可以为容器提供良好的网络性能，但也会不可避免地引入共享网络资源的问题，比如端口冲突。所以，在大多数情况下，我们都希望容器进程能使用自己 Network Namespace 里的网络栈，即：拥有属于自己的 IP 地址和 Port 可以看到实际使用的宿主机 ip+port 使用 docker0 网桥宿主机12345678910[root@k8s01 service]# ifconfig## 省略 docker0 为 172.17.0.1docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:87ff:fe56:a7bb prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:87:56:a7:bb txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5 bytes 446 (446.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 启动两个 busybox 容器 12docker run -d -it --name busybox1 busyboxdocker run -d -it --name busybox2 busybox 查看 ip: 123456789101112131415161718192021222324[root@k8s01 service]# docker exec -it busybox1 /bin/sh # 节选/ # ifconfig # 172.17.0.3eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:03 inet addr:172.17.0.3 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:656 (656.0 B) TX bytes:0 (0.0 B)[root@k8s01 service]# docker exec -it busybox2 /bin/sh/ # ifconfig # 172.17.0.4eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:04 inet addr:172.17.0.4 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:656 (656.0 B) TX bytes:0 (0.0 B)/ # ping 172.17.0.3 # 可以 ping 通 / # ping 192.168.43.101 # 宿主机 可以 ping 通 / # ping 192.168.43.102 # 另一台主机 可以 ping 通 图的 ip 不重要，盗的图，意思差不多 宿主机 ping 容器也能 ping 通1234[root@k8s01 service]# ping 172.17.0.3PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data.64 bytes from 172.17.0.3: icmp_seq=1 ttl=64 time=0.099 ms64 bytes from 172.17.0.3: icmp_seq=2 ttl=64 time=0.079 ms 在默认情况下，被限制在 Network Namespace 里的容器进程，实际上是通过 Veth Pair 设备 + 宿主机网桥的方式，实现了跟同其他容器的数据交换。 宿主机上，访问该宿主机上的容器的 IP 地址时，这个请求的数据包，也是先根据路由规则到达 docker0 网桥，然后被转发到对应的 Veth Pair 设备，最后出现在容器里 在 192.168.43.102 上启动一个 busybox3 1234567891011121314151617[root@k8s02 ~]# docker run -d -it --name busybox3 busyboxUnable to find image &apos;busybox:latest&apos; locallylatest: Pulling from library/busyboxd60bca25ef07: Pull completeDigest: sha256:49dae530fd5fee674a6b0d3da89a380fc93746095e7eca0f1b70188a95fd5d71Status: Downloaded newer image for busybox:latestf3864007cb0742ee8641ca19f8320be55d0f35b7a5714b47cff4a554f5f819fb[root@k8s02 ~]# docker exec -it busybox3 /bin/sh/ # ifconfig # 172.17.0.2eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:13 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:1102 (1.0 KiB) TX bytes:0 (0.0 B) 192.168.43.101 上的容器 无法 ping 通 192.168.43.102 上的容器。 Overlay Network我们需要在已有的宿主机网络上，再通过软件构建一个覆盖在已有宿主机网络之上的、可以把所有容器连通在一起的虚拟网络。所以，这种技术就被称为：Overlay Network（覆盖网络）。]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Service]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fservice%2F</url>
    <content type="text"><![CDATA[ServiceService 的概念Kubernetes Service 定义了这样一种抽象：一个Pod的逻辑分组，一种可以访问它们的策略 —— 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector。 Service 是由 kube-proxy 组件，加上 iptables 来共同实现的。 Service能够提供负载均衡的能力，但是在使用上有以下限制：只提供 4 层负载均衡能力，而没有 7 层功能，但有时我们可能需要更多的匹配规则来转发请求，这点上 4 层负载均衡是不支持的 service 类型Service 在 K8s 中 有以下四种类型 ClusterIp：默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟 IP NodePort：在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过: NodePort 来访问该服务 LoadBalancer：在 NodePort 的基础上，借助 cloud provider 创建一个外部负载均衡器，并将请求转发到: NodePort ExternalName：把集群外部的服务引入到集群内部来，在集群内部直接使用。没有任何类型代理被创建 代理模式的分类当你通过 Service 的域名去访问时，会先通过 CoreDNS 解析出 Service 对应的 Cluster IP，即虚拟 IP。然后请求到达宿主机的网络后，就会被kube-proxy 所配置的 iptables 规则所拦截，之后请求会被转发到每一个实际的后端 Pod 上面去，这样就实现了负载均衡 userspace 代理模式 （效率较低） iptables 代理模式 (默认) Ipvs 代理模式 ClusterIp service-example.yaml1234567891011121314apiVersion: v1kind: Servicemetadata: name: myapp namespace: defaultspec: type: ClusterIP selector: app: myapp release: stabel ports: - name: http port: 80 targetPort: 80 示例12345678910111213141516[root@k8s01 ~]# kubectl get pod -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESmyapp-deploy-75bf6f6cd-jnf96 1/1 Running 0 14s 172.18.236.167 k8s02 &lt;none&gt; &lt;none&gt;myapp-deploy-75bf6f6cd-m8ffb 1/1 Running 0 14s 172.18.236.168 k8s02 &lt;none&gt; &lt;none&gt;myapp-deploy-75bf6f6cd-njzj2 1/1 Running 0 14s 172.18.235.168 k8s03 &lt;none&gt; &lt;none&gt;[root@k8s01 ~]# curl 172.18.236.167## 省略## 只有处于 Running 状态，且 readinessProbe 检查通过的 Pod，才会出现在 Service 的 Endpoints 列表里。并且，当某一个 Pod 出现问题时，Kubernetes 会自动把它从 Service 里摘除掉。[root@k8s01 ~]# kubectl get endpoints myapp # 获取 endpointsNAME ENDPOINTS AGEhostnames 172.18.236.167:80,172.18.236.168:80,172.18.235.168:80 19m## service 的 hostname : myapp.default.svc.cluster.local Headless ServiceHeadless Service : 用于为Pod资源标识符生成可解析的DNS资源记录(一个典型、完整可用的 StatefulSet 通常由三个组件构成： Headless Service 、 StatefulSet 和 volumeClaimTemplate 。其中，Headless Service 用于为 Pod 资源标识符生成可解析的 DNS 资源记录，StatefulSet 用于管控 Pod 资源，volumeClaimTemplate 则基于静态或动态的PV供给方式为Pod资源提供专有且固定的存储。) 有时不需要或不想要负载均衡，以及单独的 Service IP 。遇到这种情况，可以通过指定 ClusterIP(spec.clusterIP) 的值为 None 来创建 Headless Service 。这类 Service 并不会分配 Cluster IP, kube-proxy 不会处理它们，而且平台也不会为它们进行负载均衡和路由. svc-headless-example.yaml123456789101112apiVersion: v1kind: Servicemetadata: name: myapp-headless namespace: defaultspec: clusterIP: &quot;None&quot; selector: app: myapp ports: port: 80 targetPort: 80 DNS 记录格式 $（pod_name）.$（service_name）.$（namespace）.svc.cluster.local123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@k8s01 ~]# kubectl apply -f svc-headless-example.yamlservice/myapp-headless created[root@k8s01 ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 26dmyapp ClusterIP 10.96.221.214 &lt;none&gt; 80/TCP 26mmyapp-headless ClusterIP None &lt;none&gt; 80/TCP 57s[root@k8s01 ~]# kubectl get pod -n kube-system -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATEScalico-kube-controllers-76d4774d89-rltpc 1/1 Running 12 21d 172.18.73.104 k8s01 &lt;none&gt; &lt;none&gt;calico-node-5xqsz 1/1 Running 13 26d 192.168.43.103 k8s03 &lt;none&gt; &lt;none&gt;calico-node-cwv6n 1/1 Running 86 26d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;calico-node-pfpr4 1/1 Running 11 26d 192.168.43.102 k8s02 &lt;none&gt; &lt;none&gt;coredns-7ff77c879f-7frh7 1/1 Running 14 26d 172.18.73.103 k8s01 &lt;none&gt; &lt;none&gt;coredns-7ff77c879f-hlzpn 1/1 Running 13 26d 172.18.73.105 k8s01 &lt;none&gt; &lt;none&gt;etcd-k8s01 1/1 Running 13 26d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-apiserver-k8s01 1/1 Running 15 26d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-controller-manager-k8s01 1/1 Running 14 26d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-proxy-hmlxx 1/1 Running 12 26d 192.168.43.103 k8s03 &lt;none&gt; &lt;none&gt;kube-proxy-nh96k 1/1 Running 11 26d 192.168.43.102 k8s02 &lt;none&gt; &lt;none&gt;kube-proxy-x57zq 1/1 Running 13 26d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-scheduler-k8s01 1/1 Running 14 26d 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;[root@k8s01 ~]# dig -t A myapp-headless.default.svc.cluster.local. @172.18.73.103; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-16.P2.el7_8.6 &lt;&lt;&gt;&gt; -t A myapp-headless.default.svc.cluster.local. @172.18.73.103;; global options: +cmd;; Got answer:;; WARNING: .local is reserved for Multicast DNS;; You are currently testing what happens when an mDNS query is leaked to DNS;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 49368;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; WARNING: recursion requested but not available;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;myapp-headless.default.svc.cluster.local. IN A;; ANSWER SECTION:myapp-headless.default.svc.cluster.local. 30 IN A 172.18.235.168 # 含有myapp-headless.default.svc.cluster.local. 30 IN A 172.18.236.167myapp-headless.default.svc.cluster.local. 30 IN A 172.18.236.168;; Query time: 1 msec;; SERVER: 172.18.73.103#53(172.18.73.103);; WHEN: Sun Aug 23 11:24:29 EDT 2020;; MSG SIZE rcvd: 237 NodePortnodePort 的原理在于在 node 上开了一个端口，将向该端口的流量导入到 kube-proxy，然后由 kube-proxy 进一步到给对应的 pod myapp-noode-service.yaml1234567891011121314apiVersion: v1kind: Servicemetadata: name: myapp namespace: defaultspec: type: NodePort selector: app: myapp release: stabel ports: - name: http port: 80 targetPort: 80 测试1234567891011[root@k8s01 ~]# kubectl apply -f myapp-noode-service.yamlservice/myapp configured[root@k8s01 ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 26dmyapp NodePort 10.96.221.214 &lt;none&gt; 80:30260/TCP 32mmyapp-headless ClusterIP None &lt;none&gt; 80/TCP 6m31s[root@k8s01 ~]# curl 172.18.236.167 # 略 pod 的 ip + port[root@k8s01 ~]# curl 10.96.221.214 # 略 service 的ip + port[root@k8s01 ~]# curl 192.168.43.101:30260 # 略 nodeport 的 ip + port[root@k8s01 ~]# curl 192.168.43.102:30260 # 略 LoadBalancerloadBalancer 和 nodePort 其实是同一种方式。区别在于 loadBalancer 比 nodePort 多了一步，就是可以调用 cloud provider 去创建 LB 来向节点导流 myapp-loadbalance.yaml 示例文件12345678910111213apiVersion: v1kind: Servicemetadata: name: myapp-loadbalance namespace: defaultspec: selector: app: myapp release: stabel ports: - port: 8765 targetPort: 80 type: LoadBalancer ExternalName这种类型的 Service 通过返回 CNAME 和它的值，可以将服务映射到 externalName 字段的内容( 例如：www.baidu.com )。ExternalName Service 是 Service 的特例，它没有 selector，也没有定义任何的端口和Endpoint。相反的，对于运行在集群外部的服务，它通过返回该外部服务的别名这种方式来提供服务 externalname-example.yaml12345678kind: ServiceapiVersion: v1metadata: name: my-service-1 namespace: defaultspec: type: ExternalName externalName: www.baidu.com 当查询主机 my-service-1.defalut.svc.cluster.local ( SVC_NAME.NAMESPACE.svc.cluster.local )时，集群的 DNS 服务将返回一个值 www.baidu.com 的 CNAME 记录。访问这个服务的工作方式和其他的相同，唯一不同的是重定向发生在 DNS 层，而且不会进行代理或转发 12345678910111213141516171819202122232425262728293031323334[root@k8s01 ~]# kubectl apply -f externalname-example.yamlservice/my-service-1 unchanged[root@k8s01 ~]# kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 26dmy-service-1 ExternalName &lt;none&gt; www.baidu.com &lt;none&gt; 3m27smyapp NodePort 10.96.221.214 &lt;none&gt; 80:30260/TCP 47mmyapp-headless ClusterIP None &lt;none&gt; 80/TCP 21m[root@k8s01 ~]# dig -t A my-service-1.default.svc.cluster.local. @172.18.73.103; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-16.P2.el7_8.6 &lt;&lt;&gt;&gt; -t A my-service-1.default.svc.cluster.local. @172.18.73.103;; global options: +cmd;; Got answer:;; WARNING: .local is reserved for Multicast DNS;; You are currently testing what happens when an mDNS query is leaked to DNS;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 4010;; flags: qr aa rd; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1;; WARNING: recursion requested but not available;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;my-service-1.default.svc.cluster.local. IN A;; ANSWER SECTION:my-service-1.default.svc.cluster.local. 1 IN CNAME www.baidu.com. ## 相当于做域名解析www.baidu.com. 1 IN CNAME www.a.shifen.com.www.a.shifen.com. 1 IN A 163.177.151.110www.a.shifen.com. 1 IN A 163.177.151.109;; Query time: 0 msec;; SERVER: 172.18.73.103#53(172.18.73.103);; WHEN: Sun Aug 23 11:44:59 EDT 2020;; MSG SIZE rcvd: 239 myappmyapp-deploy.yaml12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: myapp-deploy namespace: defaultspec: replicas: 3 selector: matchLabels: app: myapp release: stabel template: metadata: labels: app: myapp release: stabel env: test spec: containers: - name: myapp image: nginx:1.7.9 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Pod 生命周期二]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FPod%20%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[init 模板init-example.yaml 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: [&apos;sh&apos;,&apos;-c&apos;,&apos;echo The app is running! &amp;&amp; sleep 3600&apos;] initContainers: # 关键字 - name: init-myservice image: busybox command: [&apos;sh&apos;,&apos;-c&apos;,&apos;until nslookup myservice; do echo waiting for myservice; sleep 2;done;&apos;] - name: init-mydb image: busybox command: [&apos;sh&apos;,&apos;-c&apos;,&apos;until nslookup mydb; do echo waiting for mydb; sleep 2; done;&apos;] 1234567891011121314151617181920212223242526[root@k8s01 ~]# kubectl apply -f init-example.yamlpod/myapp-pod created[root@k8s01 ~]# kubectl get pods # init 没成功NAME READY STATUS RESTARTS AGEmyapp-pod 0/1 Init:0/2 0 13s[root@k8s01 ~]# kubectl describe pod myapp-pod# 省略 [root@k8s01 ~]# kubectl logs myapp-pod -c init-myservicewaiting for myserviceServer: 10.96.0.10Address: 10.96.0.10:53** server can&apos;t find myservice.default.svc.cluster.local: NXDOMAIN*** Can&apos;t find myservice.svc.cluster.local: No answer*** Can&apos;t find myservice.cluster.local: No answer*** Can&apos;t find myservice.default.svc.cluster.local: No answer*** Can&apos;t find myservice.svc.cluster.local: No answer*** Can&apos;t find myservice.cluster.local: No answerwaiting for myservice## init 未就绪 service-init-example.yaml 1234567891011121314151617181920kind: ServiceapiVersion: v1metadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9376 ---kind: ServiceapiVersion: v1metadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9377 1kubectl apply -f service-init-example.yaml 详细信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114[root@k8s01 ~]# kubectl get pods # 第一个 init 容器启动NAME READY STATUS RESTARTS AGEmyapp-pod 0/1 Init:1/2 0 2m2s[root@k8s01 ~]# kubectl get pods # pod内容器启动NAME READY STATUS RESTARTS AGEmyapp-pod 0/1 PodInitializing 0 2m44s[root@k8s01 ~]# kubectl get podsNAME READY STATUS RESTARTS AGEmyapp-pod 1/1 Running 0 2m49s[root@k8s01 ~]# kubectl logs myapp-podThe app is running![root@k8s01 ~]# kubectl describe pod myapp-podName: myapp-podNamespace: defaultPriority: 0Node: k8s02/192.168.43.102Start Time: Wed, 19 Aug 2020 09:05:25 -0400Labels: app=myappAnnotations: cni.projectcalico.org/podIP: 172.18.236.154/32 cni.projectcalico.org/podIPs: 172.18.236.154/32Status: RunningIP: 172.18.236.154IPs: IP: 172.18.236.154Init Containers: init-myservice: Container ID: docker://f1aac5b2b50ef5341ba949c72481cc739fbff046faa80113e388983ff438e92a Image: busybox Image ID: docker-pullable://busybox@sha256:4f47c01fa91355af2865ac10fef5bf6ec9c7f42ad2321377c21e844427972977 Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup myservice; do echo waiting for myservice; sleep 2;done; State: Terminated Reason: Completed Exit Code: 0 Started: Wed, 19 Aug 2020 09:05:43 -0400 Finished: Wed, 19 Aug 2020 09:06:58 -0400 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-rr77c (ro) init-mydb: Container ID: docker://215168a8daf652ca35b5c3dc74705561d55dc4524c0ca98d6ec214ca3cf0a429 Image: busybox Image ID: docker-pullable://busybox@sha256:4f47c01fa91355af2865ac10fef5bf6ec9c7f42ad2321377c21e844427972977 Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c until nslookup mydb; do echo waiting for mydb; sleep 2; done; State: Terminated Reason: Completed Exit Code: 0 Started: Wed, 19 Aug 2020 09:07:21 -0400 Finished: Wed, 19 Aug 2020 09:07:47 -0400 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-rr77c (ro)Containers: myapp-container: Container ID: docker://76f2df54070bb74c813d45765f0440461a7c006ad85a122fdcb3b07c936b632c Image: busybox Image ID: docker-pullable://busybox@sha256:4f47c01fa91355af2865ac10fef5bf6ec9c7f42ad2321377c21e844427972977 Port: &lt;none&gt; Host Port: &lt;none&gt; Command: sh -c echo The app is running! &amp;&amp; sleep 3600 State: Running Started: Wed, 19 Aug 2020 09:08:12 -0400 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-rr77c (ro)Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled TrueVolumes: default-token-rr77c: Type: Secret (a volume populated by a Secret) SecretName: default-token-rr77c Optional: falseQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300sEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 2m59s default-scheduler Successfully assigned default/myapp-pod to k8s02 Normal Pulling 2m58s kubelet, k8s02 Pulling image &quot;busybox&quot; Normal Pulled 2m41s kubelet, k8s02 Successfully pulled image &quot;busybox&quot; Normal Created 2m41s kubelet, k8s02 Created container init-myservice Normal Started 2m41s kubelet, k8s02 Started container init-myservice Normal Pulling 86s kubelet, k8s02 Pulling image &quot;busybox&quot; Normal Pulled 63s kubelet, k8s02 Successfully pulled image &quot;busybox&quot; Normal Created 63s kubelet, k8s02 Created container init-mydb Normal Started 63s kubelet, k8s02 Started container init-mydb Normal Pulling 36s kubelet, k8s02 Pulling image &quot;busybox&quot; Normal Pulled 13s kubelet, k8s02 Successfully pulled image &quot;busybox&quot; Normal Created 13s kubelet, k8s02 Created container myapp-container Normal Started 12s kubelet, k8s02 Started container myapp-container 检测探针 - 就绪检测readinessProbe-http-get.yaml12345678910111213141516apiVersion: v1kind: Podmetadata: name: readiness-httpget-pod namespace: defaultspec: containers: - name: readiness-httpget-container image: nginx:1.7.9 imagePullPolicy: IfNotPresent readinessProbe: # 关键字 httpGet: port: 80 path: /index1.html initialDelaySeconds: 1 # 触发延时 periodSeconds: 3 # 重试间隔时间 1234567891011121314151617181920[root@k8s01 ~]# kubectl describe pod readiness-httpget-pod ## 省略部分Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 5s default-scheduler Successfully assigned default/readiness-httpget-pod to k8s03 Normal Pulled 4s kubelet, k8s03 Container image &quot;nginx:1.7.9&quot; already present on machine Normal Created 4s kubelet, k8s03 Created container readiness-httpget-container Normal Started 3s kubelet, k8s03 Started container readiness-httpget-container Warning Unhealthy 0s kubelet, k8s03 Readiness probe failed: HTTP probe failed with statuscode: 404## 探测失败[root@k8s01 ~]# kubectl exec readiness-httpget-pod -it -- /bin/bashroot@readiness-httpget-pod:/# echo &quot;123&quot; &gt; /usr/share/nginx/html/index1.htmlroot@readiness-httpget-pod:/# exitexit[root@k8s01 ~]# kubectl get podNAME READY STATUS RESTARTS AGEmyapp-pod 1/1 Running 0 26mreadiness-httpget-pod 1/1 Running 0 3m34s 当有 index1.html 会返回 200 探测成功。日志省略 检测探针 - 存活检测livenessProbe-exec.yaml12345678910111213141516apiVersion: v1kind: Podmetadata: name: liveness-exec-pod namespace: defaultspec: containers: - name: liveness-exec-container image: busybox:1.32.0 imagePullPolicy: IfNotPresent command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;touch /tmp/live ; sleep 60; rm -rf /tmp/live; sleep 3600&quot;] livenessProbe: exec: command: [&quot;test&quot;,&quot;-e&quot;,&quot;/tmp/live&quot;] initialDelaySeconds: 1 periodSeconds: 3 12345[root@k8s01 ~]# kubectl get pod ## liveness-exec-pod 会 周期性 restart NAME READY STATUS RESTARTS AGEliveness-exec-pod 0/1 CrashLoopBackOff 6 10mmyapp-pod 1/1 Running 0 7h31mreadiness-httpget-pod 1/1 Running 0 7h1m livenessProbe-httpgetlivenessProbe-httpget.yaml1234567891011121314151617181920apiVersion: v1kind: Podmetadata: name: liveness-httpget-pod namespace: defaultspec: containers: - name: liveness-httpget-container image: nginx:1.7.9 imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 livenessProbe: httpGet: port: 80 path: /index.html initialDelaySeconds: 1 periodSeconds: 3 timeoutSeconds: 10 123456789[root@k8s01 ~]# kubectl exec liveness-httpget-pod -it -- /bin/bash## 修改 /index.html 为 index1.html[root@k8s01 ~]# kubectl get pod ## liveness-httpget-pod 会 restart NAME READY STATUS RESTARTS AGEliveness-exec-pod 0/1 CrashLoopBackOff 6 12mliveness-httpget-pod 1/1 Running 1 2m59smyapp-pod 1/1 Running 0 7h31mreadiness-httpget-pod 1/1 Running 0 7h1m livenessProbe-tcplivenessProbe-tcp.yaml1234567891011121314apiVersion: v1kind: Podmetadata: name: probe-tcpspec: containers: - name: nginx image: nginx：1.7.9 livenessProbe: initialDelaySeconds: 5 timeoutSeconds: 1 tcpSocket: port: 80 periodSeconds: 3 livenessProbe-tcp-81.yaml 1234567891011121314apiVersion: v1kind: Podmetadata: name: probe-tcp1spec: containers: - name: nginx image: nginx：1.7.9 livenessProbe: initialDelaySeconds: 5 timeoutSeconds: 1 tcpSocket: port: 81 periodSeconds: 3 1234567891011[root@k8s01 ~]# kubectl get pod # tcp 80 端口可以检测到，81端口一直重启NAME READY STATUS RESTARTS AGEprobe-tcp80 1/1 Running 0 19sprobe-tcp81 0/1 CrashLoopBackOff 4 2m48s[root@k8s01 ~]# kubectl get podNAME READY STATUS RESTARTS AGEprobe-tcp80 1/1 Running 0 74sprobe-tcp81 1/1 Running 6 3m43s 查看日志 1234567891011# 节选 ， Liveness probe failed: dial tcp 172.18.235.163:81: connect: connection refusedEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled &lt;unknown&gt; default-scheduler Successfully assigned default/probe-tcp81 to k8s03 Normal Created 6h39m (x4 over 6h41m) kubelet, k8s03 Created container nginx Normal Started 6h39m (x4 over 6h41m) kubelet, k8s03 Started container nginx Normal Killing 6h39m (x3 over 6h40m) kubelet, k8s03 Container nginx failed liveness probe, will be restarted Normal Pulled 6h39m (x4 over 6h41m) kubelet, k8s03 Container image &quot;nginx:1.7.9&quot; already present on machine Warning Unhealthy 6h39m (x10 over 6h41m) kubelet, k8s03 Liveness probe failed: dial tcp 172.18.235.163:81: connect: connection refused Warning BackOff 6h36m (x10 over 6h38m) kubelet, k8s03 Back-off restarting failed container 删除所有 pod 1kubectl delete pod --all 存活+就绪 检测 + startup 检测（1.18 版本）liveness-readiness.yaml 1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: liveness-readiness-pod namespace: defaultspec: containers: - name: liveness-readiness-container image: nginx:1.7.9 imagePullPolicy: IfNotPresent readinessProbe: # 关键字 httpGet: port: 80 path: /index1.html initialDelaySeconds: 1 # 触发延时 periodSeconds: 3 # 重试间隔时间 livenessProbe: httpGet: port: http path: /index.html initialDelaySeconds: 1 periodSeconds: 3 timeoutSeconds: 10 startupProbe: # 最先进行 startupProbe,3次没通过就重启，通过后 进行 另外两个检测 httpGet: path: /index.html port: 80 failureThreshold: 3 #失败阈值 periodSeconds: 2 启动、退出动作start_stop.yaml123456789101112131415apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: # 启动动作 exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt;/usr/share/message&quot;] preStop: # 退出动作 exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the poststop handler &gt;/usr/share/message&quot;] 查看显示 1234[root@k8s01 ~]# kubectl exec lifecycle-demo -it -- /bin/bash root@lifecycle-demo:/# cat /usr/share/messageHello from the postStart handler # start 成功]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Pod 生命周期一]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fpod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Pod 生命周期 init 容器init 容器与普通的容器非常像,除了： init 容器总是运行到成功完成为止 每个 init 容器都必须在下一个 init 容器容器启动前完成 tips: 实际上最先生成 pause 容器 Pod 的 init 容器失败，kubernetes 会不断地重启该 Pod，直到 init 容器成功为止。如果 Pod 对应的 restartPolicy 为 Never,则Pod 启动失败 init 容器优势init 容器 具有 与应用程序容器分离的单独镜像。 它们可以包含并运行实用工具，但是出于安全考虑，是不建议在应用程序容器镜像中包含这些实用工具的 它们可以包含使用工具和定制化代码来安装，但是不能出现在应用程序镜像中。例如，创建镜像没必要FROM另-一个镜像，只需要在安装过程中使用类似sed、awk、 python 或dig这样的工具。 应用程序镜像可以分离出创建和部署的角色，而没有必要联合它们构建-一个单独的镜像。 Init 容器使用Linux Namespace, 所以相对应用程序容器来说具有不同的文件系统视图。因此，它们能够具有访问Secret 的权限，而应用程序容器则不能。 它们必须在应用程序容器启动之前运行完成，而应用程序容器是并行运行的，所以Init容器能够提供了一种简单的阻塞或延迟应用容器的启动的方法，直到满足了- -组先决条件。 容器探针 livenessProbe : 指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死 容器 ，并且容器将受到其 重启策略 的影响。如果容器不提供存活探针，则默认状态为 Success。 readinessProbe : 指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配所有的 Service 的端点中删除该 Pod 的 IP 地址。 初始延迟之前的就绪状态 默认为 Failure。 如果容器不提供就绪探针，则默认状态为 Success。 新增 startupProbe : 用于判断容器是否已启动好，如果探测失败，则 kubelet 会杀死 容器 ，并且容器将受到其 重启策略 的影响。如果容器不提供此探针，则默认状态为 Success。 探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler 。有三种类型的处理程序。(k8s 为这些 Probe 内置的三个 Handler ) ExecAction : 在容器内执行命令。如果命令退出时返回码为 0 则认为诊断成功。 TCPSocketAction : 对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的。 HTTPGetAction : 对指定的端口和路径上的容器 IP 地址执行 HTTP Get 请求。响应码 200 ~400(不包含400) ，则诊断认为是成功的。 探测结果： 成功： 容器通过了诊断 失败： 容器未通过诊断 未知： 诊断失败，因此不会采取任何行动。 重启策略PodSpec 中 restartPolicy 字段，适用于 Pod 中所有容器。 值为 : Always, OnFailure,Never 。 没有此字段默认为 Always。 restartPolicy 仅指通过 同一节点上的 kubelet 重新启动容器。 Pod hookPod hook（钩子） 是 kubelet 发起，当容器的进程启动前或者容器中的进程终止前运行，这是包含在容器的生命周期之中，可以同时为 Pod 中所有容器都配置 hook hook 类型 exec : 执行一段命令 HTTP ： 发送 HTTP 请求 123456789101112131415apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: # 启动前动作 exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt;/usr/share/message&quot;] preStop: # 退出前动作 exec: command: [&quot;/usr/sbin/nginx&quot;, &quot;-s&quot;, &quot;quit&quot;] # 优雅退出 Pod phasePod 的 status 字段是一个 PodStatus 对象，PodStatus 中有一个 phase（相位） 字段，是对 Pod 在其生命周期中的简单宏观概述。 phase 仅有以下值： Pending ： Pod 已被 Kuberntes 系统接受，但有一个或多个容器镜像尚未创建 Running ： 该 Pod 已绑定到了一个节点， Pod 中所有容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。 Succeeded ： Pod 中所有容器被成功终止 （退出返回 0），并且不会再被重启 。 Failed ：Pod 中所有容器都已终止，但至少有一个容器 以 非 0 状态退出或者被系统终止。 Unknown： 因为某些原因无法取得 Pod 的状态。通常是因为 与 Pod 所在主机通信失败。 示例Pod中只有一个容器并且正在运行，容器成功退出 记录事件完成 如果restartPolicy 为： 12345Always：重启容器；Pod phase 仍为 RunningOnFailure: Pod phase 变成 SucceededNever： Pod phase 变成 Succeeded Pod 中只有一个容器并且正在运行。容器退出失败 记录失败事件 如果 restartPolicy 为： 12345Always：重启容器；Pod phase 仍为 RunningOnFailure: Pod phase 仍为 RunningNever： Pod phase 变成 failed Pod 中有两个容器并且正在运行。容器有一个退出失败 记录失败事件 如果 restartPolicy 为： 12345Always：重启容器；Pod phase 仍为 RunningOnFailure: Pod phase 仍为 RunningNever： Pod phase 仍为 Running 如果有容器没有处于运行状态，并且另一个容器退出12345Always：重启容器；Pod phase 仍为 RunningOnFailure: Pod phase 仍为 RunningNever： Pod phase 变成 failed Pod 中只有一个容器并处于运行状态。容器运行时内存超出限制 容器以失败状态终止 记录 OOM 事件 如果restartPolicy为： 12345Always：重启容器；Pod phase 仍为 RunningOnFailure: Pod phase 仍为 RunningNever： Pod phase 变成 failed Pod 正在运行，磁盘故障 杀掉所有容器。记录适当事件 Pod phase 变成 Failed 如果使用控制器来运行，Pod 将在别处重建Pod Pod 正在运行，其节点被分段 节点控制器等待直到超时 节点控制器将 Pod phase 设置为 Failed 如果是用控制器来运行，Pod 将在别处重建]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[资源清单]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2F%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[资源清单格式12# 生成一个 实例文件，然后可以自行修改 --dry-run 不会具体执行kubectl create deploy my-deployment -n demo --image busybox --dry-run server -o yaml &gt; my-deployment.yaml 一般字段123456789apiVersion: group/apiversion # 如果没有给定 group 名称，那么默认为 core，可以使用 kubectl api-versions # 获取当前 k8s 版本上所有apiVersio版本信息( 每个版本可能不同 )kind: # 资源类别metadata： # 资源元数据 name # 名字 namespace # 命名空间 lables # 标签，主要用来表示一些有意义且和对象密切相关的信息 annotations # 注解，主要用来记录一些非识别的信息，方便用户阅读查找等spec: # 期望的状态（disired state）status： # 当前状态，本字段有 Kubernetes 自身维护，用户不能去定义 pod一个pod 启动的第一个容器 pause, pod 中所有 容器都共享 pause 的网络存储卷等。即 Pod 中容器端口不能重复。 常见pod-example.yaml1234567891011121314151617181920212223apiVersion: v1 # 指定当前描述文件遵循v1版本的Kubernetes APIkind: Pod # 我们在描述一个podmetadata: name: twocontainers # 指定pod的名称 namespace: default # 指定当前描述的pod所在的命名空间 labels: # 指定pod标签 app: twocontainers annotations: # 指定pod注释 version: v1 releasedBy: weilai purpose: demospec: containers: - name: myapp # 容器的名称 image: imwl/myapp:v1 # 创建容器所使用的镜像 ports: - containerPort: 80 # 应用监听的端口 - name: shell # 容器的名称 image: centos:7 # 创建容器所使用的镜像 command: # 容器启动命令 - &quot;bin/bash&quot; - &quot;-c&quot; - &quot;sleep 10000&quot; 在生产环境中，推荐使用 Deployment、StatefulSet、Job 或者 CronJob 等控制器来创建 Pod，而不推荐直接创建 Pod。 当使用 name: nginx_pod_example 报错 1The Pod &quot;nginx_pod_example&quot; is invalid: metadata.name: Invalid value: &quot;nginx_pod_example&quot;: a DNS-1123 subdomain must consist of lower case alphanumeric characters, &apos;-&apos; or &apos;.&apos;, and must start and end with an alphanumeric character (e.g. &apos;example.com&apos;, regex used for validation is &apos;[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*&apos;) - containerPort:80 当格式错误时1error: error validating &quot;pod_duplicate_port_example.yaml&quot;: error validating data: [ValidationError(Pod.spec.containers[0].ports[0]): invalid type for io.k8s.api.core.v1.ContainerPort: got &quot;string&quot;, expected &quot;map&quot;, ValidationError(Pod.spec.containers[1].ports[0]): invalid type for io.k8s.api.core.v1.ContainerPort: got &quot;string&quot;, expected &quot;map&quot;]; if you choose to ignore these errors, turn validation off with --validate=false 测试 Pod 中容器端口重复pod-duplicate-port-example.yaml1234567891011121314151617apiVersion: v1kind: Podmetadata: name: nginx-pod-example labels: app: nginx version: latestspec: containers: - name: app image: nginx:latest ports: - containerPort: 80 - name: app-double-port image: nginx:latest ports: - containerPort: 80 定位过程如下123456789101112131415161718192021222324252627282930313233343536373839[root@k8s01 ~]# kubectl get pods # 查看 pods 状态NAME READY STATUS RESTARTS AGEmy-pod 1/1 Running 0 15mnginx-pod-example 1/2 Error 3 4m43s[root@k8s01 ~]# kubectl logs nginx-pod-exampleerror: a container name must be specified for pod nginx-pod-example, choose one of: [app app-double-port][root@k8s01 ~]# kubectl logs nginx-pod-example -c app-double-port # 查看 pods 中容器 app-double-port 日志/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d//docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh10-listen-on-ipv6-by-default.sh: Getting the checksum of /etc/nginx/conf.d/default.conf10-listen-on-ipv6-by-default.sh: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh/docker-entrypoint.sh: Configuration complete; ready for start up2020/08/09 15:19:30 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to [::]:80 failed (98: Address already in use)nginx: [emerg] bind() to [::]:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to [::]:80 failed (98: Address already in use)nginx: [emerg] bind() to [::]:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to [::]:80 failed (98: Address already in use)nginx: [emerg] bind() to [::]:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to [::]:80 failed (98: Address already in use)nginx: [emerg] bind() to [::]:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to 0.0.0.0:80 failed (98: Address already in use)nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: bind() to [::]:80 failed (98: Address already in use)nginx: [emerg] bind() to [::]:80 failed (98: Address already in use)2020/08/09 15:19:30 [emerg] 1#1: still could not bind() # 发现 端口 80 被占用 即一个pod 启动的第一个容器 pause,pod 中所有 容器都共享 pause 的网络存储卷等。即Pod 中容器端口不能重复。 删除12[root@k8s01 ~]# kubectl delete -f pod_duplicate_port_example.yamlpod &quot;nginx-pod-example&quot; deleted PodPreset编写的 Pod 里追加的字段，都可以预先定义好 preset.yaml1234567891011121314151617apiVersion: settings.k8s.io/v1alpha1kind: PodPresetmetadata: name: allow-databasespec: selector: matchLabels: role: frontend env: - name: DB_PORT value: &quot;6379&quot; volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125; 编写的 pod文件PodPreset_test.yaml12345678910111213apiVersion: v1kind: Podmetadata: name: website labels: app: website role: frontend # 匹配 PodPreset 标签spec: containers: - name: website image: nginx ports: - containerPort: 80 结果12345678910111213141516171819202122232425262728$ kubectl create -f preset.yaml$ kubectl create -f PodPreset_test.yaml$ kubectl get pod website -o yamlapiVersion: v1kind: Podmetadata: name: website labels: app: website role: frontend annotations: podpreset.admission.kubernetes.io/podpreset-allow-database: &quot;resource version&quot;spec: containers: - name: website image: nginx volumeMounts: - mountPath: /cache name: cache-volume ports: - containerPort: 80 env: - name: DB_PORT value: &quot;6379&quot; volumes: - name: cache-volume emptyDir: &#123;&#125; PodPreset 里定义的内容，只会在 Pod API 对象被创建之前追加在这个对象本身上，而不会影响任何 Pod 的控制器的定义 RS示例nginx-RS.yaml12345678910111213141516171819202122apiVersion: apps/v1kind: ReplicaSetmetadata: name: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: metadata: labels: tier: frontend spec: containers: - name: myapp image: nginx:latest env: - name: GET-HOSTS-FROM value: dns ports: - containerPort: 80 apiVersion: extensions/v1beta1 报错1error: unable to recognize &quot;nginx-RS.yaml&quot;: no matches for kind &quot;ReplicaSet&quot; in version &quot;extensions/v1beta1&quot; 当前的k8s版本是1.18.6, 而目前的extensions/v1beta1 中并没有支持 ReplicaSet, 将配置文件内的 api 接口修改为 apps/v1. 最好使用 Deployment 而不是 RS 123456789[root@k8s01 ~]# kubectl get rsNAME DESIRED CURRENT READY AGEfrontend 3 3 3 5m41s[root@k8s01 ~]# kubectl get podsNAME READY STATUS RESTARTS AGEfrontend-2w8z4 1/1 Running 0 5m51sfrontend-hwh69 1/1 Running 0 5m51sfrontend-j2pwv 1/1 Running 0 5m51smy-pod 1/1 Running 0 39m Deployment示例nginx-Deployment.yaml1234567891011121314151617181920212223apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: replicas: 3 selector: matchLabels: app: nginx updateStrategy: # 这里指定了更新策略 type: RollingUpdate # 进行滚动更新 # OnDelete 删除时 rollingUpdate: maxUnavailable: 1 # 这是默认的值 ## 这一块以上 控制器定义（包括期望状态） template: ## 被控制对象的模板 metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 12345678910111213141516[root@k8s01 ~]# kubectl get podNAME READY STATUS RESTARTS AGEfrontend-2w8z4 1/1 Running 0 15mfrontend-hwh69 1/1 Running 0 15mfrontend-j2pwv 1/1 Running 0 15mmy-pod 1/1 Running 0 49mnginx-deployment-5bf87f5f59-2m56p 1/1 Running 0 3m39snginx-deployment-5bf87f5f59-lctkl 1/1 Running 0 3m39snginx-deployment-5bf87f5f59-txqlp 1/1 Running 0 3m39s[root@k8s01 ~]# kubectl get rsNAME DESIRED CURRENT READY AGEfrontend 3 3 3 16mnginx-deployment-5bf87f5f59 3 3 3 3m48s[root@k8s01 ~]# kubectl get deploymentNAME READY UP-TO-DATE AVAILABLE AGEnginx-deployment 3/3 3 3 3m59s 定义 Deployment , Deployment 是通过 RelicaSet 管理 Pod DaemonSet示例nginx-DaemonSet.yaml12345678910111213141516apiVersion: apps/v1kind: DaemonSetmetadata: name: daemonset-examplespec: selector: matchLabels: name: daemonset-example template: metadata: labels: name: daemonset-example spec: containers: - name: daemonset-example image: nginx:1.7.8 12345678910111213141516[root@k8s01 ~]# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESdaemonset-example-6jht8 1/1 Running 0 2m45s 172.18.236.136 k8s02 &lt;none&gt; &lt;none&gt;daemonset-example-mz82g 1/1 Running 0 2m45s 172.18.235.135 k8s03 &lt;none&gt; &lt;none&gt;frontend-2w8z4 1/1 Running 0 24m 172.18.236.134 k8s02 &lt;none&gt; &lt;none&gt;frontend-hwh69 1/1 Running 0 24m 172.18.236.133 k8s02 &lt;none&gt; &lt;none&gt;frontend-j2pwv 1/1 Running 0 24m 172.18.235.132 k8s03 &lt;none&gt; &lt;none&gt;my-pod 1/1 Running 0 58m 172.18.235.131 k8s03 &lt;none&gt; &lt;none&gt;nginx-deployment-5bf87f5f59-2m56p 1/1 Running 0 12m 172.18.235.133 k8s03 &lt;none&gt; &lt;none&gt;nginx-deployment-5bf87f5f59-lctkl 1/1 Running 0 12m 172.18.235.134 k8s03 &lt;none&gt; &lt;none&gt;nginx-deployment-5bf87f5f59-txqlp 1/1 Running 0 12m 172.18.236.135 k8s02 &lt;none&gt; &lt;none&gt;[root@k8s01 ~]# kubectl get daemonsetNAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGEdaemonset-example 2 2 2 2 2 &lt;none&gt; 2m49s调度机制，默认master没有 Job示例pi-job.yaml12345678910111213141516apiVersion: batch/v1kind: Jobmetadata: name: pispec: parallelism: 2 # 最大并行数 默认为 1 # completions: 4 # 最小完成数 # 不定义 completions 时，需自行决定什么时候 pod 算完成 template: spec: containers: - name: pi image: resouer/ubuntu-bc command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo &apos;scale=5000; 4*a(1)&apos; | bc -l &quot;] restartPolicy: Never # OnFailure 仅支持这两种 backoffLimit: 4 # 重试次数 默认为6 activeDeadlineSeconds: 100 # 最长运行时间 超过 100秒此job 就会终止 CronJob12345678910111213141516171819apiVersion: batch/v1kind: CronJobmetadata: name: hellospec: schedule: &quot;*/1 * * * *&quot; # 每 1 分钟执行一次 concurrencyPolicy: Replace # 并发策略,Replace：取消当前正在运行的 Job，用一个新的来替换 failedJobsHistoryLimit: 1 # 失败任务历史显示个数 startingDeadlineSeconds: 200 # 在过去的 200秒,如果 miss 的数目达到了 100 次，那么这个 Job 就不会被创建执行了。 jonTemplate: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date;echo hello from the Kubernetes cluster restartPolicy: OnFailure 补123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177[root@k8s01 ~]# kubectl get pod my-pod --o yaml # 将资源的配置以 yaml格式输出apiVersion: v1kind: Podmetadata: annotations: cni.projectcalico.org/podIP: 172.18.235.131/32 cni.projectcalico.org/podIPs: 172.18.235.131/32 kubectl.kubernetes.io/last-applied-configuration: | &#123;&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Pod&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;app&quot;:&quot;nginx&quot;,&quot;version&quot;:&quot;latest&quot;&#125;,&quot;name&quot;:&quot;my-pod&quot;,&quot;namespace&quot;:&quot;default&quot;&#125;,&quot;spec&quot;:&#123;&quot;containers&quot;:[&#123;&quot;image&quot;:&quot;nginx:latest&quot;,&quot;name&quot;:&quot;app&quot;,&quot;ports&quot;:[&#123;&quot;containerPort&quot;:80&#125;]&#125;]&#125;&#125; creationTimestamp: &quot;2020-08-09T15:03:15Z&quot; labels: app: nginx version: latest managedFields: - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:metadata: f:annotations: .: &#123;&#125; f:kubectl.kubernetes.io/last-applied-configuration: &#123;&#125; f:labels: .: &#123;&#125; f:app: &#123;&#125; f:version: &#123;&#125; f:spec: f:containers: k:&#123;&quot;name&quot;:&quot;app&quot;&#125;: .: &#123;&#125; f:image: &#123;&#125; f:imagePullPolicy: &#123;&#125; f:name: &#123;&#125; f:ports: .: &#123;&#125; k:&#123;&quot;containerPort&quot;:80,&quot;protocol&quot;:&quot;TCP&quot;&#125;: .: &#123;&#125; f:containerPort: &#123;&#125; f:protocol: &#123;&#125; f:resources: &#123;&#125; f:terminationMessagePath: &#123;&#125; f:terminationMessagePolicy: &#123;&#125; f:dnsPolicy: &#123;&#125; f:enableServiceLinks: &#123;&#125; f:restartPolicy: &#123;&#125; f:schedulerName: &#123;&#125; f:securityContext: &#123;&#125; f:terminationGracePeriodSeconds: &#123;&#125; manager: kubectl operation: Update time: &quot;2020-08-09T15:03:15Z&quot; - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:metadata: f:annotations: f:cni.projectcalico.org/podIP: &#123;&#125; f:cni.projectcalico.org/podIPs: &#123;&#125; manager: calico operation: Update time: &quot;2020-08-09T15:03:16Z&quot; - apiVersion: v1 fieldsType: FieldsV1 fieldsV1: f:status: f:conditions: k:&#123;&quot;type&quot;:&quot;ContainersReady&quot;&#125;: .: &#123;&#125; f:lastProbeTime: &#123;&#125; f:lastTransitionTime: &#123;&#125; f:status: &#123;&#125; f:type: &#123;&#125; k:&#123;&quot;type&quot;:&quot;Initialized&quot;&#125;: .: &#123;&#125; f:lastProbeTime: &#123;&#125; f:lastTransitionTime: &#123;&#125; f:status: &#123;&#125; f:type: &#123;&#125; k:&#123;&quot;type&quot;:&quot;Ready&quot;&#125;: .: &#123;&#125; f:lastProbeTime: &#123;&#125; f:lastTransitionTime: &#123;&#125; f:status: &#123;&#125; f:type: &#123;&#125; f:containerStatuses: &#123;&#125; f:hostIP: &#123;&#125; f:phase: &#123;&#125; f:podIP: &#123;&#125; f:podIPs: .: &#123;&#125; k:&#123;&quot;ip&quot;:&quot;172.18.235.131&quot;&#125;: .: &#123;&#125; f:ip: &#123;&#125; f:startTime: &#123;&#125; manager: kubelet operation: Update time: &quot;2020-08-09T15:05:23Z&quot; name: my-pod namespace: default resourceVersion: &quot;45037&quot; selfLink: /api/v1/namespaces/default/pods/my-pod uid: aab6a853-f6b4-45cb-b8be-bd3a0307c865spec: containers: - image: nginx:latest imagePullPolicy: Always name: app ports: - containerPort: 80 protocol: TCP resources: &#123;&#125; terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: default-token-rr77c readOnly: true dnsPolicy: ClusterFirst enableServiceLinks: true nodeName: k8s03 priority: 0 restartPolicy: Always schedulerName: default-scheduler securityContext: &#123;&#125; serviceAccount: default serviceAccountName: default terminationGracePeriodSeconds: 30 tolerations: - effect: NoExecute key: node.kubernetes.io/not-ready operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 volumes: - name: default-token-rr77c secret: defaultMode: 420 secretName: default-token-rr77cstatus: conditions: - lastProbeTime: null lastTransitionTime: &quot;2020-08-09T15:03:16Z&quot; status: &quot;True&quot; type: Initialized - lastProbeTime: null lastTransitionTime: &quot;2020-08-09T15:05:23Z&quot; status: &quot;True&quot; type: Ready - lastProbeTime: null lastTransitionTime: &quot;2020-08-09T15:05:23Z&quot; status: &quot;True&quot; type: ContainersReady - lastProbeTime: null lastTransitionTime: &quot;2020-08-09T15:03:15Z&quot; status: &quot;True&quot; type: PodScheduled containerStatuses: - containerID: docker://c0deb071489b78bbcdb8b285ee1ae28684779813e2d5c601921de3ff991e1cd4 image: nginx:latest imageID: docker-pullable://nginx@sha256:36b74457bccb56fbf8b05f79c85569501b721d4db813b684391d63e02287c0b2 lastState: &#123;&#125; name: app ready: true restartCount: 0 started: true state: running: startedAt: &quot;2020-08-09T15:05:23Z&quot; hostIP: 192.168.43.103 phase: Running podIP: 172.18.235.131 podIPs: - ip: 172.18.235.131 qosClass: BestEffort startTime: &quot;2020-08-09T15:03:16Z&quot;]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[控制器说明]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fcontrol%20%E6%8E%A7%E5%88%B6%E5%99%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[控制器说明Pod 分类主要是生命周期不一致 自主式 Pod : Pod 退出了，就不会再被创建 控制器 Pod : 在控制器的生命周期里，始终要维持 Pod 的副本数目 命令式编程与声明式编程 命令式 : 侧重于如何实现程序，需要把程序的实现过程按照逻辑结果一步一步写下来 （rs） create 声明式编程 ： 侧重于定义想要什么，然后告诉计算机、引擎，让他帮你去实现 (Deployment) apply RC 和 RSReplicationController (RC) ： 用来确保 容器应用的副本数始终保持在用户定义的副本数，如有容器异常退出，会自动创建新的 Pod 来替代，异常多出来的容器也会自动回收 RelicaSet (RS) : 同 RC, 支持集合式的 selector ,(通过 lables 选择),一般只用 RS DeploymentDeployment : 为 Pod 和 RelicaSet 提供一个声明式定义方法(declarative) 定义 Deployment , Deployment 是通过 RelicaSet 管理 Pod 滚动升级回滚应用 扩容和缩容 暂停和继续 Deployment eg： 升级 RS 升级到 RS1 DaemonSetDaemonSet 确保全部（或者一些（ Node 打上污点）（标签选择）） Node 上运行 一个 Pod 副本。 有新 Node 加入集群，会为他们新增一个 Pod, Node 移除 Pod 回收，删除 DaemonSet 会删除它创建的所有 Pod。 DaemonSet 只管理 Pod 对象，然后通过 nodeAffinity 和 Toleration 这两个调度器的小功能，保证了每个节点上有且只有一个 Pod 在 Kubernetes 项目中，当一个节点的网络插件尚未安装时，这个节点就会被自动加上名为 node.kubernetes.io/network-unavailable 的“污点”。 假如当前 DaemonSet 管理的，是一个网络插件的 Agent Pod，那么你就必须在这个 DaemonSet 的 YAML 文件里，给它的 Pod 模板加上一个能够“容忍” node.kubernetes.io/network-unavailable “污点”的 Toleration 。正如下面这个例子所示： 12345678910...template: metadata: labels: name: network-plugin-agent spec: tolerations: - key: node.kubernetes.io/network-unavailable operator: Exists effect: NoSchedule 常用于 运行集群存储守护进程—如 glusterd 和 ceph 日志收集进程如 fluentd 和 logstash， 监控进程—如 Prometheus 的NodeExporter、collectd、Datadog agent 和 Ganglia 的 gmond 等。 Job 和 cronJobJob ：用于管理运行完成后即可终止的应用，例如批处理作业任务； Job 创建一个或多个 Pod，并确保其符合目标数量，直到 Pod 正常结束而终止。 Job Controller 实际上控制了，作业执行的并行度，以及总共需要完成的任务数这两个重要参数。而在实际使用时，你需要根据作业的特性，来决定并行度（parallelism）和任务数（completions）的合理取值。 cronJob 在特定时间循环创建 Job. CronJob 与 Job 的关系，正如同 Deployment 与 ReplicaSet 的关系一样。CronJob 是一个专门用来管理 Job 对象的控制器。只不过，它创建和删除 Job 的依据，是 schedule 字段定义的、一个标准的 Unix Cron格式的表达式 由于定时任务的特殊性，很可能某个 Job 还没有执行完，另外一个新 Job 就产生了。这时候，你可以通过 spec.concurrencyPolicy 字段来定义具体的处理策略。 concurrencyPolicy: Allow，这也是默认情况，这意味着这些 Job 可以同时存在； concurrencyPolicy: Forbid，这意味着不会创建新的 Pod，该创建周期被跳过； concurrencyPolicy: Replace，这意味着新产生的 Job 会替换旧的、没有执行完的 Job。 startingDeadlineSeconds: 200 在过去的 200秒,如果 miss 的数目达到了 100 次，那么这个 Job 就不会被创建执行了。 job 成功结束后一直处于 completed 状态, 需要手动清除。 StatefulSet有状态服务 StatefulSet :用于管理有状态的持久化应用，如 database 服务程序； 与 Deployment 的不同之处在于 StatefulSet 会为每个 Pod 创建一个独有的持久性标识符，并会确保各 Pod 之间的顺序性。(部署和scale顺序) 常用场景 稳定的持久化存储， Pod 重新调度后还是能访问到相同的持久化数据，基于 PVC 实现 稳定的网络标志，Pod 重新调度后 PodName 和 HostName 不变，基于 Headless Service 实现 (即没有 Cluster IP 的 Service) 有序部署，有序扩展（0 到 N-1）。 Pod 一句定义的顺序依次进行， 基于 init containers 来实现 有序收缩，有序删除 （N-1 到 0） 补充金丝雀部署：优先发布一台或少量机器升级，等验证无误后再更新其他机器。优点是用户影响范围小，不足之处是要额外控制如何做自动更新。 蓝绿部署：2组机器，蓝代表当前的V1版本，绿代表已经升级完成的V2版本。通过LB将流量全部导入V2完成升级部署。优点是切换快速，缺点是影响全部用户。 12345$ kubectl patch statefulset mysql -p &apos;&#123;&quot;spec&quot;:&#123;&quot;updateStrategy&quot;:&#123;&quot;type&quot;:&quot;RollingUpdate&quot;,&quot;rollingUpdate&quot;:&#123;&quot;partition&quot;:2&#125;&#125;&#125;&#125;&apos;statefulset.apps/mysql patched kubectl patch statefulset mysql --type=&apos;json&apos; -p=&apos;[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/image&quot;, &quot;value&quot;:&quot;mysql:5.7.23&quot;&#125;]&apos;statefulset.apps/mysql patched 比如 MySQL 镜像从 5.7.2 更新到 5.7.23，那么只有序号大于或者等于 2 的 Pod 会被更新到这个版本。并且，如果你删除或者重启了序号小于 2 的 Pod，等它再次启动后，也会保持原先的 5.7.2 版本，绝不会被升级到 5.7.23 版本 Horizontal Pod Autoscaling使 Pod 水平自动缩放。 不是控制器，可以理解为控制器的附属品.仅适用于 Deployment 和 ReplicaSet.在 V1 版本中仅支持根据 Pod 的 CPU 利用率扩所容，在 v1alpha 版本中，支持根据内存和用户自定义的 metric 扩缩容eg：部署 RS 然后用 HPA 管理 RS. CPU &gt;80% 扩容到3个节点 , CPU &lt; 60% 缩容到 2 个节点 123kubectl run php-apache --image=hpa-example --requests=cpu=200m --expose--port=80kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10 资源限制kubernetes 中对容器的限制实际是通过 CGroup 来实现的。 Pod默认情况下，Pod 运行没有 CPU 和内存的限额。这意味着系统中的任何 Pod 将能够像执行该 Pod 所在的节点一样，消耗足够多的 CPU 和内存。一般会针对某些应用的 pod 资源进行资源限制，这个资源限制是通过 resources 的 requests 和 limits 来实现 在 Kubernetes 中，像 CPU 这样的资源被称作“可压缩资源”（ compressible resources ）。它的典型特点是，当可压缩资源不足时，Pod 只会“饥饿”，但不会退出。 而像内存这样的资源，则被称作“不可压缩资源（ incompressible resources ）。当不可压缩资源不足时，Pod 就会因为 OOM（Out-Of-Memory） 被内核杀掉。 假设是一个节点4个核心123456789101112131415spec: containers: - image: xxxx imagePullPolicy: Always name: auth ports: - containerPort: 8080 protocol: TCP resources: limits: # 最大值 cpu: &quot;4&quot; memory: 2Gi requests: # 初始值 cpu: 250m # 等同于0.25个 即请求 250/4000 的核心 memory: 250M # 1Mi=1024*1024；1M=1000*1000 根据 设置的 Requests 和 limit , kubernetes 支持了三种 QOS 级别。 资源紧张时，会根据分级 决定调度和驱逐策略。 BestEffort : 优先级最低， pod 中没设置 Requests 和 limit Burstable : 中等优先级， 至少定义了 Requests ,或者 Requests 和 limit 不相等。 Guaranteed : 高优先级，cpu.limits = cpu.requests, memory.limits = memory.requests。 只定义了 limits 则 requests 和 limits 相等 cpuset 方式，是生产环境里部署在线应用类型的 Pod 时，非常常用的一种方式。这种情况下，由于操作系统在 CPU 之间进行上下文切换的次数大大减少，容器里应用的性能会得到大幅提升 1234567891011spec: containers: - name: nginx image: nginx resources: limits: # limits 与 requests 相等， 必须是 Guaranteed 的 QoS 类型 memory: &quot;200Mi&quot; cpu: &quot;2&quot; # CPU 资源设置为一个相等的整数值 requests: memory: &quot;200Mi&quot; cpu: &quot;2&quot; ResourceQuota 对 namespace 内资源总量进行限制。123456789101112apiVersion: v1kind: ResourceQuotametadata: name: compute-resources namespace: spark-clusterspec: hard: pods: &quot;20&quot; requests.cpu: &quot;20&quot; requests.memory: 100Gi limits.cpu: &quot;40&quot; limits.memory: 200Gi 对 配置对象数量配额限制12345678910111213apiVersion: v1kind: ResourceQuotametadata: name: object-counts namespace: spark-clusterspec: hard: configmaps: &quot;10&quot; persistentvolumeclaims: &quot;4&quot; replicationcontrollers: &quot;20&quot; secrets: &quot;10&quot; services: &quot;10&quot; services.loadbalancers: &quot;2 配置CPU和内存 LimitRange限制 cpu 和 memory 的申请范围，设置默认的申请，限制的值，会在 pod 创建时就注入 Container 中12345678910111213141516171819202122apiVersion: v1kind: LimitRangemetadata: name: mem-limit-rangespec: limits: - default: # 即 limit 的值 memory: 512Mi cpu: 5 defaultRequest: # 即 request 的值 memory: 256Mi cpu: 1 max: memory: 1Gi cpu: 8 min: memory: 128Mi cpu: 0.5 maxLimitRequestRatio: # limit/request 的最大比率 memory: 2 cpu: 2 type: Container # Pod PVC 三种类型]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes的资源对象]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2FKubernetes%E7%9A%84%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[Kubernetes的资源对象Kubernetes 的 API 对象大体可分五个类别 工作负载（Workload） 发现和负载均衡（Discovery&amp;LB） 配置和存储（Config&amp;Storage） 集群（Cluster） 元数据（Metadata） 它们基本上都是围绕一个核心目的而设计：如何更好地运行和丰富 Pod 资源，从而为容器化应用提供更灵活、更完善的操作与管理组件。 Kubernetes 项目的调度器，是统一按照 Pod 而非容器的资源需求进行计算的。Pod 是 Kubernetes 里的原子调度单位. Pod，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。 对于容器来说，一个容器永远只能管理一个进程。更确切地说，一个容器，就是一个进程 工作负载Pod 是工作负载型资源中的基础资源，它负责运行容器，并为其解决环境性的依赖，例如，向容器注入共享的或持久化的存储卷、配置信息或密钥数据等。 应用程序分为 无状态 和 有状态 两种类型。 无状态 : ReplicaSet (用于确保每个Pod副本在任一时刻均能满足目标数量) 和 Deployment (用于管理无状态的持久化应用，例如 HTTP 服务器；它用于为 Pod 和 ReplicaSet 提供声明式更新，是建构在 ReplicaSet 之上的更为高级的控制器) 有状态 : StatefulSet (用于管理有状态的持久化应用，如 database 服务程序；其与 Deployment 的不同之处在于 StatefulSet 会为每个 Pod 创建一个独有的持久性标识符，并会确保各 Pod 之间的顺序性) DaemonSet： 用于确保每个节点都运行了某Pod 的一个副本，新增的节点一样会被添加此类 Pod ；在节点移除时，此类 Pod 会被回收 .( DaemonSet 常用于运行集群存储守护进程—如 glusterd 和ceph ，还有日志收集进程—如 fluentd 和 logstash，以及监控进程—如 Prometheus 的NodeExporter、collectd、Datadog agent 和 Ganglia 的 gmond 等。) Job ：用于管理运行完成后即可终止的应用，例如批处理作业任务； Job 创建一个或多个 Pod，并确保其符合目标数量，直到 Pod 正常结束而终止。 发现和负载均衡Kubernetes 为工作负载添加发现机制及负载均衡功能的 Service 资源和 Endpoint 资源，以及通过七层代理实现请求流量负载均衡的 Ingress 资源。 配置与存储Kubernetes 还支持通过标准的 CSI（Container Storage Interface） 统一存储接口以及扩展支持更多类型的存储系统。 ConfigMap : 将环境变量或存储卷的方式接入到Pod资源的容器中，并且可被多个同类的Pod共享引用，从而实现“一次修改，多处生效”。Secret : 存储敏感数据，如私钥、密码等。 集群级资源Pod、 Deployment、 Service 和 ConfigMap 等资源属于名称空间级别，可由相应的项目管理员所管理。 Kubernetes 还存在一些集群级别的资源，用于定义集群自身配置信息的对象，它们仅应该由集群管理员进行操作。 Namespace：资源对象名称的作用范围，绝大多数对象都隶属于某个名称空间，默认时隶属于default 。 Node ：Kubernetes 集群的工作节点，其标识符在当前集群中必须是唯一的。 Role ：名称空间级别的由规则组成的权限集合，可被 RoleBinding 引用。ClusterRole ：Cluster 级别的由规则组成的权限集合，可被 RoleBinding 和ClusterRoleBinding 引用。RoleBinding：将 Role 中的许可权限绑定在一个或一组用户之上，它隶属于且仅能作用于一个名称空间；绑定时，可以引用同一名称空间中的 Role，也可以引用全局名称空间中的 ClusterRole 。ClusterRoleBinding ：将 ClusterRole 中定义的许可权限绑定在一个或一组用户之上；它能够引用全局名称空间中的 ClusterRole，并能通过 Subject 添加相关信息。 元数据型资源此类资源对象用于为集群内部的其他资源配置其行为或特性，如 HorizontalPodAutoscaler 资源可用于自动伸缩工作负载类型的资源对象的规模，Pod 模板资源可用于为 pod 资源的创建预制模板，而 LimitRange 则可为名称空间的资源设置其 CPU 和内存等系统级资源的数量限制等。 其他名词cni : 网络csi : 存储cri : 容器运行]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kubectl命令常用操作示例]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fkubectl%E5%91%BD%E4%BB%A4%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[kubectl命令常用操作示例获取集群相关信息1234567891011# 显示的是当前使用的客户端及服务端程序版本信息[root@centos01 ~]# kubectl version --short=trueClient Version: v1.18.6Server Version: v1.18.0# 显示集群信息[root@centos01 ~]# kubectl cluster-infoKubernetes master is running at https://192.168.43.25:6443KubeDNS is running at https://192.168.43.25:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxyTo further debug and diagnose cluster problems, use &apos;kubectl cluster-info dump&apos;. ##查看 api 信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127[root@k8s01 ~]# kubectl api-resourcesNAME SHORTNAMES APIVERSION NAMESPACED KINDbindings v1 true Bindingcomponentstatuses cs v1 false ComponentStatusconfigmaps cm v1 true ConfigMapendpoints ep v1 true Endpointsevents ev v1 true Eventlimitranges limits v1 true LimitRangenamespaces ns v1 false Namespacenodes no v1 false Nodepersistentvolumeclaims pvc v1 true PersistentVolumeClaimpersistentvolumes pv v1 false PersistentVolumepods po v1 true Podpodtemplates v1 true PodTemplatereplicationcontrollers rc v1 true ReplicationControllerresourcequotas quota v1 true ResourceQuotasecrets v1 true Secretserviceaccounts sa v1 true ServiceAccountservices svc v1 true Servicemutatingwebhookconfigurations admissionregistration.k8s.io/v1 false MutatingWebhookConfigurationvalidatingwebhookconfigurations admissionregistration.k8s.io/v1 false ValidatingWebhookConfigurationcustomresourcedefinitions crd,crds apiextensions.k8s.io/v1 false CustomResourceDefinitionapiservices apiregistration.k8s.io/v1 false APIServicecontrollerrevisions apps/v1 true ControllerRevisiondaemonsets ds apps/v1 true DaemonSetdeployments deploy apps/v1 true Deploymentreplicasets rs apps/v1 true ReplicaSetstatefulsets sts apps/v1 true StatefulSettokenreviews authentication.k8s.io/v1 false TokenReviewlocalsubjectaccessreviews authorization.k8s.io/v1 true LocalSubjectAccessReviewselfsubjectaccessreviews authorization.k8s.io/v1 false SelfSubjectAccessReviewselfsubjectrulesreviews authorization.k8s.io/v1 false SelfSubjectRulesReviewsubjectaccessreviews authorization.k8s.io/v1 false SubjectAccessReviewhorizontalpodautoscalers hpa autoscaling/v1 true HorizontalPodAutoscalercronjobs cj batch/v1beta1 true CronJobjobs batch/v1 true Jobcertificatesigningrequests csr certificates.k8s.io/v1 false CertificateSigningRequestleases coordination.k8s.io/v1 true Leasebgpconfigurations crd.projectcalico.org/v1 false BGPConfigurationbgppeers crd.projectcalico.org/v1 false BGPPeerblockaffinities crd.projectcalico.org/v1 false BlockAffinityclusterinformations crd.projectcalico.org/v1 false ClusterInformationfelixconfigurations crd.projectcalico.org/v1 false FelixConfigurationglobalnetworkpolicies gnp crd.projectcalico.org/v1 false GlobalNetworkPolicyglobalnetworksets crd.projectcalico.org/v1 false GlobalNetworkSethostendpoints crd.projectcalico.org/v1 false HostEndpointipamblocks crd.projectcalico.org/v1 false IPAMBlockipamconfigs crd.projectcalico.org/v1 false IPAMConfigipamhandles crd.projectcalico.org/v1 false IPAMHandleippools crd.projectcalico.org/v1 false IPPoolkubecontrollersconfigurations crd.projectcalico.org/v1 false KubeControllersConfigurationnetworkpolicies crd.projectcalico.org/v1 true NetworkPolicynetworksets crd.projectcalico.org/v1 true NetworkSetendpointslices discovery.k8s.io/v1beta1 true EndpointSliceevents ev events.k8s.io/v1 true Eventingresses ing extensions/v1beta1 true Ingressflowschemas flowcontrol.apiserver.k8s.io/v1beta1 false FlowSchemaprioritylevelconfigurations flowcontrol.apiserver.k8s.io/v1beta1 false PriorityLevelConfigurationnodes metrics.k8s.io/v1beta1 false NodeMetricspods metrics.k8s.io/v1beta1 true PodMetricsalertmanagerconfigs monitoring.coreos.com/v1alpha1 true AlertmanagerConfigalertmanagers monitoring.coreos.com/v1 true Alertmanagerpodmonitors monitoring.coreos.com/v1 true PodMonitorprobes monitoring.coreos.com/v1 true Probeprometheuses monitoring.coreos.com/v1 true Prometheusprometheusrules monitoring.coreos.com/v1 true PrometheusRuleservicemonitors monitoring.coreos.com/v1 true ServiceMonitorthanosrulers monitoring.coreos.com/v1 true ThanosRuleringressclasses networking.k8s.io/v1 false IngressClassingresses ing networking.k8s.io/v1 true Ingressnetworkpolicies netpol networking.k8s.io/v1 true NetworkPolicyruntimeclasses node.k8s.io/v1 false RuntimeClasspoddisruptionbudgets pdb policy/v1beta1 true PodDisruptionBudgetpodsecuritypolicies psp policy/v1beta1 false PodSecurityPolicyclusterrolebindings rbac.authorization.k8s.io/v1 false ClusterRoleBindingclusterroles rbac.authorization.k8s.io/v1 false ClusterRolerolebindings rbac.authorization.k8s.io/v1 true RoleBindingroles rbac.authorization.k8s.io/v1 true Rolepriorityclasses pc scheduling.k8s.io/v1 false PriorityClasscsidrivers storage.k8s.io/v1 false CSIDrivercsinodes storage.k8s.io/v1 false CSINodestorageclasses sc storage.k8s.io/v1 false StorageClassvolumeattachments storage.k8s.io/v1 false VolumeAttachment[root@k8s01 ~]# kubectl api-versionsadmissionregistration.k8s.io/v1admissionregistration.k8s.io/v1beta1apiextensions.k8s.io/v1apiextensions.k8s.io/v1beta1apiregistration.k8s.io/v1apiregistration.k8s.io/v1beta1apps/v1authentication.k8s.io/v1authentication.k8s.io/v1beta1authorization.k8s.io/v1authorization.k8s.io/v1beta1autoscaling/v1autoscaling/v2beta1autoscaling/v2beta2batch/v1batch/v1beta1certificates.k8s.io/v1certificates.k8s.io/v1beta1coordination.k8s.io/v1coordination.k8s.io/v1beta1crd.projectcalico.org/v1discovery.k8s.io/v1beta1events.k8s.io/v1events.k8s.io/v1beta1extensions/v1beta1flowcontrol.apiserver.k8s.io/v1beta1metrics.k8s.io/v1beta1monitoring.coreos.com/v1monitoring.coreos.com/v1alpha1networking.k8s.io/v1networking.k8s.io/v1beta1node.k8s.io/v1node.k8s.io/v1beta1policy/v1beta1rbac.authorization.k8s.io/v1rbac.authorization.k8s.io/v1beta1scheduling.k8s.io/v1scheduling.k8s.io/v1beta1storage.k8s.io/v1storage.k8s.io/v1beta1v1 创建资源对象kubectl run kubectl expose kubectl create kubectl apply 1234567# 创建名为nginx-deploy的Deployment控制器资源对象[root@k8s01 ~]# kubectl run nginx-deploy --image=nginx:1.12 --replicas=2Flag --replicas has been deprecated, has no effect and will be removed in the future.# --replicas 已不支持直接命令式操作 # 创建名为nginx-svc的Service资源对象kubectl expose pod nginx-deploy --name=nginx-svc --port=80 查看资源对象kubectl get : 可分类列出资源对象及其相关的状态信息 12345678910111213141516171819202122# 列出系统上所有的Namespace资源对象[root@k8s01 ~]# kubectl get namespacesNAME STATUS AGEdefault Active 20mkube-node-lease Active 20mkube-public Active 20mkube-system Active 20m# 列出默认名称空间内的所有Pod和Service对象，并输出额外信息[root@k8s01 ~]# kubectl get pods,services -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESpod/nginx-deploy 1/1 Running 0 8m49s 172.18.236.129 k8s02 &lt;none&gt; &lt;none&gt;NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTORservice/kubernetes ClusterIP 10.96.0.1 &lt;none&gt; 443/TCP 30m &lt;none&gt;service/nginx-svc ClusterIP 10.100.63.22 &lt;none&gt; 80/TCP 2m11s run=nginx-deploy#列出kubenamespace名称空间中拥有k8s-app标签名称的所有Pod对象kubectl get pods -l kube-apiserver kube-system 1234# k8s集群上任一节点 均可访问curl 172.18.236.129 &amp;&amp; curl 10.100.63.22### kubectl expose pod httpd-app --type=&apos;NodePort&apos; --port 80 打印资源对象的详细信息每个资源对象都包含着用户期望的状态（Spec）和现有的实际状态 (Status）两种状态息，kubectl get-o{yaml|josn} 或 kubectl describe 命令都能够打印出指定资源对象的详细描述信息。 12345# 查看kube-system名称空间中拥有标签component=kube-apiserver的Pod对象的资源配置清单（期望的状态）及当前的状态信息，并输出为yaml格式kubectl get pods -l component=kube-apiserver -o yaml -n kube-system# 查看kube-system名称空间中拥有标签component=kube-apiserver的Pod对象的详细描述信息kubectl describe pods -l component=kube-apiserver -n kube-system 打印容器中的日志信息通常一个容器中仅会运行一个进程（及其子进程），此进程作为PID为1的进程接收并处理管理信息，同时将日志直接输出至终端中，而无须再像传统的多进程系统环境那样将日志保存于文件中，因此容器日志信息的获取一般要到其控制上进行。 kubectl logs 命令可打印Pod对象内指定容器的日志信息，命令格式为 kubectl logs[-f][-p]（POD|TYPE/NAME）[-c CONTAINER][options]”kubectl logs -f ` 123# 查看名称空间kube-system中仅有一个容器的Pod对象kube-apiserver-master.ilinux.io的日志kubectl logs kube-apiserver-k8s01 -n kube-system 在容器中执行命令kubectl exec 命令便是用于在指定的容器内运行其他应用程序的命令. 12# ，在kube-system名称空间中的Pod对象kube-apiserver-master.ilinux.io上的唯一容器中运行ps命令kubectl exec kube-apiserver-k8s01 -n kube-system -- ps 若 Pod 对象中存在多个容器，则需要以 -c 选项指定容器后再运行。 删除资源对象kubectl delete 对于受控于控制器的对象来说，删除之后其控制器可能会重建出类似的对象 123456789# 删除默认名称空间中名为nginx-svc的Service资源对象kubectl delete services nginx-svc# 删除kube-system名称空间中拥有标签“k8sapp=kube-proxy”的所有Pod对象：kubectl delete pods -l app=monitor -n kube-system# kubectl delete TYPE--all-n NS# 删除kube-public名称空间中的所有Pod对象：kubectl delete pods --all -n default 有些资源类型（如 Pod ），支持优雅删除的机制，它们有着默认的删除宽限期，不过，用户可以在命令中使用 --grace-period 选项或 --now 选项来覆盖默认的宽限期。 1234567kubectl get deploymentskubectl get svckubectl get rskubectl get podkubectl get nodekubectl get cmkubectl get secret 12[root@k8s01 storage]# kubectl run myapp --image=nginx:1.7.9 --port=80 --dry-run=client # 并未真正执行pod/myapp created (dry run)]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kubectl 的三种操作方式]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fkubectl%20%E7%9A%84%E4%B8%89%E7%A7%8D%E6%93%8D%E4%BD%9C%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[kubectl 的三种操作方式kubectl 的核心功能在于通过 API Server 操作 Kubernetes 的各种资源对象 直接命令 命令式对象配置 声明式对象配置 直接通过 kubectl 命令及相关的选项创建资源对象的方式，即为直接命令式操作 12345# 创建名为nginx-deploy的Deployment控制器资源对象kubectl run nginx-deploy --image=nginx:1.12 --replicas=2# 创建名为nginx-svc的Service资源对象kubectl expose deployment/nginx --name=nginx-svc --port=80 用户也可以根据资源清单创建资源对象，即命令式对象配置文件。假设存在定义了 Deployment 对象的 nginx-deploy.yaml 文件，和定义了 Service 对象的 nginx-svc.yaml 文件。 1kubectl create -f nginx-deploy.yaml -f nginx-svc.yaml 可以将创建交由kubectl自行确定，用户只需要声明期望的状态，即为声明式对象配置。假设存在定义了Deployment对象的nginx-deploy.yaml文件，以及定义了Service对象的nginx-svc.yaml文件 1kubectl apply -f nginx-deploy.yaml -f nginx-svc.yaml 可以简单地理解为，kubectl replace 的执行过程，是使用新的 YAML 文件中的 API 对象，替换原有的 API 对象；而 kubectl apply，则是执行了一个对原有 API 对象的 PATCH 操作. kube-apiserver 在响应命令式请求（比如，kubectl replace）的时候，一次只能处理一个写请求，否则会有产生冲突的可能。而对于声明式请求（比如，kubectl apply），一次能处理多个写操作，并且具备 Merge 能力。 istio 是一个基于 Kubernetes 项目的微服务治理框架。它的架构非常清晰. Istio 最根本的组件，是运行在每一个应用 Pod 里的 Envoy 容器(高性能 C++ 网络代理)。Istio 项目的核心，就是由无数个运行在应用 Pod 中的 Envoy 容器组成的服务代理网格 Istio 项目，则把这个代理服务以 sidecar 容器的方式，运行在了每一个被治理的应用 Pod 中。Pod 里的所有容器都共享同一个 Network Namespace。所以，Envoy 容器就能够通过配置 Pod 里的 iptables 规则，把整个 Pod 的进出流量接管下来。 Istio 的控制层（Control Plane）里的 Pilot 组件，就能够通过调用每个 Envoy 容器的 API，对这个 Envoy 代理进行配置，从而实现微服务治理。 假设这个 Istio 架构图左边的 Pod 是已经在运行的应用，而右边的 Pod 则是我们刚刚上线的应用的新版本。这时候，Pilot 通过调节这两 Pod 里的 Envoy 容器的配置，从而将 90% 的流量分配给旧版本的应用，将 10% 的流量分配给新版本应用，并且，还可以在后续的过程中随时调整。这样，一个典型的“灰度发布”的场景就完成了。比如，Istio 可以调节这个流量从 90%-10%，改到 80%-20%，再到 50%-50%，最后到 0%-100%，就完成了这个灰度发布的过程。 Istio 项目使用的，是 Kubernetes 中的一个非常重要的功能，叫作 Dynamic Admission Control (也叫做Initializer)。 pod.yaml1234567891011apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: [&apos;sh&apos;, &apos;-c&apos;, &apos;echo Hello Kubernetes! &amp;&amp; sleep 3600&apos;] 注入 envoy 容器： 123456789101112131415apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: [&apos;sh&apos;, &apos;-c&apos;, &apos;echo Hello Kubernetes! &amp;&amp; sleep 3600&apos;] - name: envoy image: lyft/envoy:845747b88f102c0fd262ab234308e9e22f693a1 command: [&quot;/usr/local/bin/envoy&quot;] ... Istio 要做的，就是编写一个用来为 Pod “自动注入” Envoy 容器的 Initializer。 Initializer 要做的工作，就是把这部分 Envoy 相关的字段，自动添加到用户提交的 Pod 的 API 对象里。可是，用户提交的 Pod 里本来就有 containers 字段和 volumes 字段，所以 Kubernetes 在处理这样的更新请求时，就必须使用类似于 git merge 这样的操作，才能将这两部分内容合并在一起(正是声明式 API 最主要的能力。)]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s基本概念]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2F%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[NamespaceNamespace 可以将一个物理的 cluster 逻辑上划分为多个虚拟 cluster 。每个cluster 就是一个Namespace 。不同的 Namespace 里的资源是完全隔离的。( 不能实现pod 间网络通讯隔离，仅用来限制资源对象名称的作用域) default : 创建资源时，默认放入 这个 Namespace 中 kube-system : Kubernetes 自己创建的系统资源放入这个 Namespace 中 K8S 组件Master组件 API Service : 提供 HTTP/HTTPS RESTful API, 即Kubernetes API, 是 Kubernetes Cluster 的前端接口，各种客户端 以及 Kubernetes其他组件可以通过它 管理 Cluster 的各种资源 Scheduler : 负责决定将 Pod 放在哪个 Node 上运行，在调度时会充分考虑 Cluster 的拓步结构，当前各个节点的负载，以及应用对高可用、性能、数据清和性的需求 Controller Manager : 负责管理 Cluster 各种资源,保证资源处于预期的状态。为满足不同业务，开发了多种 Controller etcd ： 负责保存 Kubernetes Cluster 的配置信息和各种资源的状态信息。当数据发生变化时，etcd 会快速地通知 Kubernetes相关组件。(只与 API Service 交互) Pod网络： 实现 Pod 间的相互通信 eg： flannel Node 节点kubelet: 运行在 Cluster 所有节点上，负责启动 Pod 和容器。kubelet 是 Node 的 agent ,当 Scheduler 确定在 某个 Node 上运行 Pod 后，会将 Pod 的具体配置信息（image,volume 等）发送给 该节点的 kubelet ,kubelet 根据这些信息创建和运行容器，并向 Master 报告运行状态。 kube-proxy : 集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分 Container Runtime : 容器运行环境是负责运行容器的软件,支持多个容器运行环境: Docker (1.20开始移除，预计 1.23 正式移除)、 containerd、 CRI-O 以及任何实现 Kubernetes CRI (容器运行环境接口)。 kubeadm,kubectlkubeadm : 用于初始化 Cluster kubectl : Kubernetes 命令行工具，可以通过 kubectl 部署和管理应用，查看各种资源的，创建、删除和更新各种组件。(kubelet会在API Server上注册当前工作节点，定期向Master汇报节点资源使用情况，并通过cAdvisor监控容器和节点的资源占用状况) 1234kubectl get nodes # 查看节点的状态kubectl get pod --all-namespaces # 查看所有命名空间的podkubectl get pod --all-namespaces -o wide # 查看所有命名空间的pod，并显示详细信息kubectl describe pod -n kube-system etcd-k8s01 # 查看namespace 为 kube-system pod 为 etcd-k8s01 的具体情况 service : Service是建立在一组Pod对象之上的资源抽象，它通过标签选择器选定一组Pod对象, 定义了 外界访问一组特定 Pod 的方式 (eg : 这组Pod对象定义一个统一的固定访问入口)， service有自己的 IP和端口，为 Pod 提供了负载均衡。(Service对象创建完成后即可作为服务被各客户端访问，但要真正响应这些请求，还是要依赖于各后端的资源对象。) (并不配置于任何主机或容器的网络接口之上，而是通过 Node 之上的 kube-proxy 配置为 iptables或 ipvs 规则，从而将发往此地址的所有流量调度至其后端的各 Pod 对象之上。Service 网络在 Kubernetes 集群创建时予以指定，而各 Service 的地址则在用户创建Service时予以动态配置。) Service 主要有三种常用类型 仅用于集群内部通信的 ClusterIP 类型 接入集群外部请求的 NodePort 类型，它工作于每个节点的主机 IP 之上； LoadBalancer 类型，它可以把外部请求负载均衡至多个 Node 的主机 IP 的 NodePort 之上。 此三种类型中，每一种都以其前一种为基础才能实现，而且第三种类型中的 LoadBalancer 需协同集群外部的组件才能实现，并且此外部组件并不接受 Kubernetes 的管理。 kube-proxy : 外界通过 service 访问 Pod, kube-proxy 将 service 的 TCP/UDP 数据流转发到后端的容器。如有多个副本， kube-proxy 会实现负载均衡。（每个工作节点都需要运行一个 kube-proxy 守护进程，它能够按需为 Service资源对象生成 iptables 或 ipvs 规则，从而捕获访问当前 Service 的 ClusterIP 的流量并将其转发至正确的后端Pod 对象） Pod 网络 : 实现 Pod 间的相互通信 eg： flannel, calico kube-dns : 为 Cluster 提供 DNS 服务，在执行 kubeadm init 时作为附加组件安装 Port : :port 提供给集群内部访问 service 的入口NodePort : :NodePort 提供给集群外部访问 service 的入口targetPort : 从 Port 或 NodePort 上来的数据最终经过 kube-proxy 流入到后端Pod 的 targetPort 进入容器.containerPort : 容器内部的 port,映射到 targetPort eg:docker run -p 16379:6379 --name k8s-redis redis redis-server 16379(targetPort) 实际访问的 6379(containerPo) 例子1kubectl run httpd-app --image=httpd --replicas=2 kubectl 发送 部署请求到 API Server API Server 通知 Controller Manager 创建一个 deployment资源 Scheduler 执行调度任务， 将两个副本 Pod 分发到 k8s02 和 k8s03 k8s02 和 k8s03 上的 kubelet 再各自的节点上创建并运行 Pod 执行 kubectl get pod 时 API Service 会从 etcd 中读取这些数据。 集群运行模式 “独立组件”模式，系统各组件直接以守护进程的方式运行于节点之上，各组件之间相互协作构成集群 “静态Pod模式”，除 kubelet 和 Docker 之外的其他组件（如 etcd、kube-apiserver、 kube-controller-manager 和 kubescheduler 等）都是以静态 Pod 对象运行于 Master主机之上的 Kubernetes 的“自托管”（self-hosted ）模式，它类似于第二种方式，将除了 kubelet 和 Docker 之外的其他组件运行为集群之上的 Pod 对象，但不同的是，这些 Pod 对象托管运行在集群自身之上受控于 DaemonSet 类型的控制器，而非静态的 Pod 对象 使用 kubeadm 部署的 Kubernetes 集群可运行为第 2 种或第 3 种模式，默认为静态 Pod 对象模式，需要使用自托管模式时，kubeadm init 命令使用--features-gates=selfHosting 选项即可。第 1 种模式集群的构建需要将各组件运行于系统之上的独立守护进程中，其间需要用到的证书及 Token 等认证信息也都需要手动生成，过程烦琐且极易出错，一般不推荐使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@centos01 ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s01 Ready master 18m v1.18.6k8s02 Ready &lt;none&gt; 15m v1.18.6k8s03 Ready &lt;none&gt; 15m v1.18.6[root@k8s01 ~]# kubectl label nodes k8s02 node-role.kubernetes.io/node=node/k8s02 labeled[root@k8s01 ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONk8s01 Ready master 18m v1.18.6k8s02 Ready node 15m v1.18.6k8s03 Ready &lt;none&gt; 15m v1.18.6[root@centos01 ~]# kubectl get pod --all-namespaces # kubectl get pod -ANAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-76d4774d89-xqw6g 1/1 Running 0 14mkube-system calico-node-5xqsz 1/1 Running 0 14mkube-system calico-node-cwv6n 1/1 Running 0 14mkube-system calico-node-pfpr4 1/1 Running 0 14mkube-system coredns-7ff77c879f-7frh7 1/1 Running 0 18mkube-system coredns-7ff77c879f-hlzpn 1/1 Running 0 18mkube-system etcd-k8s01 1/1 Running 0 18mkube-system kube-apiserver-k8s01 1/1 Running 0 18mkube-system kube-controller-manager-k8s01 1/1 Running 0 18mkube-system kube-proxy-hmlxx 1/1 Running 0 15mkube-system kube-proxy-nh96k 1/1 Running 0 15mkube-system kube-proxy-x57zq 1/1 Running 0 18mkube-system kube-scheduler-k8s01 1/1 Running 0 18m[root@k8s01 ~]# kubectl get pod -A -o wideNAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESkube-system calico-kube-controllers-76d4774d89-xqw6g 1/1 Running 0 44m 172.18.235.129 k8s03 &lt;none&gt; &lt;none&gt;kube-system calico-node-5xqsz 1/1 Running 0 44m 192.168.43.103 k8s03 &lt;none&gt; &lt;none&gt;kube-system calico-node-cwv6n 1/1 Running 0 44m 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system calico-node-pfpr4 1/1 Running 0 44m 192.168.43.102 k8s02 &lt;none&gt; &lt;none&gt;kube-system coredns-7ff77c879f-7frh7 1/1 Running 0 48m 172.18.73.66 k8s01 &lt;none&gt; &lt;none&gt;kube-system coredns-7ff77c879f-hlzpn 1/1 Running 0 48m 172.18.73.65 k8s01 &lt;none&gt; &lt;none&gt;kube-system etcd-k8s01 1/1 Running 0 48m 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-apiserver-k8s01 1/1 Running 0 48m 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-controller-manager-k8s01 1/1 Running 0 48m 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-hmlxx 1/1 Running 0 45m 192.168.43.103 k8s03 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-nh96k 1/1 Running 0 45m 192.168.43.102 k8s02 &lt;none&gt; &lt;none&gt;kube-system kube-proxy-x57zq 1/1 Running 0 48m 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;kube-system kube-scheduler-k8s01 1/1 Running 0 48m 192.168.43.101 k8s01 &lt;none&gt; &lt;none&gt;[root@k8s01 ~]#]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pytorch 环境配置]]></title>
    <url>%2Fpytorch%2F%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[使用AnacondaAnaconda是Python的一个开源发行版本，主要面向科学计算,可以简单理解为，Anaconda 是一个预装了很多我们用的到或用不到的第三方库的 Python。而且相比于大家熟悉的 pip install 命令，Anaconda 中增加了 conda install 命令。 1234wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh # 可以去官网上找合适的版本bash Anaconda3-2020.02-Linux-x86_64.shconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # 换源conda config --set show_channel_urls yes # 设置搜索时显示通道地址 安装pytorch12conda install pytorch torchvision cudatoolkit=10.2 -c pytorch# conda install pytorch torchvision cpuonly -c pytorch # cpu only 使用 jupyter12345jupyter notebook --generate-configvi /root/.jupyter/jupyter_notebook_config.pynohup jupyter notebook --allow-root &gt; jupyter.log 2&gt;&amp;1 &amp; 写入的配置文件1234567891011121314from notebook.auth import passwdpasswd()# 允许通过任意绑定服务器的ip访问c.NotebookApp.ip = &apos;*&apos;# 用于访问的端口c.NotebookApp.port = 8527# 不自动打开浏览器c.NotebookApp.open_browser = False# 设置登录密码c.NotebookApp.password = &apos;sha1:14855cd59712:1cf1063d38e08cd2703a07a52b66714281676b6d&apos;# 设置默认目录c.NotebookApp.notebook_dir = u&apos;/root/&apos;c.NotebookApp.base_url = &apos;/&apos; ###jupyter 还可以搭配 nginx， 切换主题，不展开 jupyter参考]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[有关于优化复杂度]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2F%E4%BC%98%E5%8C%96%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[有关于优化复杂度时间复杂度 ：与代码的结构有非常强的关系。经验论：顺序结构 O(1)二分查找 O(logn)for循环 O(n)顺序for循环 O(n)+O(n) 也是 O(n)嵌套for循环 O(n^2) 空间复杂度 ： 与代码中的数据结构的选择高度相关 优化的终极目标： 尽可能低的时间复杂度和空间复杂度，去完成一段代码的开发。 一般都 以空间换时间，因为时间是无价的常见降低时间复杂度方法： 递归，二分，排序算法，动态规划等降低空间复杂度核心思路： 能用低复杂度的数据结构， 就不用高复杂度的数据结构 日常尽量使用 内置方法，一般是最优的，但面试还是最好用基本数据结构实现 查最大值12345678910111213141516a = [1, 2, 3, 4, 9, 8, 7, 6, 5，5，4，5，9]def max_value1(): max_value = max(a) # 内置 max() 函数 print(max_value)def max_value2(): max_value = float(&apos;-inf&apos;) # float(&apos;-inf&apos;), float(&apos;inf&apos;) 无穷小 与 无穷大 for i in a: if i &gt; max_value: max_value = i print(max_value)test1()test2() 程序优化的核心思路： 暴力解法 剔除无效操作 时空转换，设计合理数据结构，完成时间复杂度向空间复杂度转移 示例剔除无效操作时间复杂度 O(n**3) 降低为 O(n**2) 1,2,5 三种金额组成 100 元，有多少种组合1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from timeit import Timer## 暴力解法def add100_1(): sum = 0 for i in range(0, 21): for j in range(0, 51): for k in range(0, 101): if 5*i + 2*j + k == 100: sum += 1## 剔除无效操作def add100_2(): sum = 0 for i in range(0, 101): for j in range(0, 51): k = 100 - 1*i - 2*j if k == 0: sum += 1 elif k &gt; 0 and k % 5 ==0: sum += 1## 进一步剔除无效操作， 随着 i 的增大， j 的循环次数会变小, 不过时间复杂度不变，扩展一下def add100_3(): sum = 0 for i in range(0, 101): for j in range(0, (100 - i)//2 + 1): k = 100 - 1*i - 2*j if k == 0: sum += 1 elif k &gt; 0 and k % 5 ==0: sum += 1t1 = Timer(&quot;add100_1()&quot;, &quot;from __main__ import add100_1&quot;)print(&quot;add100_1 cost &quot;,t1.timeit(number=1000), &quot;seconds&quot;)t2 = Timer(&quot;add100_2()&quot;, &quot;from __main__ import add100_2&quot;)print(&quot;add100_2 cost &quot;,t2.timeit(number=1000), &quot;seconds&quot;)t3 = Timer(&quot;add100_3()&quot;, &quot;from __main__ import add100_3&quot;)print(&quot;add100_3 cost &quot;,t3.timeit(number=1000), &quot;seconds&quot;)&apos;&apos;&apos;add100_1 cost 10.915886700000101 secondsadd100_2 cost 0.9650682000001325 secondsadd100_3 cost 0.5938704999998663 seconds 时空转换时间复杂度 O(n**2) 降低为 O(n) 输入数组 a = [1, 2, 3, 4, 5, 5, 5, 6, 6, 7], 查找出现最多的数值， 输出 5。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748## 嵌套 for 循环 O(n\*\*2)from timeit import Timerdef test1(): a = [1, 2, 3, 4, 5, 5, 5, 6, 6, 7] max_index = -1 time_max = 0 for i in range(len(a)): time_tem = 0 for j in range(len(a)): # 第二层循环 所有的 元素 与 a[i] 匹配 if a[i] == a[j]: time_tem +=1 if time_tem &gt; time_max: time_max = time_tem max_index = a[i] return (max_index, time_max)## 使用字典结构，两个并行的 for 循环 O(n) + O(n) 还是 O(n)def test2(): a = [1, 2, 3, 4, 5, 5, 5, 6, 6, 7] b = dict() for i in range(len(a)): # 以元素值为 key, 次数为 value 生成字段的 键值对 if a[i] in b: b[a[i]] += 1 else: b[a[i]] = 1 v_max = 0 k_max = 0 for k, v in b.items(): # 查找最大的 value 以及对应的 key if v &gt; v_max: v_max = v k_max = k return (k_max, v_max) t1 = Timer(&quot;test1()&quot;, &quot;from __main__ import test1&quot;)print(&quot;test1 cost &quot;,t1.timeit(number=1000), &quot;seconds&quot;)t2 = Timer(&quot;test2()&quot;, &quot;from __main__ import test2&quot;)print(&quot;test2 cost &quot;,t2.timeit(number=1000), &quot;seconds&quot;)&apos;&apos;&apos;test1 cost 0.012685200000305485 secondstest2 cost 0.0039678000002822955 seconds&apos;&apos;&apos;]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据结构的存储方式]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2F%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[数据结构的存储方式数据结构的存储方式只有两种：数组（顺序存储）和链表（链式存储）。 数组 : 紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间。由于是连续存储内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)；而且你如果想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N) 链表 : 元素不连续，而是靠指针指向下一个元素的位置，所以不存在数组的扩容问题。如果知道某一元素的前驱和后驱，操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)。但是正因为存储空间不连续，你无法根据一个索引算出对应元素的地址，所以不能随机访问；而且由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间。 总结数组优点: 构建简单，根据下标（indedx）查询某个元素的时间复杂度 O(1)缺点: 必须连续空间，查询元素是否存在要遍历整个数组 O(n), 删除和添加某个元素 O(n) 链表优点: 灵活分配内存空间，删除，添加元素 O(1) (单链表：前提是前一个元素已知) (双链表：前提是前/后一个元素已知)缺点: 读取元素要从链表头开始一个一个读取，查询第K 个元素 O(k) 应用场景需要很多快速查询 : 数组数据元素个数不确定, 需要经常添加删除 : 链表数据元素确定，删除插入操作不多 : 数组 python 中的基本数据结构str 是一种序列， 类似于 tuple list 和 tuple 两种类型采用了顺序表的实现技术 tuple 是不可变类型，即不变的顺序表，因此不支持改变其内部状态的任何操作，而其他方面，则与 list 的性质类似。 list 是一种采用分离式技术实现的动态顺序表,建立空表（或者很小的表）时，系统分配一块能容纳8个元素的存储区；在执行插入操作（insert或append）时，如果元素存储区满就换一块4倍大的存储区。但如果此时的表已经很大（目前的阀值为50000），则改变策略，采用加一倍的方法。引入这种改变策略的方式，是为了避免出现过多空闲的存储位置。 dict 和 set 都是通过 hash table 来实现的键值对数据结构, 实现上 set 是带空值相同的 dict。 特点 dict 中的数据是无序存放的 操作的时间复杂度，插入、查找和删除都可以在O(1)的时间复杂度 键的限制，只有可 hash 的对象才能成为 dict 的 key 和 set 的 value。可 hash 的对象即 python中的不可变对象和自定义的对象。可变对象(lits ,set , dict )是不能作为字典的键和st的值的。 dict的内存花销大但是查询速度快。自定义的对象，或者python内部的对象都是dict包装的。（hash简单的来说即映射，映射之后，不可能是连续的存在内存空间中的，总有一些内存时空的，当发现内存空间中的”空” 不足时 ，便会触发扩容操作，以免引起hash冲突） 补充数组的特点是：寻址容易，插入和删除困难； 而链表的特点是：寻址困难，插入和删除容易。 Hash Table的查询速度非常的快，几乎是O(1)的时间复杂度。hash就是找到一种数据内容和数据存放地址之间的映射关系。基于数组的，数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重，所以程序员必须要清楚表中将要存储多少数据（或者准备好定期地把数据转移到更大的哈希表中，这是个费时的过程） 一个对象的哈希值如果在其生命周期内绝不改变，就被称为 可哈希 （它需要具有 __hash__() 方法），并可以同其他对象进行比较（它需要具有 __eq__()方法）。可哈希对象必须具有相同的哈希值比较结果才会相同。 可哈希性使得对象能够作为字典键或集合成员使用，因为这些数据结构要在内部使用哈希值。]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s搭建遇到的问题]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2Fk8s%E6%90%AD%E5%BB%BA%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[master主机名错误没有修改主机名就进行了 kubeadm config print init-defaults &gt; kubeadm_init.yaml 配置文件节选123456nodeRegistration: criSocket: /var/run/dockershim.sock name: loaclhost.localdomain taints: - effect: NoSchedule key: node-role.kubernetes.io/master Unable to connect to the server: x509: certificate signed by unknown authority配置文件没有删除干净 先执行12yes|kubeadm reset # 所有节点执行，重置rm -rf $HOME/.kube # master 节点 然后12345kubeadm init --config kubeadm_init.yamlmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configsource &lt;(kubectl completion bash) # 自动补充 ImageInspectError123456789101112131415161718[root@k8s01 ~]# kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system calico-kube-controllers-76d4774d89-lwxgd 1/1 Running 0 8m1skube-system calico-node-gc24p 1/1 Running 0 8m1skube-system calico-node-ttm4x 1/1 Running 0 8m1skube-system calico-node-zns84 1/1 Running 0 8m1skube-system coredns-7ff77c879f-k66n8 0/1 ImageInspectError 0 22mkube-system coredns-7ff77c879f-vhbph 0/1 ImageInspectError 0 22mkube-system etcd-k8s01 1/1 Running 0 22mkube-system kube-apiserver-k8s01 1/1 Running 0 22mkube-system kube-controller-manager-k8s01 1/1 Running 0 22mkube-system kube-proxy-fszcx 1/1 Running 0 9m18skube-system kube-proxy-wssrj 1/1 Running 0 9m16skube-system kube-proxy-xrk2d 1/1 Running 0 22mkube-system kube-scheduler-k8s01 1/1 Running 0 22m[root@k8s01 ~]# kubectl get pods --all-namespaces|grep Inspectkube-system coredns-7ff77c879f-k66n8 0/1 ImageInspectError 0 22mkube-system coredns-7ff77c879f-vhbph 0/1 ImageInspectError 0 22m 删除重新部署 1234567891011121314[root@k8s01 ~]# docker rmi registry.aliyuncs.com/google_containers/coredns:1.6.7Untagged: registry.aliyuncs.com/google_containers/coredns:1.6.7Untagged: registry.aliyuncs.com/google_containers/coredns@sha256:695a5e109604331f843d2c435f488bf3f239a88aec49112d452c1cbf87e88405Deleted: sha256:67da37a9a360e600e74464da48437257b00a754c77c40f60c65e4cb327c34bd5Deleted: sha256:995fd0f6e0d57be9165b3568d9a9c5de6b0c138d36740727001a2e3cb0401035Deleted: sha256:225df95e717ceb672de0e45aa49f352eace21512240205972aca0fccc9612722[root@k8s01 ~]# docker pull registry.aliyuncs.com/google_containers/coredns:1.6.71.6.7: Pulling from google_containers/corednsc6568d217a00: Already existsff0415ad7f19: Pull completeDigest: sha256:695a5e109604331f843d2c435f488bf3f239a88aec49112d452c1cbf87e88405Status: Image is up to date for registry.aliyuncs.com/google_containers/coredns:1.6.7registry.aliyuncs.com/google_containers/coredns:1.6.7 部署 dashboard 时，提示权限问题eg：123customresourcedefinitions.apiextensions.k8s.io is forbidden: User &quot;system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard&quot; cannot list resource &quot;customresourcedefinitions&quot; in API group &quot;apiextensions.k8s.io&quot; at the cluster scopesecrets is forbidden: User &quot;system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard&quot; cannot list resource &quot;secrets&quot; in API group &quot;&quot; in the namespace &quot;default&quot;services is forbidden: User &quot;system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard&quot; cannot list resource &quot;services&quot; in API group &quot;&quot; in the namespace &quot;default&quot; 需要修改配置文件 1234567891011121314apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: kubernetes-dashboard namespace: kube-systemroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole ## 赋予clusterrole cluster-admin的权限 name: cluster-admin # 默认配置 kubernetes-dashboard ,只授予了此 namespaces 的权限权限 subjects:- kind: ServiceAccount name: kubernetes-dashboard namespace: kubernetes-dashboard]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k8s简介与安装]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fk8s%2F%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介docker容器化封装缺点 单机使用，集群困难 容器数量上升，管理成本加大 没有有效的容灾，自愈机制 没有统一的配置管理中心工具 没有容器周期性管理工具 没有预设编排模板，无法快速实现，大规模容器调度 没有图形化运维工具 …. Kubernetes(k8s) 是一套容器编排工具。Kubernetes 项目的本质，是为用户提供一个具有普遍意义的容器编排工具。 一个用于容器集群的自动化部署，扩展，以及管理容器应用，提供了资源调度，部署管理，服务发现，扩容缩容，监控等一整套功能。 k8s主要功能数据卷 ： pod中容器共享数据 应用程序健康检查 ： 容器内服务可能进程堵塞无法处理请求，可以设置监控检查策略保证应用健壮性 复制应用程序实例 ： 控制器维护着pod副本数量，保证一个pod或一组同类的pod数量始终可用 弹性伸缩 ： 根据设定的指标（cpu利用率）自动伸缩副本数量 服务发现 ： 使用环境变量或DNS服务插件保证容器中程序发现Pod入口访问地址 负载均衡 ： 一组pod副本分配 一个私有的集群IP地址，负载均衡转发请求到后端容器，在集群内部其他pod可通过这个clusterIP访问应用 滚动更新 ：更新服务不中断，一次更新一个pod，而不是同时删除整个服务 服务编排 ：通过文件描述部署服务，使得应用程序部署变得高效 资源监控 ：Node节点组件集成cAdvisor资源收集工具，可通过Heapster汇总整个集群节点资源数据，然后存储到InfluxDB时序数据库，再由Grafana展示 提供认证和授权 ： 支持角色访问控制（RBAC）认证授权等策略 基本对象访问这个pod集合的策略 ： 代理Pod集合对外表现是一个访问入口，分配一个集群 安装步骤 修改root密码 修改主机名 配置静态ip 修改hosts 安装docker 禁止防火墙 关闭 swap 禁止selinux k8s系统网络配置 安装k8s 验证k8s centsos7 安装最新版 k8s 流程示例准备工作三台刚安装系统的 centos7 主机（系统随意），国内环境先准备换源 192.168.43.101 k8s01192.168.43.102 k8s02192.168.43.103 k8s03 以下操作在所有主机进行 （虚拟机可以在一台主机操作完后 clone） yum 换阿里源 国内网络可能下载不了 k8s 123mv /etc/yum.repos.d/ /etc/yum.repos.d.backup/mkdir /etc/yum.repos.d/curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 配置主机名 123echo &apos;192.168.43.101 k8s01192.168.43.102 k8s02192.168.43.103 k8s03&apos; &gt;&gt; /etc/hosts 关闭 swap， 注释 swap 分区，关闭 selinux ,关闭防火墙kubernetes 的想法是将实例紧密包装到尽可能接近 100％。 所有的部署应该与CPU /内存限制固定在一起。 所以如果调度程序发送一个 pod到一台机器，它不应该使用交换。也可添加 kubelet参数 --fail-swap-on=false 来解决。但经常会出问题且难以定位，所以不推荐开启 swap 关闭 selinux 以允许容器访问宿主机的文件系统,和访问 pod 网络的需要 nftables后端兼容性问题，产生重复的防火墙规则12345678swapoff -ased -ri &apos;s/.*swap.*/#&amp;/&apos; /etc/fstab grep SELINUX= /etc/selinux/config | grep -v &quot;#&quot;sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/g&apos; /etc/selinux/configgrep SELINUX= /etc/selinux/config | grep -v &quot;#&quot;setenforce 0systemctl stop firewalldsystemctl disable firewalld 配置内核参数，将桥接的 IPv4 流量传递到 iptables的链,并加载所有配置123456cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOFsysctl --system 或者 1234567891011121314151617cat &gt; /etc/sysctl.d/kubernetes.conf &lt;&lt;EOFnet.bridge.bridge-nf-call-iptables=1net.bridge.bridge-nf-call-ip6tables=1net.ipv4.ip_forward=1net.ipv4.tcp_tw_recycle=0vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它vm.overcommit_memory=1 # 不检查物理内存是否够用vm.panic_on_oom=0 # 开启 OOMfs.inotify.max_user_instances=8192fs.inotify.max_user_watches=1048576fs.file-max=52706963fs.nr_open=52706963net.ipv6.conf.all.disable_ipv6=1net.netfilter.nf_conntrack_max=2310720 EOFsysctl --system 安装常用包,调整时区1yum install vim bash-completion net-tools gcc -y 1234567891011## 设置系统时区为中国/上海timedatectl set-timezone Asia/Shanghai## 将当前的 UTC 时间写入硬件时钟timedatectl set-local-rtc 0## 重启依赖于系统时间的服务systemctl restart rsyslogsystemctl restart crond kube-proxy开启ipvs的前置条件 123456789101112131415161718# 1、加载netfilter模块modprobe br_netfilter # 2、添加配置文件cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOF# 3、赋予权限并引导chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp;lsmod | grep -e ip_vs -e nf_conntrack_ipv4 使用阿里云安装 docker-ce , 并使用阿里云 作为镜像仓库,改为 systemd 1234567891011121314yum install -y yum-utils device-mapper-persistent-data lvm2yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum -y install docker-cemkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://1hdirfy9.mirror.aliyuncs.com&quot;], &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]&#125;EOFsystemctl daemon-reloadsystemctl enable dockersystemctl restart docker 安装 kubectl、kubelet、kubeadm 1234567891011121314151617## 添加阿里kubernetes源cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 安装yum install kubectl kubelet kubeadm -ysystemctl enable kubeletyum list --showduplicates kubeadm --disableexcludes=kubernetes # 查找kubeadm 版本yum install -y kubeadm-1.20.0-0 --disableexcludes=kubernetes # 安装 kubeadm-1.20.0-0 国内镜像拉取镜像,及修改配置 12345# 初始化配置写入文件 一般修改 advertiseAddress:master的IP eg：advertiseAddress: 192.168.43.101# 修改 imageRepository: registry.aliyuncs.com/google_containers #阿里云镜像kubeadm config print init-defaults &gt; kubeadm_init.yaml kubeadm config images pull --config kubeadm_init.yaml # 从配置文件拉取镜像 修改后的配置文件示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546apiVersion: kubeadm.k8s.io/v1beta2bootstrapTokens:- groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authenticationkind: InitConfigurationlocalAPIEndpoint: advertiseAddress: 192.168.43.101 # 主节点IP bindPort: 6443nodeRegistration: criSocket: /var/run/dockershim.sock name: k8s01 taints: - effect: NoSchedule key: node-role.kubernetes.io/master---apiServer: timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta2certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: type: CoreDNSetcd: local: dataDir: /var/lib/etcdimageRepository: registry.aliyuncs.com/google_containerskind: ClusterConfigurationkubernetesVersion: v1.18.0networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 10.244.0.0/16 # 添加pod网段scheduler: &#123;&#125;---apiVersion: kubeproxy.config.k8s.io/v1alpha1kind: KubeProxyConfigurationfeatureGates: SupportIPVSProxyMode: truemode: ipvs # 默认调度方式 IPVS 以下操作在各个主机进行 修改主机名 1hostnamectl --static set-hostname k8s01 master 12345kubeadm init --config kubeadm_init.yamlmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configecho &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc # 自动补全 slave 1kubeadm join 192.168.43.100:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:9817c0962e497c7bde436c1be5e4e98acecaf862c46dd0e1ba3d81ee04860104 master 实例 12kubectl create -f calico.yaml # 创建资源kubectl delete -f calico.yaml # 删除资源 二进制安装二进制安装 calico 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840---# Source: calico/templates/calico-config.yaml# This ConfigMap is used to configure a self-hosted Calico installation.kind: ConfigMapapiVersion: v1metadata: name: calico-config namespace: kube-systemdata: # Typha is disabled. typha_service_name: &quot;none&quot; # Configure the backend to use. calico_backend: &quot;bird&quot; # Configure the MTU to use for workload interfaces and the # tunnels. For IPIP, set to your network MTU - 20; for VXLAN # set to your network MTU - 50. veth_mtu: &quot;1440&quot; # The CNI network configuration to install on each node. The special # values in this config will be automatically populated. cni_network_config: |- &#123; &quot;name&quot;: &quot;k8s-pod-network&quot;, &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;plugins&quot;: [ &#123; &quot;type&quot;: &quot;calico&quot;, &quot;log_level&quot;: &quot;info&quot;, &quot;datastore_type&quot;: &quot;kubernetes&quot;, &quot;nodename&quot;: &quot;__KUBERNETES_NODE_NAME__&quot;, &quot;mtu&quot;: __CNI_MTU__, &quot;ipam&quot;: &#123; &quot;type&quot;: &quot;calico-ipam&quot; &#125;, &quot;policy&quot;: &#123; &quot;type&quot;: &quot;k8s&quot; &#125;, &quot;kubernetes&quot;: &#123; &quot;kubeconfig&quot;: &quot;__KUBECONFIG_FILEPATH__&quot; &#125; &#125;, &#123; &quot;type&quot;: &quot;portmap&quot;, &quot;snat&quot;: true, &quot;capabilities&quot;: &#123;&quot;portMappings&quot;: true&#125; &#125;, &#123; &quot;type&quot;: &quot;bandwidth&quot;, &quot;capabilities&quot;: &#123;&quot;bandwidth&quot;: true&#125; &#125; ] &#125;---# Source: calico/templates/kdd-crds.yamlapiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: bgpconfigurations.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: BGPConfiguration plural: bgpconfigurations singular: bgpconfiguration---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: bgppeers.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: BGPPeer plural: bgppeers singular: bgppeer---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: blockaffinities.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: BlockAffinity plural: blockaffinities singular: blockaffinity---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: clusterinformations.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: ClusterInformation plural: clusterinformations singular: clusterinformation---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: felixconfigurations.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: FelixConfiguration plural: felixconfigurations singular: felixconfiguration---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: globalnetworkpolicies.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: GlobalNetworkPolicy plural: globalnetworkpolicies singular: globalnetworkpolicy shortNames: - gnp---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: globalnetworksets.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: GlobalNetworkSet plural: globalnetworksets singular: globalnetworkset---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: hostendpoints.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: HostEndpoint plural: hostendpoints singular: hostendpoint---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ipamblocks.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: IPAMBlock plural: ipamblocks singular: ipamblock---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ipamconfigs.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: IPAMConfig plural: ipamconfigs singular: ipamconfig---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ipamhandles.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: IPAMHandle plural: ipamhandles singular: ipamhandle---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: ippools.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: IPPool plural: ippools singular: ippool---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: kubecontrollersconfigurations.crd.projectcalico.orgspec: scope: Cluster group: crd.projectcalico.org version: v1 names: kind: KubeControllersConfiguration plural: kubecontrollersconfigurations singular: kubecontrollersconfiguration---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: networkpolicies.crd.projectcalico.orgspec: scope: Namespaced group: crd.projectcalico.org version: v1 names: kind: NetworkPolicy plural: networkpolicies singular: networkpolicy---apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: networksets.crd.projectcalico.orgspec: scope: Namespaced group: crd.projectcalico.org version: v1 names: kind: NetworkSet plural: networksets singular: networkset------# Source: calico/templates/rbac.yaml# Include a clusterrole for the kube-controllers component,# and bind it to the calico-kube-controllers serviceaccount.kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: calico-kube-controllersrules: # Nodes are watched to monitor for deletions. - apiGroups: [&quot;&quot;] resources: - nodes verbs: - watch - list - get # Pods are queried to check for existence. - apiGroups: [&quot;&quot;] resources: - pods verbs: - get # IPAM resources are manipulated when nodes are deleted. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - ippools verbs: - list - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - blockaffinities - ipamblocks - ipamhandles verbs: - get - list - create - update - delete # kube-controllers manages hostendpoints. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - hostendpoints verbs: - get - list - create - update - delete # Needs access to update clusterinformations. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - clusterinformations verbs: - get - create - update # KubeControllersConfiguration is where it gets its config - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - kubecontrollersconfigurations verbs: # read its own config - get # create a default if none exists - create # update status - update # watch for changes - watch---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: calico-kube-controllersroleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: calico-kube-controllerssubjects:- kind: ServiceAccount name: calico-kube-controllers namespace: kube-system---# Include a clusterrole for the calico-node DaemonSet,# and bind it to the calico-node serviceaccount.kind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: calico-noderules: # The CNI plugin needs to get pods, nodes, and namespaces. - apiGroups: [&quot;&quot;] resources: - pods - nodes - namespaces verbs: - get - apiGroups: [&quot;&quot;] resources: - endpoints - services verbs: # Used to discover service IPs for advertisement. - watch - list # Used to discover Typhas. - get # Pod CIDR auto-detection on kubeadm needs access to config maps. - apiGroups: [&quot;&quot;] resources: - configmaps verbs: - get - apiGroups: [&quot;&quot;] resources: - nodes/status verbs: # Needed for clearing NodeNetworkUnavailable flag. - patch # Calico stores some configuration information in node annotations. - update # Watch for changes to Kubernetes NetworkPolicies. - apiGroups: [&quot;networking.k8s.io&quot;] resources: - networkpolicies verbs: - watch - list # Used by Calico for policy information. - apiGroups: [&quot;&quot;] resources: - pods - namespaces - serviceaccounts verbs: - list - watch # The CNI plugin patches pods/status. - apiGroups: [&quot;&quot;] resources: - pods/status verbs: - patch # Calico monitors various CRDs for config. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - globalfelixconfigs - felixconfigurations - bgppeers - globalbgpconfigs - bgpconfigurations - ippools - ipamblocks - globalnetworkpolicies - globalnetworksets - networkpolicies - networksets - clusterinformations - hostendpoints - blockaffinities verbs: - get - list - watch # Calico must create and update some CRDs on startup. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - ippools - felixconfigurations - clusterinformations verbs: - create - update # Calico stores some configuration information on the node. - apiGroups: [&quot;&quot;] resources: - nodes verbs: - get - list - watch # These permissions are only requried for upgrade from v2.6, and can # be removed after upgrade or on fresh installations. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - bgpconfigurations - bgppeers verbs: - create - update # These permissions are required for Calico CNI to perform IPAM allocations. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - blockaffinities - ipamblocks - ipamhandles verbs: - get - list - create - update - delete - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - ipamconfigs verbs: - get # Block affinities must also be watchable by confd for route aggregation. - apiGroups: [&quot;crd.projectcalico.org&quot;] resources: - blockaffinities verbs: - watch # The Calico IPAM migration needs to get daemonsets. These permissions can be # removed if not upgrading from an installation using host-local IPAM. - apiGroups: [&quot;apps&quot;] resources: - daemonsets verbs: - get---apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBindingmetadata: name: calico-noderoleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: calico-nodesubjects:- kind: ServiceAccount name: calico-node namespace: kube-system---# Source: calico/templates/calico-node.yaml# This manifest installs the calico-node container, as well# as the CNI plugins and network config on# each master and worker node in a Kubernetes cluster.kind: DaemonSetapiVersion: apps/v1metadata: name: calico-node namespace: kube-system labels: k8s-app: calico-nodespec: selector: matchLabels: k8s-app: calico-node updateStrategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 template: metadata: labels: k8s-app: calico-node annotations: # This, along with the CriticalAddonsOnly toleration below, # marks the pod as a critical add-on, ensuring it gets # priority scheduling and that its resources are reserved # if it ever gets evicted. scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos; spec: nodeSelector: kubernetes.io/os: linux hostNetwork: true tolerations: # Make sure calico-node gets scheduled on all nodes. - effect: NoSchedule operator: Exists # Mark the pod as a critical add-on for rescheduling. - key: CriticalAddonsOnly operator: Exists - effect: NoExecute operator: Exists serviceAccountName: calico-node # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a &quot;force # deletion&quot;: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods. terminationGracePeriodSeconds: 0 priorityClassName: system-node-critical initContainers: # This container performs upgrade from host-local IPAM to calico-ipam. # It can be deleted if this is a fresh installation, or if you have already # upgraded to use calico-ipam. - name: upgrade-ipam image: calico/cni:v3.14.1 command: [&quot;/opt/cni/bin/calico-ipam&quot;, &quot;-upgrade&quot;] env: - name: KUBERNETES_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: CALICO_NETWORKING_BACKEND valueFrom: configMapKeyRef: name: calico-config key: calico_backend volumeMounts: - mountPath: /var/lib/cni/networks name: host-local-net-dir - mountPath: /host/opt/cni/bin name: cni-bin-dir securityContext: privileged: true # This container installs the CNI binaries # and CNI network config file on each node. - name: install-cni image: calico/cni:v3.14.1 command: [&quot;/install-cni.sh&quot;] env: # Name of the CNI config file to create. - name: CNI_CONF_NAME value: &quot;10-calico.conflist&quot; # The CNI network config to install on each node. - name: CNI_NETWORK_CONFIG valueFrom: configMapKeyRef: name: calico-config key: cni_network_config # Set the hostname based on the k8s node name. - name: KUBERNETES_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName # CNI MTU Config variable - name: CNI_MTU valueFrom: configMapKeyRef: name: calico-config key: veth_mtu # Prevents the container from sleeping forever. - name: SLEEP value: &quot;false&quot; volumeMounts: - mountPath: /host/opt/cni/bin name: cni-bin-dir - mountPath: /host/etc/cni/net.d name: cni-net-dir securityContext: privileged: true # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes # to communicate with Felix over the Policy Sync API. - name: flexvol-driver image: calico/pod2daemon-flexvol:v3.14.1 volumeMounts: - name: flexvol-driver-host mountPath: /host/driver securityContext: privileged: true containers: # Runs calico-node container on each Kubernetes node. This # container programs network policy and routes on each # host. - name: calico-node image: calico/node:v3.14.1 env: # Use Kubernetes API as the backing datastore. - name: DATASTORE_TYPE value: &quot;kubernetes&quot; # Wait for the datastore. - name: WAIT_FOR_DATASTORE value: &quot;true&quot; # Set based on the k8s node name. - name: NODENAME valueFrom: fieldRef: fieldPath: spec.nodeName # Choose the backend to use. - name: CALICO_NETWORKING_BACKEND valueFrom: configMapKeyRef: name: calico-config key: calico_backend # Cluster type to identify the deployment type - name: CLUSTER_TYPE value: &quot;k8s,bgp&quot; # Auto-detect the BGP IP address. - name: IP value: &quot;autodetect&quot; # Enable IPIP - name: CALICO_IPV4POOL_IPIP value: &quot;Always&quot; # Enable or Disable VXLAN on the default IP pool. - name: CALICO_IPV4POOL_VXLAN value: &quot;Never&quot; # Set MTU for tunnel device used if ipip is enabled - name: FELIX_IPINIPMTU valueFrom: configMapKeyRef: name: calico-config key: veth_mtu # Set MTU for the VXLAN tunnel device. - name: FELIX_VXLANMTU valueFrom: configMapKeyRef: name: calico-config key: veth_mtu # The default IPv4 pool to create on startup if none exists. Pod IPs will be # chosen from this range. Changing this value after installation will have # no effect. This should fall within `--cluster-cidr`. # - name: CALICO_IPV4POOL_CIDR # value: &quot;10.96.0.0/12&quot; # Disable file logging so `kubectl logs` works. - name: CALICO_DISABLE_FILE_LOGGING value: &quot;true&quot; # Set Felix endpoint to host default action to ACCEPT. - name: FELIX_DEFAULTENDPOINTTOHOSTACTION value: &quot;ACCEPT&quot; # Disable IPv6 on Kubernetes. - name: FELIX_IPV6SUPPORT value: &quot;false&quot; # Set Felix logging to &quot;info&quot; - name: FELIX_LOGSEVERITYSCREEN value: &quot;info&quot; - name: FELIX_HEALTHENABLED value: &quot;true&quot; securityContext: privileged: true resources: requests: cpu: 250m livenessProbe: exec: command: - /bin/calico-node - -felix-live - -bird-live periodSeconds: 10 initialDelaySeconds: 10 failureThreshold: 6 readinessProbe: exec: command: - /bin/calico-node - -felix-ready - -bird-ready periodSeconds: 10 volumeMounts: - mountPath: /lib/modules name: lib-modules readOnly: true - mountPath: /run/xtables.lock name: xtables-lock readOnly: false - mountPath: /var/run/calico name: var-run-calico readOnly: false - mountPath: /var/lib/calico name: var-lib-calico readOnly: false - name: policysync mountPath: /var/run/nodeagent volumes: # Used by calico-node. - name: lib-modules hostPath: path: /lib/modules - name: var-run-calico hostPath: path: /var/run/calico - name: var-lib-calico hostPath: path: /var/lib/calico - name: xtables-lock hostPath: path: /run/xtables.lock type: FileOrCreate # Used to install CNI. - name: cni-bin-dir hostPath: path: /opt/cni/bin - name: cni-net-dir hostPath: path: /etc/cni/net.d # Mount in the directory for host-local IPAM allocations. This is # used when upgrading from host-local to calico-ipam, and can be removed # if not using the upgrade-ipam init container. - name: host-local-net-dir hostPath: path: /var/lib/cni/networks # Used to create per-pod Unix Domain Sockets - name: policysync hostPath: type: DirectoryOrCreate path: /var/run/nodeagent # Used to install Flex Volume Driver - name: flexvol-driver-host hostPath: type: DirectoryOrCreate path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds---apiVersion: v1kind: ServiceAccountmetadata: name: calico-node namespace: kube-system---# Source: calico/templates/calico-kube-controllers.yaml# See https://github.com/projectcalico/kube-controllersapiVersion: apps/v1kind: Deploymentmetadata: name: calico-kube-controllers namespace: kube-system labels: k8s-app: calico-kube-controllersspec: # The controllers can only have a single active instance. replicas: 1 selector: matchLabels: k8s-app: calico-kube-controllers strategy: type: Recreate template: metadata: name: calico-kube-controllers namespace: kube-system labels: k8s-app: calico-kube-controllers annotations: scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos; spec: nodeSelector: kubernetes.io/os: linux tolerations: # Mark the pod as a critical add-on for rescheduling. - key: CriticalAddonsOnly operator: Exists - key: node-role.kubernetes.io/master effect: NoSchedule serviceAccountName: calico-kube-controllers priorityClassName: system-cluster-critical containers: - name: calico-kube-controllers image: calico/kube-controllers:v3.14.1 env: # Choose which controllers to run. - name: ENABLED_CONTROLLERS value: node - name: DATASTORE_TYPE value: kubernetes readinessProbe: exec: command: - /usr/bin/check-status - -r---apiVersion: v1kind: ServiceAccountmetadata: name: calico-kube-controllers namespace: kube-system---# Source: calico/templates/calico-etcd-secrets.yaml---# Source: calico/templates/calico-typha.yaml---# Source: calico/templates/configure-canal.yaml]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker安全]]></title>
    <url>%2Fdocker%2FDocker%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[Docker 是基于 Linux 内核的 Namespace 技术实现资源隔离的，所有容器都共享主机的内核 尽管目前 Namespace 已经提供了非常多的资源隔离类型，但是仍然有部分关键内容没有完全隔离。其中包括一些系统的关键性目录（eg: /sys /proc） 安全问题解决 User namespace : 主要用来做容器内用户和主机的用户隔离 保障镜像安全： 私有镜像进行安全检查，拉取镜像使用 https 和受信任的镜像仓库 及时升级宿主机内核 使用安全加固组件 ： selinux , AppArmor(控制用户的访问权限), GRSecurity(只能访问控制，提供内存破坏防御，文件系统增强等多种防御形式)。 进行资源限制 使用安全容器 （每个容器都运行在一个单独的微型虚拟机中，拥有独立的操作系统和内核）（eg: Kata Container） 及时升级 docker 组件]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python性能优化(1)]]></title>
    <url>%2Fpython%2Fpython%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96(1)%2F</url>
    <content type="text"><![CDATA[列表操作列表相加 &lt; append &lt; 列表推到式12345678910111213141516171819202122import timeitdef way1(max1): mylist = [] for i in range(max1): mylist.append(i*i)def way2(max1): mylist = [i*i for i in range(max1)]def way3(max1): mylist = [] for i in range(max1): mylist = mylist + [i*i]if __name__ == &apos;__main__&apos;: t1 = timeit.Timer(&quot;way1(10000)&quot;,&quot;from __main__ import way1&quot;) t2 = timeit.Timer(&quot;way2(10000)&quot;,&quot;from __main__ import way2&quot;) t3 = timeit.Timer(&quot;way3(10000)&quot;,&quot;from __main__ import way3&quot;) print(t1.timeit(number=1000)) # 3.6928262000000003 print(t2.timeit(number=1000)) # 3.6928262000000003 print(t3.timeit(number=1000)) # 118.5624449 搜索成员时set比list快。 列表O(n), 集合O(1).12345678910111213141516171819202122232425262728import timeitdef way1(max1): mylist = [i*i for i in range(max1)] n = 0 for i in range(10000): if i in mylist: n += 1 else: n += i*2 return ndef way2(max1): myset = &#123;i*i for i in range(max1)&#125; n = 0 for i in range(10000): if i in myset: n += 1 else: n += i*2 return nif __name__ == &apos;__main__&apos;: t1 = timeit.Timer(&quot;way1(1000)&quot;,&quot;from __main__ import way1&quot;) t2 = timeit.Timer(&quot;way2(1000)&quot;,&quot;from __main__ import way2&quot;) print(t1.timeit(number=10)) # 1.479847 print(t2.timeit(number=10)) # 0.056411800000000234 if 放在 for循环外面巧用 try/except神器 collection]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[域名绑定]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fnginx%2F%E5%9F%9F%E5%90%8D%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 8088; server_name www.k8s.com; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root master; index index.html index.htm; &#125; &#125; server &#123; listen 8088; server_name www.baidu.com; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx.conf 主要功能配置文件说明]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fnginx%2FReadme%2F</url>
    <content type="text"><![CDATA[主要功能nginx 专为性能优化而开发。主要功能 正向代理 反向代理 负载均衡 动静分离 配置文件配置文件分为三块: 全局块 ：主要是设置一些影响 Nginx 服务器 整体运行的配置指令 events 块 ： 影响 Nginx 服务器与用户的网络连接 HTTP 块： 诸如反向代理和均衡负载都在此配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310# 全局块#定义Nginx运行的用户和用户组user www www; #nginx进程数，通常设置成和cpu的数量相等worker_processes 4; #全局错误日志定义类型，[debug | info | notice | warn | error | crit]#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#进程pid文件#pid logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接数上限##这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。worker_rlimit_nofile 65535;# events 块events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll #单个进程最大连接数（最大连接数=连接数+进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cup跑到100%就行。 worker_connections 1024; #keepalive 超时时间 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors on;&#125;# http 块#设定http服务器，利用它的反向代理功能提供负载均衡支持http&#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream piao.jd.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.jd.com jd.com; #默认入口文件名称 index index.html index.htm index.php; root /data/www/jd; #对******进行负载均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 &quot;/connect-controller&quot; 启用反向代理 location /connect-controller &#123; proxy_pass http://127.0.0.1:88; #请注意此处端口号不能与虚拟主机监听的端口号一样（也就是server监听的端口） proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ansible基础]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fansible%2F</url>
    <content type="text"><![CDATA[运维自动化 操作系统预备自动化 : 主机上线时，操作系统的部署 （pxe等） 配置自动化 ： 监控自动化 : 系统与应用监控，日志监控 代码持续集成与代码持续发布自动化 （git docker jenkins等） 配置自动化配置自动化优点 ： 提高工作效率，提高配置文件准确性，降低人力成本 ansible : 使用 ssh 协议，开箱即用 saltstack ： 需要配合 agent使用，配置部署极快 puppet ： 老牌工具，配合agent使用 ansible 简介ansible : 无主从结构，开箱即用，用完即走 工作原理主要分为 主机和 ansibleansible又细分为: 模块（核心和用户模块）， 主机清单， ssh, playerbook 安装123yum -y install epel-release # 安装源可获取最新版本yum -y install ansible rpm -qa | grep ansible # 查看是否安装成功 主机清单 用于ansible controller 配置主机时读取主机列表 实现主机分组 配置 直接在 主机清单文件中添加ip或主机名 先在主机清单文件添加分组，然后添加ip或主机名到分组中去 默认位置 /etc/ansible/hostseg:1echo -e &quot;[webgroup]\nwl.imwl.ml&quot; &gt;&gt; /etc/ansible/hosts ansible应用实例 实现多主机之间免密登录 12ssh-keygen -t rsa -f /root/.ssh/id_rsa -N &apos;&apos; # 在ansible controler 生成密钥ssh-copy-id -p 8822 imwl@wl.imwl.ml # wl.imwl.ml 为远程主机 改过端口8822 用户 imwl 或者使用密码登录写入host文件eg： 123[password]192.168.1.11 ansible_ssh_pass=123456192.168.1.11 ansible_ssh_user=imwl ansible_ssh_pass=123456 ansible_sudo_pass=12345678 定义主机清单 123456echo -e &quot;[webgroup]wl.imwl.ml[webgroup:vars] ansible_ssh_user=&quot;imwl&quot; ansible_ssh_port=8822ansible_ssh_pass=&apos;password&apos;&quot; &gt;&gt; /etc/ansible/hosts 使用 1ansible 主机清单中的ip或组 -m 模块 -a 参数 ping模块使用ansible webgroup -m ping 或者 ansible webgroup -m ping -u imwl输出如下：1234567891011# ansible webgroup -m ping[WARNING]: Platform linux on host wl.imwl.ml is using the discovered Python interpreter at /usr/bin/python,but future installation of another Python interpreter could change this. Seehttps://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information.wl.imwl.ml | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; ping是假ping，只是测试能否 ssh连接上 cron模块使用批量服务器周期性任务1234567891011121314# ansible webgroup -m cron -a &apos;name=&quot;testAnsibleCron&quot; job=&quot;ntpdate time.windows.com&quot; minute=0 hour=*/1&apos;[WARNING]: Platform linux on host wl.imwl.ml is using the discovered Python interpreter at /usr/bin/python,but future installation of another Python interpreter could change this. Seehttps://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information.wl.imwl.ml | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: true, &quot;envs&quot;: [], &quot;jobs&quot;: [ &quot;testAnsibleCron&quot; ]&#125; copy模块拷贝本地文件到远程src: 源文件 dest 目标文件123456789101112131415161718192021# ansible webgroup -m copy -a &apos;src=/etc/ansible/hosts dest=/home/imwl/hosts_copy&apos;[WARNING]: Platform linux on host wl.imwl.ml is using the discovered Python interpreter at /usr/bin/python,but future installation of another Python interpreter could change this. Seehttps://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information.wl.imwl.ml | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;bad8196a56cc9eaef510f76115aa6a0c3a39879c&quot;, &quot;dest&quot;: &quot;/home/imwl/hosts_copy&quot;, &quot;gid&quot;: 1001, &quot;group&quot;: &quot;imwl&quot;, &quot;md5sum&quot;: &quot;3b17254cad71ff05d84b98a72e7a5eff&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;imwl&quot;, &quot;size&quot;: 1123, &quot;src&quot;: &quot;/home/imwl/.ansible/tmp/ansible-tmp-1587796258.0093608-13268-146684972100283/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 1000&#125; 其他12# ansible-doc -l # 列出 Ansible 支持的模块# ansible-doc ping # 查看该模块帮助信息 安装1# ansible-playbook /etc/ansible/install_zabbix_agent.yml]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ansible_playbook安装案例]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fansible_playbook%2F</url>
    <content type="text"><![CDATA[ansible_playbook的一个安装案例 hosts 文件 12# echo -e &quot;[zabbix]wl.imwl.ml&quot; &gt;&gt; /etc/ansible/hosts 入口文件install_zabbix_agent.yml 1234# echo -e &quot;---- hosts: zabbix # azbbix组 roles: - install_zabbix_agent # 角色 install_zabbix_agent&quot; &gt; /etc/ansible/install_zabbix_agent.yml 定义角色 install_zabbix_agent 1234567891011121314151617# cd /etc/ansible/roles/ &amp;&amp; mkdir install_zabbix_agent &amp;&amp; cd install_zabbix_agent &amp;&amp; mkdir files tasks templates vars &amp;&amp; touch tasks/main.yml templates/zabbix_agentd templates/zabbix_agentd.conf vars/main.yml &amp;&amp; wget -c &apos;https://cdn.zabbix.com/stable/4.4.7/zabbix-4.4.7.tar.gz&apos; -O files/zabbix-4.4.7.tar.gz# tree /etc/ansible/roles/install_zabbix_agent/├── files│ └── zabbix.tar.gz├── tasks│ └── main.yml├── templates│ ├── zabbix_agentd│ └── zabbix_agentd.conf└── vars └── main.yml## 建立 files 目录，存放编译安装过的 zabbix_agent 目录的压缩文件，用于拷贝到远程主机## 建立 tasks 目录，用于编写将要执行的任务## 建立 templates 目录，用于存放可变的模板文件## 建立 vars 目录，用于存放变量信息 建立tasks主文件/etc/ansible/roles/install_zabbix_agent/tasks/main.yml 12345678910111213141516171819202122--- - name: Install Software yum: name=&#123;&#123; item &#125;&#125; state=latest with_items: - libcurl-devel - name: Create Zabbix User user: name=&#123;&#123; zabbix_user &#125;&#125; state=present createhome=no shell=/sbin/nologin - name: Copy Zabbix.tar.gz copy: src=zabbix-&#123;&#123; zabbix_version &#125;&#125;.tar.gz dest=&#123;&#123; zabbix_dir &#125;&#125;/src/zabbix-&#123;&#123; zabbix_version &#125;&#125;.tar.gz owner=root group=root - name: Uncompression Zabbix.tar.gz shell: tar zxf &#123;&#123; zabbix_dir &#125;&#125;/src/zabbix-&#123;&#123; zabbix_version &#125;&#125;.tar.gz -C &#123;&#123; zabbix_dir &#125;&#125;/ - name: Copy Zabbix Start Script template: src=zabbix_agentd dest=/etc/init.d/zabbix_agentd owner=root group=root mode=0755 - name: Copy Zabbix Config File template: src=zabbix_agentd.conf dest=&#123;&#123; zabbix_dir &#125;&#125;/zabbix/etc/zabbix_agentd.conf owner=&#123;&#123; zabbix_user &#125;&#125; group=&#123;&#123; zabbix_user &#125;&#125; mode=0644 - name: Modify Zabbix Dir Permisson file: path=&#123;&#123; zabbix_dir &#125;&#125;/zabbix owner=&#123;&#123; zabbix_user &#125;&#125; group=&#123;&#123; zabbix_user &#125;&#125; mode=0755 recurse=yes - name: Start Zabbix Service shell: /etc/init.d/zabbix_agentd start - name: Add Boot Start Zabbix Service shell: chkconfig --level 35 zabbix_agentd on 建立主变量文件/etc/ansible/roles/install_zabbix_agent/vars/main.yml 12345zabbix_dir: /usr/localzabbix_version: 4.4.7zabbix_user: zabbixzabbix_port: 10050zabbix_server_ip: 34.92.109.248 建立模板文件/etc/ansible/roles/install_zabbix_agent/templates/zabbix_agentd 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117#!/bin/bash## chkconfig: - 90 10# description: Starts and stops Zabbix Agent using chkconfig# Tested on Fedora Core 2 - 5# Should work on all Fedora Core versions## @name: zabbix_agentd# @author: Alexander Hagenah &lt;hagenah@topconcepts.com&gt;# @created: 18.04.2006## Modified for Zabbix 2.0.0# May 2012, Zabbix SIA## Source function library.. /etc/init.d/functions# Variables# Edit these to match your system settings # Zabbix-Directory BASEDIR=&#123;&#123; zabbix_dir &#125;&#125;/zabbix # Binary File BINARY_NAME=zabbix_agentd # Full Binary File Call FULLPATH=$BASEDIR/sbin/$BINARY_NAME # PID file PIDFILE=/tmp/$BINARY_NAME.pid # Establish args ERROR=0 STOPPING=0## No need to edit the things below## application checking statusif [ -f $PIDFILE ] &amp;&amp; [ -s $PIDFILE ] then PID=`cat $PIDFILE` if [ &quot;x$PID&quot; != &quot;x&quot; ] &amp;&amp; kill -0 $PID 2&gt;/dev/null &amp;&amp; [ $BINARY_NAME == `ps -e | grep $PID | awk &apos;&#123;print $4&#125;&apos;` ] then STATUS=&quot;$BINARY_NAME (pid `pidof $APP`) running..&quot; RUNNING=1 else rm -f $PIDFILE STATUS=&quot;$BINARY_NAME (pid file existed ($PID) and now removed) not running..&quot; RUNNING=0 fielse if [ `ps -e | grep $BINARY_NAME | head -1 | awk &apos;&#123; print $1 &#125;&apos;` ] then STATUS=&quot;$BINARY_NAME (pid `pidof $APP`, but no pid file) running..&quot; else STATUS=&quot;$BINARY_NAME (no pid file) not running&quot; fi RUNNING=0fi# functionsstart() &#123; if [ $RUNNING -eq 1 ] then echo &quot;$0 $ARG: $BINARY_NAME (pid $PID) already running&quot; else action $&quot;Starting $BINARY_NAME: &quot; $FULLPATH touch /var/lock/subsys/$BINARY_NAME fi&#125;stop() &#123; echo -n $&quot;Shutting down $BINARY_NAME: &quot; killproc $BINARY_NAME RETVAL=$? echo [ $RETVAL -eq 0 ] &amp;&amp; rm -f /var/lock/subsys/$BINARY_NAME RUNNING=0&#125;# logiccase &quot;$1&quot; in start) start ;; stop) stop ;; status) status $BINARY_NAME ;; restart) stop sleep 10 start ;; help|*) echo $&quot;Usage: $0 &#123;start|stop|status|restart|help&#125;&quot; cat &lt;&lt;EOF start - start $BINARY_NAME stop - stop $BINARY_NAME status - show current status of $BINARY_NAME restart - restart $BINARY_NAME if running by sending a SIGHUP or start if not running help - this screenEOF exit 1 ;;esacexit 0 /etc/ansible/roles/install_zabbix_agent/templates/zabbix_agentd.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295# This is a config file for the Zabbix agent daemon (Unix)# To get more information about Zabbix, visit http://www.zabbix.com&quot;############ GENERAL PARAMETERS #################### Option: PidFile# Name of PID file.## Mandatory: no# Default:# PidFile=/tmp/zabbix_agentd.pid### Option: LogFile# Name of log file.# If not set, syslog is used.## Mandatory: no# Default:# LogFile=LogFile=/tmp/zabbix_agentd.log### Option: LogFileSize# Maximum size of log file in MB.# 0 - disable automatic log rotation.## Mandatory: no# Range: 0-1024# Default:# LogFileSize=1### Option: DebugLevel# Specifies debug level# 0 - basic information about starting and stopping of Zabbix processes# 1 - critical information# 2 - error information# 3 - warnings# 4 - for debugging (produces lots of information)## Mandatory: no# Range: 0-4# Default:# DebugLevel=3### Option: SourceIP# Source IP address for outgoing connections.## Mandatory: no# Default:# SourceIP=### Option: EnableRemoteCommands# Whether remote commands from Zabbix server are allowed.# 0 - not allowed# 1 - allowed## Mandatory: no# Default:# EnableRemoteCommands=0### Option: LogRemoteCommands# Enable logging of executed shell commands as warnings.# 0 - disabled# 1 - enabled## Mandatory: no# Default:# LogRemoteCommands=0##### Passive checks related### Option: Server# List of comma delimited IP addresses (or hostnames) of Zabbix servers.# Incoming connections will be accepted only from the hosts listed here.# If IPv6 support is enabled then &apos;127.0.0.1&apos;, &apos;::127.0.0.1&apos;, &apos;::ffff:127.0.0.1&apos; are treated equally.## Mandatory: no# Default:# Server=Server=&#123;&#123; zabbix_server_ip &#125;&#125;### Option: ListenPort# Agent will listen on this port for connections from the server.## Mandatory: no# Range: 1024-32767# Default:# ListenPort=10050ListenPort=&#123;&#123; zabbix_port &#125;&#125;### Option: ListenIP# List of comma delimited IP addresses that the agent should listen on.# First IP address is sent to Zabbix server if connecting to it to retrieve list of active checks.## Mandatory: no# Default:# ListenIP=0.0.0.0### Option: StartAgents# Number of pre-forked instances of zabbix_agentd that process passive checks.# If set to 0, disables passive checks and the agent will not listen on any TCP port.## Mandatory: no# Range: 0-100# Default:# StartAgents=3##### Active checks related### Option: ServerActive# List of comma delimited IP:port (or hostname:port) pairs of Zabbix servers for active checks.# If port is not specified, default port is used.# IPv6 addresses must be enclosed in square brackets if port for that host is specified.# If port is not specified, square brackets for IPv6 addresses are optional.# If this parameter is not specified, active checks are disabled.# Example: ServerActive=127.0.0.1:20051,zabbix.domain,[::1]:30051,::1,[12fc::1]## Mandatory: no# Default:# ServerActive=#ServerActive=127.0.0.1:10051### Option: Hostname# Unique, case sensitive hostname.# Required for active checks and must match hostname as configured on the server.# Value is acquired from HostnameItem if undefined.## Mandatory: no# Default:# Hostname=Hostname=&#123;&#123; ansible_all_ipv4_addresses[1] &#125;&#125;### Option: HostnameItem# Item used for generating Hostname if it is undefined. Ignored if Hostname is defined.# Does not support UserParameters or aliases.## Mandatory: no# Default:# HostnameItem=system.hostname### Option: HostMetadata# Optional parameter that defines host metadata.# Host metadata is used at host auto-registration process.# An agent will issue an error and not start if the value is over limit of 255 characters.# If not defined, value will be acquired from HostMetadataItem.## Mandatory: no# Range: 0-255 characters# Default:# HostMetadata=### Option: HostMetadataItem# Optional parameter that defines an item used for getting host metadata.# Host metadata is used at host auto-registration process.# During an auto-registration request an agent will log a warning message if# the value returned by specified item is over limit of 255 characters.# This option is only used when HostMetadata is not defined.## Mandatory: no# Default:# HostMetadataItem=### Option: RefreshActiveChecks# How often list of active checks is refreshed, in seconds.## Mandatory: no# Range: 60-3600# Default:# RefreshActiveChecks=120### Option: BufferSend# Do not keep data longer than N seconds in buffer.## Mandatory: no# Range: 1-3600# Default:# BufferSend=5### Option: BufferSize# Maximum number of values in a memory buffer. The agent will send# all collected data to Zabbix Server or Proxy if the buffer is full.## Mandatory: no# Range: 2-65535# Default:# BufferSize=100### Option: MaxLinesPerSecond# Maximum number of new lines the agent will send per second to Zabbix Server# or Proxy processing &apos;log&apos; and &apos;logrt&apos; active checks.# The provided value will be overridden by the parameter &apos;maxlines&apos;,# provided in &apos;log&apos; or &apos;logrt&apos; item keys.## Mandatory: no# Range: 1-1000# Default:# MaxLinesPerSecond=100############ ADVANCED PARAMETERS #################### Option: Alias# Sets an alias for an item key. It can be used to substitute long and complex item key with a smaller and simpler one.# Multiple Alias parameters may be present. Multiple parameters with the same Alias key are not allowed.# Different Alias keys may reference the same item key.# For example, to retrieve the ID of user &apos;zabbix&apos;:# Alias=zabbix.userid:vfs.file.regexp[/etc/passwd,^zabbix:.:([0-9]+),,,,\1]# Now shorthand key zabbix.userid may be used to retrieve data.# Aliases can be used in HostMetadataItem but not in HostnameItem parameters.## Mandatory: no# Range:# Default:### Option: Timeout# Spend no more than Timeout seconds on processing## Mandatory: no# Range: 1-30# Default:Timeout=20### Option: AllowRoot# Allow the agent to run as &apos;root&apos;. If disabled and the agent is started by &apos;root&apos;, the agent# will try to switch to the user specified by the User configuration option instead.# Has no effect if started under a regular user.# 0 - do not allow# 1 - allow## Mandatory: no# Default:# AllowRoot=0### Option: User# Drop privileges to a specific, existing user on the system.# Only has effect if run as &apos;root&apos; and AllowRoot is disabled.## Mandatory: no# Default:# User=zabbix### Option: Include# You may include individual files or all files in a directory in the configuration file.# Installing Zabbix will create include directory in /usr/local/etc, unless modified during the compile time.## Mandatory: no# Default:# Include=# Include=/usr/local/etc/zabbix_agentd.userparams.conf# Include=/usr/local/etc/zabbix_agentd.conf.d/# Include=/usr/local/etc/zabbix_agentd.conf.d/*.conf####### USER-DEFINED MONITORED PARAMETERS ########## Option: UnsafeUserParameters# Allow all characters to be passed in arguments to user-defined parameters.# 0 - do not allow# 1 - allow## Mandatory: no# Range: 0-1# Default:UnsafeUserParameters=1### Option: UserParameter# User-defined parameter to monitor. There can be several user-defined parameters.# Format: UserParameter=&lt;key&gt;,&lt;shell command&gt;# See &apos;zabbix_agentd&apos; directory for examples.## Mandatory: no# Default:# UserParameter=####### LOADABLE MODULES ########## Option: LoadModulePath# Full path to location of agent modules.# Default depends on compilation options.## Mandatory: no# Default:# LoadModulePath=$&#123;libdir&#125;/modules### Option: LoadModule# Module to load at agent startup. Modules are used to extend functionality of the agent.# Format: LoadModule=&lt;module.so&gt;# The modules must be located in directory specified by LoadModulePath.# It is allowed to include multiple LoadModule parameters.## Mandatory: no# Default:# LoadModule= 安装1# ansible-playbook /etc/ansible/install_zabbix_agent.yml]]></content>
      <categories>
        <category>运维开发</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[端口绑定]]></title>
    <url>%2F%E8%BF%90%E7%BB%B4%2Fnginx%2F%E7%AB%AF%E5%8F%A3%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[localhost:8088 : nginx默认页面localhost：8089 ： master文件夹下路径1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 8089; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root master; index index.html index.htm; &#125; &#125; server &#123; listen 8088; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python_socket]]></title>
    <url>%2Fpython%2Fpython_socket%2F</url>
    <content type="text"><![CDATA[server_tcp.py123456789101112131415161718192021222324252627282930import socketimport sys# 创建 socket 对象serversocket = socket.socket( socket.AF_INET, socket.SOCK_STREAM) # socket.AF_INET6 ipv6# socket.SOCK_DGRAM udp# 获取本地主机名host = socket.gethostname()print(host)port = 9999# 绑定地址与端口号serversocket.bind((host, port))# 设置最大连接数，超过后排队serversocket.listen(5)while True: # 建立客户端连接 接受TCP连接并返回（conn,addr） clientsocket,addr = serversocket.accept() print(&quot;tcp 连接地址: %s&quot; % str(addr)) msg=&apos;欢迎访问&apos;+ &quot;\r\n&quot; clientsocket.send(msg.encode(&apos;utf-8&apos;)) # 发送TCP数据 clientsocket.close() client_tcp.py12345678910111213141516171819202122import socketimport sys# 创建 socket 对象s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 获取本地主机名host = &apos;10.40.191.58&apos;print(host)# 设置端口号port = 9999# 连接服务，指定主机和端口s.connect((host, port))# 接收小于 1024 字节的数据msg = s.recv(1024)s.close()print (msg.decode(&apos;utf-8&apos;)) server_udp.py12345678910111213141516171819202122232425262728import socketimport sys# 创建 socket 对象serversocket = socket.socket( socket.AF_INET, socket.SOCK_DGRAM) # socket.AF_INET6 ipv6# socket.SOCK_DGRAM udp# 获取本地主机名host = &apos;127.0.0.1&apos;print(host)port = 10000# 绑定地址与端口号serversocket.bind((host, port))# 设置最大连接数，超过后排队# serversocket.listen(5) 不需要while True: data, addr = serversocket.recvfrom(1024) print(&quot;udp 连接地址: %s&quot; % str(addr)) serversocket.sendto(f&apos;hello &#123;data&#125;!&apos;.encode(&apos;utf-8&apos;), addr) client_udp.py 1234567891011121314import socketimport sys s = socket.socket( socket.AF_INET, socket.SOCK_DGRAM) host = &apos;127.0.0.1&apos;port = 10000for data in [&apos;abd&apos;, &apos;嘻嘻&apos;]: s.sendto(data, (host, port)) print(s.recv(102444).code(&apos;utf-8&apos;))s.close()]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[进程与线程]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[CPU，它承担了所有的计算任务，进程是指程序的一次执行，线程是CPU的基本调度单位。 进程的内存空间是共享的，每个线程都可以使用这些共享内存, 一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存,”互斥锁”（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域 “互斥锁”（Mutual exclusion，缩写 Mutex），防止多个线程同时读写某一块内存区域 某些内存区域，只能供给固定数目的线程使用,”信号量”（Semaphore），用来保证多个线程不会互相冲突 概念进程就是操作系统中执行的一个程序，操作系统以进程为单位分配存储空间，每个进程都有自己的地址空间、数据栈以及其他用于跟踪进程执行的辅助数据，操作系统管理所有进程的执行，为它们合理的分配资源。进程可以通过fork或spawn的方式来创建新的进程来执行其他的任务，不过新的进程也有自己独立的内存空间，因此必须通过进程间通信机制（IPC，Inter-Process Communication）来实现数据共享，具体的方式包括管道、信号、套接字、共享内存区等。 一个进程还可以拥有多个并发的执行线索，简单的说就是拥有多个可以获得CPU调度的执行单元，这就是所谓的线程。由于线程在同一个进程下，它们可以共享相同的上下文，因此相对于进程而言，线程间的信息共享和通信更加容易。当然在单核CPU系统中，真正的并发是不可能的，因为在某个时刻能够获得CPU的只有唯一的一个线程，多个线程共享了CPU的执行时间 同步与异步同步： 发出一个功能调用时，在没得到结果前，该调用 不返回或继续执行后续操作异步： 发出一个功能调用时，在没得到结果前，可以继续执行后续操作。 调用的返回不受控制 异步是目的，多线程是实现这个目的的方法 阻塞和非阻塞阻塞和非阻塞 主要是程序(线程) 等待消息 通知时的状态有关。阻塞 ： 调用结果没返回前，当前线程被挂起非阻塞 ：调用不能得到结果前，该调用不会阻塞当前线程 并发并行并发 ：单核cpu 多线程，一个时间段 只有一个线程，其他线程处于挂起状态。多个线程共享了CPU的执行时间并行 ：多核cpu , 一个cpu 执行一个线程时，另一个cpu同时执行另一个线程。这两个线程间不抢占cpu资源，可同时进行 线程线程 本质上是 进程中一段并发运行的代码，所以 线程需要 操作系统投入 cpu 资源来运行和调度（Python 计算密集型，gil锁，效率反而会低） 多线程优点 ： 依然顺序执行，编程简单多线程缺点 ： 上下文切换的额外负担、线程间共享变量会出现死锁 同步/异步/阻塞/非阻塞同步阻塞 ：效率低同步非阻塞 ：需要在两种状态来回切换异步阻塞 ： 不是处理消息时阻塞，而是等待消息阻塞。不做其他任务处理异步非阻塞 ：效率高]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[tcp]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[为什么连接的时候是三次握手，关闭的时候却是四次握手？因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 ##]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HTTP基本原理]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FHTTP%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[网络模型应用层，（表现层，会话层），运输层，网络层，链路层，物理层 （链路层+物理层 表示为 网络接口层） 0. HTTP 的特性HTTP 协议构建于 TCP/IP 协议之上，是一个应用层协议，默认端口号是 80 (HTTPS: 443) HTTP 是无连接无状态的 无连接：服务器处理完客户的请求，并收到客户的应答后，即断开连接 （keep-alive :Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接 tcp连接） 无状态：对于事务处理没有记忆能力 (Cookie 客户端， Session 服务端) 1. URL 与 URIURI : 统一资源标识符 URL : 统一资源定位符 (URN : 统一资源名称 只命名资源 而不指定如何定位资源) URL 是 URI 的子集 2. 超文本Hypertext ,用超链接的方法，将各种不同空间的文字信息组织在一起的网状文本。 网页源代码 HTML 可以称之为超文本。 3. HTTP HTTPSHTTP : 超文本传输协议，用于从网络传输超文本数据到本地浏览器的传送协议 HTTPS ： 以安全为目标的 HTTP通道。 HTTP over TLS。 建立一个安全信息通道，来保证数据传输的安全。 确认网站的真实性。 TLS : 传输安全层 4. HTTP 请求过程https://imwl.ml/blog.... https: 访问数组的协议imwl.ml 服务器域名或 ip地址 DNS 服务器保存了 ip和 域名 的对应关系blog... 数据源路径,后面没有内容时，显示设置的 默认文件 浏览器（客户端） 输入 URL ,向服务器发送一个 Request (请求), 服务器收到 Request 后，返回对应的一个 Response (响应), Response 中包含页面的源代码等内容，浏览器再进行解析，便将网页呈现出来。 客户端 → 本地DNS服务器 → 根域 → eg:com → server.com → 本地DNS服务器 → 客户端 5. RequestRequest 可分为四部分 Request Method (请求方式) Request URL （请求连接） Request Headers （请求头） Request Body （请求体） 5.1 Request Method请求方式，常见有 GET , POST GET 请求参数会直接包含在URL里， （eg:https://www.baidu.com/s?wd=Python wd 就是要搜寻的关键字） POST 一般用于表单提交发起，数据常以 Form Data 即表单形式传输，不会体现在 URL 中。（包含在 Request Body 中） GET 请求提交的数据最多只有1024字节。 其他请求方式 HEAD PUT DELETE CONNECT OPTIONS TRACE 5.2 Request URL请求的网址，即统一资源定位符，可以唯一确定我们想请求的资源 5.3 Request Headers请求头， 用来说明服务器要使用的附加信息，比较重要的有Cookie,Refer,User-Agent等 Accept : 请求报头域，用于指定客户端可接受的语言类型 Accept-Language : 指定客户端可接受的语言类型 Accept-Encoding : 指定客户端可接受的内容编码 HOST : 用于指定请求资源的主机和端口号 Cookie : 是网站为了辨别用户进行 Session 跟踪而储存在用户本地的数据。 Referer : 用来标识这个请求是从哪个页面发出来的 User-Agent : UA,特殊的字符串头，使得服务器能够识别客户使用的操作系统及版本、浏览器及版本等信息。（爬虫时可加次信息伪装成浏览器） Content-type : 互联网媒体类型，在 HTTP 协议消息中，使用它来表示具体请求中的媒体类型信息。（Application/josn ,image/gif, text/html等） 5.4 Request Body一般承载的内容为 POST 请求中的Form Data , 而对于 GET 请求 Request Body 则为空。 6. Response由服务端返回给客服端。Response可以分为三部分 Request Status Code (响应状态码) Response Headers （响应头） Response Body （响应体） 6.1 Request Status Code200 表示正常。 404 表示页面未找到。 500 表示服务器内部异常。 一般情况下 2开头 （请求成功）表示成功处理了请求的状态代码。 3开头 （请求被重定向）表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。 4开头 （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。 5开头（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。 6.2 Response Headers包含了服务器对请求的应答信息 部分信息 date : 标识 Response 产生的时间 Last-Modified : 指定资源的最后修改时间 Content-Encoding ：指定 Response 内容的编码 Server : 包含了服务器的信息 Content-type ： 同Request Set-Cookie : 设置Cookie, 即告诉浏览器需要将此内容放到Cookies中，下次请求携带Cookies请求。 Expires : 指定 Response 的过期时间，使用它可以控制代理服务器或浏览器将内容更新到缓存中，如再次访问，直接从缓存中加载，降低服务器荷载，缩短加载时间。 6.3 Response Body响应的正文数据都是在响应体中（爬虫请求网页后要解析的数据就是解析响应体） 在浏览器开发工具中点击Preview,就可以看到网页源代码、json数据等，然后从中做相应内容的提取]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SQL查询优化，分库分表(3)]]></title>
    <url>%2FMySQL%2FSQL%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%EF%BC%8C%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[一、SQL查询优化（重要）1.1 获取有性能问题SQL的三种方式 通过用户反馈获取存在性能问题的SQL； 通过慢查日志获取存在性能问题的SQL； 实时获取存在性能问题的SQL； 1.1.2 慢查日志分析工具相关配置参数： 12345slow_query_log # 启动停止记录慢查日志，慢查询日志默认是没有开启的可以在配置文件中开启(on)slow_query_log_file # 指定慢查日志的存储路径及文件，日志存储和数据从存储应该分开存储long_query_time # 指定记录慢查询日志SQL执行时间的阀值默认值为10秒通常,对于一个繁忙的系统来说,改为0.001秒(1毫秒)比较合适log_queries_not_using_indexes #是否记录未使用索引的SQL 常用工具：mysqldumpslow和pt-query-digest 1pt-query-digest --explain h=127.0.0.1,u=root,p=p@ssWord slow-mysql.log 1.1.3 实时获取有性能问题的SQL（推荐） 123SELECT id,user,host,DB,command,time,state,infoFROM information_schema.processlistWHERE TIME&gt;=60 查询当前服务器执行超过60s的SQL，可以通过脚本周期性的来执行这条SQL，就能查出有问题的SQL。 1.2 SQL的解析预处理及生成执行计划（重要）1.2.1 查询过程描述（重点！！！） 上图原文连接 通过上图可以清晰的了解到MySql查询执行的大致过程： 发送SQL语句。 查询缓存，如果命中缓存直接返回结果。 SQL解析，预处理，再由优化器生成对应的查询执行计划。 执行查询，调用存储引擎API获取数据。 返回结果。 1.2.2 查询缓存对性能的影响（建议关闭缓存）第一阶段：相关配置参数： 12345query_cache_type # 设置查询缓存是否可用query_cache_size # 设置查询缓存的内存大小query_cache_limit # 设置查询缓存可用的存储最大值（加上sql_no_cache可以提高效率）query_cache_wlock_invalidate # 设置数据表被锁后是否返回缓存中的数据query_cache_min_res_unit # 设置查询缓存分配的内存块的最小单 缓存查找是利用对大小写敏感的哈希查找来实现的，Hash查找只能进行全值查找（sql完全一致），如果缓存命中，检查用户权限，如果权限允许，直接返回，查询不被解析，也不会生成查询计划。 在一个读写比较频繁的系统中，建议关闭缓存，因为缓存更新会加锁。将query_cache_type设置为off,query_cache_size设置为0。1.2.3 第二阶段：MySQL依照执行计划和存储引擎进行交互 这个阶段包括了多个子过程： 一条查询可以有多种查询方式，查询优化器会对每一种查询方式的（存储引擎）统计信息进行比较，找到成本最低的查询方式，这也就是索引不能太多的原因。1.3 会造成MySQL生成错误的执行计划的原因1、统计信息不准确2、成本估算与实际的执行计划成本不同 3、给出的最优执行计划与估计的不同 4、MySQL不考虑并发查询5、会基于固定规则生成执行计划6、MySQL不考虑不受其控制的成本，如存储过程，用户自定义函数 1.4 MySQL优化器可优化的SQL类型 查询优化器：对查询进行优化并查询mysql认为的成本最低的执行计划。 为了生成最优的执行计划，查询优化器会对一些查询进行改写 可以优化的sql类型 1、重新定义表的关联顺序； 2、将外连接转换为内连接； 3、使用等价变换规则； 4、优化count(),min(),max()； 5、将一个表达式转换为常数； 6、子查询优化； 7、提前终止查询，如发现一个不成立条件(如where id = -1)，立即返回一个空结果； 8、对in()条件进行优化； 1.5 查询处理各个阶段所需要的时间1.5.1 使用profile(目前已经不推荐使用了)12345set profiling = 1; #启动profile,这是一个session级的配制执行查询show profiles; # 查询每一个查询所消耗的总时间的信息show profiles for query N; # 查询的每个阶段所消耗的时间 1.5.2 performance_schema是5.5引入的一个性能分析引擎（5.5版本时期开销比较大）启动监控和历史记录表：use performance_schema 123update setup_instruments set enabled=&apos;YES&apos;,TIME = &apos;YES&apos; WHERE NAME LIKE &apos;stage%&apos;;update set_consumbers set enabled=&apos;YES&apos;,TIME = &apos;YES&apos; WHERE NAME LIKE &apos;event%&apos;; 1.6 特定SQL的查询优化1.6.1 大表的数据修改 1.6.2 大表的结构修改 利用主从复制，先对从服务器进入修改，然后主从切换 （推荐） 添加一个新表（修改后的结构），老表数据导入新表，老表建立触发器，修改数据同步到新表， 老表加一个排它锁（重命名）， 新表重命名， 删除老表。 修改语句这个样子： 1alter table sbtest4 modify c varchar(150) not null default &apos;&apos; 利用工具修改： ## 1.6.3 优化not in 和 &lt;&gt; 查询 子查询改写为关联查询： 二、分库分表2.1 分库分表的几种方式 分担读负载 可通过 一主多从，升级硬件来解决。 2.1.1 把一个实例中的多个数据库拆分到不同实例（集群） **拆分简单,不允许跨库。但并不能减少写负载。** 2.1.2 把一个库中的表分离到不同的数据库中 **该方式只能在一定时间内减少写压力。** 以上两种方式只能暂时解决读写性能问题。 2.1.3 数据库分片 对一个库中的相关表进行水平拆分到不同实例的数据库中 2.1.3.1 如何选择分区键 分区键要能尽可能避免跨分区查询的发生 分区键要尽可能使各个分区中的数据平均 2.1.3.2 分片中如何生成全局唯一ID 扩展：表的垂直拆分和水平拆分]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库结构优化(2)]]></title>
    <url>%2FMySQL%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一、数据库结构优化1.1 数据库结构优化目的1、减少数据冗余：（数据冗余是指在数据库中存在相同的数据，或者某些数据可以由其他数据计算得到），注意，尽量减少不代表完全避免数据冗余； 2、尽量避免数据维护中出现更新，插入和删除异常： 总结：要避免异常，需要对数据库结构进行范式化设计。 3、节约数据存储空间。 4、提高查询效率。 1.2 数据库结构设计步骤1、需求分析：全面了解产品设计的存储需求、数据处理需求、数据安全性与完整性； 2、逻辑设计（重要）：设计数据的逻辑存储结构。数据实体之间的逻辑关系，解决数据冗余和数据维护异常。数据范式可以帮助我们设计； 3、物理设计：表结构设计，存储引擎与列的数据类型； 4、维护优化：**索引优化**、存储结构优化。 1.3 数据库范式设计与反范式化传送门：数据库逻辑设计之三大范式通俗理解，一看就懂，书上说的太晦涩 1.4 物理设计 相关传送门：MySQL中字段类型与合理的选择字段类型；int(11)最大长度是多少？，varchar最大长度是多少二、高可用架构设计 2.1 读写分离 MaxScale：实现MySQL读写分离与负载均衡的中间件利器 三、数据库索引优化（非常重要）3.1 两种主要数据结构：B-tree和Hash3.1.1 B-tree结构 B-tree索引的限制： 3.1.2 Hash结构 Hash索引的限制： Hash索引必须进行二次查找 Hash索引无法用于排序 Hash索引不支持部分索引查找也不支持范围查找 Hash索引中Hash码的计算可能存在Hash冲突，不适合重复值很高的列，如性别，身份证比较合适。 3.1.3 MySQL常见索引和各种索引区别12345PRIMARY KEY（主键索引） ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) UNIQUE(唯一索引) ALTER TABLE `table_name` ADD UNIQUE (`column`)INDEX(普通索引) ALTER TABLE `table_name` ADD INDEX index_name ( `column` ) FULLTEXT(全文索引) ALTER TABLE `table_name` ADD FULLTEXT ( `column` )组合索引 ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` ) 普通索引：最基本的索引，没有任何限制 唯一索引：与”普通索引”类似，不同的就是：索引列的值必须唯一，但允许有空值。 主键索引：它 是一种特殊的唯一索引，不允许有空值。 全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时好空间。 组合索引：为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则。 3.2 使用索引好处和索引缺陷3.2.1 为什么要使用索引1、索引大大减少了存储引擎需要扫描的数据量； 2、索引可以帮助我们进行排序以避免使用临时表； 3、索引可以把随机I/O变为顺序I/O。 3.2.2 索引不是越多越好1、索引会增加写操作的成本； 2、太多的索引会增加查询优化器的选择时间。 索引就好比一本书的目录，它会让你更快的找到内容，显然目录（索引）并不是越多越好，假如这本书1000页，而有500页是目录，它当然效率低，目录是要占纸张的,而索引是要占磁盘空间的。 3.3 索引优化策略3.3.1 索引列上不能使用表达式和函数 3.3.2 前缀索引和索引列的选择性 Innodb索引列最大宽度为667个字节(utf-8 差不多255个字符),MyIsam索引类宽度最大为1000个字节，于是出现前缀索引，索引的选择性。 对于列的值较长，比如`BLOB、TEXT、VARCHAR`，就必须建立前缀索引，即将值的前一部分作为索引。这样既可以节约空间，又可以提高查询效率。但无法使用前缀索引做 `ORDER BY` 和 `GROUP BY`，也无法使用前缀索引做覆盖扫描。 **语法：** `ALTER TABLE table_name ADD KEY(column_name(prefix_length))` 如何选择索引列的顺序：1、经常会被使用到的列优先（选择性差的列不适合，如性别，查询优化器可能会认为全表扫描性能更好）； 2、选择性高的列优先； 3、宽度小的列优先（一页中存储的索引越多，降低I/O，查找越快）； 3.3.3 组合/联合索引策略如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。深入理解请移步：最左前缀原理与相关优化 3.3.4 覆盖索引策略跟组合索引有点类似，如果索引包含所有满足查询需要的数据的索引则成为覆盖索引(Covering Index)，也就是平时所说的不需要回表操作。即索引的叶子节点上面包含了他们索引的数据(hash索引不可以)。 判断标准：使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为using index,MySQL查询优化器在执行查询前会决定是否有索引覆盖查询。 优点:1、可以优化缓存,减少磁盘IO操作；2、可以减少随机IO,变随机IO操作变为顺序IO操作；3、可以避免对InnoDB主键索引的二次查询；4、可以避免MyISAM表进行系统调用； 无法使用覆盖索引的情况：1、存储引擎不支持覆盖索引；2、查询中使用了太多的列（如SELECT * ）；3、使用了双%号的like查询（底层API所限制）； mysql高效索引之覆盖索引 3.3.5 SQL索引优化总结口诀（套路重点） 全值匹配我最爱，最左前缀要遵守；带头大哥不能死，中间兄弟不能断；索引列上不计算，范围之后全失效；LIKE百分写最右，覆盖索引不写 *；不等空值还有or，索引失效要少用；字符单引不可丢，SQL高级也不难 ； MySQL高级-索引优化 3.4 使用索引来优化查询3.4.1 利用索引排序1、group by 实质是先排序后分组，遵照索引的最佳左前缀。； 2、索引中所有列的方向(升序、降序)和Order By子句完全一致； 3、当无法使用索引列，增大max_length_for_sort_data参数的设置+增大sort_buffer_size参数的设置； 4、如果最左列使用了范围，则排序会失效； 5、where 高于having，能写在where限定的条件就不要去having去限定了 3.5 索引的维护和优化3.5.1 删除重复索引 注：主键约束相当于(唯一约束 + 非空约束) 一张表中最多有一个主键约束,如果设置多个主键,就会出现如下提示：Multiple primary key defined!!! 3.5.2 删除冗余索引 检查工具：**pt-duplicate-key-checker** 扩展阅读：MySQL索引背后的数据结构及算法原理 explain 查询计划 Using where：表示优化器需要通过索引回表查询数据； Using index：表示直接访问索引就足够获取到所需要的数据，不需要通过索引回表，如覆盖索引；]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql事务，锁]]></title>
    <url>%2FMySQL%2Fmysql%E4%BA%8B%E5%8A%A1%EF%BC%8C%E9%94%81%2F</url>
    <content type="text"><![CDATA[事务事务是必须满足4个条件（ACID）： Atomicity（原子性或不可分割性）、Consistency（一致性）、Isolation（隔离性或独立性）、Durability（持久性） 原子性：一组事务，要么成功；要么撤回，即事务在执行过程中出错会回滚到事务开始前的状态。 一致性： 一个事务不论是开始前还是结束后，数据库的完整性都没有被破坏。因此写入的数据必须完全符合所有预设规则（资料精确度、串联性以及后续数据库能够自发完成预定工作）。 隔离性：数据库允许多个事务并发的同时对其数据进行读写修改等操作，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离可分为：Read uncommitted（读未提交）、Read committed（读提交）、Repeatable read（可重复读）、Serializable（串行化）。 持久性：事务在处理结束后对数据做出的修改是永久的，无法丢失 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的SQL语句要么全部执行，要么全部不执行。事务用来管理 insert , update , delete 语句。 事务控制语句 显式的开始一个事务： 123start transaction 或begin 做保存点，一个事务中可以有多个保存点： 1savepoint 保存点名称 提交事务，并使数据库中进行的所有修改成为永久性的： 1234commit 或commit work 回滚结束用户的事务，并撤销正在进行的所有未提交的修改： 1234rollback或rollback work 删除一个事务的保存点，若没有指定保存点，执行该语句操作会抛错。 1release savepoint 保存点名称 将事务滚回标记点： 1rollback to 标记点 设置事务的隔离级别。InnoDB 存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。1set transaction 事务处理方法 用 begin ， rollback ， commit 来实现事务处理。 用 set 来改变 MySQL 的自动提交模式。 set autocommit = 0 （禁止自动提交）。set autocommit = 1 （开启自动提交）。 锁锁种类 锁的粒度划分： 行锁(INNODB)，表锁(MyISAM)，页锁 锁的使用方式划分： 共享锁 （s 锁），排它锁 （x 锁） 思想上划分： 乐观锁（假设不会发生冲突，只在提交时检查是否违反数据完整性），悲观锁（假设会发生并发冲突，屏蔽一切违反数据完整性的操作） 死锁，INNODB 中才会出现，两个或多个事务在同一资源上相互占用，并请求锁定对方的资源。 #### MyISAM 表锁 表锁的实现 锁竞争 并发插入 锁调度 InnoDB 锁 事务隔离级别 锁竞争 锁实现]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql优化(1)]]></title>
    <url>%2FMySQL%2Fmysql%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一、什么影响了数据库查询速度1.1 影响数据库查询速度的四个因素 1.2 风险分析 QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 TPS：是TransactionsPerSecond的缩写，也就是事务数/秒。它是软件测试结果的测量单位。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 Tips：最好不要在主库上数据库备份，大型活动前取消这样的计划。 效率低下的sql：超高的QPS与TPS。 大量的并发：数据连接数被占满（max_connection默认100，一般把连接数设置得大一些）。并发量:同一时刻数据库服务器处理的请求数量 超高的CPU使用率：CPU资源耗尽出现宕机。 磁盘IO：磁盘IO性能突然下降、大量消耗磁盘性能的计划任务。解决：更快磁盘设备、调整计划任务、做好磁盘维护。 1.3 网卡流量：如何避免无法连接数据库的情况 减少从服务器的数量（从服务器会从主服务器复制日志） 进行分级缓存（避免前端大量缓存失效） 避免使用select * 进行查询 分离业务网络和服务器网络 1.4 大表带来的问题（重要）1.4.1 大表的特点 记录行数巨大，单表超千万 表数据文件巨大，超过10个G 1.4.2 大表的危害1.慢查询：很难在短时间内过滤出需要的数据 查询字区分度低 -&gt; 要在大数据量的表中筛选出来其中一部分数据会产生大量的磁盘io -&gt; 降低磁盘效率 2.对DDL影响： 建立索引需要很长时间： MySQL -v&lt;5.5 建立索引会锁表 MySQL -v&gt;=5.5 建立索引会造成主从延迟（mysql建立索引，先在组上执行，再在库上执行） 修改表结构需要长时间的锁表: 会造成长时间的主从延迟(‘480秒延迟’) 1.4.3 如何处理数据库上的大表 分库分表把一张大表分成多个小表 难点： 分表主键的选择 分表后跨分区数据的查询和统计 1.5 大事务带来的问题（重要）1.5.1 什么是事务 1.5.2事务的ACID属性 1、原子性（atomicity)：全部成功，全部回滚失败。银行存取款。 2、一致性（consistent)：银行转账的总金额不变。 3、隔离性（isolation)： 隔离性等级： 未提交读(READ UNCOMMITED) 脏读,两个事务之间互相可见；– 存在脏读、不可重复读、幻读的问题 已提交读(READ COMMITED)符合隔离性的基本概念,一个事务进行时，其它已提交的事物对于该事务是可见的，即可以获取其它事务提交的数据（不可重复读）。– 解决脏读的问题，存在不可重复读、幻读的问题。 可重复读(REPEATABLE READ) InnoDB的默认隔离等级。事务进行时，其它所有事务对其不可见，即多次执行读，得到的结果是一样的！ – mysql 默认级别，解决脏读、不可重复读的问题，存在幻读的问题。使用 MVCC（多版本并发控制，提高并发，不加锁）机制 实现可重复读。But，MySQL在可重复读级别已经解决幻读，插不进数据，有间隙锁。 可串行化（SERIALIZABLE） 在读取的每一行数据上都加锁，会造成大量的锁超时和锁征用，严格数据一致性且没有并发是可使用。 – 解决脏读、不可重复读、幻读，可保证事务安全，但完全串行执行，性能最低。 12345678910不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。幻读：事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。不可重复读和幻读比较：两者有些相似，但是前者针对的是update或delete，后者针对的insert。 **查看系统的事务隔离级别：**`show variables like &apos;%iso%&apos;`; **开启一个新事务：**`begin`; **提交一个事务：**`commit`; **修改事物的隔离级别：**`set session tx_isolation=&apos;read-committed&apos;`; 4、持久性(DURABILITY)：从数据库的角度的持久性，磁盘损坏就不行了 redo log机制保证事务更新的一致性和持久性 1.5.3 大事务 运行时间长，操作数据比较多的事务； 风险：锁定数据太多，回滚时间长，执行时间长。 锁定太多数据，造成大量阻塞和锁超时； 回滚时所需时间比较长，且数据仍然会处于锁定； 如果执行时间长，将造成主从延迟，因为只有当主服务器全部执行完写入日志时，从服务器才会开始进行同步，造成延迟。 解决思路： 避免一次处理太多数据，可以分批次处理； 移出不必要的SELECT操作，保证事务中只有必要的写操作。 二、什么影响了MySQL性能（非常重要）2.1 影响性能的几个方面 服务器硬件。 服务器系统（系统参数优化）。 存储引擎。MyISAM： 不支持事务，表级锁。InnoDB: 支持事务，支持行级锁，事务ACID。 数据库参数配置。 数据库结构设计和SQL语句。（重点优化） 2.2 MySQL体系结构分三层：客户端-&gt;服务层-&gt;存储引擎 MySQL是插件式的存储引擎，其中存储引擎分很多种。只要实现符合mysql存储引擎的接口，可以开发自己的存储引擎! 所有跨存储引擎的功能都是在服务层实现的。 MySQL的存储引擎是针对表的，不是针对库的。也就是说在一个数据库中可以使用不同的存储引擎。但是不建议这样做。 2.3 InnoDB存储引擎MySQL5.5及之后版本默认的存储引擎：InnoDB。 2.3.1 InnoDB使用表空间进行数据存储。show variables like &#39;innodb_file_per_table 如果innodb_file_per_table 为 ON 将建立独立的表空间，文件为tablename.ibd； 如果innodb_file_per_table 为 OFF 将数据存储到系统的共享表空间，文件为ibdataX（X为从1开始的整数）； .frm ：是服务器层面产生的文件，类似服务器层的数据字典，记录表结构。 2.3.2 (MySQL5.5默认)系统表空间与(MySQL5.6及以后默认)独立表空间1.1 系统表空间无法简单的收缩文件大小，造成空间浪费，并会产生大量的磁盘碎片。1.2 独立表空间可以通过optimeze table 收缩系统文件，不需要重启服务器也不会影响对表的正常访问。2.1 如果对多个表进行刷新时，实际上是顺序进行的，会产生IO瓶颈。2.2 独立表空间可以同时向多个文件刷新数据。 强烈建立对Innodb 使用独立表空间，优化什么的更方便，可控。 2.3.3 系统表空间的表转移到独立表空间中的方法1、使用mysqldump 导出所有数据库数据（存储过程、触发器、计划任务一起都要导出 ）可以在从服务器上操作。 2、停止MYsql 服务器，修改参数（my.cnf加入innodb_file_per_table），并删除Inoodb相关文件（可以重建Data目录）。 3、重启MYSQL，并重建Innodb系统表空间。 4、 重新导入数据。 或者 Alter table 同样可以的转移，但是无法回收系统表空间中占用的空间。 2.4 InnoDB存储引擎的特性2.4.1 特性一：事务性存储引擎及两个特殊日志类型：Redo Log 和 Undo Log Innodb 是一种事务性存储引擎。 完全支持事务的ACID特性。 支持事务所需要的两个特殊日志类型：Redo Log 和Undo Log Redo Log：实现事务的持久性(已提交的事务)。Undo Log：未提交的事务，独立于表空间，需要随机访问，可以存储在高性能io设备上。 Undo日志记录某数据被修改前的值，可以用来在事务失败时进行rollback；Redo日志记录某数据块被修改后的值，可以用来恢复未写入data file的已成功事务更新的数据。 2.4.2 特性二：支持行级锁 InnoDB支持行级锁。 行级锁可以最大程度地支持并发。 行级锁是由存储引擎层实现的。 2.5 什么是锁2.5.1 锁 2.5.2 锁类型 12S锁（读锁）： select ... lock in share modeX锁（写锁）：select ... for update (update、delete、) 2.5.3 锁的粒度MySQL的事务支持不是绑定在MySQL服务器本身，而是与存储引擎相关 将table_name加表级锁命令：lock table table_name write; 写锁会阻塞其它用户对该表的‘读写’操作，直到写锁被释放：unlock tables； 锁的开销越大，粒度越小，并发度越高。 表级锁通常是在服务器层实现的。 行级锁是存储引擎层实现的。innodb的锁机制，服务器层是不知道的 2.5.4 锁的分类（1）悲观锁 总是假设最坏的情况，每次拿数据都认为别人会修改数据，所以要加锁，别人只能等待，直到我释放锁才能拿到锁；数据库的行锁、表锁、读锁、写锁都是这种方式，java中的synchronized和ReentrantLock也是悲观锁的思想。 （2）乐观锁 总是假设最好的情况，每次拿数据都认为别人不会修改数据，所以不会加锁，但是更新的时候，会判断在此期间有没有人修改过；一般基于版本号机制实现。 （3）使用场景 乐观锁适用于读多写少的情况，即冲突很少发生；如果是多写的情况，应用会不断重试，反而会降低系统性能，这种情况最好用悲观锁，因为等待到锁被释放后，可以立即获得锁进行操作。 拓展： (1)图解悲观锁和乐观锁(2)什么是乐观锁与悲观锁？ 2.5.5 阻塞和死锁（1）阻塞是由于资源不足引起的排队等待现象。（2）死锁是由于两个对象在拥有一份资源的情况下申请另一份资源，而另一份资源恰好又是这两对象正持有的，导致两对象无法完成操作，且所持资源无法释放。 2.6 如何选择正确的存储引擎参考条件： 事务 备份(Innobd免费在线备份) 崩溃恢复 存储引擎的特有特性 总结:**Innodb大法好。 注意:**尽量别使用混合存储引擎，比如回滚会出问题在线热备问题。 2.7 配置参数2.7.1 内存配置相关参数 确定可以使用的内存上限。 1内存的使用上限不能超过物理内存，否则容易造成内存溢出；（对于32位操作系统，MySQL只能试用3G以下的内存。） 确定MySQL的每个连接单独使用的内存。 1234sort_buffer_size #定义了每个线程排序缓存区的大小，MySQL在有查询、需要做排序操作时才会为每个缓冲区分配内存（直接分配该参数的全部内存）；join_buffer_size #定义了每个线程所使用的连接缓冲区的大小，如果一个查询关联了多张表，MySQL会为每张表分配一个连接缓冲，导致一个查询产生了多个连接缓冲；read_buffer_size #定义了当对一张MyISAM进行全表扫描时所分配读缓冲池大小，MySQL有查询需要时会为其分配内存，其必须是4k的倍数；read_rnd_buffer_size #索引缓冲区大小，MySQL有查询需要时会为其分配内存，只会分配需要的大小。 注意：以上四个参数是为一个线程分配的，如果有100个连接，那么需要×100。 MySQL数据库实例： ①MySQL是单进程多线程（而oracle是多进程），也就是说MySQL实例在系统上表现就是一个服务进程，即进程； ②MySQL实例是线程和内存组成，实例才是真正用于操作数据库文件的； 一般情况下一个实例操作一个或多个数据库；集群情况下多个实例操作一个或多个数据库。 如何为缓存池分配内存：Innodb_buffer_pool_size，定义了Innodb所使用缓存池的大小，对其性能十分重要，必须足够大，但是过大时，使得Innodb 关闭时候需要更多时间把脏页从缓冲池中刷新到磁盘中； 1总内存-（每个线程所需要的内存*连接数）-系统保留内存 key_buffer_size，定义了MyISAM所使用的缓存池的大小，由于数据是依赖存储操作系统缓存的，所以要为操作系统预留更大的内存空间； 1select sum(index_length) from information_schema.talbes where engine=&apos;myisam&apos; 注意：即使开发使用的表全部是Innodb表，也要为MyISAM预留内存，因为MySQL系统使用的表仍然是MyISAM表。 max_connections 控制允许的最大连接数， 一般2000更大。不要使用外键约束保证数据的完整性。 2.8 性能优化顺序从上到下：]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql索引]]></title>
    <url>%2FMySQL%2Fmysql%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[mysql B+树 正确创建合适的索引是数据库优化的基础 索引本质索引为了 加速对表中数据行的检索 而创建的 一种分散存储的数据结构 在 RDBMS系统中 数据的索引都是 硬盘级索引，只有一少部分在内存中 hash索引 等值匹配非常快，但范围查询不可以 二叉树性结构存在问题 树的高度的太高,IO次数太多 页为单位，默认4K MYSQL默认 16K， 可以加载多个关键字，但一次加载关键字太少 B 树 （多路 平衡 树）关键字的个数 = 路数 -1 关键字都有数据区,会多余读取 B + 树 （加强版 多路 平衡 树）mysql 匹配过程 采用了 左闭合 的比较规则 读取的关键字 以及 子节点的引用 只有最后一层有数据区 IO能力， 排序能力， 扫表能力，查询效率稳定可靠 索引离散性越好，列的选折性就越好，越适合作为索引。离散性差的作为索引适得其反（例如性别） 聚集索引 ： 数据库 表中数据的 物理顺序 与 键值 的逻辑（索引） 顺序相同主键索引 ：辅助索引 ：三星索引 ：联合索引：联合索引 ： eg: create index idx_name_phoneNum on user(name,phoneNum,age)单列索引 : 一种特殊的联合索引 create index idx_name on user(name) 联合索引 用到 范围匹配后面的索引 就会失效 最左匹配对 索引中关键字的对比 ，从左往右 依次进行比较 abc &lt; acd所以使用 like %abc %在左边 不好，因为会查询整个 B+tree]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[有关于@property]]></title>
    <url>%2Fpython%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F%E6%9C%89%E5%85%B3%E4%BA%8E%40property%2F</url>
    <content type="text"><![CDATA[有关于@property1. 将方法改为属性这种类型的attributes并不会被实际的存储，而是在需要的时候计算出来 1234567891011121314151617181920import mathclass Circle: def __init__(self, radius): self.radius = radius def area(self): return math.pi * self.radius ** 2 @property def diameter(self): return self.radius * 2 @property def perimeter(self): return 2 * math.pi * self.radiusc = Circle(3)print(c.area()) # 方法调用print(c.diameter) # 属性访问print(c.perimeter) 2. 做限定参考前文 3.]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[上下文管理器]]></title>
    <url>%2Fpython%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[上下文管理器让对象支持上下文管理器对象需要定义 __enter__ 和 __exit__1234567891011121314151617181920212223242526272829303132333435from socket import socket, AF_INET, SOCK_STREAMclass LazyConnection: def __init__(self, address, family=AF_INET, type=SOCK_STREAM): self.address = address self.family = family self.type = type self.sock = None def __enter__(self): if self.sock is not None: raise RuntimeError(&apos;Already connected&apos;) self.sock = socket(self.family, self.type) self.sock.connect(self.address) return self.sock def __exit__(self, exc_ty, exc_val, tb): # 异常类型，异常值和异常的trackback self.sock.close() self.sock = None #return True 如果这里返回True 则代表不处理with中的异常if __name__ == &apos;__main__&apos;: from functools import partial conn = LazyConnection((&apos;www.python.org&apos;, 80)) # Connection closed with conn as s: # conn.__enter__() executes: connection open s.send(b&apos;GET /index.html HTTP/1.0\r\n&apos;) s.send(b&apos;Host: www.python.org\r\n&apos;) s.send(b&apos;\r\n&apos;) resp = b&apos;&apos;.join(iter(partial(s.recv, 8192), b&apos;&apos;)) print(resp) # conn.__exit__() executes: connection closed 线程安全修改版12345678910111213141516171819202122232425262728293031323334353637383940from socket import socket, AF_INET, SOCK_STREAMimport threadingclass LazyConnection: def __init__(self, address, family=AF_INET, type=SOCK_STREAM): self.address = address self.family = AF_INET self.type = SOCK_STREAM self.local = threading.local() def __enter__(self): if hasattr(self.local, &apos;sock&apos;): raise RuntimeError(&apos;Already connected&apos;) self.local.sock = socket(self.family, self.type) self.local.sock.connect(self.address) return self.local.sock def __exit__(self, exc_ty, exc_val, tb): self.local.sock.close() del self.local.sockfrom functools import partialdef test(conn): with conn as s: s.send(b&apos;GET /index.html HTTP/1.0\r\n&apos;) s.send(b&apos;Host: www.huawei.com\r\n&apos;) s.send(b&apos;\r\n&apos;) resp = b&apos;&apos;.join(iter(partial(s.recv, 8192), b&apos;&apos;)) print(&apos;Got &#123;&#125; bytes&apos;.format(len(resp)))if __name__ == &apos;__main__&apos;: conn = LazyConnection((&apos;www.huawei.com&apos;, 80)) t1 = threading.Thread(target=test, args=(conn,)) t2 = threading.Thread(target=test, args=(conn,)) t1.start() t2.start() t1.join() t2.join() 使用 contexlib 模块中的 @contextmanager装饰器实现一个新的上下文管理器的最简单的方法 yield 之前的代码会在上下文管理器中作为 __enter__() 方法执行，所有在 yield 之后的代码会作为 __exit__() 方法执行 先执行print(&#39;《&#39;, end=&#39;&#39;)，遇到yeild ,执行 print(&#39;挪威的森林&#39;,end=&#39;&#39;) , 最后执行 print(&#39;》&#39;, end=&#39;&#39;)123456789101112from contextlib import contextmanager@contextmanagerdef book_mark(): print(&apos;《&apos;, end=&apos;&apos;) yield print(&apos;》&apos;, end=&apos;&apos;)with book_mark(): print(&apos;挪威的森林&apos;,end=&apos;&apos;) # 《挪威的森林》 123456789101112131415161718import timeclass timethis: def __init__(self, label): self.label = label def __enter__(self): self.start = time.time() print(f&apos;start = &#123;self.start&#125;&apos;) def __exit__(self, exc_ty, exc_val, exc_tb): end = time.time() print(f&apos;&#123;end = &#125;&apos;) print(&apos;&#123;&#125;: &#123;&#125;&apos;.format(self.label, end - self.start)) with timethis(&apos;counting&apos;): n = 10000000 while n &gt; 0: n -= 1 使用from contextlib import contextmanager12345678910111213141516171819import timefrom contextlib import contextmanager@contextmanagerdef timethis(label): start = time.time() print(f&apos;&#123;start = &#125;&apos;) try: yield finally: end = time.time() print(f&apos;&#123;end = &#125;&apos;) print(f&apos;&#123;label&#125; : &#123;end - start&#125;&apos;)# Example usewith timethis(&apos;counting&apos;): n = 10000000 while n &gt; 0: n -= 1 任何对列表的修改只有当所有代码运行完成并且不出现异常的情况下才会生效123456789101112131415161718192021222324 from contextlib import contextmanager@contextmanagerdef list_transaction(orig_list): working = list(orig_list) yield working orig_list[:] = working # 任何对列表的修改只有当所有代码运行完成并且不出现异常的情况下才会生效items = [1,2,3]with list_transaction(items) as working: working.append(4) working.append(5)print(items) # [1,2,3,4,5]with list_transaction(items) as working: working.append(6) working.append(7) working是[1,2,3,4,5,6,7] raise RuntimeError(&apos;oops&apos;) 执行不了orig_list[:] = workingprint(items) ## 还是 [1,2,3,4,5]]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面向对象]]></title>
    <url>%2Fpython%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[待解决dataclass + __solts__的问题 __solts__ 使用slots一个不好的地方就是我们不能再给实例添加新的属性了，只能使用在 __slots__ 中定义的那些属性名 使用__solts__,python实例通过一个很小的固定大小的数组来构建，而不是为每个实例定义一个字典，这跟元组或列表很类似.Python的很多特性都依赖于普通的基于字典的实现。另外，定义了slots后的类不再支持一些普通类特性了，比如多继承。 尽量不要使用 __solts__ github上相关问题 多加一个装饰器 基础1234567891011121314151617181920212223class Color(): r = 200 def __init__(self,r=250): self.r = r self.g = self.get_g() self.b = self.get_b def get_g(self): g = 223 return g @property def get_b(self): b = 222 return b def __str__(self): return f&apos;&#123;self.__class__.__name__&#125;(class_r = &#123;self.__class__.r&#125;, r = &#123;self.r&#125;, g = &#123;self.g&#125;, b = &#123;self.b&#125;)&apos;color = Color(255)color1 = Color()print(color) # Color(class_r = 200, r = 255, g = 223, b = 222)print(color1) # Color(class_r = 200, r = 250, g = 223, b = 222) 1234567891011121314151617181920class Color(): r = 200 def __init__(self): self.g = self.get_g() self.b = self.get_b def get_g(self): g = 223 return g @property def get_b(self): b = 222 return b def __str__(self): return f&apos;&#123;self.__class__.__name__&#125;(class_r = &#123;self.__class__.r&#125;, r = &#123;self.r&#125;, g = &#123;self.g&#125;, b = &#123;self.b&#125;)&apos;color = Color()print(color) # Color(class_r = 200, r = 255, g = 223, b = 222) 使用第三方插件修改一下1234567891011121314151617from attr import attrs, attrib # dataclass 内置库可替代&apos;&apos;&apos;attrs 修饰符，可以自动实现__init__,__repr__,__eq__,__ne__,__it__,__le__,__gt__,__ge__,__hash__,这几个方法&apos;&apos;&apos;@attrsclass Color(): r = attrib(type=int, default=100) g = attrib(type=int, default=200) b = attrib(type=int, default=222)color = Color(255,254,253)color1 = Color()print(color) # Color(class_r = 200, r = 255, g = 223, b = 222)print(color1) # Color(class_r = 200, r = 250, g = 223, b = 222) 声明和比较123456789101112131415from attr import attrs, attrib # dataclass内置库可替代&apos;&apos;&apos;attrs 修饰符，可以自动实现__init__,__repr__,__eq__,__ne__,__it__,__le__,__gt__,__ge__,__hash__,这几个方法&apos;&apos;&apos;@attrsclass Point(): x = attrib() y = attrib()p1 = Point(1,2)p2 = Point(y=3,x=4)print(p1,p2) # Point(x=1, y=2) Point(x=4, y=3) 使用python3.7 的内置库12345678910from dataclasses import dataclass@dataclassclass Point(): x:int = 0 y:int = 0p1 = Point(1,2)p2 = Point(y=3,x=4)print(p1,p2) # Point(x=1, y=2) Point(x=4, y=3) 1234567891011# 默认init,repr,eq 为True， 其余为False@dataclass(init=1,repr=1,eq=1,order=1,unsafe_hash=0,frozen=0)class Point(): x:int = 0 y:int = 0p1 = Point(1,2)p2 = Point(y=3,x=4)p3 = Point(x=1,y=2)print(p1&gt;p2) # fasleprint(p1==p3) # True 1234567891011from dataclasses import dataclass@dataclass(frozen=1)class Point(): x:int = 0 y:int = 0p1 = Point(1,2)print(p1) # 当实例化一个frozen 对象时，任何企图修改对象属性的行为都会引发 FrozenInstanceError#p1.x = 10 # dataclasses.FrozenInstanceError: cannot assign to field &apos;x&apos; 1234567891011121314from dataclasses import dataclass@dataclass()class Point(): x:int = 0 y:int = 0 def x_add_1(self): self.x += 1p1 = Point(1,2)print(p1) # Point(x=1, y=2)p1.x_add_1()print(p1) # Point(x=2, y=2) __init__方法在返回前会调用__post_init__123456789101112from dataclasses import dataclass@dataclass()class Point(): x:int = 0 y:int = 0 def __post_init__(self): self.x += 1 p1 = Point(1,2)print(p1) # Point(x=2, y=2) 有关继承12345678910111213141516from dataclasses import dataclass@dataclassclass Point: x:int = 0 y:int = 0 def __post_init__(self): self.x += 1@dataclassclass ThirdPonit(Point): z:int =0ppp = ThirdPonit(1,3,4)print(ppp) # ThirdPonit(x=2, y=3, z=4) super1234567891011121314151617181920from dataclasses import dataclass@dataclassclass Point: x:int = 0 y:int = 0 def __post_init__(self): self.x += 1@dataclassclass ThirdPonit(Point): z:int =0 def __post_init__(self): super().__post_init__() # 调用 父类的__post_init__() self.x += 10ppp = ThirdPonit(1,3,4)print(ppp) # ThirdPonit(x=12, y=3, z=4) 复合初始化12345678910111213141516import randomfrom dataclasses import dataclassdef get_random_marks(): return [random.randint(1,10) for _ in range(5)]@dataclassclass Student: marks:list = list def __post_init__(self): # 额外的工作 self.marks = get_random_marks()a = Student()print(a) # Student(marks=[2, 9, 8, 8, 2])print(a.marks) # [2, 9, 8, 8, 2] 修改123456789101112131415161718192021import randomfrom dataclasses import dataclass, fielddef get_random_marks(): return [random.randint(1,10) for _ in range(5)]@dataclassclass Student: marks:int = field(default_factory= get_random_marks) # int 不建议，建议使用数据类型 # default_factory ：如果在创建对象时没赋值，则使用该方法初始化该字段 （必须是可以调用的无参数方法） # 使用 get_random_marks 方法 初始化 marks a = Student()print(a) # Student(marks=[7, 2, 4, 7, 4])print(a.marks) # [7, 2, 4, 7, 4]print(type(a.marks)) # &lt;class &apos;list&apos;&gt;b = Student(&apos;b&apos;) # 传参则不影响print(b) # Student(marks=&apos;b&apos;)print(b.marks) # bprint(type(b.marks)) # &lt;class &apos;str&apos;&gt; filed 更多操作123456789101112131415from dataclasses import dataclass, field@dataclass(order=1)class Number: number:int = field(compare= False,repr= False) # number 不进行比较,不打印 val:int verified:1 = field(default=0,init=0) # 默认为 1，不进行初始化a = Number(3,4)b = Number(4,3)print(a &lt; b) # Falseprint(a) # Number(val=4, verified=0)print(b) # Number(val=3, verified=0)b.verified = 1print(b) # Number(val=3, verified=1)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[格式化字符串]]></title>
    <url>%2Fpython%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[实例的字符串显示1234567891011121314class Pair: def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return f&apos;(&#123;self.x&#125;, &#123;self.y&#125;)&apos; def __str__(self): return f&apos;Pair(&#123;self.x=&#125;, &#123;self.y=&#125;)&apos;p = Pair(3, 4)print(p) 12345678from dataclasses import dataclass@dataclassclass Pair: x:int y:int = 0 # y 默认值为0p = Pair(3, 4)print(p) 对象自定义格式化12345678910111213141516171819202122232425_formats = &#123; &apos;ymd&apos;: &apos;&#123;d.year&#125;-&#123;d.month&#125;-&#123;d.day&#125;&apos;, &apos;mdy&apos;: &apos;&#123;d.month&#125;/&#123;d.day&#125;/&#123;d.year&#125;&apos;, &apos;dmy&apos;: &apos;&#123;d.day&#125;/&#123;d.month&#125;/&#123;d.year&#125;&apos;&#125;class Date: def __init__(self, year, month, day): self.year = year self.month = month self.day = day def __format__(self, code): if code == &apos;&apos;: code = &apos;ymd&apos; fmt = _formats[code] return fmt.format(d=self)d = Date(2012, 12, 21)print(d)print(format(d, &apos;mdy&apos;))print(&apos;The date is &#123;:ymd&#125;&apos;.format(d))print(&apos;The date is &#123;:mdy&#125;&apos;.format(d)) 修改后12345678910111213141516171819202122232425from dataclasses import dataclass_formats = &#123; &apos;ymd&apos;: &apos;&#123;d.year&#125;-&#123;d.month&#125;-&#123;d.day&#125;&apos;, &apos;mdy&apos;: &apos;&#123;d.month&#125;/&#123;d.day&#125;/&#123;d.year&#125;&apos;, &apos;dmy&apos;: &apos;&#123;d.day&#125;/&#123;d.month&#125;/&#123;d.year&#125;&apos;&#125;@dataclassclass Date: year:int month:int day:int def __format__(self, code): if code == &apos;&apos;: code = &apos;ymd&apos; fmt = _formats[code] return fmt.format(d=self)a = Date(2012, 12, 21)print(a)print(format(a, &apos;mdy&apos;))print(&apos;The date is &#123;:ymd&#125;&apos;.format(a))print(&apos;The date is &#123;:mdy&#125;&apos;.format(a))]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[调用父类方法]]></title>
    <url>%2Fpython%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F%E8%B0%83%E7%94%A8%E7%88%B6%E7%B1%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[调用父类方法super() 为了调用父类(超类)的一个方法，可以使用 super() 函数 12345678910111213141516class A: def spam(self): print(&apos;A.spam&apos;)class B(A): def spam(self): print(&apos;B.spam&apos;) super().spam() # Call parent spam()b = B()b.spam()&apos;&apos;&apos; 输出结果B.spam 先调用 B 的 spamA.spam 然后再调用 A 的 spam&apos;&apos;&apos; super() 函数的一个常见用法是在 __init__() 方法中确保父类被正确的初始化了1234567891011class A: def __init__(self): self.x = 0class B(A): def __init__(self): super().__init__() self.y = 1b = B()print(b.x,b.y) # 0,1 使用dataclasses改写123456789101112from dataclasses import dataclass@dataclassclass A: x:int = 0@dataclassclass B(A): y:int = 1b = B()print(b) # B(x=0, y=1) 123456789101112131415161718192021222324class Father: def __init__(self, name): self.name = name print(&quot;init Father&apos;s name&quot;)class Mather: def __init__(self, age): self.age = age print(&quot;init Mather&apos;s age&quot;)class Son(Father, Mather): def __init__(self, name, age, sex): super().__init__(name) # 先继承 Father 的 name super(Father, self).__init__(age) # 继承后 再继承 Mother 的age self.sex = sex # 最后 实例化自己的 sex print(&quot;init Son&apos;s sex&quot;)if __name__ == &quot;__main__&quot;: son = Son(&quot;Tom&quot;, 5, &quot;Male&quot;) print(Son.__mro__) # (&lt;class &apos;__main__.Son&apos;&gt;, &lt;class &apos;__main__.Father&apos;&gt;, &lt;class &apos;__main__.Mather&apos;&gt;, &lt;class &apos;object&apos;&gt;) print(son.name, son.age, son.sex) 12345678910111213141516171819202122from dataclasses import dataclass@dataclassclass Father: name:str print(&quot;init Father&apos;s name&quot;)@dataclassclass Mather: age:int print(&quot;init Mather&apos;s age&quot;)@dataclassclass Son(Father, Mather): sex:str print(&quot;init Son&apos;s sex&quot;)if __name__ == &quot;__main__&quot;: son = Son(name=&quot;Tom&quot;, age=5, sex=&quot;Male&quot;) # 这个会先实例化age,再name,再sex print(Son.__mro__) # (&lt;class &apos;__main__.Son&apos;&gt;, &lt;class &apos;__main__.Father&apos;&gt;, &lt;class &apos;__main__.Mather&apos;&gt;, &lt;class &apos;object&apos;&gt;) print(son) MRO列表Python会在MRO列表上继续搜索下一个类。只要每个重定义的方法统一使用 super() 并只调用它一次，那么控制流最终会遍历完整个MRO列表，每个方法也只会被调用一次super()有个令人吃惊的地方是它并不一定去查找某个类在MRO中下一个直接父类，你甚至可以在一个没有直接父类的类中使用它 123456789101112131415161718class A: def spam(self): print(&apos;A.spam&apos;) super().spam()class B: def spam(self): print(&apos;B.spam&apos;)class C(A,B): passc = C()print(C.__mro__) # (&lt;class &apos;__main__.C&apos;&gt;, &lt;class &apos;__main__.A&apos;&gt;, &lt;class &apos;__main__.B&apos;&gt;, &lt;class &apos;object&apos;&gt;)c.spam() &apos;&apos;&apos;A.spamB.spam&apos;&apos;&apos; 12345678910class C(B,A): passc = C()print(C.__mro__) # (&lt;class &apos;__main__.C&apos;&gt;, &lt;class &apos;__main__.B&apos;&gt;, &lt;class &apos;__main__.A&apos;&gt;, &lt;class &apos;object&apos;&gt;)c.spam() &apos;&apos;&apos;B.spam&apos;&apos;&apos;# 不会报错，只会执行 B下面的 关于super()由于 super() 可能会调用不是你想要的方法，你应该遵循一些通用原则。首先，确保在继承体系中所有相同名字的方法拥有可兼容的参数签名(比如相同的参数个数和参数名称)。这样可以确保 super() 调用一个非直接父类方法时不会出错。其次，最好确保最顶层的类提供了这个方法的实现，这样的话在MRO上面的查找链肯定可以找到某个确定的方法。 在Python社区中对于 super() 的使用有时候会引来一些争议。尽管如此，如果一切顺利的话，你应该在你最新代码中使用它。Raymond Hettinger为此写了一篇非常好的文章Python’s super() Considered Super通过大量的例子向我们解释了为什么 super() 是极好的。]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多进程]]></title>
    <url>%2Fpython%2F%E5%A4%9A%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[多进程多进程 Multiprocessing 和多线程 threading 类似，用来弥补 threading 的一些劣势（例如GIL）， Python 出了一个 multiprocessing 多进程与多线程使用方法几乎一致1234567891011121314151617import multiprocessingimport threadingdef job_t(a,d): print(&apos;tttt&apos;)def job_p(a,d): print(&apos;pppp&apos;)t1 = threading.Thread(target=job_t,args=(1,2))p1 = multiprocessing.Process(target=job_p,args=(1,2))t1.start()p1.start()t1.join()p1.join() 进程结果 Queue()123456789101112131415161718192021import multiprocessing as mpdef job(q): res=0 for i in range(1000): res+=i+i**2+i**3 q.put(res) #queueif __name__==&apos;__main__&apos;: q = mp.Queue() p1 = mp.Process(target=job,args=(q,)) p2 = mp.Process(target=job,args=(q,)) p1.start() p2.start() p1.join() p2.join() res1 = q.get() print(res1) res2 = q.get() print(res2) print(res1+res2) 效率对比1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import timeimport multiprocessing import threadingdef _cost_time(func): def warpper(*args,**kw): start_time = time.time() func(*args,**kw) end_time = time.time() print(&apos;cost time :&apos;,end_time - start_time) return warpper def job(q): res = 0 for i in range(1000000): res += i + i**2 + i**3 q.put(res) # queue@_cost_timedef normal(): res = 0 for _ in range(2): for i in range(1000000): res += i + i**2 + i**3 print(&apos;normal:&apos;, res) @_cost_timedef multithread(): q = multiprocessing.Queue() t1 = threading.Thread(target=job, args=(q,)) t2 = threading.Thread(target=job, args=(q,)) t1.start() t2.start() t1.join() t2.join() res1 = q.get() res2 = q.get() print(&apos;multithread:&apos;, res1 + res2)@_cost_timedef multicore(): q = multiprocessing.Queue() p1 = multiprocessing .Process(target=job, args=(q,)) p2 = multiprocessing .Process(target=job, args=(q,)) p1.start() p2.start() p1.join() p2.join() res1 = q.get() res2 = q.get() print(&apos;multicore:&apos;,res1 + res2)normal()multithread()multicore() 打印结果123456(&apos;normal:&apos;, 499999666667166666000000L)(&apos;cost time :&apos;, 0.8630490303039551)(&apos;multithread:&apos;, 499999666667166666000000L)(&apos;cost time :&apos;, 1.8854999542236328)(&apos;multicore:&apos;, 499999666667166666000000L)(&apos;cost time :&apos;, 0.47038793563842773) 耗时 多进程 &lt; 普通 &lt; 多线程 。 多线程不适合计算密集型]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[staticmethod和classmethod]]></title>
    <url>%2Fpython%2F%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F%40staticmethod%E5%92%8C%40classmethod%2F</url>
    <content type="text"><![CDATA[一般来说，要使用某个类的方法，需要先实例化一个对象再调用方法。 而使用 @staticmethod或 @classmethod，就可以不需要实例化，直接类名.方法名()来调用。 123456789101112131415161718class A: bar = 1 def foo(self): print &apos;foo&apos; @staticmethod def static_foo(): print &apos;static_foo&apos; print A.bar @classmethod def class_foo(cls): print &apos;class_foo&apos; print cls.bar cls().foo() A.static_foo()A.class_foo() 如果在@staticmethod中要调用到这个类的一些属性方法，只能直接类名.属性名或类名.方法名。 而@classmethod因为持有cls参数，可以来调用类的属性，类的方法，实例化对象等，避免硬编码 这两个方法的用法是类似的，大多数情况下，classmethod也可以通过staticmethod代替，在通过类调用时，这两者对于调用者来说是不可区分的。 这两者的区别在于，classmethod增加了一个对实际调用类的引用，这带来了很多方便的地方： 方法可以判断出自己是通过基类被调用，还是通过某个子类被调用 通过子类调用时，方法可以返回子类的实例而非基类的实例 通过子类调用时，方法可以调用子类的其他classmethod]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多线程]]></title>
    <url>%2Fpython%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[添加线程1234567891011121314151617import threadingdef main1(): print(threading.active_count()) # 获取已激活的线程数 print(threading.enumerate()) # 查看所有线程信息 print(threading.current_thread()) # 查看现在正在运行的线程def thread_job(): print(&apos;This is a thread of %s&apos; % threading.current_thread())def main(): thread = threading.Thread(target=thread_job,) # 定义线程 thread.start() # 让线程开始工作 if __name__ == &apos;__main__&apos;: main1() main() join功能使用join()主线程一直等待全部的子线程结束之后，主线程自身才结束( print(&#39;all done\n&#39;))，程序退出123456789101112131415161718192021222324import threadingimport timedef T1_job(): print(&apos;T1 start\n&apos;) for i in range(10): time.sleep(0.1) print(&apos;T1 finish\n&apos;)def T2_job(): print(&apos;T2 start\n&apos;) print(&apos;T2 finish\n&apos;)def main(): T1_thread = threading.Thread(target=T1_job, name=&apos;T1&apos;) T2_thread = threading.Thread(target=T2_job, name=&apos;T2&apos;) T1_thread.start() T2_thread.start() T1_thread.join() T2_thread.join() print(&apos;all done\n&apos;) if __name__ == &apos;__main__&apos;: main() 线程锁不使用线程锁1234567891011121314151617181920212223import threadingdef job1(): global A for i in range(10): A+=1 print(&apos;job1&apos;,A)def job2(): global A for i in range(10): A+=10 print(&apos;job2&apos;,A)if __name__== &apos;__main__&apos;: lock=threading.Lock() A=0 t1=threading.Thread(target=job1) t2=threading.Thread(target=job2) t1.start() t2.start() t1.join() t2.join() 打印结果,很杂乱12345678910111213141516171819job1 job2111job1 job21222job1job2 3323job2job1 4344job2job1 5554job2job1 6566job2job1 7677job2job1 8788job2job1 9899job2job1 110109 使用线程锁lock在不同线程使用同一共享内存时，能够确保线程之间互不影响123456789101112131415161718192021222324252627import threadingdef job1(): global A,lock lock.acquire() # 在每个线程执行运算修改共享内存之前，执行lock.acquire()将共享内存上锁， 确保当前线程执行时，内存不会被其他线程访问 for i in range(10): A+=1 print(&apos;job1&apos;,A) lock.release() # 执行运算完毕后，使用lock.release()将锁打开， 保证其他的线程可以使用该共享内存def job2(): global A,lock lock.acquire() for i in range(10): A+=10 print(&apos;job2&apos;,A) lock.release()if __name__== &apos;__main__&apos;: lock=threading.Lock() A=0 t1=threading.Thread(target=job1) t2=threading.Thread(target=job2) t1.start() t2.start() t1.join() t2.join() 打印结果1234567891011121314151617181920job1 1job1 2job1 3job1 4job1 5job1 6job1 7job1 8job1 9job1 10job2 20job2 30job2 40job2 50job2 60job2 70job2 80job2 90job2 100job2 110 储存进程结果 Queue123456789101112131415161718192021222324252627282930313233import threadingimport timefrom queue import Queuedef job(l,q): &apos;&apos;&apos; 对列表的每个元素进行平方计算，将结果保存在队列中 &apos;&apos;&apos; for i in range (len(l)): l[i] = l[i]**2 q.put(l) # 多线程调用的函数不能用return返回值def multithreading(): q = Queue() # q 中存放返回值，代替return的返回值 data = [[1,2,3],[3,4,5],[4,4,4],[5,5,5]] threads = [] for i in range(4): t = threading.Thread(target=job,args=(data[i],q)) # 被调用的job函数没有括号，只是一个索引，参数在后面 t.start() # 开始线程 threads.append(t) # 把每个线程append到线程列表中 for thread in threads: thread.join() # 分别join四个线程到主线程 results = [] # 定义一个空的列表results，将四个线运行后保存在队列中的结果返回给空列表results for _ in range(4): results.append(q.get()) print(results)if __name___==&apos;__main__&apos;: multithreading()]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python判断是否json格式]]></title>
    <url>%2Fpython%2Fis_json%2F</url>
    <content type="text"><![CDATA[is_json.py1234567891011121314151617181920212223242526272829#!/usr/bin/env python#-*-coding:utf-8-*-import jsonimport sysimport osimport globscript_path = os.path.split(os.path.realpath(__file__))[0]def is_json(json_file): try: with open(json_file,&apos;r&apos;) as f: load_dict = json.load(f) print(json_file + &apos; True&apos;) except Exception as e: print(json_file + &apos; ERROR&apos;) print(e)def json_list(): try: json_name = sys.argv[1] json_list = [] for json_name in sys.argv[1:]: json_list.append(json_name) except: json_list = glob.glob(os.path.join(script_path,&apos;*.json&apos;)) return json_list[is_json(json_file) for json_file in json_list()]]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python里的一些函数]]></title>
    <url>%2Fpython%2Fpython%E7%9A%84%E4%B8%80%E4%BA%9B%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[参考 1. lambda 函数 （匿名函数）没有函数名的函数12x = lambda a,b : a*bprint(x(2,3)) 2. Map 函数Map() 是 python 里的内置函数，它可以将 函数应用于各种数据结构中的元素123x = map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10,11])print(x) # &lt;map object at 0x00000255474D24A8&gt; 迭代器print(list(x)) # [3, 7, 11, 15, 19] 3. filter 函数与 map()类似，但只返回True的元素1234567891011numbers = [1, 2, 3, 4, 5, 6, 7, 8]def filter_odd_numbers(num): if num % 2 == 0: return True else: return False filtered_numbers = filter(filter_odd_numbers, numbers)print(filtered_numbers) # &lt;filter object at 0x00000237EFD62438&gt; print(list(filtered_numbers)) # [2, 4, 6, 8] 4. any(),all()123x = [0, 2, 1]print(all(x)) # Falseprint(any(x)) # True 5. zip()zip() 函数 用于将可迭代对象作为参数，将对象中对应的元素打包成一个个元组，然后返回这些元组组成的列表12345678910keys = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;]values = [1, 2, 3, 3]zipped = dict(zip(keys, values))print(zipped) # &#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3, &apos;d&apos;: 3&#125;d = &#123;k:v for k,v in zip(zipped.values(),zipped.keys())&#125;print(d) # &#123;1: &apos;a&apos;, 2: &apos;b&apos;, 3: &apos;d&apos;&#125;# 根据字典值的大小，对字典的项从大到小排序print(dict(sorted(d.items(),key=lambda x:x[1],reverse=True))) # &#123;3: &apos;d&apos;, 2: &apos;b&apos;, 1: &apos;a&apos;&#125;]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python里的特殊方法]]></title>
    <url>%2Fpython%2Fpython%E9%87%8C%E7%9A%84%E7%89%B9%E6%AE%8A%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[特殊方法是什么是一种具有特殊魅力的正常方法，python通过这些方法可以赋予你的class魔力。 这些魔法方法 都是以双下划线__作为 前缀和后缀。 初始化__new__()创造实例， __init__()初始化实例。 __init__() 是一个类 (class) 的第一个方法，也叫构造函数。 是第一个被创建，但不是第一个被执行的。 __new__() 才是最早被调用的方法 __new__() : 先读取参数( 如类名称,args,和kwargs）, 然后 new() 方法把这些参数传递给 __init__() , __new__(class_name, args, kwargs) __init__() : 类的初始化方法或构造方法, 几乎用于 全局的初始化目的。 __init__(slef, args, kwargs) __del__() : 类的析构函数，定义一个对象被垃圾回收的行为。 __del__(self) 12345678910111213141516171819202122232425262728293031323334353637class SimpleInit: def __new__(cls): print(&quot;__new__ is called&quot;) return super(SimpleInit, cls).__new__(cls) # 不过与python3.7后的dataclass 不兼容，dataclass 机制得好好看一下 def __init__(self, value=10): print(&apos;__init__ is called&apos;) print(&quot;self is: &quot;, self) self._list = [value] def __del__(self): print(self._list) del self._list print(self._list)a = SimpleInit()a.__del__()&apos;&apos;&apos;输出如下：__new__ is called # __new__()创造实例， __init__()初始化实例__init__ is calledself is: &lt;__main__.SimpleInit object at 0x0000017E8A132470&gt;[10]---------------------------------------------------------------------------AttributeError Traceback (most recent call last)&lt;ipython-input-22-3666a9307d4d&gt; in &lt;module&gt;----&gt; 1 a.__del__()&lt;ipython-input-21-cb926d3eed30&gt; in __del__(self) 12 print(self._list) 13 del self._list---&gt; 14 print(self._list) 15 16 a = SimpleInit()AttributeError: &apos;SimpleInit&apos; object has no attribute &apos;_list&apos;&apos;&apos;&apos; 算术运算,增量赋值 __add__(self.other) + __iadd__(self.other) += __sub__(self.other) - __isub__(self.other) -= __mul__(self.other) * __imul__(self.other) *= __floordiv__(self.other) // __ifloordiv__(self.other) //= __div__(self.other) / __idiv__(self.other) /= __mod__(self.other) % __imod__(self.other) %= __and__(self.other) &amp; __iand__(self.other) &amp;= __or__(self.other) | __ior__(self.other) |= __xor__(self.other) ^ __ixor__(self.other) ^= __pow__(self.other) ** __ipow__(self.other) **= __lshift__(self.other) &lt;&lt; __ilshift__(self.other) &lt;&lt;= __rshift__(self.other) &gt;&gt; __irshift__(self.other) &gt;&gt;=1234567891011121314from dataclasses import dataclass, field@dataclassclass Simpleadder: _elements:list = list def __add__(self, other): return self._elements + other._elementsa = Simpleadder([1,2,3,4,5])b = Simpleadder([4,5,6,7,8])print(a, b) # Simpleadder(_elements=[1, 2, 3, 4, 5]) Simpleadder(_elements=[4, 5, 6, 7, 8])print(a + b) # [1, 2, 3, 4, 5, 4, 5, 6, 7, 8] 比较运算python3.7 可使用dataclass __eq__(self.other) == __ne__(self.other) != __lt__(self.other) &lt; __gt__(self.other) &gt; __le__(self.other) &lt;= __ge__(self.other) &gt;= 类型转换 __int__(self) int __long__(self) long __float__(self) float __complex__(self) complex __oct__(self) octal (八进制) __hex__(self) (十六进制) __index__(self) 转为int, 当对象被用于切片表达式 最常用 __str__(self) __repr__(self) 类似__str__() str()主要用于人类可读, repr() 机器可读 __hash__(self) 定义了行为调用hash() __len__(self) 返回容器长度 __getitem__(self) setitem(self) __delitem__(self) 定义一个删除一个项目的行为 __iter__(self) 返回一个迭代容器 __call__(self) 使实例能够像函数一样被调用，同时不影响实例本身的生命周期 __call__()不影响一个实例的构造和析构。但是__call__()可以用来改变实例的内部成员的值123456789101112131415from dataclasses import dataclass@dataclass()class X: a:int b:int range:int def __call__(self): print(&apos;__call__ with （&#123;&#125;, &#123;&#125;）&apos;.format(self.a, self.b))x = X(1,2,3)print(x)x() # 把实例直接当函数调用]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[装饰器]]></title>
    <url>%2Fpython%2F%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[绝大多数装饰器都是基于函数和 闭包 实现的，但这并非制造装饰器的唯一方式. Python 对某个对象是否能通过装饰器（@decorator）形式使用只有一个要求：decorator 必须是一个“可被调用（callable）的对象123def foo(): passtype(foo) # functioncallable(foo) # True 只要自定义类的 __call__ 魔法方法即可让任意类变成可被调用123456789101112131415161718from dataclasses import dataclass@dataclass()class X: a:int b:int range:int def __call__(self): # 定义类的 `__call__` 方法 print(&apos;__call__ with （&#123;&#125;, &#123;&#125;）&apos;.format(self.a, self.b)) def __del__(self): del self.a del self.b del self.rangex = X(1,2,3)x() # 像函数一样调用 1234567891011121314151617181920212223242526272829303132333435363738import timeimport randomimport functoolsdef timer(wrapped): &quot;&quot;&quot;装饰器：记录并打印函数耗时&quot;&quot;&quot; @functools.wraps(wrapped) # 可以使函数保持原有签名 def decorated(*args, **kwargs): st = time.time() ret = wrapped(*args, **kwargs) print(&apos;execution take: &#123;&#125; seconds&apos;.format(time.time() - st)) return ret return decorateddef counter(func): &quot;&quot;&quot;装饰器：记录并打印调用次数&quot;&quot;&quot; count = 0 @functools.wraps(func) def decorated(*args, **kwargs): # 次数累加 nonlocal count count += 1 print(f&quot;Count: &#123;count&#125;&quot;) return func(*args, **kwargs) return decorated@counter@timerdef random_sleep(): &apos;德玛西亚&apos; time.sleep(random.random())random_sleep()random_sleep()print(random_sleep.__name__)print(random_sleep.__doc__) 1234567891011121314151617181920def provide_number(min_num, max_num): &quot;&quot;&quot;装饰器：随机生成一个在 [min_num, max_num] 范围的整数，追加为函数的第一个位置参数 &quot;&quot;&quot; def wrapper(func): def decorated(*args, **kwargs): num = random.randint(min_num, max_num) # 将 num 作为第一个参数追加后调用函数 return func(num, *args, **kwargs) return decorated return wrapper@provide_number(1, 100)def print_random_number(num): print(num) wrapt 模块是一个专门帮助编写装饰器的工具库。可以非常方便的改造 provide_number 装饰器，完美解决“嵌套层级深”和“无法通用”两个问题123456789101112131415161718192021222324252627282930import wraptimport randomdef provide_number(min_num, max_num): @wrapt.decorator def wrapper(wrapped, instance, args, kwargs): # 参数含义： # # - wrapped：被装饰的函数或类方法 # - instance： # - 如果被装饰者为普通类方法，该值为类实例 # - 如果被装饰者为 classmethod 类方法，该值为类 # - 如果被装饰者为类/函数/静态方法，该值为 None # # - args：调用时的位置参数（注意没有 * 符号） # - kwargs：调用时的关键字参数（注意没有 ** 符号） # num = random.randint(min_num, max_num) # 无需关注 wrapped 是类方法或普通函数，直接在头部追加参数 args = (num,) + args return wrapped(*args, **kwargs) return wrapper@provide_number(1,100)def number(num): print(num)number() 1234567891011121314151617181920212223242526272829303132333435import timeimport functoolsclass DelayFunc: def __init__(self, duration, func): self.duration = duration self.func = func def __call__(self, *args, **kwargs): print(f&apos;Wait for &#123;self.duration&#125; seconds...&apos;) time.sleep(self.duration) return self.func(*args, **kwargs) def eager_call(self, *args, **kwargs): print(&apos;Call without delay&apos;) return self.func(*args, **kwargs)def delay(duration): &quot;&quot;&quot;装饰器：推迟某个函数的执行。同时提供 .eager_call 方法立即执行 &quot;&quot;&quot; # 此处为了避免定义额外函数，直接使用 functools.partial 帮助构造 # DelayFunc 实例 return functools.partial(DelayFunc, duration)@delay(duration=2)def add(a, b): return a + b# 这次调用将会延迟 2 秒print(add(1, 2))# 这次调用将会立即执行print(add.eager_call(1, 2)) # 还是进入了类，duration=2， 但调用类里面的eager_call()方法直接返回函数 123456def add(a, b): return a + bimport functoolsadd_3 = functools.partial(add, 3)print(add_3(1))]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python拾遗_函数]]></title>
    <url>%2Fpython%2Fpython%E6%8B%BE%E9%81%97_%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数 函数有机会给一组语句命名 函数可以减少重复代码 一长段程序可以拆分为多个函数，组合起来使用 一次书写, 多次调用。 在函数内部 实参会赋值给形参的变量 12345def print_twice(x): print(x) print(x)a = print_twice(&apos;haha&apos;)a == None # True # 没有return,返回None 只会实现函数作用 增量开发每次只增加和测试一小部分代码，来避免长时间的调试过程 eg: 圆心坐标(x1,y1)例如(0,0),圆上一点的坐标(x2,y2)例如(2,2), 计算圆的面积。 圆的面积 12345import mathdef area(radius): return math.pi * radius **2a = area(2) # a 等于return的值print(area(2),a) 圆的半径 123456789def distance(x1, y1, x2, y2): &apos;&apos;&apos; 计算两点之间的距离 文档字符串，一般用来简明的解释函数是用来做什么的 &apos;&apos;&apos; dx = x2 -x1 dy = y2 -y1 # 临时变量，在计算中可以用来保存中间计算值 dsquared = dx ** 2 + dy ** 2 result = math.sqrt(dsquared) # 脚手架代码，构建时有用，最终可以删除 return result 计算结果 12radius = distance(x1, y1, x2, y2)result = area(radius) 封装成一个函数1234def circle_area(x1, y1, x2, y2): radius = distance(x1, y1, x2, y2) result = area(radius) return result 简化123def circle_area(x1, y1, x2, y2): return area(distance(x1, y1, x2, y2))circle_area(0, 0, 2, 2) # 25.132741228718352 递归调用自己的函数称为 递归的函数，执行过程称为递归 无限递归,会在递归深度到上限时报错123def recurse(): recurse()recurse() # RecursionError: maximum recursion depth exceeded 123456def print_n(s, n): if n &lt;= 0: return print(s) print_n(s,n-1)print_n(&apos;haha&apos;, 5) 12345678910def countdown(n): if n &gt; 100000: # 守卫,保护后面代码，避免出现错误 print(&apos;over limit&apos;) return elif n &lt;= 0: print(&apos;haha&apos;) else: print(n) countdown(n-1)countdown(10000000000000) while 循环123456789def countdown(n): if n &gt; 100000: # 守卫,保护后面代码，避免出现错误 print(&apos;over limit&apos;) return while n &gt; 0: print(n) n -= 1 print(&apos;haha&apos;)countdown(10000000000000) 12345while 1: line = input(&apos;&gt;&apos;) if line == &apos;done&apos;: break # 使用 break 退出循环 print(line)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java变量类型]]></title>
    <url>%2Fjava%2F%E5%8F%98%E9%87%8F%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[变量类型在Java语言中 局部变量 实例变量 类变量 所有的变量在使用前必须声明。声明变量的基本格式如下： type identifier [ = value][, identifier [= value] ...] ; 12345int a, b, c; // 声明三个int型整数：a、b、c。int d = 3, e, f = 5; // 声明三个整数并赋予初值。byte z = 22; // 声明并初始化z。double pi = 3.14159; // 声明了pi。char x = &apos;x&apos;; // 变量x的值是字符&apos;x&apos;。 局部变量123456789101112public class Test&#123; public void pupAge()&#123; int age = 0; // age是一个局部变量。定义在pupAge()方法中，它的作用域就限制在这个方法中 age = age + 7; System.out.println(&quot;Puppy age is : &quot; + age); &#125; public static void main(String args[])&#123; Test test = new Test(); test.pupAge(); &#125;&#125; 实例变量1234567891011121314151617181920212223242526import java.io.*;public class Employee&#123; // 这个成员变量对子类可见 public String name; // 私有变量，仅在该类可见 private double salary; //在构造器中对name赋值 public Employee (String empName)&#123; name = empName; &#125; //设定salary的值 public void setSalary(double empSal)&#123; salary = empSal; &#125; // 打印信息 public void printEmp()&#123; System.out.println(&quot;name : &quot; + name ); System.out.println(&quot;salary :&quot; + salary); &#125; public static void main(String args[])&#123; Employee empOne = new Employee(&quot;Ransika&quot;); empOne.setSalary(1000); empOne.printEmp(); &#125;&#125; 类变量12345678910111213import java.io.*;public class Employee&#123; //salary是静态的私有变量 private static double salary; // DEPARTMENT是一个常量 public static final String DEPARTMENT = &quot;Development &quot;; public static void main(String args[])&#123; salary = 1000; System.out.println(DEPARTMENT+&quot;average salary:&quot;+salary); &#125;&#125;// 如果其他类想要访问该变量，可以这样访问：Employee.DEPARTMENT]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java修饰符]]></title>
    <url>%2Fjava%2F%E4%BF%AE%E9%A5%B0%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[Java修饰符主要分为以下两类： 访问修饰符 非访问修饰符 修饰符用来定义类、方法或者变量，通常放在语句的最前端 123456789public class className &#123; // ...&#125;private boolean myFlag;static final double weeks = 9.5;protected static final int BOXWIDTH = 42;public static void main(String[] arguments) &#123; // 方法体&#125; 访问控制修饰符默认访问修饰符-不使用任何关键字使用默认访问修饰符声明的变量和方法，对同一个包内的类是可见的。接口里的变量都隐式声明为public static final,而接口里的方法默认情况下访问权限为public。1234String version = &quot;1.5.1&quot;;boolean processOrder() &#123; return true;&#125; 私有访问修饰符-private私有访问修饰符是最严格的访问级别，所以被声明为private的方法、变量和构造方法只能被所属类访问，并且类和接口不能声明为private。 声明为私有访问类型的变量只能通过类中公共的getter方法被外部类访问。 Private访问修饰符的使用主要用来隐藏类的实现细节和保护类的数据。123456789public class Logger &#123; private String format; public String getFormat() &#123; return this.format; &#125; public void setFormat(String format) &#123; this.format = format; &#125;&#125; 公有访问修饰符-public被声明为public的类、方法、构造方法和接口能够被任何其他类访问。 如果几个相互访问的public类分布在不同的包中，则需要导入相应public类所在的包。由于类的继承性，类所有的公有方法和变量都能被其子类继承。123public static void main(String[] arguments) &#123; // ...&#125; 受保护的访问修饰符-protected被声明为protected的变量、方法和构造器能被同一个包中的任何其他类访问，也能够被不同包中的子类访问。 Protected访问修饰符不能修饰类和接口，方法和成员变量能够声明为protected，但是接口的成员变量和成员方法不能声明为protected。 子类能访问Protected修饰符声明的方法和变量，这样就能保护不相关的类使用这些方法和变量。 下面的父类使用了protected访问修饰符，子类重载了父类的openSpeaker()方法 1234567891011class AudioPlayer &#123; protected boolean openSpeaker(Speaker sp) &#123; // 实现细节 &#125;&#125;class StreamingAudioPlayer &#123; boolean openSpeaker(Speaker sp) &#123; // 实现细节 &#125;&#125; 如果把openSpeaker()方法声明为private，那么除了AudioPlayer之外的类将不能访问该方法。如果把openSpeaker()声明为public，那么所有的类都能够访问该方法。如果我们只想让该方法对其所在类的子类可见，则将该方法声明为protected。 访问控制和继承请注意以下方法继承的规则： 父类中声明为public的方法在子类中也必须为public。 父类中声明为protected的方法在子类中要么声明为protected，要么声明为public。不能声明为private。 父类中声明为private的方法，不能够被继承。非访问修饰符 static : 用来创建类方法和类变量。 final : 用来修饰类、方法和变量，final修饰的类不能够被继承，修饰的方法不能被继承类重新定义，修饰的变量为常量，是不可修改的。 abstract : 用来创建抽象类和抽象方法。 synchronized和volatile : 主要用于线程的编程。 static修饰符 静态变量 ： 也被称为类变量。用来声明独立于对象的静态变量,局部变量不能被声明为static变量 静态方法 ： 来声明独立于对象的静态方法12345678910111213141516171819202122public class InstanceCounter &#123; private static int numInstances = 0; protected static int getCount() &#123; return numInstances; &#125; private static void addInstance() &#123; numInstances++; &#125; InstanceCounter() &#123; InstanceCounter.addInstance(); &#125; public static void main(String[] arguments) &#123; System.out.println(&quot;Starting with &quot; + InstanceCounter.getCount() + &quot; instances&quot;); for (int i = 0; i &lt; 500; ++i)&#123; new InstanceCounter(); &#125; System.out.println(&quot;Created &quot; + InstanceCounter.getCount() + &quot; instances&quot;); &#125; &#125; final修饰符final变量:12345678910public class Test&#123; final int value = 10; // 下面是声明常量的实例 public static final int BOXWIDTH = 6; static final String TITLE = &quot;Manager&quot;; public void changeValue()&#123; value = 12; //将输出一个错误 &#125;&#125; final方法:类中的Final方法可以被子类继承，但是不能被子类修改。 声明final方法的主要目的是防止该方法的内容被修改12345public class Test&#123; public final void changeName()&#123; // 方法体 &#125;&#125; final类： 不能被继承123public final class Test &#123; // 类体&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java简介]]></title>
    <url>%2Fjava%2Freadme%2F</url>
    <content type="text"><![CDATA[java简介Java分为三个体系： JavaSE(J2SE)(Java2 Platform Standard Edition，java平台标准版) JavaEE(J2EE)(Java 2 Platform,Enterprise Edition，java平台企业版) JavaME(J2ME)(Java 2 Platform Micro Edition，java平台微型版) 开发环境配置(windows下)java下载 下载后安装，配置系统环境变量 此电脑 &gt; 右键属性 &gt; 高级 &gt; 环境变量12345678变量名：JAVA_HOME变量值：C:\Program Files (x86)\Java\jdk1.8.0_91 // 要根据自己的实际路径配置变量名：CLASSPATH变量值：.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar; //记得前面有个&quot;.&quot;变量名：Path变量值：%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;windows10 变量值已有的上面点开，然后新建加到下方，以免破坏原有的环境变量 重启后生效 测试JDK是否安装成功 “开始”-&gt;”运行”，键入”cmd”； 键入命令: java -version、java、javac 几个命令]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java基础语法]]></title>
    <url>%2Fjava%2Fjava%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[hello worldHelloWorld.java (源文件名必须和类名相同)12345678public class HelloWorld &#123; /* 第一个Java程序. * 它将打印字符串 Hello World */ public static void main(String []args) &#123; // 主方法入口：所有的Java 程序由public static void main(String args[])方法开始执行 System.out.println(&quot;Hello World&quot;); // 打印 Hello World &#125;&#125; （cmd在java文件的同一路径下） 编译 javac -encoding utf-8 HelloWorld.java (含中文最好使用 -encoding utf-8编译，以免出现错误) 运行 java HelloWorld 打印 HelloWorld 类和对象123456789101112131415161718192021222324252627public class Puppy&#123; // Puppy 类 一个源文件中只能有一个public类 int puppyAge; public Puppy(String name)&#123; // 这个构造器仅有一个参数：name System.out.println(&quot;Passed Name is :&quot; + name ); &#125; public void setAge( int age )&#123; puppyAge = age; &#125; public int getAge( )&#123; System.out.println(&quot;Puppy&apos;s age is :&quot; + puppyAge ); return puppyAge; &#125; public static void main(String []args)&#123; /* 创建对象 */ Puppy myPuppy = new Puppy( &quot;tommy&quot; ); // 声明：声明一个对象，包括对象名称和对象类型 实例化：使用关键字new来创建一个对象 初始化：使用new创建对象时，会调用构造方法初始化对象 /* 通过方法来设定age */ myPuppy.setAge( 2 ); /* 调用另一个方法获取age */ myPuppy.getAge( ); /*你也可以像下面这样访问成员变量 */ System.out.println(&quot;Variable Value :&quot; + myPuppy.puppyAge ); &#125;&#125; importEmployee.java1234567891011import java.io.*; //下面的命令行将会命令编译器载入java_installation/java/io路径下的所有类public class Employee&#123; //salary是静态的私有变量 private static double salary; // DEPARTMENT是一个常量 public static final String DEPARTMENT = &quot;Development &quot;; public static void main(String args[])&#123; salary = 1000; System.out.println(DEPARTMENT+&quot;average salary:&quot;+salary); &#125;&#125; EmployeeTest.java1234567891011121314151617181920import java.io.*;public class EmployeeTest&#123; public static void main(String args[])&#123; /* 使用构造器创建两个对象 */ Employee empOne = new Employee(&quot;James Smith&quot;); Employee empTwo = new Employee(&quot;Mary Anne&quot;); // 调用这两个对象的成员方法 empOne.empAge(26); empOne.empDesignation(&quot;Senior Software Engineer&quot;); empOne.empSalary(1000); empOne.printEmployee(); empTwo.empAge(21); empTwo.empDesignation(&quot;Software Engineer&quot;); empTwo.empSalary(500); empTwo.printEmployee(); &#125;&#125; 编译后，执行EmployeeTest就可以得到结果]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[部分命令]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[service nginx reload 反向代理，负载均衡 硬件资源信息1234free -hdf -hw/topcat /proc/cpuinfo 防火墙保护服务器，设置防火墙规则，开闭端口1234yum install firewalldservice firewalld startservice firewalld statusservice firewalld stop/disable 服务1234crontabNtpdateLogrotatesupervisor]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于 vi]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2Fvim%2Freadme%2F</url>
    <content type="text"><![CDATA[vivi的使用 一般模式 编辑模式 （i,I，o,O,a,A,r,R）(Ii aA 插入右边)（oO 插入一行）(Rr 替换) 命令行模式 (: / ?) （yy 复制当行）（p 前面复制后，粘贴） （dd 删除当行）（/字符 搜索 N 向后， n 向前）123dos2unix filenamedos2unix和unix2dos，dos2unix把&quot;\r\n&quot;转化成&quot;\n&quot;，unixtodos把&quot;\n&quot;转化成&quot;\r\n]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java运算符]]></title>
    <url>%2Fjava%2F%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[Java 运算符主要分为一下几种 算术运算符 关系运算符 位运算符 逻辑运算符 赋值运算符 其他运算符 算术运算符ArithmeticOperator.java1234567891011121314151617181920public class ArithmeticOperator &#123; public static void main(String args[]) &#123; int a = 10; int b = 20; int c = 25; int d = 25; System.out.println(&quot;a + b = &quot; + (a + b) ); System.out.println(&quot;a - b = &quot; + (a - b) ); System.out.println(&quot;a * b = &quot; + (a * b) ); System.out.println(&quot;b / a = &quot; + (b / a) ); System.out.println(&quot;b % a = &quot; + (b % a) ); System.out.println(&quot;c % a = &quot; + (c % a) ); System.out.println(&quot;a++ = &quot; + (a++) ); System.out.println(&quot;a-- = &quot; + (a--) ); // 查看 d++ 与 ++d 的不同 System.out.println(&quot;d++ = &quot; + (d++) ); // 当前语句后 +1 System.out.println(&quot;++d = &quot; + (++d) ); // 当前语句前 +1 &#125; &#125; 关系运算符RelationalOperator.java12345678910111213public class RelationalOperator &#123; public static void main(String args[]) &#123; int a = 10; int b = 20; System.out.println(&quot;a == b = &quot; + (a == b) ); System.out.println(&quot;a != b = &quot; + (a != b) ); System.out.println(&quot;a &gt; b = &quot; + (a &gt; b) ); System.out.println(&quot;a &lt; b = &quot; + (a &lt; b) ); System.out.println(&quot;b &gt;= a = &quot; + (b &gt;= a) ); System.out.println(&quot;b &lt;= a = &quot; + (b &lt;= a) ); &#125; &#125; 逻辑运算符LogicalOperators.java123456789public class LogicalOperators &#123; public static void main(String args[]) &#123; boolean a = true; boolean b = false; System.out.println(&quot;a &amp;&amp; b = &quot; + (a&amp;&amp;b)); System.out.println(&quot;a || b = &quot; + (a||b) ); System.out.println(&quot;!(a &amp;&amp; b) = &quot; + !(a &amp;&amp; b)); &#125; &#125; 赋值运算符AssignmentOperator.java123456789101112131415161718public class AssignmentOperator &#123; public static void main(String args[]) &#123; int a = 10; int b = 20; int c; c = a + b; System.out.println(&quot;c = a + b is &quot; + (a + b)); System.out.println(&quot;c += a is &quot; + (c+=a) ); System.out.println(&quot;c -= a is &quot; + (c -=a)); System.out.println(&quot;c *= a is &quot; + (c *= a)); a = 10; c = 15; System.out.println(&quot;c /= a is &quot; + (c/=a) ); a = 10; c = 15; System.out.println(&quot;c %= a is &quot; + (c %= a)); &#125; &#125; 条件运算符ConditionalOperator.java12345678910public class ConditionalOperator &#123; public static void main(String args[])&#123; int a , b; a = 10; b = (a == 1) ? 20: 30; // 不成立 System.out.println( &quot;Value of b is : &quot; + b ); // 30 b = (a == 10) ? 20: 30; // 成立 System.out.println( &quot;Value of b is : &quot; + b ); // 20 &#125;&#125; instanceOf 运算符Car.java123456789class Vehicle &#123;&#125;public class Car extends Vehicle &#123; // Car 继承了Vehicle所有属性和方法 public static void main(String args[])&#123; Vehicle a = new Car(); boolean result = a instanceof Car; // 被比较的对象兼容于右侧类型,该运算符仍然返回true System.out.println( result); // true &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[安装Chrome浏览器和ChromeDriver]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F%E5%AE%89%E8%A3%85Chrome%E6%B5%8F%E8%A7%88%E5%99%A8%E5%92%8CChromeDriver%2F</url>
    <content type="text"><![CDATA[一、 安装Chrome浏览器1、安装依赖 sudo apt-get install libxss1 libappindicator1 libindicator7 2、下载Chrome安装包 (最新稳定版) wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb 3、安装 12sudo dpkg -i google-chrome*.debsudo apt-get install -f 二、安装ChromeDriver1、安装xvfb以便我们可以无头奔跑地运行Chrome sudo apt-get install xvfb 2、安装依赖 sudo apt-get install unzip 3、下载安装包 wget -N http://chromedriver.storage.googleapis.com/2.26/chromedriver_linux64.zip 要下载对应版本 http://chromedriver.storage.googleapis.com/index.html 4、解压缩+添加执行权限 unzip chromedriver_linux64.zip 5、移动 sudo mv -f chromedriver /usr/local/share/chromedriver 6、建立软连接 sudo ln -s /usr/local/share/chromedriver /usr/local/bin/chromedriversudo ln -s /usr/local/share/chromedriver /usr/bin/chromedriver 三、无头运行Chrome1、安装Python依赖 pip3 install selenium pip3 install pyvirtualdisplay]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java分支结构]]></title>
    <url>%2Fjava%2F%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[if elseIfElse.java12345678910111213141516171819public class Test &#123; public static void main(String args[])&#123; int x = 30; if( x == 10 )&#123; System.out.print(&quot;Value of X is 10&quot;); &#125; else if( x == 20 )&#123; System.out.print(&quot;Value of X is 20&quot;); &#125; else if( x == 30 )&#123; System.out.print(&quot;Value of X is 30&quot;); &#125; else&#123; System.out.print(&quot;这是 else 语句&quot;); &#125; &#125;&#125; 嵌套的if…else语句12345678910111213public class Test &#123; public static void main(String args[])&#123; int x = 30; int y = 10; if( x == 30 )&#123; if( y == 10 )&#123; System.out.print(&quot;X = 30 and Y = 10&quot;); &#125; &#125; &#125;&#125; switch语句1234567891011121314151617181920212223242526public class Test &#123; public static void main(String args[])&#123; //char grade = args[0].charAt(0); char grade = &apos;C&apos;; switch(grade) &#123; case &apos;A&apos; : System.out.println(&quot;优秀&quot;); break; case &apos;B&apos; : case &apos;C&apos; : System.out.println(&quot;良好&quot;); break; case &apos;D&apos; : System.out.println(&quot;及格&quot;); case &apos;F&apos; : System.out.println(&quot;你需要继续努力&quot;); break; default : System.out.println(&quot;无效等级&quot;); &#125; System.out.println(&quot;你的等级是 &quot; + grade); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java基本数据类型]]></title>
    <url>%2Fjava%2F%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[基本数据类型两大数据类型： 内置数据类型 引用数据类型 内置数据类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class PrimitiveTypeTest &#123; public static void main(String[] args) &#123; // byte System.out.println(&quot;基本类型：byte 二进制位数：&quot; + Byte.SIZE); System.out.println(&quot;包装类：java.lang.Byte&quot;); System.out.println(&quot;最小值：Byte.MIN_VALUE=&quot; + Byte.MIN_VALUE); System.out.println(&quot;最大值：Byte.MAX_VALUE=&quot; + Byte.MAX_VALUE); System.out.println(); // short System.out.println(&quot;基本类型：short 二进制位数：&quot; + Short.SIZE); System.out.println(&quot;包装类：java.lang.Short&quot;); System.out.println(&quot;最小值：Short.MIN_VALUE=&quot; + Short.MIN_VALUE); System.out.println(&quot;最大值：Short.MAX_VALUE=&quot; + Short.MAX_VALUE); System.out.println(); // int System.out.println(&quot;基本类型：int 二进制位数：&quot; + Integer.SIZE); System.out.println(&quot;包装类：java.lang.Integer&quot;); System.out.println(&quot;最小值：Integer.MIN_VALUE=&quot; + Integer.MIN_VALUE); System.out.println(&quot;最大值：Integer.MAX_VALUE=&quot; + Integer.MAX_VALUE); System.out.println(); // long System.out.println(&quot;基本类型：long 二进制位数：&quot; + Long.SIZE); System.out.println(&quot;包装类：java.lang.Long&quot;); System.out.println(&quot;最小值：Long.MIN_VALUE=&quot; + Long.MIN_VALUE); System.out.println(&quot;最大值：Long.MAX_VALUE=&quot; + Long.MAX_VALUE); System.out.println(); // float System.out.println(&quot;基本类型：float 二进制位数：&quot; + Float.SIZE); System.out.println(&quot;包装类：java.lang.Float&quot;); System.out.println(&quot;最小值：Float.MIN_VALUE=&quot; + Float.MIN_VALUE); System.out.println(&quot;最大值：Float.MAX_VALUE=&quot; + Float.MAX_VALUE); System.out.println(); // double System.out.println(&quot;基本类型：double 二进制位数：&quot; + Double.SIZE); System.out.println(&quot;包装类：java.lang.Double&quot;); System.out.println(&quot;最小值：Double.MIN_VALUE=&quot; + Double.MIN_VALUE); System.out.println(&quot;最大值：Double.MAX_VALUE=&quot; + Double.MAX_VALUE); System.out.println(); // char System.out.println(&quot;基本类型：char 二进制位数：&quot; + Character.SIZE); System.out.println(&quot;包装类：java.lang.Character&quot;); // 以数值形式而不是字符形式将Character.MIN_VALUE输出到控制台 System.out.println(&quot;最小值：Character.MIN_VALUE=&quot; + (int) Character.MIN_VALUE); // 以数值形式而不是字符形式将Character.MAX_VALUE输出到控制台 System.out.println(&quot;最大值：Character.MAX_VALUE=&quot; + (int) Character.MAX_VALUE);&#125;&#125; 引用数据类型 引用类型变量由类的构造函数创建，可以使用它们访问所引用的对象。这些变量在声明时被指定为一个特定的类型，比如Employee、Pubby等。变量一旦声明后，类型就不能被改变了。 对象、数组都是引用数据类型。 所有引用类型的默认值都是null。 一个引用变量可以用来引用与任何与之兼容的类型。 例子：Animal animal = new Animal(“giraffe”） 常量1final double PI = 3.1415927; //常量指不能改变的量,用final标志,通常用大写标识 123int decimal = 100; // 十进值int octal = 0144; // 8进值int hexa = 0x64; // 16进值 字符串双引号 123&quot;Hello World&quot;&quot;two\nlines&quot;&quot;\&quot;This is in quotes\&quot;&quot; 12char a = &apos;\u0001&apos;; // 变量a 的值为 &apos;\u0001&apos;String a = &quot;\u0001&quot;;]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go基础语法]]></title>
    <url>%2Fgolang%2F%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一般结构12345678910111213141516171819202122232425// 当前程序的包名package main// 导入其他包import . &quot;fmt&quot;// 常量定义const PI = 3.14// 全局变量的声明和赋值var name = &quot;gopher&quot;// 一般类型声明type newType int// 结构的声明type gopher struct&#123;&#125;// 接口的声明type golang interface&#123;&#125;// 由main函数作为程序入口点启动func main() &#123; Println(&quot;Hello World!&quot;)&#125; 变量12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package mainimport &quot;fmt&quot;var x1, y1 intvar ( // 这种因式分解关键字的写法一般用于声明全局变量 a1 int b1 bool)var c1, d1 int = 1, 2var e1, f1 = 123, &quot;hello&quot;var h1 int // 全局变量 允许声明但不使用// e1 := &quot;weilai&quot; // 只能被用在函数体内，而不可以用于全局变量的声明与赋值func main() &#123; /* 多行注释 */ // 一行注释 var a string = &quot;weilai&quot; // 声明一个变量并初始化 var b, c int = 1, 2 // 一次声明多个变量： var d int // 声明变量，不初始化，一般情况下，值类型默认为 0, 布尔类型默认值为 false ,string 默认值为空字符串 &apos;&apos; var z bool // bool 0值 false fmt.Println(z) fmt.Println(a) // 打印 a 换行 fmt.Print(b, c) // 不会换行 fmt.Println(d) fmt.Println(&quot;hello&quot;) // 会换行 fmt.Println(&quot;world&quot; ) fmt.Print(&quot;hello&quot;) fmt.Print(&quot;world&quot;) // var e int 这行存在 下行就会报错就会报错 no new variables on left side of := e := &quot;weilai&quot; // 等同于 var e string = &quot;weilai&quot; // 使用操作符 := 可以高效地创建一个新的变量，称之为初始化声明 f, g := 20, 30 f, g = g, f // 如果你想要交换两个变量的值，，两个变量的类型必须是相同。 // h := 40 // 声明但未使用 局部变量 会报错 fmt.Println(&quot;e=&quot;, e , &quot;,f=&quot; , f , &quot;,g=&quot; , g) fmt.Printf(&quot;e=%s,f=%d,g=%d&quot; , e , f , g) // Printf 是格式化输出 var vname1, vname2, vname3 = &quot;v1&quot;, &quot;v2&quot;, &quot;v3&quot; fmt.Printf(vname1, vname2, vname3) println(x1, y1, a1, b1, c1, d1, e1, f1) _,numb,strs := numbers() //只获取函数返回值的后两个 fmt.Println(numb,strs)&#125;//一个可以返回多个值的函数func numbers()(int,int,string)&#123; a , b , c := 1 , 2 , &quot;str&quot; return a,b,c&#125;/*falseweilai1 20helloworldhelloworlde= weilai ,f= 30 ,g= 20e=weilai,f=30,g=20v1%!(EXTRA string=v2, string=v3)0 0 0 false 1 2 123 hello2 str*/]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Go的package与import]]></title>
    <url>%2Fgolang%2Fpackage%E4%B8%8Eimport%2F</url>
    <content type="text"><![CDATA[package package 是最基本的分发单位 和 工程管理中依赖关系的体现 每个 GO 语言源代码文件开头 都拥有一个 package 声明，表示源代码所属的代码包 要生成 GO 语言可执行程序，必须要有main 的 package包，且必须在该包下 有 main()函数 同一个路径下(文件夹) 只能存在 一个 package, 一个package 可以拆分为多个源文件组成 import 原理此处需要插图 import 导入包的几种方式：点，别名与下划线在写Go代码的时候经常用到import这个命令用来导入包文件，看到的方式参考如下：123import( &quot;fmt&quot;) 然后在代码里面可以通过如下的方式调用fmt.Println(&quot;hello world&quot;) 上面这个fmt是Go语言的标准库，他其实是去GOROOT下去加载该模块，当然Go的import还支持如下两种方式来加载自己写的模块： 相对路径 import &quot;./model&quot; // 当前文件同一目录的model目录，但是不建议这种方式import 绝对路径 import &quot;shorturl/model&quot; // 加载GOPATH/src/shorturl/model模块 三种导入包的使用方法。 点操作import( . &quot;fmt&quot; )可以省略前缀的包名，fmt.Println(&quot;hello world&quot;) 可以省略的写成Println(“hello world”) 别名操作import( f &quot;fmt&quot; ) 调用包函数时前缀变成了重命名的前缀，即f.Println(“hello world”) _ 操作import ( &quot;database/sql&quot; _ &quot;github.com/ziutek/mymysql/godrv&quot; ) _操作其实只是引入该包。即使用_操作引用包是无法通过包名来调用包中的导出函数，而是只是为了简单的调用其init函数()]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis-补充]]></title>
    <url>%2Fredis%2Fredis-%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[reids 过期时间1234567891011121314151617127.0.0.1:6379&gt; SET cache_page &quot;www.google.com&quot;OK127.0.0.1:6379&gt; EXPIRE cache_page 30 # 设置过期时间为 30 秒(integer) 1127.0.0.1:6379&gt; TTL cache_page # 查看当前过期时间(integer) 24127.0.0.1:6379&gt; EXPIRE cache_page 300 # 修改过期时间(integer) 1127.0.0.1:6379&gt; TTL cache_page(integer) 296127.0.0.1:6379&gt; PERSIST cache_page # 移除过期时间(integer) 1127.0.0.1:6379&gt; TTL cache_page(integer) -1127.0.0.1:6379&gt; GET cache_page &quot;www.google.com&quot;127.0.0.1:6379&gt; redis 默认采用定期删除+惰性删除 12345678127.0.0.1:6379&gt; config get maxmemory1) &quot;maxmemory&quot;2) &quot;0&quot; # 不限制127.0.0.1:6379&gt; config set maxmemory 100mbOK127.0.0.1:6379&gt; config get maxmemory1) &quot;maxmemory&quot;2) &quot;104857600&quot; 内存淘汰机制 redis.conf1234127.0.0.1:6379&gt; config get maxmemory-policy1) &quot;maxmemory-policy&quot;2) &quot;noeviction&quot;127.0.0.1:6379&gt; config set maxmemory-policy volatile-lru noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。推荐使用，目前项目在用这种。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。应该也没人用吧，你不删最少使用Key,去随机删。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。依然不推荐 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。不推荐 redis 常见问题redis 与数据库双写一致性的问题 对 数据库有强一致性要求，不要放缓存 缓存穿透 缓存雪崩 缓存击穿缓存穿透： 查询不存在数据 但是请求每次都会打到数据库上面去 缓存击穿： 大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去 缓存雪崩： 某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面 一般避免以上情况发生我们从三个时间段去分析下： 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。 事中：本地 ehcache 缓存 + Hystrix 限流+降级，避免MySQL被打死。 事后：Redis 持久化 RDB+AOF，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 redis 多线程单线程性能瓶颈 主要在 网络 IO 上。redis 6 版本将 网络数据读写和协议 解析 通过 多线程 的方式来处理，执行命令依旧使用单线程操作 redis 锁]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis部分命令]]></title>
    <url>%2Fredis%2F%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[键123456redis 127.0.0.1:6379&gt; SET weilai redis -- 设置键OKredis 127.0.0.1:6379&gt; DEL weilai -- 删除键(integer) 1redis 127.0.0.1:6379&gt; DEL weilai -- 删除键(integer) 0 # 删除失败 keys * 遍历所有key – 一般不会使用 dbsize 计算 key 总数 – O（1） exists key 检查key 是否存在（0,1）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全性能测试客户端连接管道技术]]></title>
    <url>%2Fredis%2F%E5%AE%89%E5%85%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BF%9E%E6%8E%A5%E7%AE%A1%E9%81%93%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[安全查看是否设置密码12345127.0.0.1:6379&gt; CONFIG get requirepass1) &quot;requirepass&quot;2) &quot;&quot;# 默认没有设置 设置密码12345127.0.0.1:6379&gt; CONFIG set requirepass &quot;mypassword&quot;OK127.0.0.1:6379&gt; CONFIG get requirepass1) &quot;requirepass&quot;2) &quot;mypassword&quot; 设置密码后，客户端连接 redis 服务就需要密码验证，否则无法执行命令。 123456127.0.0.1:6379&gt; AUTH &quot;mypassword&quot;OK127.0.0.1:6379&gt; SET mykey &quot;Test value&quot;OK127.0.0.1:6379&gt; GET mykey&quot;Test value&quot; 性能测试Redis 性能测试是通过同时执行多个命令实现的redis-benchmark [option] [option value] 1234redis-benchmark -h 127.0.0.1 -p 6379 -t set,lpush -n 100000 -qSET: 146198.83 requests per secondLPUSH: 145560.41 requests per second 客户端连接Redis 通过监听一个 TCP 端口或者 Unix socket 的方式来接收来自客户端的连接，当一个连接建立后，Redis 内部会进行以下一些操作： 首先，客户端 socket 会被设置为非阻塞模式，因为 Redis 在网络事件处理上采用的是非阻塞多路复用模型。 然后为这个 socket 设置 TCP_NODELAY 属性，禁用 Nagle 算法 然后创建一个可读的文件事件用于监听这个客户端 socket 的数据发送 1234config get maxclients1) &quot;maxclients&quot;2) &quot;10000&quot; 启动时设置最大连接数1redis-server --maxclients 100000 管道技术Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。这意味着通常情况下一个请求会遵循以下步骤： 客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应。服务端处理命令，并将结果返回给客户端。 Redis 管道技术可以在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应。12345678$(echo -en &quot;PING\r\n SET MYkey redis\r\nGET MYkey\r\nINCR visitor\r\nINCR visitor\r\nINCR visitor\r\n&quot;; sleep 10) | nc localhost 6379+PONG+OKredis:1:2:3]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis备份]]></title>
    <url>%2Fredis%2F%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[rdb : 在指定的时间间隔对数据进行快照存储 （默认开启） aof : 记录每次对服务器的写操作，重启时会重新执行这些命令。（AOF 文件会后台重写，使得文件不会太大） （需要修改配置文件 appendonly yes 开启） appendfsync : always/everysec(默认)/noappendfilename “appendonly.aof” 备份Redis SAVE 命令用于创建当前数据库的备份12redis 127.0.0.1:6379&gt; SAVE OK 该命令将在 redis 安装目录中创建dump.rdb文件 BGSAVE后台执行123127.0.0.1:6379&gt; BGSAVEBackground saving started 恢复将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务123redis 127.0.0.1:6379&gt; CONFIG GET dir -- CONFIG 命令获取 redis目录1) &quot;dir&quot;2) &quot;/usr/local/redis/bin&quot; 从 rdb 切换为 aof1234127.0.0.1:6379&gt; config set appendonly yes # 开启 aof 功能 ，永久修改需要修改配置文件 redis.confOK127.0.0.1:6379&gt; config set save &apos;&apos; # 关闭rdb (也可以同时使用)OK]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 数据类型]]></title>
    <url>%2Fredis%2F%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[redis 数据类型Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。 stringstring类型是Redis最基本的数据类型，二进制安全的。redis的string可以包含任何数据，比如jpg图片或者序列化的对象，一个键最大能存储512MB1234567891011121314151617181920212223242526272829# SET 设置键值 GET 获取键值redis 127.0.0.1:6379&gt; SET name &quot;weilai&quot; OKredis 127.0.0.1:6379&gt; GET name &quot;weilai&quot;127.0.0.1:6379&gt; strlen name(integer) 6127.0.0.1:6379&gt; getset name newvalue&quot;weilai&quot;127.0.0.1:6379&gt; get name&quot;newvalue&quot;127.0.0.1:6379&gt; getrange name 1 3&quot;ewv&quot;127.0.0.1:6379&gt; SETRANGE name 1 a(integer) 8127.0.0.1:6379&gt; get name&quot;nawvalue&quot;127.0.0.1:6379&gt; setnx name 1 -- key存在时，不创建(integer) 0127.0.0.1:6379&gt; set name newname xx -- key存在时，才更新OK127.0.0.1:6379&gt; get name&quot;newname&quot;127.0.0.1:6379&gt; set name1 newname1 xx -- key不存在时，不更新(nil)127.0.0.1:6379&gt; get name1(nil)127.0.0.1:6379&gt; get name&quot;nawvalue&quot; mset 和 mget 设置（得到） 多个key的值1234567127.0.0.1:6379&gt; mset date &quot;2019.08.30&quot; time &quot;11:00 a.m.&quot; weather &quot;sunny&quot;OK127.0.0.1:6379&gt; mget date time name weather1) &quot;2019.08.30&quot;2) &quot;11:00 a.m.&quot;3) &quot;weilai&quot;4) &quot;sunny&quot; append 添加字符串1234127.0.0.1:6379&gt; append name &apos;1995&apos;(integer) 10127.0.0.1:6379&gt; GET name&quot;weilai1995&quot; del 删除1234127.0.0.1:6379&gt; del name(integer) 1127.0.0.1:6379&gt; get name(nil) incr/decr 增加/减少 112345678910111213141516127.0.0.1:6379&gt; decr num(integer) -1127.0.0.1:6379&gt; get num&quot;-1&quot;127.0.0.1:6379&gt; incr num(integer) 0127.0.0.1:6379&gt; get num&quot;0&quot;127.0.0.1:6379&gt; incrby num 3(integer) 3127.0.0.1:6379&gt; decrby num 2(integer) 1127.0.0.1:6379&gt; get num&quot;1&quot;127.0.0.1:6379&gt; incrbyfloat num 3.5&quot;4.5&quot; HashRedis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。HMSET, HGETALL 命令 user:1 为键值12345678910111213141516171819202122232425262728293031323334353637383940414243redis 127.0.0.1:6379&gt; hmset user:1 username weilai password handsome OK127.0.0.1:6379&gt; hmget user:1 username password1) &quot;weilai&quot;2) &quot;handsome&quot;redis 127.0.0.1:6379&gt; HGETALL user:11) &quot;username&quot;2) &quot;weilai&quot;3) &quot;password&quot;4) &quot;handsome&quot;127.0.0.1:6379&gt; hmget user:1 username password port1) &quot;weilai&quot;2) &quot;handsome&quot;3) &quot;22&quot;redis 127.0.0.1:6379&gt; hget user:1 username&quot;weilai&quot;127.0.0.1:6379&gt; HGET user:1 weilai(nil)127.0.0.1:6379&gt; hkeys user:1 # 获取 key1) &quot;username&quot;2) &quot;password&quot;3) &quot;port&quot;127.0.0.1:6379&gt; hvals user:1 #获取 value1) &quot;weilai&quot;2) &quot;handsome&quot;3) &quot;22&quot;127.0.0.1:6379&gt; hlen user:1(integer) 3127.0.0.1:6379&gt; hexists user:1 password # 是否存在 passw(integer) 1127.0.0.1:6379&gt; hexists user:1 passwd(integer) 0 hdel user:1 password port(integer) 2127.0.0.1:6379&gt; hgetall user:11) &quot;username&quot;2) &quot;weilai&quot;127.0.0.1:6379&gt; hsetnx user:1 username fisher # 存在username 不创建(integer) 0127.0.0.1:6379&gt; hgetall user:1 1) &quot;username&quot;2) &quot;weilai&quot;# 每个 hash 可以存储 232 - 1 键值对（40多亿） ListRedis 列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素lpush到列表的头部（左边）或者rpush尾部（右边）lrange 获取指定长度 （从0 开始） lpushx/rpushx 只能是 key 存在，且仅能添加一个 lpop/rpop 移除最左/右 边 的一个元素 ltrim 截取一段长度 llen 列表元素个数 lrem weilai 0 python 删除所有的’python’123456789101112131415161718192021222324252627282930313233343536373839404142redis 127.0.0.1:6379&gt; lpush weilai redis(integer) 1redis 127.0.0.1:6379&gt; lpush weilai mongodb(integer) 2redis 127.0.0.1:6379&gt; rpush weilai rabitmq(integer) 3redis 127.0.0.1:6379&gt; lrange weilai 0 101) &quot;mongodb&quot;2) &quot;redis&quot;3) &quot;rabitmq&quot;&quot;127.0.0.1:6379&gt; lrange weilai 0 11) &quot;mongodb&quot;2) &quot;redis&quot;127.0.0.1:6379&gt; llen weilai(integer) 3127.0.0.1:6379&gt; lpush weilai python java c++ shell(integer) 8127.0.0.1:6379&gt; lrange weilai 0 10 1) &quot;shell&quot;2) &quot;c++&quot;3) &quot;java&quot;4) &quot;python&quot;5) &quot;mongodb&quot;6) &quot;redis&quot;7) &quot;rabitmq&quot;127.0.0.1:6379&gt; lrem weilai 0 python # 删除所有的python 元素(integer) 1127.0.0.1:6379&gt; lrange weilai 0 10 1) &quot;shell&quot;2) &quot;c++&quot;3) &quot;java&quot;4) &quot;mongodb&quot;5) &quot;redis&quot;6) &quot;rabitmq&quot;127.0.0.1:6379&gt; ltrim weilai 2 4OK127.0.0.1:6379&gt; lrange weilai 0 101) &quot;java&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;# 列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿) SetRedis的Set是string类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1) sadd/srem 添加/删除元素sismember 判断是否为set的一个元素smembers 返回该集合的所有成员sdiff 返回一个集合与其它集合的差异sinter 返回几个集合的交集sunion 返回几个集合的并集 12345678910111213141516171819202122232425262728293031323334353637127.0.0.1:6379&gt; sadd zoo cat dog(integer) 2127.0.0.1:6379&gt; sadd zoo cat dog fisher(integer) 1127.0.0.1:6379&gt; smembers zoo1) &quot;fisher&quot;2) &quot;dog&quot;3) &quot;cat&quot;127.0.0.1:6379&gt; srem zoo cat(integer) 1127.0.0.1:6379&gt; srem zoo cat(integer) 0127.0.0.1:6379&gt; sismember zoo cat(integer) 0127.0.0.1:6379&gt; sismember zoo fisher(integer) 1127.0.0.1:6379&gt; smembers zoo1) &quot;fisher&quot;2) &quot;dog&quot;127.0.0.1:6379&gt; sadd zoo1 dog cow(integer) 2127.0.0.1:6379&gt; smembers zoo11) &quot;cow&quot;2) &quot;dog&quot;127.0.0.1:6379&gt; sdiff zoo zoo11) &quot;fisher&quot;127.0.0.1:6379&gt; sdiff zoo1 zoo1) &quot;cow&quot;127.0.0.1:6379&gt; sinter zoo1 zoo1) &quot;dog&quot;127.0.0.1:6379&gt; sunion zoo1 zoo1) &quot;fisher&quot;2) &quot;dog&quot;3) &quot;cow&quot;# 添加一个string元素到,key对应的set集合中，成功返回1,如果元素以及在集合中返回0,key对应的set不存在返回错误。集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员) zset(sorted set：有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复 12345678910111213redis 127.0.0.1:6379&gt; zadd weilai 0 redis(integer) 1redis 127.0.0.1:6379&gt; zadd weilai 0 mongodb(integer) 1redis 127.0.0.1:6379&gt; zadd weilai 0 rabitmq(integer) 1redis 127.0.0.1:6379&gt; zadd weilai 10 redis -- 添加元素到集合，元素在集合中存在则更新对应score(integer) 0redis 127.0.0.1:6379&gt; ZRANGEBYSCORE weilai 0 10001) &quot;redis&quot;2) &quot;mongodb&quot;3) &quot;rabitmq&quot;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python操作redis]]></title>
    <url>%2Fredis%2Fpython%E6%93%8D%E4%BD%9Credis%2F</url>
    <content type="text"><![CDATA[1. 准备工作 安装好 redis 和 RedisPy库 RedisDump 可以用来做数据导入或导出2. RedisPy库RedisPy库 提供两个类 redis 和 StrictRedis 来实现 Redis 的命令操作。 StrictRedis 实现了绝大部分官方命令，参数也一一对应。 redis 是 StrictRedis 的子类，主要功能是用于向后兼容旧版本库里的几个方法。 推荐使用 StrictRedis 连接 Redis12345from redis import StrictRedis# localhost port=6379 默认数据库 password=passwordredis = StrictRedis(host=&apos;localhost&apos;, port=6379, db=0, password=&apos;password&apos;) redis.set(&apos;name&apos;, &apos;weilai&apos;)print(redis.get(&apos;name&apos;)) 使用ConnectionPool 连接 1234567from redis import StrictRedis, ConnectionPoolpool = ConnectionPool(host=&apos;localhost&apos;, port=6379, db=0, password=password)# localhost port=6379 默认数据库 password=passwordredis = StrictRedis(connection_pool=pool) #redis.set(&apos;name&apos;, &apos;weilai&apos;)print(redis.get(&apos;name&apos;)) ConnectionPool 还支持通过 url 来构建 123redis://[:password]@host:port/db # tcprediss://[:password]@host:port/db # tcp +ssl unix://[:password]@/path/to/socket.sock?db=db # UNIX socket 连接 eg:1234url = &apos;redis://:password@localhost:6379/0&apos;pool = ConnectionPool.from_url(url)redis = StrictRedis(connection_pool=pool) print(redis.get(&apos;name&apos;)) 类 改写1234567891011121314151617181920212223242526272829303132333435363738394041import redisclass TestString: def __init__(self): self.r = redis.StrictRedis(host=&apos;localhost&apos;, port=6379, db=0) def test_set(self): result = self.r.set(&apos;name2&apos;,&apos;weilai2&apos;) print(result) return result def test_get(self): result = self.r.get(&apos;name2&apos;) print(result) return result def test_mset(self): d = &#123; &apos;name3&apos; : &apos;user3&apos;, &apos;name4&apos; : &apos;user4&apos; &#125; result = self.r.mset(d) print(result) return result def test_mget(self): l = [&apos;name3&apos;, &apos;name4&apos;] result = self.r.mget(l) print(result) return resultdef main(): str_obj = TestString() str_obj.test_set() str_obj.test_get() str_obj.test_mset() str_obj.test_mget()if __name__ == &apos;__main__&apos;: main()]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装redis集群]]></title>
    <url>%2Fredis%2Fdocker%E5%AE%89%E8%A3%85redis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[在 /home 目录下创建redis-cluster-test 文件夹12➜ mkdir -p /home/redis-cluster-test➜ cd /home/redis-cluster-test 把下列信息写入redis-cluster.tmpl文件中123456789port $&#123;PORT&#125;protected-mode nocluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000cluster-announce-ip 192.168.1.157cluster-announce-port $&#123;PORT&#125;cluster-announce-bus-port 1$&#123;PORT&#125;appendonly yes 当前目录下生成conf和data目标，并生成配置信息 共生成6个文件夹，从7001到7006，每个文件夹下包含data和conf文件夹，同时conf里面有redis.conf配置文件 123456 #for port in `seq 7001 7006`; do \ # 7001 ~7006 mkdir -p ./$&#123;port&#125;/conf \ &amp;&amp; PORT=$&#123;port&#125; envsubst &lt; ./redis-cluster.tmpl &gt; ./$&#123;port&#125;/conf/redis.conf \ &amp;&amp; mkdir -p ./$&#123;port&#125;/data; \done 创建6个redis容器1234567for port in `seq 7001 7006`; do \ docker run -d -ti \ -v `pwd`/$&#123;port&#125;/conf/redis.conf:/usr/local/etc/redis/redis.conf \ -v `pwd`/$&#123;port&#125;/data:/data \ --restart always --name redis-$&#123;port&#125; --net host \ --sysctl net.core.somaxconn=1024 redis:latest redis-server /usr/local/etc/redis/redis.conf; \done 进入任一容器1docker exec -it redis-7001 bash]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装redis]]></title>
    <url>%2Fredis%2Fdocker%E5%AE%89%E8%A3%85redis%2F</url>
    <content type="text"><![CDATA[docker search redis 查询镜像 docker pull redis 拉取官方镜像 docker images 查看一下是否成功 启动镜像 4.1. 下载并凭需求修改redis.conf，配置文件放在/opt/data/redis/目录下4.2 docker启动redis 12$ mkdir -p /opt/data/redis$ docker run -p 6379:6379 --name myredis -v /opt/data/redis/redis.conf:/etc/redis/redis.conf -v /opt/data/redis:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes --requirepass &quot;passwd&quot; 命令解释说明：-p 6379:6379 ##端口映射，:前表示主机部分，:后表示容器部分。–name myredis ##指定容器名称，查看和进行操作都比较方便。 -v /opt/data/redis:/data ##将主机中/opt/data/redis目录下的redis挂载到容器的/data-v /opt/data/redis/redis.conf:/etc/redis/redis.conf ##将主机中redis.conf配置文件挂载到容器的/etc/redis/redis.conf文件中 -d redis 表示后台启动redisredis-server /etc/redis/redis.conf 以配置文件启动redis，加载容器内的conf文件，最终找到的是挂载的目录/opt/data/redis/redis.conf–appendonly yes 开启redis 持久化 –requirepass “passwd” 需要密码 docker ps 查看容器启动情况 连接redis的几种方式 1234567docker exec -ti myredis redis-cli # 或者用iddocker exec -ti myredis redis-cli -a &quot;passwd&quot;docker exec -ti myredis redis-cli -h localhost -p 6379 docker exec -ti myredis redis-cli -h 127.0.0.1 -p 6379 docker exec -ti myredis redis-cli -h 172.17.0.3 -p 6379 docker-compose.yml文件内容：123456789redis: image: redis container_name: test-redis restart: always ports: - 6379:6379 volumes: - /opt/data/redis:/data command: redis-server --appendonly yes --requirepass &quot;redis&quot; 客户端连接docker run --name myredis-cli -it redis:latest redis-cli -h 服务器 -p 6379ctrl + p + q后台运行再次进入docker exec -ti myredis-cli redis-cli -h 服务器 -p 6379]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter备份]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fbackup%2Fnginx%2Freadme%2F</url>
    <content type="text"><![CDATA[pip3 install jupyter vi /usr/share/vim/vim81/defaults.vim jupyter notebook –generate-config jupyter contrib nbextension install –user –skip-running-check vi /root/.jupyter/jupyter_notebook_config.py rm /etc/nginx/sites-enabled/default ln -s /root/flask_nginx.conf /etc/nginx/conf.d/ setsid uwsgi –ini /root/flask_uwsgi.ini &amp; nohup jupyter notebook –allow-root &gt; jupyter.log 2&gt;&amp;1 &amp; service nginx restart 12from notebook.auth import passwdpasswd() 1234567891011# 允许通过任意绑定服务器的ip访问c.NotebookApp.ip = &apos;*&apos;# 用于访问的端口c.NotebookApp.port = 8527# 不自动打开浏览器c.NotebookApp.open_browser = False# 设置登录密码c.NotebookApp.password = &apos;sha1:14855cd59712:1cf1063d38e08cd2703a07a52b66714281676b6d&apos;# 设置默认目录c.NotebookApp.notebook_dir = u&apos;/root/&apos;c.NotebookApp.base_url = &apos;/jupyter/&apos;]]></content>
      <categories>
        <category>jupyter</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis简介]]></title>
    <url>%2Fredis%2Freadme%2F</url>
    <content type="text"><![CDATA[简介Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份 高可用，分布式 功能丰富，发布订阅，事物，pipeline,lua脚本 不依赖外部库，单线程模型 高可用 redis-sentinel ,分布式 redis-cluster Redis运行在内存中但是可以持久化到磁盘(性能极高)( aof或rdb )，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存. 主要用途 ： 数据库，缓存和消息中间件,计数器，排行榜，消息队列，社交网络，实时系统 执行文件redis-check-aof aof文件检查工具 redis-check-dump rdb文件检查工具 redis-sentinel sentinel服务器 redis-server redis服务器 redis-cli redis命令行客户端 redis-benchmark redis性能测试工具 安装1234567891011121314151617181920212223242526wget http://download.redis.io/releases/redis-5.0.5.tar.gztar xzf redis-5.0.5.tar.gzln -s redis-5.0.5 rediscd redismake ./redis-server # 启动redis服务./redis-server redis.conf # 依据配置，启动redis服务./redis-cli # 使用测试客户端程序redis-cli和redis服务交互# eg:$ ./redis-cliredis&gt; pingPONG # 以上操作代表 redis已经安装完成。# 在远程服务器上执行命令redis-cli -h host -p port -a passwordeg:$redis-cli -h 127.0.0.1 -p 6379 -a &quot;mypass&quot;redis 127.0.0.1:6379&gt;redis 127.0.0.1:6379&gt; PINGPONG 配置 redis.conf可以通过修改 redis.conf 文件或使用 CONFIG set 命令(CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE)来修改配置 eg：123456redis 127.0.0.1:6379&gt; CONFIG SET loglevel &quot;notice&quot;OKredis 127.0.0.1:6379&gt; CONFIG GET loglevel1) &quot;loglevel&quot;2) &quot;notice&quot; 具体配置信息参考文档]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python操作MongoDB]]></title>
    <url>%2Fmongodb%2Fpython%E6%93%8D%E4%BD%9CMongoDB%2F</url>
    <content type="text"><![CDATA[python操作MongoDB 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869from pymongo import MongoClientfrom dataclasses import dataclassfrom bson.objectid import ObjectId@dataclassclass Test_Mongo(): client:dict = MongoClient() db:dict = client[&apos;test&apos;] # 连接到 test 数据库 def add_one(self): post = &#123; &apos;name&apos;: &apos;justin&apos;, &apos;age&apos;: 18, &apos;sex&apos;: &apos;male&apos;, &apos;grade&apos;: 80 &#125; return self.db.students.insert_one(post) def add_many(self): return self.db.students.insert_many([&#123;&apos;name&apos;:i&#125; for i in range(0,10)]) def get_one(self): return self.db.students.find_one(&#123;&apos;name&apos;:&apos;justin&apos;&#125;) def get_more(self): return self.db.students.find(&#123;&apos;sex&apos;:&apos;male&apos;&#125;) def get_one_from_oid(self, oid): obj = ObjectId(oid) return self.db.students.find_one(&#123;&apos;_id&apos;: obj&#125;) def get_count(self): return self.db.students.estimated_document_count() def update_one(self): return self.db.students.update_one(&#123;&apos;name&apos;:&apos;justin&apos;&#125;,&#123;&apos;$inc&apos;:&#123;&apos;age&apos;:10&#125;&#125;) def update_many(self): return self.db.students.update_many(&#123;&#125;,&#123;&apos;$inc&apos;:&#123;&apos;age&apos;:5&#125;&#125;) def delete_one(self): return self.db.students.delete_one(&#123;&apos;name&apos;:&apos;justin&apos;&#125;) def delete_many(self): return self.db.students.delete_many(&#123;&apos;name&apos;:&apos;justin&apos;&#125;)def main(): obj = Test_Mongo() print(obj.add_one().inserted_id) print(obj.get_one()) print(obj.add_many().inserted_ids) print(obj.get_count()) for item in obj.get_more(): print(item[&apos;_id&apos;]) print(obj.get_one_from_oid(obj.add_one().inserted_id)) print(obj.update_one().matched_count) print(obj.update_one().matched_count) print(obj.update_many().matched_count) print(obj.update_many().matched_count) print(obj.delete_one().deleted_count) print(obj.delete_many().deleted_count)if __name__ == &apos;__main__&apos;: main()]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test_odm]]></title>
    <url>%2Fmongodb%2Ftest_odm%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from odm import Grade, Studentclass TestMongoEngine: def add_one(self): math = Grade(name = &apos;数学&apos;, score = 90) English = Grade(name = &apos;英语&apos;, score = 89.5) stu_obj = Student( name = &apos;weilai&apos;, age = 22, sex = &apos;male&apos;, grades = [math, English] ) stu_obj.remake = &apos;remake&apos; # 动态插入 stu_obj.save() return stu_obj def get_one(self): return Student.objects.first() def get_more(self): return Student.objects.all() def get_from_oid(self, oid): return Student.objects.filter(pk=oid).first() # 根据id 得到一条数据 def update_more(self): return Student.objects.filter(sex=&apos;male&apos;,age__gt=20).update(inc__age=10) def update_one(self): return Student.objects.filter(sex=&apos;male&apos;,age__gt=20).update_one(inc__age=100) def delete_one(self): return Student.objects.filter(sex=&apos;male&apos;).first().delete() def delete_more(self): return Student.objects.filter(sex=&apos;male&apos;).delete()def main(): obj = TestMongoEngine() result = obj.add_one() print(result.pk) get_one = obj.get_one() print(get_one.id) print(get_one.name) print(obj.get_from_oid(get_one.id).id) rows = obj.get_more() for row in rows: print(row.sex) print(obj.update_more()) print(obj.update_one()) print(obj.delete_one()) print(obj.delete_more())if __name__ == &apos;__main__&apos;: main()]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb插入数据]]></title>
    <url>%2Fmongodb%2F%E5%85%A5%E9%97%A8%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[插入数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203&gt; use testswitched to db test&gt; db.students.insertMany(... [&#123;&quot;name&quot;: &quot;测试-0&quot;, &quot;age&quot;: 63, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 1&#125;,&#123;&quot;name&quot;: &quot;测试-1&quot;, &quot;age&quot;: 32, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 7&#125;,&#123;&quot;name&quot;: &quot;测试-2&quot;, &quot;age&quot;: 20, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 8&#125;,&#123;&quot;name&quot;: &quot;测试-3&quot;, &quot;age&quot;: 55, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 58&#125;,&#123;&quot;name&quot;: &quot;测试-4&quot;, &quot;age&quot;: 84, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 65&#125;,&#123;&quot;name&quot;: &quot;测试-5&quot;, &quot;age&quot;: 27, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 57&#125;,&#123;&quot;name&quot;: &quot;测试-6&quot;, &quot;age&quot;: 86, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 61&#125;,&#123;&quot;name&quot;: &quot;测试-7&quot;, &quot;age&quot;: 18, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 93&#125;,&#123;&quot;name&quot;: &quot;测试-8&quot;, &quot;age&quot;: 50, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 71&#125;,&#123;&quot;name&quot;: &quot;测试-9&quot;, &quot;age&quot;: 81, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 42&#125;,&#123;&quot;name&quot;: &quot;测试-10&quot;, &quot;age&quot;: 26, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 25&#125;,&#123;&quot;name&quot;: &quot;测试-11&quot;, &quot;age&quot;: 91, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 14&#125;,&#123;&quot;name&quot;: &quot;测试-12&quot;, &quot;age&quot;: 6, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 54&#125;,&#123;&quot;name&quot;: &quot;测试-13&quot;, &quot;age&quot;: 73, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 24&#125;,&#123;&quot;name&quot;: &quot;测试-14&quot;, &quot;age&quot;: 51, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 14&#125;,&#123;&quot;name&quot;: &quot;测试-15&quot;, &quot;age&quot;: 53, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 19&#125;,&#123;&quot;name&quot;: &quot;测试-16&quot;, &quot;age&quot;: 3, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 48&#125;,&#123;&quot;name&quot;: &quot;测试-17&quot;, &quot;age&quot;: 13, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 11&#125;,&#123;&quot;name&quot;: &quot;测试-18&quot;, &quot;age&quot;: 40, &quot;sex&quot;: &quot;female&quot;, &quot;grade&quot;: 97&#125;,&#123;&quot;name&quot;: &quot;测试-19&quot;, &quot;age&quot;: 97, &quot;sex&quot;: &quot;male&quot;, &quot;grade&quot;: 96&#125;])&#123; &quot;acknowledged&quot; : true, &quot;insertedIds&quot; : [ ObjectId(&quot;5de8b35c75deb540ecfc5332&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5333&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5334&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5335&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5336&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5337&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5338&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5339&quot;), ObjectId(&quot;5de8b35c75deb540ecfc533a&quot;), ObjectId(&quot;5de8b35c75deb540ecfc533b&quot;), ObjectId(&quot;5de8b35c75deb540ecfc533c&quot;), ObjectId(&quot;5de8b35c75deb540ecfc533d&quot;), ObjectId(&quot;5de8b35c75deb540ecfc533e&quot;), ObjectId(&quot;5de8b35c75deb540ecfc533f&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5340&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5341&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5342&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5343&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5344&quot;), ObjectId(&quot;5de8b35c75deb540ecfc5345&quot;) ]&#125;&gt; db.students.find()&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5332&quot;), &quot;name&quot; : &quot;测试-0&quot;, &quot;age&quot; : 63, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 1 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5333&quot;), &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 32, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 7 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5334&quot;), &quot;name&quot; : &quot;测试-2&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 8 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5335&quot;), &quot;name&quot; : &quot;测试-3&quot;, &quot;age&quot; : 55, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 58 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5336&quot;), &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 84, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 65 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5337&quot;), &quot;name&quot; : &quot;测试-5&quot;, &quot;age&quot; : 27, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 57 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5338&quot;), &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 86, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5339&quot;), &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533a&quot;), &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 50, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533b&quot;), &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 81, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 42 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533c&quot;), &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 26, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 25 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533d&quot;), &quot;name&quot; : &quot;测试-11&quot;, &quot;age&quot; : 91, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533e&quot;), &quot;name&quot; : &quot;测试-12&quot;, &quot;age&quot; : 6, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 54 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533f&quot;), &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 73, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 24 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5340&quot;), &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 51, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5341&quot;), &quot;name&quot; : &quot;测试-15&quot;, &quot;age&quot; : 53, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 19 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5342&quot;), &quot;name&quot; : &quot;测试-16&quot;, &quot;age&quot; : 3, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 48 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5343&quot;), &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 13, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 11 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5344&quot;), &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 40, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5345&quot;), &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 97, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 96 &#125;&gt; db.students.find(&#123;sex:&apos;male&apos;&#125;,&#123;age:1,name:1,_id:0&#125;) # sex 为 male false 不显示， true 显示&#123; &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 32 &#125;&#123; &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 84 &#125;&#123; &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 81 &#125;&#123; &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 26 &#125;&#123; &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 73 &#125;&#123; &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 51 &#125;&#123; &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 13 &#125;&#123; &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 97 &#125;&gt; db.students.find(&#123;grade:&#123;&apos;$gte&apos;:60&#125;&#125;,&#123;_id:0&#125;) # grade 大于等于 60 &#123; &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 84, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 65 &#125;&#123; &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 86, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61 &#125;&#123; &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93 &#125;&#123; &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 50, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71 &#125;&#123; &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 40, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97 &#125;&#123; &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 97, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 96 &#125;&gt; db.students.find(&#123;&apos;$or&apos;:[&#123;sex:&apos;female&apos;,age:18&#125;,&#123;sex:&apos;male&apos;,age:81&#125;]&#125;,&#123;_id:0&#125;) # age =18,sex = famale 或 age = 81,sex = male&#123; &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93 &#125;&#123; &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 81, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 42 &#125;&gt; db.students.find().sort(&#123;age:-1&#125;) # 按 age 倒序 &#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5345&quot;), &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 97, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 96 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533d&quot;), &quot;name&quot; : &quot;测试-11&quot;, &quot;age&quot; : 91, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5338&quot;), &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 86, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5336&quot;), &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 84, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 65 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533b&quot;), &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 81, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 42 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533f&quot;), &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 73, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 24 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5332&quot;), &quot;name&quot; : &quot;测试-0&quot;, &quot;age&quot; : 63, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 1 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5335&quot;), &quot;name&quot; : &quot;测试-3&quot;, &quot;age&quot; : 55, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 58 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5341&quot;), &quot;name&quot; : &quot;测试-15&quot;, &quot;age&quot; : 53, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 19 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5340&quot;), &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 51, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533a&quot;), &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 50, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5344&quot;), &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 40, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5333&quot;), &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 32, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 7 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5337&quot;), &quot;name&quot; : &quot;测试-5&quot;, &quot;age&quot; : 27, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 57 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533c&quot;), &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 26, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 25 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5334&quot;), &quot;name&quot; : &quot;测试-2&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 8 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5339&quot;), &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5343&quot;), &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 13, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 11 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc533e&quot;), &quot;name&quot; : &quot;测试-12&quot;, &quot;age&quot; : 6, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 54 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8b35c75deb540ecfc5342&quot;), &quot;name&quot; : &quot;测试-16&quot;, &quot;age&quot; : 3, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 48 &#125;&gt; db.students.find(&#123;&#125;,&#123;_id:0&#125;).sort(&#123;age:1&#125;) # 查询所有，不显示_id,按age 升序&#123; &quot;name&quot; : &quot;测试-16&quot;, &quot;age&quot; : 3, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 48 &#125;&#123; &quot;name&quot; : &quot;测试-12&quot;, &quot;age&quot; : 6, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 54 &#125;&#123; &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 13, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 11 &#125;&#123; &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93 &#125;&#123; &quot;name&quot; : &quot;测试-2&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 8 &#125;&#123; &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 26, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 25 &#125;&#123; &quot;name&quot; : &quot;测试-5&quot;, &quot;age&quot; : 27, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 57 &#125;&#123; &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 32, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 7 &#125;&#123; &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 40, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97 &#125;&#123; &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 50, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71 &#125;&#123; &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 51, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;name&quot; : &quot;测试-15&quot;, &quot;age&quot; : 53, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 19 &#125;&#123; &quot;name&quot; : &quot;测试-3&quot;, &quot;age&quot; : 55, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 58 &#125;&#123; &quot;name&quot; : &quot;测试-0&quot;, &quot;age&quot; : 63, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 1 &#125;&#123; &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 73, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 24 &#125;&#123; &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 81, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 42 &#125;&#123; &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 84, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 65 &#125;&#123; &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 86, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61 &#125;&#123; &quot;name&quot; : &quot;测试-11&quot;, &quot;age&quot; : 91, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 97, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 96 &#125;&gt; db.students.update(&#123;&#125;,&#123;&apos;$set&apos;:&#123;class:&apos;class 1&apos;&#125;&#125;) # 仅修改第一条数据WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.students.find(&#123;&#125;,&#123;_id:0&#125;)&#123; &quot;name&quot; : &quot;测试-0&quot;, &quot;age&quot; : 63, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 1, &quot;class&quot; : &quot;class 1&quot; &#125;&#123; &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 32, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 7 &#125;&#123; &quot;name&quot; : &quot;测试-2&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 8 &#125;&#123; &quot;name&quot; : &quot;测试-3&quot;, &quot;age&quot; : 55, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 58 &#125;&#123; &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 84, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 65 &#125;&#123; &quot;name&quot; : &quot;测试-5&quot;, &quot;age&quot; : 27, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 57 &#125;&#123; &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 86, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61 &#125;&#123; &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93 &#125;&#123; &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 50, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71 &#125;&#123; &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 81, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 42 &#125;&#123; &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 26, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 25 &#125;&#123; &quot;name&quot; : &quot;测试-11&quot;, &quot;age&quot; : 91, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;name&quot; : &quot;测试-12&quot;, &quot;age&quot; : 6, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 54 &#125;&#123; &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 73, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 24 &#125;&#123; &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 51, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 14 &#125;&#123; &quot;name&quot; : &quot;测试-15&quot;, &quot;age&quot; : 53, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 19 &#125;&#123; &quot;name&quot; : &quot;测试-16&quot;, &quot;age&quot; : 3, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 48 &#125;&#123; &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 13, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 11 &#125;&#123; &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 40, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97 &#125;&#123; &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 97, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 96 &#125;&gt; db.students.update(&#123;&#125;,&#123;&apos;$set&apos;:&#123;class:&apos;class 2&apos;&#125;&#125;,&#123;multi:true&#125;) # &#123;multi:true&#125; 多条属性WriteResult(&#123; &quot;nMatched&quot; : 20, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 19 &#125;)&gt; db.students.find(&#123;&#125;,&#123;_id:0&#125;)&#123; &quot;name&quot; : &quot;测试-0&quot;, &quot;age&quot; : 63, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 1, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 32, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 7, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-2&quot;, &quot;age&quot; : 20, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 8, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-3&quot;, &quot;age&quot; : 55, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 58, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 84, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 65, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-5&quot;, &quot;age&quot; : 27, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 57, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 86, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 18, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 50, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 81, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 42, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 26, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 25, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-11&quot;, &quot;age&quot; : 91, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 14, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-12&quot;, &quot;age&quot; : 6, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 54, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 73, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 24, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 51, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 14, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-15&quot;, &quot;age&quot; : 53, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 19, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-16&quot;, &quot;age&quot; : 3, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 48, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 13, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 11, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 40, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 97, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 96, &quot;class&quot; : &quot;class 2&quot; &#125;&gt; db.students.update(&#123;&#125;,&#123;&apos;$inc&apos;:&#123;age:1&#125;&#125;,&#123;multi:true&#125;) # 所有人的age加1 WriteResult(&#123; &quot;nMatched&quot; : 20, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 20 &#125;)&gt; db.students.find(&#123;&#125;,&#123;_id:0&#125;) &#123; &quot;name&quot; : &quot;测试-0&quot;, &quot;age&quot; : 64, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 1, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 33, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 7, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-2&quot;, &quot;age&quot; : 21, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 8, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-3&quot;, &quot;age&quot; : 56, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 58, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 85, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 65, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-5&quot;, &quot;age&quot; : 28, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 57, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 87, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 19, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 51, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 82, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 42, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 27, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 25, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-11&quot;, &quot;age&quot; : 92, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 14, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-12&quot;, &quot;age&quot; : 7, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 54, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 74, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 24, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 52, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 14, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-15&quot;, &quot;age&quot; : 54, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 19, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-16&quot;, &quot;age&quot; : 4, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 48, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 14, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 11, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 41, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 98, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 96, &quot;class&quot; : &quot;class 2&quot; &#125;&gt; db.students.update(&#123;sex:&apos;male&apos;&#125;,&#123;&apos;$inc&apos;:&#123;grade:-1&#125;&#125;,&#123;multi:true&#125;) # sex:male 的grade 减1 WriteResult(&#123; &quot;nMatched&quot; : 8, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 8 &#125;)&gt; db.students.find(&#123;&#125;,&#123;_id:0&#125;)&#123; &quot;name&quot; : &quot;测试-0&quot;, &quot;age&quot; : 64, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 1, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-1&quot;, &quot;age&quot; : 33, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 6, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-2&quot;, &quot;age&quot; : 21, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 8, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-3&quot;, &quot;age&quot; : 56, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 58, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-4&quot;, &quot;age&quot; : 85, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 64, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-5&quot;, &quot;age&quot; : 28, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 57, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-6&quot;, &quot;age&quot; : 87, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 61, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-7&quot;, &quot;age&quot; : 19, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 93, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-8&quot;, &quot;age&quot; : 51, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 71, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-9&quot;, &quot;age&quot; : 82, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 41, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-10&quot;, &quot;age&quot; : 27, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 24, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-11&quot;, &quot;age&quot; : 92, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 14, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-12&quot;, &quot;age&quot; : 7, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 54, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-13&quot;, &quot;age&quot; : 74, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 23, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-14&quot;, &quot;age&quot; : 52, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 13, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-15&quot;, &quot;age&quot; : 54, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 19, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-16&quot;, &quot;age&quot; : 4, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 48, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-17&quot;, &quot;age&quot; : 14, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 10, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-18&quot;, &quot;age&quot; : 41, &quot;sex&quot; : &quot;female&quot;, &quot;grade&quot; : 97, &quot;class&quot; : &quot;class 2&quot; &#125;&#123; &quot;name&quot; : &quot;测试-19&quot;, &quot;age&quot; : 98, &quot;sex&quot; : &quot;male&quot;, &quot;grade&quot; : 95, &quot;class&quot; : &quot;class 2&quot; &#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb补充数据]]></title>
    <url>%2Fmongodb%2F%E5%85%A5%E9%97%A8%E8%A1%A5%E5%85%85%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021import randomimport jsona = &#123; &apos;name&apos; : &apos;weilai&apos;, &apos;age&apos; : 18, &apos;sex&apos;: &apos;male&apos;, &apos;grade&apos; : 45 &#125;list_json = []for i in range(0,20): a[&apos;name&apos;] = f&quot;测试-&#123;i&#125;&quot; a[&apos;age&apos;] = random.randint(0, 100) a[&apos;sex&apos;] = random.choice([&apos;male&apos;, &apos;female&apos;]) a[&apos;grade&apos;] = random.randint(0, 100) j = json.dumps(a, ensure_ascii=False) list_json.append(j)list_json = &apos;,&apos;.join(list_json)list_json = &apos;[&apos; + list_json +&apos;]&apos;print(list_json)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[odm]]></title>
    <url>%2Fmongodb%2Fodm%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728from mongoengine import connect, Document, StringField, IntField, \ FloatField, EmbeddedDocument, ListField, EmbeddedDocumentField, DynamicDocument # 可以在后面插入其他关键字connect(&apos;test&apos;) # 连接的数据库# connect(&apos;test&apos;, host = &apos;192.168.0.2&apos;, port=27017)# connect(&apos;test&apos;, host = &apos;mongodb://localhost/test&apos;) SEX_CHOICE = ( (&apos;male&apos;, &apos;男&apos;), (&apos;female&apos;, &apos;女&apos;))class Grade(EmbeddedDocument): &apos;&apos;&apos; 成绩信息 &apos;&apos;&apos; name = StringField(required=True) score = FloatField(required=True)class Student(DynamicDocument): # 可以在后面插入其他关键字 &apos;&apos;&apos; 学生信息 &apos;&apos;&apos; name = StringField(max_length=32, required=True) age = IntField(required=True) sex = StringField(choices=SEX_CHOICE, required=True) grade = FloatField() address = StringField() grades = ListField(EmbeddedDocumentField(Grade)) # 与 Grade 关联 meta = &#123; &apos;collection&apos;: &apos;students&apos; # 指定连接的集合 &#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb入门]]></title>
    <url>%2Fmongodb%2F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[简介文档 eg: {“foo”:3,”greeting”:”Hello world!”} 区分大小写 key唯一 文档可嵌套 键值对 有序 集合 集合就是一组文档 文档类似于 关系库里的 行 集合类似于 关系库里的表 集合中的文档无需固定的结构 集合命名规则： 数据库 多个文档组成集合，多个集合组成数据库 一个实例 可以承载多个数据库 （可以理解为一个mongodb可以有多个数据库） 每个数据库都有独立权限 保留的数据库名称（admin,local,config） 使用命令行操作数据库兼容js操作 1+23function add(r1,r2){… return r1 + r2;… }add(8,2)10 新增数据show dbs 查看所有数据库db.collection.insert()db.collection.insertOne()db.collection.insertMany()123&gt; show dbsadmin 0.078GBlocal 0.078GB use test 使用 test 数据库 （没有就会创建）12345678910&gt; use studentsswitched to db students&gt; db # 查看当前数据库students&gt; stu = &#123; name : &apos;weilai&apos;, age : 22 &#125;&#123; &quot;name&quot; : &quot;weilai&quot;, &quot;age&quot; : 22 &#125;&gt; db.students.insert(stu)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; db.students.insert(&#123; &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot;: &quot;male&quot; &#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 查询数据db.collection.find()123&gt; db.students.find()&#123; &quot;_id&quot; : ObjectId(&quot;5de8a491ff626673ec5503c9&quot;), &quot;name&quot; : &quot;weilai&quot;, &quot;age&quot; : 22 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8a554ff626673ec5503ca&quot;), &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125; db.collection.findOne()123456&gt; db.students.findOne() # 查询第一条数据&#123; &quot;_id&quot; : ObjectId(&quot;5de8a491ff626673ec5503c9&quot;), &quot;name&quot; : &quot;weilai&quot;, &quot;age&quot; : 22&#125; 修改数据db.collection.update()1234567891011121314&gt; db.students.find()&#123; &quot;_id&quot; : ObjectId(&quot;5de8a491ff626673ec5503c9&quot;), &quot;name&quot; : &quot;weilai&quot;, &quot;age&quot; : 22 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8a554ff626673ec5503ca&quot;), &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125;&gt; s = db.students.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;5de8a491ff626673ec5503c9&quot;), &quot;name&quot; : &quot;weilai&quot;, &quot;age&quot; : 22&#125;&gt; db.students.update(&#123;name:&apos;weilai&apos;&#125;,&#123;name:&apos;cool&apos;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.students.find()&#123; &quot;_id&quot; : ObjectId(&quot;5de8a491ff626673ec5503c9&quot;), &quot;name&quot; : &quot;cool&quot; &#125; # 直接替换，并非仅修改 name 的值&#123; &quot;_id&quot; : ObjectId(&quot;5de8a554ff626673ec5503ca&quot;), &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125; 仅修改值1234567891011121314&gt; s_obj = db.students.findOne(&#123;&apos;name&apos;:&apos;weilai1&apos;&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5de8a554ff626673ec5503ca&quot;), &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot;&#125;&gt; s_obj.name = &apos;amy&apos;amy&gt; db.students.update(&#123;name:&apos;weilai1&apos;&#125;,s_obj)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.students.find()&#123; &quot;_id&quot; : ObjectId(&quot;5de8a491ff626673ec5503c9&quot;), &quot;name&quot; : &quot;cool&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8a554ff626673ec5503ca&quot;), &quot;name&quot; : &quot;amy&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125; 删除数据db.collection.remove({name:&#39;cool&#39;}) 删除 1条数据db.collection.remove({}) 删除所有数据123456789101112131415&gt; db.students.insert(&#123; &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot;: &quot;male&quot; &#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; db.students.find()&#123; &quot;_id&quot; : ObjectId(&quot;5de8a491ff626673ec5503c9&quot;), &quot;name&quot; : &quot;cool&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8a554ff626673ec5503ca&quot;), &quot;name&quot; : &quot;amy&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8ae63ff626673ec5503cb&quot;), &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125;&gt; db.students.remove(&#123;name:&apos;cool&apos;&#125;)WriteResult(&#123; &quot;nRemoved&quot; : 1 &#125;)&gt; db.students.find()&#123; &quot;_id&quot; : ObjectId(&quot;5de8a554ff626673ec5503ca&quot;), &quot;name&quot; : &quot;amy&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5de8ae63ff626673ec5503cb&quot;), &quot;name&quot; : &quot;weilai1&quot;, &quot;age&quot; : 22, &quot;sex&quot; : &quot;male&quot; &#125;&gt; db.students.remove(&#123;&#125;)WriteResult(&#123; &quot;nRemoved&quot; : 2 &#125;)&gt; db.students.find()&gt;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb常用命令]]></title>
    <url>%2Fmongodb%2Fmongodb%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1.mongo连入本机数据库 2.mongo 10.66.66.126:27017连入ip地址为10.66.66.126的机器的数据库 3.db / db.getName()查看当前数据库(db就是Database) 4.use demo切换/创建数据库(demo为数据库名) 5.show dbs查看所有数据库show tables查看所有表集合 6.db.dropDatabase()删除当前操作的数据库 7.db.copyDatabase(“mydb”, “temp”, “127.0.0.1”)从指定的机器上复制指定数据库数据到某个数据库，将本机的mydb的数据复制到temp数据库中 8.db.repairDatabase()修复当前数据库 9.db.version()当前db版本 10.db.stats()显示当前db状态 11.db.getMongo()查看当前db的链接机器地址 12.数据库表 (Collection聚集集合 ) 1)创建一个表 db.createCollection(“collName”, {size: 20, capped: 5, max: 100}) 2)得到指定名称的表 db.getCollection(&quot;table&quot;) 3)查询当前db的所有表名的集合 db.getCollectionNames() 4)显示当前db所有表索引的状态 db.printCollectionStats() 13.查数据 1)查询某表中所有记录(如果数据太多分页查看输出 it 回车) db.table.find() 相当于：select * from table; db.table.find().pretty() 查看的数据格式化 db.table.find({}, {id: 0, “name”: 0}) 查询表中所有数据,id和name字段不返回 db.table.find({}, {id: 1, “name”: 1}) 查询表中所有数据,id和name字段返回(默认返回) 2)查询某张表中的某个字段的重复数据(会过滤掉name字段中相同的数据) db.table.distinct(&quot;name&quot;) 相当于: select distinct name from table; 3)查询某张表中&quot;name&quot;=&quot;Bill&quot;的数据 db.table.find({&quot;name&quot;=&quot;Bill&quot;}) 相当于：select * from table where name = Bill; 4)查询某张表中 id &gt; 1 的数据 ($gt &gt;, $lt &lt;，$gte &gt;=, $lte &lt;=, $ne !=) db.table.find({id: {$gt: 1}}) 相当于: select * from table where id &gt; 1; 5)查询某张表中 id &gt; 1 $$ id &lt;= 5的数据 db.table.find({id: {$gt: 1,$lte: 5}}) 相当于： select * from table where (id &gt; 1 and id &lt;= 5); 6)查询某张表中 name 中包含 li 的数据 db.table.find({name: /li/}) 相当于： select * from table where name like &apos;%li%&apos;; 7)查询某张表中 name 以 li 开头的数据 db.table.find({name: /^li/}) 相当于： select * from table where name like &apos;li%&apos;; 8)查询某张表中 name 以 li 结尾的数据 db.table.find({name: /li$/}) 相当于：select * from table where name like &apos;%li&apos;; 9)查询指定列 name 和 work 的数据 db.table.find({}, {name: 1, work: 1}) 相当于：select name, work from table; 10)查询 id &gt; 3 的指定列 name 和 work 的数据 db.table.find({id: {$gt: 3}}, {name: 1, work: 1}) 想当于： select name, work from table where id &gt; 3; 11)按照 number 大小 升序和降序查询 (1表示升序, -1表示降序) 升序: db.table.find().sort({number: 1}) 降序：db.table.find().sort({number: -1}) 12)查询前三条数据 db.table.find().limit(3) 相当于：select top 3 * from table; 13)查询前三条之后的数据 db.table.find().skip(3) 相当于：select * from table where id not in (select top 3 * from table); 14)查询前三条之后的5条数据 db.table.find().limit(5).skip(3) 15)查询 id=2 或者 id=5 的数据($or 或者, $in 包含, $nin 不包含) db.table.find({$or: [{id: 2}, {id: 5}]}) 相当于：select * from table where id = 2 or id = 5; 16)查询第一条数据 db.table.findOne() 相当于：select top 1 * from table; 17)查询 id &gt;= 5 的数据的个数 (count() 查询数量) db.table.find({id: {$gte: 5}}).count() 相当于：select count(*) from table where id &gt;= 5; 18)查询有 name字段 的数据的个数 db.table.find({name: {$exists: true}}).count() 相当于: select count(name) from table; 14.索引索引是为了快速查找数据用的,主要是用来降低CPU成本消耗的。索引相当于排序，但与排序不同的是，排序是将原数据重新排列，改变了原数据的排列顺序。而索引只是建立一个顺序表，由这个顺序表指出数据的顺序，所以索引不改变原数据的排列顺序。MongoDB支持的索引：_id索引(默认建立)、单键索引、多键索引、复合索引、过期索引、全文索引、地理位置索引此外，排序可能升序或降序排列，而索引只有升序一种方式。 1)创建索引 db.table.ensureIndex({name: 1}) db.table.ensureIndex({name: 1, ts: -1}) 2)查询当前聚集集合所有索引 db.table.getIndexes() 3)查看总索引记录大小 db.table.totalIndexSize() 4)读取当前集合的所有index信息 db.table.reIndex() 5)删除指定索引 db.table.dropIndex(&quot;name_1&quot;) 6)删除所有索引索引 db.table.dropIndexes() 15.添加数据 1)插入数据字段 db.table.insert({}) db.table.save({}) 2)导入数据表 mongoimport -d Lanyu -c shangpin --file D:\MongoDB\data\product.json --jsonArray -d: 数据库 -c: 表名 --file: 数据文件地址 --jsonArray: 导入json文件专用,否则导入失败, json文件格式：[{},{},{},{},{}] 16.修改数据 1)修改表中条件为 name : “baiqi” 的数据的 字段 number($set设置) db.table.update({name: “baiqi”}, {$set: {number: “111”}}, false, true) 第一个false表示不新增数据 相当于：update table set number = ‘111’ where name = “baiqi”; 2)修改表中条件为 name : &quot;mayun&quot; 的数据 让 number = number + 111, id = id + 2($inc自增) db.table.update({name: &quot;mayun&quot;}, {$inc: {number: 111, id: 2}}, false, true) 相当于：update table set number = number + 111, id = id + 2 where name = &quot;mayun&quot;; 3)综合上面两个修改 db.table.update({name: &apos;liuqiangdong&apos;}, {$inc: {id: 3}, $set: {number: 113}}, false, true) 相当于： update table set id = id + 3, number = 113 where name = &apos;liuqiangdong&apos;; 17.删除数据 db.table.remove({_id: ObjectId(“59a67e103cbae75d282fe46b”)}) 其他 1)查询之前的错误信息 db.getPrevError() 2)清除错误记录 db.resetError()]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker推送备份]]></title>
    <url>%2Fdocker%2F%E6%8E%A8%E9%80%81%EF%BC%8C%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[提交运行的容器成为镜像生产环境一般使用 dockerfile. commit 的镜像不可控12345678docker run --name imwltest -h docker -dit -e TZ=Asia/Shanghai debian# docker commit -a=&apos;作者&apos; -m=&apos;备注&apos; 运行时容器ID 新镜像名称docker commit -a=&apos;imwl&apos; -m=&apos;Test&apos; imwltest imwl/test # 默认TAG: latestdocker commit -a=&apos;imwl&apos; -m=&apos;Test&apos; imwltest imwl/test:0.14docker export imwltest &gt; imwltest.tar # 导出容器docker import imwltest.tar imwltest:test # 导入容器 1234# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEimwl/test 0.14 69c1c6c58124 About a minute ago 114MBimwl/test latest ad65438d599f 7 minutes ago 114MB Docker Hub 账户 imwl12345678910111213141516docker logindocker push imwl/test:0.14docker push imwl/testdocker tag flasky:latest imwl/flask:latestdocker push imwl/flask:latestdocker run --name flasky -d -p 8000:5000 imwl/flask:latest # -d 后台运行容器，并返回容器ID -p 端口映射（8000宿主机，5000容器端口） # -P 随机端口映射# -e TZ=Asia/Shanghai 指定时区 备份与还原有些机密性，可以通过docker镜像备份和迁移实现12345678910111213141516171819202122232425262728# docker save -o 备份镜像的名称 源镜像名称:tag版本docker save -o imwltest.tar imwl/test:0.14# 当前目录下 会有 imwltest.tar文件# docker imagesREPOSITORY TAG IMAGE ID CREATEDimwl/test 0.14 69c1c6c58124 27 minutes agoimwl/test latest ad65438d599f 32 minutes ago# docker rmi imwl/test:0.14Untagged: imwl/test:0.14Untagged: imwl/test@sha256:97b496724012eee3df3421edb2ab6edcd6115e42b8060c24ba06b51da466e0ddDeleted: sha256:69c1c6c58124c56456a22c92a2e2125c9abc744f6acde379f5039779becbcc29# docker imagesREPOSITORY TAG IMAGE ID CREATEDimwl/test latest ad65438d599f 32 minutes ago## 恢复# docker load -i imwltest.tarLoaded image: imwl/test:0.14# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEimwl/test 0.14 69c1c6c58124 32 minutes ago 114MBimwl/test latest ad65438d599f 37 minutes ago 114MBdebian latest a8797652cfd9 2 weeks ago 114MB 私有仓库Docker私有仓库内部用来存放镜像的仓库，具有更高的保密安全级别 搭建12345678910111213141516171819202122# docker pull registry # 拉取私有仓库镜像# docker run -di --name=myRegistry --restart=always -p 5000:5000 registry # 启动私有仓库容器365d3d60c6741b95bd4c7c1ea7ab0d68f2f3ef62264b2beff3120d77f5c82a88# wget http://207.246.103.127:5000/v2/_catalog # 本机IP地址 207.246.103.127--2020-02-20 15:27:49-- http://207.246.103.127:5000/v2/_catalogConnecting to 207.246.103.127:5000... connected.HTTP request sent, awaiting response... 200 OKLength: 20 [application/json]Saving to: &apos;_catalog&apos;_catalog 100%[=============================================================&gt;] 20 --.-KB/s in 0s2020-02-20 15:27:49 (2.54 MB/s) - &apos;_catalog&apos; saved [20/20]# cat _catalog&#123;&quot;repositories&quot;:[]&#125;## 因为仓库里还没有镜像，所以就是空的；# cd /etc/docker# &quot;insecure-registries&quot;: [&quot;207.246.103.127:5000&quot;] 写入到 daemon.json文件 ## 信任私有仓库# systemctl restart docker # 重启docker 测试标记镜像为私有仓库的镜像docker tag imwl/test 207.246.103.127:5000/debiantest 上传镜像到私有仓库docker push 207.246.103.127:5000/debiantest]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker容器间的通信]]></title>
    <url>%2Fdocker%2F%E5%AE%B9%E5%99%A8%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/u013355826/article/details/84987233容器之间通信的主要方式 1.通过容器ip访问 容器重启后，ip会发生变化。通过容器ip访问不是一个好的方案。 2.通过宿主机的ip:port访问 通过宿主机的ip:port访问，只能依靠监听在暴露出的端口的进程来进行有限的通信。 3.通过link建立连接（官方不推荐使用） 运行容器时，指定参数link，使得源容器与被链接的容器可以进行相互通信，并且接受的容器可以获得源容器的一些数据，比如：环境变量。 源容器：mysqldocker run -itd –name test-mysql -e MYSQL_ROOT_PASSWORD=root mysql:5.7 #被链接容器 centosdocker run -itd –name test-centos –link test-mysql:mysql centos /bin/bash #进入test-centosdocker exec -it test-centos /bin/bash直接通过 link的名字或者link时候取的别名就能进入： 通过link建立连接的容器，被链接的容器能 ping 通源容器，反过来不行。 在被链接的容器上查看环境变量 被链接容器会继承源容器的环境变量信息。 与/etc/hosts中的主机条目不同，如果重新启动源容器，则不会自动更新存储在环境变量中的IP地址。我们建议使用主机条目 /etc/hosts来解析链接容器的IP地址。 除了环境变量之外，Docker还将源容器的主机条目添加到/etc/hosts文件中。 如果重新启动源容器，/etc/hosts链接容器上的文件将使用源容器的新IP地址自动更新，从而允许链接通信继续。 4.通过 User-defined networks（推荐） docker network来创建一个桥接网络，在docker run的时候将容器指定到新创建的桥接网络中，这样同一桥接网络中的容器就可以通过互相访问。 创建网络 docker network create test-network启动容器时，加入创建的网络 docker run -it –network test-network –network-alias mysql -e MYSQL_ROOT_PASSWORD=123 mysql:5.7启动被链接的容器 docker run -it –network test-network –network-alias centos centos /bin/bash]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker_windos10下]]></title>
    <url>%2Fdocker%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86windows10%2Bdocker%2Bwsl%2Bubuntu%2F</url>
    <content type="text"><![CDATA[准备工作安装wsl linux 开启Linux子系统，以管理员权限打开 PowerShell 1234# 启用虚拟机平台Enable-WindowsOptionalFeature -Online -FeatureName VirtualMachinePlatform# 开启Linux子系统Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 开启开发者模式，WIN + S 搜索 开发者设置，打开后选择 开发者模式 WIN + S 搜索 store， 打开 Microsoft Store（微软应用商店）,eg: 搜索 Ubuntu ，选择 Ubuntu 18.04 LST 进行安装 待安装完成后，从应用中打开 Ubuntu 18.04 LST优化 换源 打开自动切换到root用户 当前用户目录下 vi .bash_profile 添加以下内容12345678910111213141516#.bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then . ~/.bashrcfisudo su - rootPATH=$PATH:$HOME/binexport PATH 修改/etc/sudoers文件 12345678910su - rootchmod u+w /etc/sudoersvi /etc/sudoers # 编辑文件，在root ALL=(ALL)ALL行下添加xxx ALL=(ALL) NOPASSWD: ALL# XXX为用户名。chmod u－w /etc/sudoers # 回到文件的原权限！ 安装docker实际上是在Win10中安装Docker桌面服务，Linux子系统中安装客户端，连接Win10上的Docker服务，进行操作 在Ubuntu子系统中安装Docker123456789101112131415161718192021222324252627282930313233343536373839404142# 更新apt包管理列表sudo apt-get update -y# 安装依赖包sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-common# 加入Docker官方PGP公钥curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 确认指纹sudo apt-key fingerprint 0EBFCD88# 将stable（稳定版）Docker加入apt源中## If you want to live on the edge, you can change &quot;stable&quot; below to &quot;test&quot; or# &quot;nightly&quot;. I highly recommend sticking with stable!sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot;# 更新apt包管理列表sudo apt-get update -y# 安装Docker CE最新版本sudo apt-get install -y docker-ce# 允许当前用户访问Docker CLI，不必使用rootsudo usermod -aG docker $USER# 此时执行 docker version 会提示如下错误：# Cannot connect to the Docker daemon at unix:///var/run/docker.sock.# 配置Windows Docker服务地址 （Settings =&gt; General =&gt; Expose daemon on tcp://localhost:2375 without TLS）echo &quot;export DOCKER_HOST=localhost:2375&quot; &gt;&gt; ~/.bashrc # 使配置生效. ~/.bashrc powershell其他操作使用管理员模式，打开PowerShell12345启动停止 wsl 服务# 停止子系统服务net stop LxssManager# 启动子系统服务net start LxssManager 备份恢复，导出、导入子系统1234# d:\Ubuntu-18.04.tar 导出文件路径wsl --export Ubuntu-18.04 d:\Ubuntu-18.04.tar# d:\wsl\u18.04 子系统导入后的安装路径wsl --import Ubuntu-18.04 d:\wsl\u18.04 d:\Ubuntu-18.04.tar]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[docker简介]]></title>
    <url>%2Fdocker%2Freadme%2F</url>
    <content type="text"><![CDATA[dockerLinux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口 Docker 将应用程序与该程序的依赖，打包在一个文件(image)里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样. 容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例 容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。 Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版） docker 用途 简化环境搭建 简化运维工作量 微服务利器 docker 安装uname -r 内核版本大于 3.10 12345678910111213141516171819202122# 先进行卸载sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine \ docker-cecurl https://get.docker.com &gt; /tmp/install.shchmod +x /tmp/install.sh/tmp/install.sh# curl -sSL https://get.daocloud.io/docker | sh # 国内可以这样安装sudo usermod -aG docker $USER # 避免每次都输入 sudo,将用户加入 docker 用户组service docker restartservice docker statussystemctl enable docker # 开机自启docker info # 获取docker信息docker --help # docker 帮助文档 快速确认docker version 换源cd /etc/docker 目录下找到在daemon.json文件（没有就新建），将下面内容写入(阿里云)123456tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://1hdirfy9.mirror.aliyuncs.com&quot;], &quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]&#125;EOF 重启daemonsystemctl daemon-reload 重启docker服务systemctl restart docker 第一个镜像123docker pull [Registry]/[Respository]/[images]:[tag] # 获取镜像操作docker pull debian # 获取官方仓库下的 debian：latestdocker run debian echo &quot;hello world&quot; docker run : 启动容器 debian : 使用的镜像名称 （本地如果没有镜像，就在docker hub 进行搜素，并下载最新版） echo “hello world” : 执行的命令 12docker run -i -t debian /bin/bash docker run -i -t debian # 也可以不加 /bin/bash -i -t : 附有一个 tty 的交互会话 -i 支持stdin , -t 终端或伪终端 /bin/bash : 获得一个 bash shell 退出 shell, 容器就会停止, Ctrl+ P + Q 退出而不停止 容器生命周期 123456789101112131415161718192021docker run --name weilai -h docker -it debian /bin/bash # -h 指定hostname --name 指定docker namedocker inspect weilai # 获取 weilai 容器的更多信息docker stats weilai # 查看容器 weilai 资源使用状态docker run --name nginx -m 1024M --cpus=0.2 -d nginx # 启动限制资源容器doker diff weilai # 查看 weilai 文件的更改docker logs weilai # weilai 容器日志记录docker ps # 正在运行的 docker 容器docker ps -a # 列出所有容器docker ps -n 2 # 显示最近创建的2个容器docker ps -f status=exited # 查看停止的容器docker start weilai # 启动已有容器 docker run 是启动一个新的实例 docker attach weilai # 切换到运行交互式容器，阻塞式 一般推荐使用 exec docker exec -it weilai # 切换到运行交互式容器，阻塞式 一般推荐使用 exec docker cp weilai:/tmp /home # 拷贝容器下的/tmp文件夹 到宿主机下的 /home 目录下docker cp /home/test.sh weilai:/tmp/weuilai.sh # 宿主机下的 /home 目录的 tets.sh 到容器下的/tmp文件夹 并改名为weilai.shdocker exec weilai ls -l # 进入容器 执行 ls -l 并回到宿主机，显示结果docker start weilai # 查看容器进程docker stop weilai # 停止容器docker kill weilai # 强制停止（不建议）docker rm weilai # 删除容器docker rmi -f debian # 删除 debian -f 强制删除 docker run ：创建和启动一个新的容器实例，操作对象是镜像，选项较多，如果你要创建和启动一个容器，只能用run；docker exec: 在已运行的容器中，执行命令，操作对象是容器，如果你要进入已运行的容器，并且执行命令，用exec；docker attach: 同样操作的是已运行的容器，可以将本机标准输入（键盘输入）输到容器中，也可以将容器的输出显示在本机的屏幕上，如果你想查看容器运行过程中产生的标准输入输出，用attach； docker 镜像docker images : 列出本机所有镜像123docker images -qa # -a 显示所有镜像（含中间层） -q 只显示镜像iddocker images --digests # 显示镜像的摘要信息docker images --no-trunc # 显示完整的镜像信息 docker search redis : 搜索 redis 镜像docker pull redis:latest : 拉取 redis:latest 镜像 (TAG 默认为 latest 删除多个镜像：docker rmi -f 镜像名称1:[TAG] 镜像名称2:[TAG]中间空格隔开 删除全部镜像：docker rmi -f $(docker images -qa) 同样的 强制删除 docker rm -f 容器ID或name 删除多个容器docker rm -f 容器ID1 容器ID2 删除所有容器 docker rm -f $(docker ps -qa) 容器目录挂载创建容器的时候，将宿主机的目录与容器内的目录进行映射，实现宿主机和容器目录的双向数据自动同步； 相比前面的 cp 更加简单方便 语法docker run -it -v /宿主机目录:/容器目录 镜像名 多目录挂载docker run -it -v /宿主机目录:/容器目录 -v /宿主机目录2:/容器目录2 镜像名 挂载目录制度docker run -it -v /宿主机目录:/容器目录:ro 镜像名 例如安装redis12$ mkdir -p /opt/data/redis$ docker run -p 6379:6379 --name myredis -v /opt/data/redis/redis.conf:/etc/redis/redis.conf -v /opt/data/redis:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes --requirepass &quot;passwd&quot; 注意同步多级目录，可能会出现权限不足的提示；这是因为selinux把权限禁掉了，我们需要添加 –privileged=true 来解决挂载的目录没有权限的问题； docker 网络模式docker 默认使用的是 bridge桥接网络模式 12345# docker network lsNETWORK ID NAME DRIVER SCOPEd2a8ca970a9c bridge bridge locale379fa1c8774 host host local3dfff078ede1 none null local 自定义网络模式 12345678910111213141516171819202122# docker network create --subnet=172.20.0.0/16 extnetworka2c75e5e49ea2bf16380befd73ac19be54e271f4ad1e39549c47290d1b9fa7f3# ifconfigbr-a2c75e5e49ea: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 172.20.0.1 netmask 255.255.0.0 broadcast 172.20.255.255 ether 02:42:43:82:72:6e txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:d5ff:fe34:51d4 prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:d5:34:51:d4 txqueuelen 0 (Ethernet) RX packets 10771 bytes 601704 (587.6 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 10230 bytes 51101359 (48.7 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0......... 创建容器并指定ip --net extnetwork --ip 172.20.0.2 extnetwork 上文指定172.20.0.1 是网关,所以从2 分配 12345678910# docker run -p 8066:8066 -it --net extnetwork --ip 172.20.0.2 debianroot@b4246dddf9f5:/#ip address1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever17: eth0@if18: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:14:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.20.0.2/16 brd 172.20.255.255 scope global eth0 valid_lft forever preferred_lft forever 也可以用 docker inspect 容器id 查看信息 12345678910# docker inspect b4246dddf9f5.... &quot;NetworkID&quot;: &quot;a2c75e5e49ea2bf16380befd73ac19be54e271f4ad1e39549c47290d1b9fa7f3&quot;, &quot;EndpointID&quot;: &quot;efa3cd2ed24010ba37bcf7183fba6cce7bc89f9327375f1148db1a6888005d6f&quot;, &quot;Gateway&quot;: &quot;172.20.0.1&quot;, &quot;IPAddress&quot;: &quot;172.20.0.2&quot;, &quot;IPPrefixLen&quot;: 16, &quot;IPv6Gateway&quot;: &quot;&quot;,.... 删除网络docker network rm extnetwork 限制cpu 内存等 容器的监控原理其实就是定时读取 Linux 主机上相关的文件并展示给用户。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576root@test:~# docker run --name nginx -m 200M --cpus=0.2 -d nginxWARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.1c8999af3a3654cb9e053795198f0d1c377fc1080173213a6fdd2179123bcf00root@test:~# ls -l /sys/fs/cgroup/memory/dockertotal 0drwxr-xr-x 2 root root 0 Oct 23 16:31 1c8999af3a3654cb9e053795198f0d1c377fc1080173213a6fdd2179123bcf00-rw-r--r-- 1 root root 0 Oct 23 16:31 cgroup.clone_children--w--w--w- 1 root root 0 Oct 23 16:31 cgroup.event_control-rw-r--r-- 1 root root 0 Oct 23 16:31 cgroup.procs-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.failcnt--w------- 1 root root 0 Oct 23 16:31 memory.force_empty-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.failcnt-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.limit_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.max_usage_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.slabinfo-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.tcp.failcnt-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.tcp.limit_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.tcp.max_usage_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.tcp.usage_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.usage_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.limit_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.max_usage_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.move_charge_at_immigrate-r--r--r-- 1 root root 0 Oct 23 16:31 memory.numa_stat-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.oom_control---------- 1 root root 0 Oct 23 16:31 memory.pressure_level-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.soft_limit_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:31 memory.stat-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.swappiness-r--r--r-- 1 root root 0 Oct 23 16:31 memory.usage_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.use_hierarchy-rw-r--r-- 1 root root 0 Oct 23 16:31 notify_on_release-rw-r--r-- 1 root root 0 Oct 23 16:31 tasksroot@test:~# ls -l /sys/fs/cgroup/memory/docker/1c8999af3a3654cb9e053795198f0d1c377fc1080173213a6fdd2179123bcf00total 0-rw-r--r-- 1 root root 0 Oct 23 16:32 cgroup.clone_children--w--w--w- 1 root root 0 Oct 23 16:31 cgroup.event_control-rw-r--r-- 1 root root 0 Oct 23 16:31 cgroup.procs-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.failcnt--w------- 1 root root 0 Oct 23 16:32 memory.force_empty-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.failcnt-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.kmem.limit_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.max_usage_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.slabinfo-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.tcp.failcnt-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.tcp.limit_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.tcp.max_usage_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.tcp.usage_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:32 memory.kmem.usage_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.limit_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.max_usage_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.move_charge_at_immigrate-r--r--r-- 1 root root 0 Oct 23 16:32 memory.numa_stat-rw-r--r-- 1 root root 0 Oct 23 16:31 memory.oom_control---------- 1 root root 0 Oct 23 16:32 memory.pressure_level-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.soft_limit_in_bytes-r--r--r-- 1 root root 0 Oct 23 16:32 memory.stat-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.swappiness-r--r--r-- 1 root root 0 Oct 23 16:32 memory.usage_in_bytes-rw-r--r-- 1 root root 0 Oct 23 16:32 memory.use_hierarchy-rw-r--r-- 1 root root 0 Oct 23 16:32 notify_on_release-rw-r--r-- 1 root root 0 Oct 23 16:32 tasksroot@test:~# cat /sys/fs/cgroup/memory/docker/1c8999af3a3654cb9e053795198f0d1c377fc1080173213a6fdd2179123bcf00/memory.limit_in_bytes209715200 # 200M = 200 * 1024 * 1024 B = 209715200 Bmemory.usage_in_bytes # 使用值root@test:~# docker inspect nginx |grep Pid # 查看网络情况 &quot;Pid&quot;: 7641, &quot;PidMode&quot;: &quot;&quot;, &quot;PidsLimit&quot;: null,root@test:~# cat /proc/7641/net/devInter-| Receive | Transmit face |bytes packets errs drop fifo frame compressed multicast|bytes packets errs drop fifo colls carrier compressed lo: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 eth0: 1186 15 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[指针]]></title>
    <url>%2Fgolang%2F%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[变量是一种使用方便的占位符，用于引用计算机内存地址。 Go 语言的取地址符是 &amp;，放到一个变量前使用就会返回相应变量的内存地址 123456789package mainimport &quot;fmt&quot;func main() &#123; var a int = 10 fmt.Printf(&quot;变量的地址: %x\n&quot;, &amp;a )&#125; 指针声明 : var var_name *var-type eg: var fp *float32 123456789101112131415161718package mainimport &quot;fmt&quot;func main() &#123; var a int= 20 /* 声明实际变量 */ var ip *int /* 声明指针变量 */ ip = &amp;a /* 指针变量的存储地址 */ fmt.Printf(&quot;a 变量的地址是: %x\n&quot;, &amp;a ) /* 指针变量的存储地址 */ fmt.Printf(&quot;ip 变量的存储地址: %x\n&quot;, ip ) /* 使用指针访问值 */ fmt.Printf(&quot;*ip 变量的值: %d\n&quot;, *ip )&#125; 空指针 :当一个指针被定义后没有分配到任何变量时，它的值为 nil123456789package mainimport &quot;fmt&quot;func main() &#123; var ptr *int var ptr1 * fmt.Printf(&quot;ptr 的值为 : %x\n&quot;, ptr ) /* 0 */&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python 浅拷贝与深拷贝]]></title>
    <url>%2Fpython%2FDesignPattern%2F%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2Fpython%E4%B8%AD%E7%9A%84%E6%B5%85%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B7%B1%E6%8B%B7%E8%B4%9D%E7%9A%84%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[python 浅拷贝与深拷贝python的引用计数 int float str tuple 为不可变对象 list dict set 为可变对象 python 内不可变对象的内存管理方式是引用计数，python 不会对值相同的不可变对象，申请单独的内存空间。只会记录它的引用次数。12345678910import copya = &apos;weilai&apos;b = ac = copy.copy(a)if id(a) == id(b) == id(c): print(f&apos;all id is &#123;id(a)&#125;&apos;)else: print(f&apos;id(a) is &#123;id(a)&#125;&apos;) print(f&apos;id(b) is &#123;id(b)&#125;&apos;) print(f&apos;id(c) is &#123;id(c)&#125;&apos;) 浅拷贝浅拷贝会创建一个新的对象，对于对象中的元素，他依然会引用原来的物体123456789101112131415import copy a = [&apos;weilai&apos;, &apos;handsome&apos;]b = ac = copy.copy(a)if id(a) == id(b) == id(c): print(f&apos;all id is &#123;id(a)&#125;&apos;)else: print(f&apos;id(a) is &#123;id(a)&#125;&apos;) print(f&apos;id(b) is &#123;id(b)&#125;&apos;) print(f&apos;id(c) is &#123;id(c)&#125;&apos;) # c创建了一个新对象，指向原来的 aa.append(&apos;cool&apos;)print(a)print(b)print(c) # c 还是[&apos;weilai&apos;, &apos;handsome&apos;] 由于浅拷贝会使用原始元素的引用（内存地址），所以在操作对象内部的可变元素时，其结果是会影响到拷贝对象的 123456789import copy a = [[1, 2, 3], 3, 4]b = ac = copy.copy(a) # [[1, 2, 3], 3, 4]a[0][0] = &apos;a&apos; a[1] = &apos;b&apos;print(a) # [[&apos;a&apos;, 2, 3], &apos;b&apos;, 4]print(b) # [[&apos;a&apos;, 2, 3], &apos;b&apos;, 4]print(c) # [[&apos;a&apos;, 2, 3], 3, 4] 深拷贝**深拷贝遇到可变对象，则又会进行一层对象的创建，操作被考对象内部的可变对象，不影响拷贝对象内部的值。123456789import copy a = [[1, 2, 3], 3, 4]b = ac = copy.deepcopy(a) # [[1, 2, 3], 3, 4]a[0][0] = &apos;a&apos; a[1] = &apos;b&apos;print(a) # [[&apos;a&apos;, 2, 3], &apos;b&apos;, 4]print(b) # [[&apos;a&apos;, 2, 3], &apos;b&apos;, 4]print(c) # [[1, 2, 3], 3, 4] 总结python变量实际上是指向相关值在内存中存储位置的指针 。 深浅拷贝都是对源对象的复制，占用不同的内存空间 如果源对象只有一级目录的话，源对象做任何改动，不影响深浅拷贝对象 如果源对象不止一级目录的话，源对象做任何改动，都要影响浅拷贝，但不影响深拷贝 序列对象的切片其实是浅拷贝，即只拷贝顶级的对象]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[适配器模式]]></title>
    <url>%2Fpython%2FDesignPattern%2F%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2Freadme%2F</url>
    <content type="text"><![CDATA[适配器模式具有以下要素： 目标 –定义客户端所使用的特定于 领域的接口 客户端 – 使用遵从于 目标接口的对象 适配者类 –由于对象不遵从目标而必须修改的接口 适配器 – 将适配者类中所具有的接口 修改为我们想要在客户端中 使用的接口的代码 1.定义我们希望适应的组成部分是什么2.识别出客户端需要的接口3.设计和实现适配器以便将客户端所需的接口映射到适配者类所提供的接口 客户端从适配者类中解耦出来并且被耦合到接口，这样实现了可扩展性和可维护性 不要重复自己 面向接口 而非 面向现实进行编程 支持对象组合，而非继承 关注点分离将系统分割为 单独单元 并让每个单元尤其自己的关注点。单元彼此越独立，系统的维护和扩展也会变的越容易。 1234567class ObjectAdapter(object): def __init__(self, what_i_have, provided_function): self.what_i_have = what_i_have self.required_function = provided_function def __getattr__(self, attr): return getatrr(self.what_i_have, attr)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[工厂模式]]></title>
    <url>%2Fpython%2FDesignPattern%2F%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2Freadme%2F</url>
    <content type="text"><![CDATA[当希望通过一个通用接口来创建对象，而不是让创建代码分散在整个系统中 创建一个集中式的系统来进行对象创建的一种方式就是使用工厂模式 原型模式不需要子类化，不过需要一个初始化操作，而工厂模式需要子类化，但不需要初始化 工厂模式一个简单的实现原始代码123456789101112131415161718192021222324import pygamewindows_dimensions = 800,600screen = pygame.display.set_mode(windows_dimensions)x,y = 100, 100player_quits = Falsewhile not player_quits: for event in pygame.event.get(): if event.type == pygame.QUIT: player_quits = True pressed = pygame.key.get_pressed() if pressed[pygame.K_UP]: y -=4 if pressed[pygame.K_DOWN]: y += 4 if pressed[pygame.K_LEFT]: x -= 4 if pressed[pygame.K_RIGHT]: x += 4 screen.fill((0, 0, 0)) pygame.draw.rect(screen,(255, 255, 0 ), pygame.Rect(x, y, 20, 20)) pygame.display.flip() 改写，方便扩展 shape_factory.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import pygameimport time# pygame.init()class Shape(): def __init__(self,x ,y): self.x = x self.y = y def draw(self): raise NotImplementedError() def move(self, direction): if direction == &apos;up&apos;: self.y -= 4 if direction == &apos;down&apos;: self.y += 4 if direction == &apos;left&apos;: self.x -= 4 if direction == &apos;right&apos;: self.x += 4 @staticmethod def factory(type): # 工厂模式,可在这里加type类型 if type == &apos;Circle&apos;: return Circle(100, 100) if type == &apos;Square&apos;: return Square(100, 100) assert 0, &apos;Bad shape requested: &apos; + typeclass Square(Shape): def draw(self): pygame.draw.rect(screen,(255, 255, 0 ), pygame.Rect(self.x, self.y, 20, 20))class Circle(Shape): def draw(self): pygame.draw.circle(screen, (0, 255, 255), (self.x, self.y),10)if __name__ == &apos;__main__&apos;: windows_dimensions = 800,600 screen = pygame.display.set_mode(windows_dimensions) obj = Shape.factory(&apos;Circle&apos;) player_quits = False while not player_quits: for event in pygame.event.get(): if event.type == pygame.QUIT: player_quits = True pressed = pygame.key.get_pressed() if pressed[pygame.K_UP]: obj.move(&apos;up&apos;) if pressed[pygame.K_DOWN]: obj.move(&apos;down&apos;) if pressed[pygame.K_LEFT]: obj.move(&apos;left&apos;) if pressed[pygame.K_RIGHT]: obj.move(&apos;right&apos;) screen.fill((0, 0, 0)) obj.draw() pygame.display.flip() 抽象工厂当希望创建单个接口来访问整个工厂集合时，可以使用一个抽象工厂12345678910111213141516171819202122232425262728import abcclass AbstractFactory(): # 抽象工厂会定义这些具体工厂的结构，之后这些具体工厂会创建本例中的原型和正方形 __metaclass__ = abc.ABCMeta @abc.abstractmethod def make_object(self): returnclass CircleFactory(AbstractFactory): def make_object(self): # do something return Circle()class SquareFactory(AbstractFactory): def make_object(self): # do something return Square()def draw_function(factory): drawable = factory.make_object() drawable.draw()def prepare_client(): squareFactory = SquareFactory() draw_function(squareFactory) circleFactory = CircleFactory() draw_function(circleFactory)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[go简介]]></title>
    <url>%2Fgolang%2Freadme%2F</url>
    <content type="text"><![CDATA[简介GO 语言特点 运行效率高，开发高效，部署简单 （可直接编译成机器码，不依赖其他库，glibc的版本有一定要求，部署就是扔一个文件上去就完成了） 语言层面支持并发，易于利用多核实现并发 （最大特点） 内置runtime（作用：性能监控，GC等），支持垃圾回收 丰富标准库，强大网络库 内置强大的工具（gofmt）,跨平台编译，内嵌C支持 GO 语言的应用 服务器编程，以前你如果使用C或者C++做的那些事情，用Go来做很合适，例如处理日志、数据打包、虚拟机处理、文件系统等。 分布式系统，数据库代理器等 网络编程，这一块目前应用最广，包括Web应用、API应用、下载应用、 内存数据库，前一段时间google开发的groupcache，couchbase的部分组建 云平台，目前国外很多云平台在采用Go开发，CloudFoundy的部分组建，前VMare的技术总监自己出来搞的apcera云平台。 GO 语言命令行工具 go build 用于编译源码文件，代码包，依赖包; go run 可以编译并运行Go源码文件 go get 主要用来动态获取远程代码包]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[规范]]></title>
    <url>%2Fgolang%2F%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[变量声明，初始化，赋值 同一行声明多个变量并赋值： var a,b,c int =1,2,3 或者 d,e := 4,5 全局变量声明必须使用var关键字,局部变量可以省略（a,b,c int =1,2,3） 变量 _ 表示丢弃变量类型转换 类型转换必须是显示的，不存在隐式转换 只发生在兼容类型之间 &lt;变量名称&gt; [:]= &lt;目标类型&gt;(&lt;需要转换的变量&gt;)123456789101112131415package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func main()&#123; var a float32 = 3.1 c := int(a) fmt.Println(c) fmt.Println(reflect.TypeOf(c)) &#125; 变量可见性规则 大写字母开头的变量可导出，其他包可以读取，是共有变量 小写字母开头的变量不可导出，是私有变量 常量常量定义形式常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型 显示 const identifier [type] = value 隐式 const identifier = value (通常叫做 无类型常量) 常量可以使用 内置表达式定义 eg: len(),unsafe.Size0f()等 特殊常量 iota iota 在 const 关键字出现时被重置为 0 const 中每新增一行常量声明 iota 就计数一次 iota 只能在常量中使用 iota 常见使用法： 跳值使用法 插队使用法 表达式隐式使用法 单行使用法]]></content>
      <categories>
        <category>golang</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[建造者模式]]></title>
    <url>%2Fpython%2FDesignPattern%2F%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%2Freadme%2F</url>
    <content type="text"><![CDATA[建造者模式，将复杂对象的构造从其表示形式中分离了出来，因此可用相同的构造过程来创建不同形式的表单。 其最大的缺点在于，我们要为希望创建的每一种产品类型创建ConcreteBuilder建造者 原始代码12345678910111213141516def generator_webform(text_field_list=[],checkbox_field_list=[]): generator_fields = &quot;\n&quot;.join(map(lambda x:&apos;&#123;0&#125;：&lt;br&gt; &lt;input type=&quot;text&quot; name=&quot;&#123;0&#125;&quot;&gt; &lt;br&gt;&apos;.format(x),text_field_list)) generator_fields += &quot;\n&quot;.join(map(lambda x:&apos;&lt;label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;&#123;0&#125;&quot; value=&#123;0&#125;&gt;&#123;0&#125; &lt;br&gt;&apos;.format(x),checkbox_field_list)) return &quot;&lt;form&gt;&#123;fields&#125;&lt;/form&gt;&quot;.format(fields=generator_fields)def build_html_form(text_field_list=[],checkbox_field_list=[]): with open(&apos;form_file.html&apos;,&apos;w&apos;) as f : f.write(&apos;&lt;html&gt;&lt;body&gt;&#123;&#125;&lt;/body&gt;&lt;/html&gt;&apos;.format(generator_webform(text_field_list=text_fields,checkbox_field_list=checkbox_fields)))if __name__ == &quot;__main__&quot;: text_fields = [&quot;name&quot;,&quot;age&quot;,&quot;email&quot;,&quot;telephone&quot;] checkbox_fields = [&apos;awesome&apos; , &apos;bad&apos;] print(generator_webform(text_field_list=text_fields,checkbox_field_list=checkbox_fields)) build_html_form(text_field_list=text_fields,checkbox_field_list=checkbox_fields) 改造后123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107from abc import ABCMeta, abstractmethodclass Director(object, metaclass=ABCMeta): def __init__(self): self._builder =None def set_build(self, builder): self._builder = builder @abstractmethod def construct(self, field_list): pass def get_constructed_object(self): return self._builder.constructed_objectclass AbstractFormBuilder(object,metaclass=ABCMeta): def __init__(self): self.constructed_object = None @abstractmethod # 定义一个抽象基类 def add_checkbox(self, checkbox_dict): pass @abstractmethod def add_text_field_dict(self,field_dict): pass @abstractmethod def add_button(self, button_dict): passclass HtmlForm(object): def __init__(self): self.field_list = [] def __repr__(self): return &apos;&lt;form&gt;&#123;&#125;&lt;/form&gt;&apos;.format(&apos;&apos;.join(self.field_list))class HtmlFormBuilder(AbstractFormBuilder): def __init__(self): self.constructed_object =HtmlForm() def add_text_field(self, field_dict): self.constructed_object.filed_list.append( &apos;&#123;0&#125;:&lt;br&gt;&lt;input type=&quot;text&quot; name=&quot;&#123;1&#125;&quot;&gt;&lt;br&gt;&apos;.format(field_dict[&apos;label&apos;], field_dict[&apos;field_name&apos;])) def add_checkbox(self, checkbox_dict): self.constructed_object.filed_list.append( &apos;&lt;label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;&#123;0&#125;&quot; value = &quot;&#123;1&#125;&quot;&gt; &#123;2&#125;&lt;br&gt;&apos;.format(&apos;field_id&apos;, checkbox_dict[&apos;value&apos;], checkbox_dict[&apos;label&apos;])) def add_button(self, button_dict): self.constructed_object.filed_list.append( &apos;&lt;button type=&quot;button&quot;&gt; &#123;&#125; &lt;/button&gt;&apos;.format(button_dict[&apos;text&apos;]))class FormDirector(Director): def __init__(self): Director.__init__(self) def construct(self, field_list): for field in field_list: if field[&quot;field_type&quot;] == &apos;text_field&apos;: self._builder.add_text_field(field) elif field[&quot;field_type&quot;] == &apos;checkbox&apos;: self._builder.add_check(field) elif field[&quot;field_type&quot;] == &apos;button&apos;: self._builder.add_button(field)if __name__ == &apos;__main__&apos;: director = FormDirector() html_form_builder = HtmlFormBuilder() director.set_build(html_form_builder) field_list = [ &#123; &apos;field_type&apos; : &apos;text_field&apos;, &apos;label&apos; : &apos;Best text you have ever writen&apos;, &apos;field_name&apos; : &apos;Field One&apos; &#125;, &#123; &apos;field_type&apos;: &apos;checkbox&apos;, &apos;field_id&apos; : &apos;check_it&apos;, &apos;label&apos;: &apos;check for on&apos;, &apos;value&apos;: &apos;1&apos; &#125;, &#123; &apos;field_type&apos;: &apos;text_field&apos;, &apos;label&apos;: &apos;another text you have ever writen&apos;, &apos;field_name&apos;: &apos;Field One&apos; &#125;, &#123; &apos;field_type&apos; : &apos;button&apos;, &apos;text&apos; : &apos;Done&apos; &#125; ] director.construct(field_list) with open(&apos;form_file.html&apos;, &apos;w&apos;) as f: f.write( &apos;&lt;html&gt;&lt;body&gt;&#123;0!r&#125;&lt;/body&gt;&lt;/html&gt;&apos;.format( director.get_constructed_object() ) )]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[原型模式]]></title>
    <url>%2Fpython%2FDesignPattern%2F%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2Freadme%2F</url>
    <content type="text"><![CDATA[在原型模式中，优先使用组合而非继承。组成的类使我们可以在运行时替换那些组成部分，从而彻底改善系统的可测试性和可维护性。 原型模式在一般情况下的样子声明一个抽象基类 prototype_1.py123456from abc import ABCMeta, abstractmethodclass Prototype(metaclass=ABCMeta): @abstractmethod def clone(self): pass 调用 concrete.py123456from prototype_1 import Prototypefrom copy import deepcopyclass Concrete(Prototype): def clone(self): return deepcopy(self) **扩展该抽象基类时，会强制实现clone方法。]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[迭代对象，迭代器，生成器]]></title>
    <url>%2Fpython%2F%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1%EF%BC%8C%E8%BF%AD%E4%BB%A3%E5%99%A8%EF%BC%8C%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[容器容器是一种把多个元素组织在一起的数据结构，容器中的元素可以逐个地迭代获取，可以用 in , not in 关键字判断元素是否包含在容器中 assert 如果为Fasle, 那么raise一个AssertionError123assert False, &apos;error&apos;assert True, &apos;error&apos;assert 1 in [1, 2, 3, 4],&apos;error&apos; 大多数容器提供了某种方式来获取其中每一个元素,（是可迭代对象赋予了容器这种能力） 可迭代对象 （iterable）凡是可以返回一个迭代器的对象都可以称之为可迭代对象 可迭代对象实现了 iter (返回可迭代对象本身) 和 next 方法，123456789101112x = [1, 2, 3] # 列表，可迭代对象y = iter(x)z = iter(x) # 两个不同的迭代器next(y) next(y)next(z)type(x) # list 可迭代对象type(y) # list_iterator 具体的迭代类型a = &apos;hahaha&apos;b = iter(a)type(b) # str_iterator 迭代器 (iterator)迭代器是一个带状态的对象，能在调用 next() 方法时返回容器的下一个值. 迭代器等有人需要的时候才生成值返回， 没调用的时候， 就处于休眠状态等待下一次调用。 生成器（generator）相比其他容器对象，它更能节省内存和cpu。 12sum(i for i in range(100_000_000)) # 生成器sum[i for i in range(100_000_000)] # 列表推导式 生成器是一种特殊的迭代器，只需要yield关键字。生成器一定是迭代器（反之不成立）。 12345def someting(): result = [] for x in ..: result.append(x) return result 都可以改写123def iter_something(): for x in ..: yield x 生成器表达式（generator expression）列表推导式的生成器版本，但他返回的是一个生成器对象，而不是列表对象1a = (x * x for x in range(10)) 生成器只能遍历一次 附判断 a 是不是 b 的子序列 123456def is_subsequence(a, b): b = iter(b) return all(i in b for i in a) print(is_subsequence([1, 3, 5], [1, 2, 3, 4, 5])) # True print(is_subsequence([1, 4, 3], [1, 2, 3, 4, 5])) # False]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[网络请求]]></title>
    <url>%2Fpython%2F%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[url 与 ipip : Internet Protocol 如果 ‘域名-ip’ 已被记录，则直接访问目标ip浏览器缓存，系统缓存，路由缓存 没有被记录，则 依靠 DNSDNS : Domain Name System 是一个将域名和 IP 相互映射的分布式数据库。 网卡上，有 ‘DNS 服务器’ 配置项 DNS 劫持访问 A 结果 访问了 B DNS 投毒(污染)从客户端 向 DNS 服务器发出 查询IP 的请求，到响应 返回到客户端 的这段时间，被伪造返回来一个 错误的DNS应答，那么访问不到真正的资源 DNS 正常解析返回正常的 ip 地址]]></content>
      <categories>
        <category>flask</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[多线程的鸡肋]]></title>
    <url>%2Fpython%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E9%B8%A1%E8%82%8B%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536from contextlib import contextmanagerimport time## 因为GIL锁的原因，多线程并没有多少用## 不适合计算密集型@contextmanagerdef _cost_time(): start_time = time.time() print(&apos;start time : &apos; + time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())) yield end_time = time.time() seconds = end_time - start_time m, s = divmod(seconds, 60) h, m = divmod(m, 60) print(&apos;end time : &apos; + time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())) print(&apos;time cost %d:%02d:%02d &apos; % (h, m, s))def decrement(n): while n &gt; 0: n -= 1# Single threadwith _cost_time(): decrement(100000000)#import threadingwith _cost_time(): t1 = threading.Thread(target=decrement,args=[50000000]) t2 = threading.Thread(target=decrement,args=[50000000]) t1.start() t2.start() t1.join() t2.join() 修改一下123456789101112131415161718192021222324252627282930313233343536import time## 因为GIL锁的原因，多线程并没有多少用## 不适合计算密集型def _cost_time(func): def warpper(*args,**kw): start_time = time.time() print(&apos;start time : &apos; + time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())) func(*args,**kw) end_time = time.time() seconds = end_time - start_time m, s = divmod(seconds, 60) h, m = divmod(m, 60) print(&apos;end time : &apos; + time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime())) print(&apos;time cost %d:%02d:%02d &apos; % (h, m, s)) return warpper@_cost_timedef decrement(n): while n &gt; 0: n -= 1# Single threaddecrement(100000000)# Multithreadingimport threadingt1 = threading.Thread(target=decrement,args=[50000000])t2 = threading.Thread(target=decrement,args=[50000000])t1.start()t2.start()t1.join()t2.join()]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[优雅的python写法]]></title>
    <url>%2Fpython%2F%E4%BC%98%E9%9B%85%E7%9A%84python%E5%86%99%E6%B3%95%2F</url>
    <content type="text"><![CDATA[学习python cook book 有感1. 交换变量1a, b = b, a 2. 循环遍历区间12345for i in range(6): print (i)``` ## 3. 带有索引位置的集合遍历 for i, color in enumerate(colors): print (i ,colors[i])12## 4. 字符串拼接 print ‘. ‘ .join(names)‘’’join 方法全程只会产生一个字符串对象，而每执行一次 + 操作，就会在内存中生成一个新的字符串对象‘’’123现在已经可以直接使用加号，不会影响效率。（不要被落后的经验给拖累了）## 5. 打开/关闭文件 with open (‘xxx.xxx’,’r’) as f: data = f.read()12## 6. 列表推导式 [i for i in range(10)]12## 7. 善用装饰器 ‘’’装饰器可以吧与业务逻辑无关的代码抽离出来，让代码保持干净清爽，且能多次利用url 曾使用过直接从cache读出，没有的话存到saved中‘’’import urllib.request as urllib def cache(func): saved = {} def wrapper(url): if url in saved: return saved[url] else: page = func(url) saved[url] = page return page return wrapper @cachedef web_lookup(url): return urllib.urlopen(url).read()12## 8. 合理使用列表 ‘’’list是一个查询效率高于更新操作的数据结构,删除/插入 一个元素 执行的效率较低，因为还要对剩下的元素进行移动‘’’from collections import dequenames = deque([1, 2, 3, 4, ‘haha’])names.popleft()names.appendleft(‘mark’) ‘’’deque 是一个双向队列的数据结构，删除元素和插入元素会很快‘’’12## 9. 序列解包 p = ‘1’ , ‘2’ , ‘3’ , 4a, b, c, d, = p12## 10. 遍历字典的 key 和 value dict ={1:’haha’,2:’xixi’}for key, value in dict.items(): print(key ,’ + ‘, value)‘’’dict.items 返回迭代器对象，可节省更多的内存‘’’12## 11. 链式比较操作 age = 18if 18 &lt; age &lt; 60: print(‘young man’) False == True == True == True False12## 12. if/else text = ‘男’ if gender == ‘male’ else ‘女’12## 13. True/Fales 值判断 if a: do_someting()if b: do_someting()‘’’a,b 的值有就是True, 没有就是False‘’’12## 14. 字符串格式化 a,b = ‘haha’, [1,2,3]s = f’str is {a}, list is {b}’‘’’不支持python2‘’’12## 15. 列表切片 items = range(10)sub_items = items[1:4] # 取第1号到第4号元素odd_items = items[1::2] # 第1号到最后面，步长为2 （奇数）copy_items = items[::] # 或者 items[:]12## 16. 善用生成器 def fib(n): a, b = 0, 1 while a &lt; n: yeild a a ,b = b, a + b‘’’生成器的好处是无需一次性把所有元素加载到内存，只有迭代获取元素时才返回该元素，而列表是预先一次性把全部元素加载到内存中遇到 yield 会暂停执行另一个函数‘’’12# 17. 获取字典元素 d = {‘name’:’foo’}d.get(‘name’,’unknow’)d.get(‘age’,’unknow’)12# 18. 预设字典默认值 groups = {}for (key, value) in data: groups.setdefault(key, []).append(value) from collections import defaultdictgroups = defaultdict(list)for (key, value) in data: groups[key].append(value)12## 19 字典/列表/集合 推导式 numbers = [1, 2, 3, 4]my_dict = {number: number*2 for number in numbers}print(my_dict)123456## 20. for/else&apos;&apos;&apos;python 特有的语法格式，else中的代码在for 循环完所有元素成后执行&apos;&apos;&apos; flagfound = Falsemylist = [1, 2, 3, ‘theflag’, 4, 5, 6]for i in mylist: if i == ‘theflag’: flagfound = True break print(i)else: raisd ValueError(‘list argument missing terminal flag’)1234## 21 一些特性### 给数字加\_分组并不影响实际 a = 11_22_33_44error = 0xbad_c0ffee12### 将类型注释添加到函数和方法中 def my_add(a:str,b:int) -&gt; str: return a + bmy_add(1,2) 12### 直接操作数字 PI =3.141592653f’PI is {PI:.4f}’`]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python列表操作]]></title>
    <url>%2Fpython%2Fpython%E5%88%97%E8%A1%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[1、迭代列表，如何访问列表下标索引普通版：12345678items = [8, 23, 45]for index in range(len(items)): print(index, &quot;--&gt;&quot;, items[index])&gt;&gt;&gt;0 --&gt; 81 --&gt; 232 --&gt; 45 优雅版：1234567for index, item in enumerate(items): print(index, &quot;--&gt;&quot;, item)&gt;&gt;&gt;0 --&gt; 81 --&gt; 232 --&gt; 45 enumerate 还可以指定元素的第一个元素从几开始，默认是0，也可以指定从1开始：1234567for index, item in enumerate(items, start=1): print(index, &quot;--&gt;&quot;, item)&gt;&gt;&gt;1 --&gt; 82 --&gt; 233 --&gt; 45 2、append 与 extend 方法有什么区别append表示把某个数据当做新元素追加到列表的最后面，它的参数可以是任意对象1234567x = [1, 2, 3]y = [4, 5]x.append(y)print(x)&gt;&gt;&gt;[1, 2, 3, [4, 5]] extend 的参数必须是一个可迭代对象，表示把该对象里面的所有元素逐个地追加到列表的后面1234567891011x = [1, 2, 3]y = [4, 5]x.extend(y)print(x)&gt;&gt;&gt;[1, 2, 3, 4, 5]# 等价于：for i in y: x.append(i) 3、检查列表是否为空普通版：12if len(items) == 0: print(&quot;空列表&quot;) 或者12if items == []: print(&quot;空列表&quot;) 优雅版：12if not items: print(&quot;空列表&quot;) 4、如何理解切片切片用于获取列表中指定范围的子集，语法非常简单 items[start:end:step] 从 start 到 end-1 位置之间的元素。step 表示步长，默认为1，表示连续获取，如果 step为2 就表示每隔一个元素获取。12345678910111213141516a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; a[3:8] # 第3到第8位置之间的元素[4, 5, 6, 7, 8]&gt;&gt;&gt; a[3:8:2] # 第3到第8位置之间的元素，每隔一个元素获取[4, 6, 8]&gt;&gt;&gt; a[:5] # 省略start表示从第0个元素开始[1, 2, 3, 4, 5]&gt;&gt;&gt; a[3:] # 省略end表示到最后一个元素[4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; a[::] # 都省略相当于拷贝一个列表，这种拷贝属于浅拷贝[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 5、如何拷贝一个列表对象第一种方法：1new_list = old_list[:] 第二种方法：1new_list = list(old_list) 第三种方法：12345import copy# 浅拷贝new_list = copy.copy(old_list)# 深拷贝new_list = copy.deepcopy(old_list) 6、如何获取列表中的最后一个元素索引列表中的元素不仅支持正数还支持负数，正数表示从列表的左边开始索引，负数表示从列表的右边开始索引，获取最后一个元素有两种方法。12345&gt;&gt;&gt; a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; a[len(a)-1]10&gt;&gt;&gt; a[-1]10 7、如何对列表进行排序列表排序有两种方式，一种是列表自带的方法 list.sort()，一种是内建函数 sorted(list)。复杂的数据类型可通过指定 key参数进行排序。由字典构成的列表，根据字典元素中的age字段进行排序： 12345678910items = [&#123;&apos;name&apos;: &apos;Homer&apos;, &apos;age&apos;: 39&#125;, &#123;&apos;name&apos;: &apos;Bart&apos;, &apos;age&apos;: 10&#125;, &#123;&quot;name&quot;: &apos;cater&apos;, &apos;age&apos;: 20&#125;]items.sort(key=lambda item: item.get(&quot;age&quot;))print(items)&gt;&gt;&gt;[&#123;&apos;age&apos;: 10, &apos;name&apos;: &apos;Bart&apos;&#125;, &#123;&apos;age&apos;: 20, &apos;name&apos;: &apos;cater&apos;&#125;, &#123;&apos;age&apos;: 39, &apos;name&apos;: &apos;Homer&apos;&#125;] 列表有sort方法，用于对原列表进行重新排序，指定key 参数，key是匿名函数，item是列表中的字典元素，我们根据字典中的age进行排序，默认是按升序排列，指定reverse=True 按降序排列1234items.sort(key=lambda item: item.get(&quot;age&quot;), reverse=True)&gt;&gt;&gt;[&#123;&apos;name&apos;: &apos;Homer&apos;, &apos;age&apos;: 39&#125;, &#123;&apos;name&apos;: &apos;cater&apos;, &apos;age&apos;: 20&#125;, &#123;&apos;name&apos;: &apos;Bart&apos;, &apos;age&apos;: 10&#125;] 如果不希望改变原列表，而是生成一个新的有序列表对象，那么可以内置函数 sorted，该函数返回新列表12345678910111213items = [&#123;&apos;name&apos;: &apos;Homer&apos;, &apos;age&apos;: 39&#125;, &#123;&apos;name&apos;: &apos;Bart&apos;, &apos;age&apos;: 10&#125;, &#123;&quot;name&quot;: &apos;cater&apos;, &apos;age&apos;: 20&#125;]new_items = sorted(items, key=lambda item: item.get(&quot;age&quot;))print(items)&gt;&gt;&gt;[&#123;&apos;name&apos;: &apos;Homer&apos;, &apos;age&apos;: 39&#125;, &#123;&apos;name&apos;: &apos;Bart&apos;, &apos;age&apos;: 10&#125;, &#123;&apos;name&apos;: &apos;cater&apos;, &apos;age&apos;: 20&#125;]print(new_items)&gt;&gt;&gt;[&#123;&apos;name&apos;: &apos;Bart&apos;, &apos;age&apos;: 10&#125;, &#123;&apos;name&apos;: &apos;cater&apos;, &apos;age&apos;: 20&#125;, &#123;&apos;name&apos;: &apos;Homer&apos;, &apos;age&apos;: 39&#125;] 8、如何移除列表中的元素删除列表中的元素有三种方式 remove 移除某个元素，而且只能移除第一次出现的元素1234567891011121314151617181920212223242526272829303132333435&gt;&gt;&gt; a = [0, 2, 2, 3]&gt;&gt;&gt; a.remove(2)&gt;&gt;&gt; a[0, 2, 3]# 如果要移除的元素不在列表中，则抛出 ValueError 异常&gt;&gt;&gt; a.remove(7)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ValueError: list.remove(x): x not in list·del指令：根据指定的位置移除某元素&gt;&gt;&gt; a = [3, 2, 2, 1]# 移除第一个元素&gt;&gt;&gt; del a[1][3, 2, 1]# 当超出列表的下表索引时，抛出IndexError的异常&gt;&gt;&gt; del a[7]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list assignment index out of rangepop函数 与del 类似，但是 pop 函数可以返回移除的元素&gt;&gt;&gt; a = [4, 3, 5]&gt;&gt;&gt; a.pop(1)3&gt;&gt;&gt; a[4, 5]# 同样，当超出列表的下表索引时，抛出IndexError的异常&gt;&gt;&gt; a.pop(7)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: pop index out of range 9、如何连接两个列表12345678listone = [1, 2, 3]listtwo = [4, 5, 6]mergedlist = listone + listtwoprint(mergelist)&gt;&gt;&gt;[1, 2, 3, 4, 5, 6] 列表实现了 + 的运算符重载，使得 + 不仅支持数值相加，还支持两个列表相加，只要你实现了 对象的__add__操作，任何对象都可以实现 + 操作，例如：1234567891011121314151617181920class User(object): def __init__(self, age): self.age = age def __repr__(self): return &apos;User(%d)&apos; % self.age def __add__(self, other): age = self.age + other.age return User(age)user_a = User(10)user_b = User(20)c = user_a + user_bprint(c)&gt;&gt;&gt;User(30) 10、如何随机获取列表中的某个元素123456789import randomitems = [8, 23, 45, 12, 78]&gt;&gt;&gt; random.choice(items)78&gt;&gt;&gt; random.choice(items)45&gt;&gt;&gt; random.choice(items)12 转载]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[时间格式]]></title>
    <url>%2Fpython%2F%E6%97%B6%E9%97%B4%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[mysql 中的时间格式 TIME [3 bytes] : [HH:MM:SS] [-838:59:59 ~ + 838:59:59] DATE [3 bytes] : [YYYY-MM-DD] [1000-01-01 ~ 9999-12-31] DATETIME [8 bytes] : [YYYY-MM-DD HH:MM:SS] [1000-01-01 00:00:00 ~ 9999-12-31 23:59:59] TIMESTAMP [4 bytes] : [1970-01-01 00:00:01 ~ 2038-01-19 03:14:07] YEAR [1 bytes] : [YYYY] [1901 ~ 2155] 常用的是 DATE, DATETIME, 和时间戳 TIMESTAMP python中的 time 时间模块 time 基本时间日期模块 datetime 日历模块 Calendar (用的较少) 1234import time， datetimetimestamp = time.time()print(timestamp,type(timestamp)) # 1563432562.7813718 &lt;class &apos;float&apos;&gt; 获取当前时间戳，数据类型print(datetime.datetime.now()) # 2019-07-18 14:51:57.888187]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[cookbook有感]]></title>
    <url>%2Fpython%2Fcookbook%2Frecord%2F</url>
    <content type="text"><![CDATA[解压可迭代对象赋值给多个变量12items = [1, 10, 7, 4, 5, (1,2,3)]head,*tail,(*_,end) =items 保留最后 N 个元素12345678910111213from collections import deque &gt;&gt;&gt; q = deque(maxlen=3) &gt;&gt;&gt; q.append(1) &gt;&gt;&gt; q.append(2) &gt;&gt;&gt; q.append(3) &gt;&gt;&gt; q deque([1, 2, 3], maxlen=3) &gt;&gt;&gt; q.append(4) &gt;&gt;&gt; q deque([2, 3, 4], maxlen=3) &gt;&gt;&gt; q.append(5) &gt;&gt;&gt; q deque([3, 4, 5], maxlen=3) 不指定，那么无限大小队列1234567891011121314151617&gt;&gt;&gt; q = deque()&gt;&gt;&gt; q.append(1)&gt;&gt;&gt; q.append(2)&gt;&gt;&gt; q.append(3)&gt;&gt;&gt; qdeque([1, 2, 3])&gt;&gt;&gt; q.appendleft(4)&gt;&gt;&gt; qdeque([4, 1, 2, 3])&gt;&gt;&gt; q.pop() # 取出队列中最后一个元素3&gt;&gt;&gt; qdeque([4, 1, 2])&gt;&gt;&gt; q.popleft()4&gt;&gt;&gt; qdeque([1, 2]) 在队列两端插入或删除元素时间复杂度都是 ``O(1)`` ，区别于列表，在列表的开头插入或删除元素的时间复杂度为 ``O(N)`` 从一个集合中获得最大或者最小的 N 个元素列表heapq 模块有两个函数：nlargest() 和 nsmallest() 可以完美解决这个问题。 12345678910111213141516import heapqnums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]print(heapq.nlargest(3, nums)) # Prints [42, 37, 23]print(heapq.nsmallest(3, nums)) # Prints [-4, 1, 2]portfolio = [ &#123;&apos;name&apos;: &apos;IBM&apos;, &apos;shares&apos;: 100, &apos;price&apos;: 91.1&#125;, &#123;&apos;name&apos;: &apos;AAPL&apos;, &apos;shares&apos;: 50, &apos;price&apos;: 543.22&#125;, &#123;&apos;name&apos;: &apos;FB&apos;, &apos;shares&apos;: 200, &apos;price&apos;: 21.09&#125;, &#123;&apos;name&apos;: &apos;HPQ&apos;, &apos;shares&apos;: 35, &apos;price&apos;: 31.75&#125;, &#123;&apos;name&apos;: &apos;YHOO&apos;, &apos;shares&apos;: 45, &apos;price&apos;: 16.35&#125;, &#123;&apos;name&apos;: &apos;ACME&apos;, &apos;shares&apos;: 75, &apos;price&apos;: 115.65&#125;]cheap = heapq.nsmallest(3, portfolio, key=lambda s: s[&apos;price&apos;])expensive = heapq.nlargest(3, portfolio, key=lambda s: s[&apos;price&apos;]) 对集合进行排序&gt;&gt;&gt; nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2] &gt;&gt;&gt; import heapq &gt;&gt;&gt; heap = list(nums) &gt;&gt;&gt; heapq.heapify(heap) # 从小到大排序 &gt;&gt;&gt; heap [-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8] &gt;&gt;&gt; &gt;&gt;&gt; heapq.heappop(heap) # 弹出最小元素 -4 &gt;&gt;&gt; heapq.heappop(heap) 1 &gt;&gt;&gt; heapq.heappop(heap) 2 #### 1234&gt;&gt;&gt; line = &apos;asdf fjdk; afed, fjek,asdf, foo&apos;&gt;&gt;&gt; import re&gt;&gt;&gt; re.split(r&apos;[;,\s]\s*&apos;, line)[&apos;asdf&apos;, &apos;fjdk&apos;, &apos;afed&apos;, &apos;fjek&apos;, &apos;asdf&apos;, &apos;foo&apos;] 按顺序插入字典123456789101112131415161718192021from collections import OrderedDictd = OrderedDict()d[&apos;foo&apos;] = 1d[&apos;bar&apos;] = 2d[&apos;spam&apos;] = 4d[&apos;grok&apos;] = 3for key in d: print(key, d[key]) &apos;&apos;&apos;foo 1bar 2spam 4grok 3import jsona = json.dumps(d)type(a) # str print(a) # &apos;&#123;&quot;foo&quot;: 1, &quot;bar&quot;: 2, &quot;spam&quot;: 4, &quot;grok&quot;: 3&#125;&apos; &apos;&apos;&apos; 在两个字典中寻找相同点（比如相同的键、相同的值等等） 123456789101112131415161718192021222324a = &#123; &apos;x&apos; : 1, &apos;y&apos; : 2, &apos;z&apos; : 3 &#125;b = &#123; &apos;w&apos; : 10, &apos;x&apos; : 11, &apos;y&apos; : 2 &#125; # Find keys in common# 类似于集合求合集差集等。a.keys() &amp; b.keys() # &#123; &apos;x&apos;, &apos;y&apos; &#125;# Find keys in a that are not in ba.keys() - b.keys() # &#123; &apos;z&apos; &#125;# Find (key,value) pairs in commona.items() &amp; b.items() # &#123; (&apos;y&apos;, 2) &#125;# 使用列表推导式 从字典a 中删除 键 &apos;z&apos;,&apos;w&apos; c = &#123;key:a[key] for key in a.keys() - &#123;&apos;z&apos;, &apos;w&apos;&#125;&#125; # 值非唯一，不建议用来进行 集合 操作 不打乱顺序去重123456789def dedupe(items): seen = set() for item in items: if item not in seen: yield item seen.add(item)a = [1, 5, 2, 1, 9, 1, 5, 10]list(add(a)) # [1, 5, 2, 9, 10] 可用slice() 优化切片操作123456789101112131415161718items = [0, 1, 2, 3, 4, 5, 6]a = slice(2, 4)items[a] # 等同于 items[2, 4] a = slice(2,10,2)items[a] # 等同于 items[2,10,2]a.start # 2a.stop # 10a.step # 2 &gt;&gt;&gt; s = &apos;HelloWorld&apos; &gt;&gt;&gt; a.indices(len(s)) (5, 10, 2) &gt;&gt;&gt; for i in range(*a.indices(len(s))): ... print(s[i]) ... W r d 看一下range函数 123456789101112 In [178]: a = (5,10,2)In [179]: range(a)In [180]: range(*a)Out[180]: range(5, 10, 2)* 就是将 a 中元素当 位置参数传进去** 就是当字典 def kw_dict(**kwargs): return kwargs print kw_dict(a=1,b=2,c=3) == &#123;&apos;a&apos;:1, &apos;b&apos;:2, &apos;c&apos;:3&#125;]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[初探元编程]]></title>
    <url>%2Fpython%2F%E5%85%83%E7%BC%96%E7%A8%8B%2F%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[typetype 是python 内置元类，为改变 Python 中类的行为（比如，SomeClass 的行为），我们可以通过继承 type 元类，定义一个自定义元类。元类是在 Python 中进行元编程的一种方法1234class SomeClass: passsome_object = SomeClass()type(some_object) # __main__.SomeClass 1234567&gt;&gt;&gt; import inspect&gt;&gt;&gt;inspect.isclass(SomeClass)True&gt;&gt;&gt;inspect.isclass(some_object)False&gt;&gt;&gt;inspect.isclass(type(some_object))True 12345678&gt;&gt;&gt; type(type(SomeClass))&lt;type &apos;type&apos;&gt;&gt;&gt;&gt;inspect.isclass(type(type(SomeClass)))True&gt;&gt;&gt;type(type(type(SomeClass)))&lt;type &apos;type&apos;&gt;&gt;&gt;&gt;isclass(type(type(type(SomeClass))))True 除 type 之外，Python 中的一切都是对象，它们要么是类的实例，要么是元类的实例。1234567&gt;&gt;&gt; some_obj = SomeClass()&gt;&gt;&gt; isinstance(some_obj,SomeClass)True&gt;&gt;&gt; isinstance(SomeClass, type)True&gt;&gt;&gt; isinstance(some_obj,type)False 在 Python 中使用 type 来创建类通过一个参数调用 type 时，会生成现有类的 type 信息。通过三个参数调用 type 时，会创建一个新的类对象。调用 type 时，参数是类名、基类列表以及指定类的名称空间的字典（所有字段和方法） 1SomeClass = type(&apos;SomeClass&apos;, (), &#123;&#125;) 与下面等价1SomeClass = type(&apos;SomeClass&apos;, (), &#123;&#125;) 此外12345678def some_function(self): print(&quot;Hello&quot;) ParentClass = type(&apos;ParentClass&apos;, (), &#123;&#125;)SomeClass = type(&apos;SomeClass&apos;, (ParentClass,), &#123;&apos;some_function&apos;: some_function, &apos;some_var&apos;:5&#125;) 等价于1234567class ParentClass: pass class SomeClass(ParentClass): some_var = 5 def some_function(self): print(&quot;Hello!&quot;) 元类编写自定义元类分为两个步骤： 编写元类类型的子类。 使用元类挂钩将新元类插入到类创建流程中 元类的实际使用因为在子类中会继承元类，所以元类解决了代码冗余（不要重复自己 — DRY）这一实际问题。 通常情况下，在生成类对象的同时，通过执行额外操作或添加额外代码，元类也可以帮助提取有关类创建的复杂逻辑。元类的一些实际用例包括： 抽象基类 类的注册 在库和框架中创建 API 抽象基类抽象基类是只能被继承而不会被实例化的类1234567891011from abc import ABCMeta, abstractmethod class Vehicle(metaclass=ABCMeta): @abstractmethod def refill_tank(self, litres): pass @abstractmethod def move_ahead(self): pass 创建一个从 Vehicle 类继承的 Truck 类： 1234567891011class Truck(Vehicle): def __init__(self, company, color, wheels): self.company = company self.color = color self.wheels = wheels def refill_tank(self, litres): pass def move_ahead(self): pass 调用 1mini_truck = Truck(&quot;Tesla Roadster&quot;, &quot;Black&quot;, 4) (参考文档)[https://www.ibm.com/developerworks/cn/analytics/library/ba-metaprogramming-python/index.html]]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[鸭子类型]]></title>
    <url>%2Fpython%2F%E9%B8%AD%E5%AD%90%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324class Duck: @classmethod def fly(cls): print(&quot;Duck flying&quot;) class Airplane: @staticmethod def fly(): print(&quot;Airplane flying&quot;) class Bird: def fly(self): print(&apos;Bird is flying&apos;) def lift_off(entity): entity.fly() if __name__ == &quot;__main__&quot;: lift_off(Duck) lift_off(Airplane) bird = Bird() lift_off(bird)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python的日志模块]]></title>
    <url>%2Fpython%2Fpython%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[日志概述 日志会记录下操作，运行的一些相关内容 查看日志是获取信息，排查异常，发现问题的最好途径 日志可在控制台显示，也可以记录到文件中，或者同时输出 日志级别 一般指的是： DEBUG, INFO, WARNING, ERROR, CRITICAL 等严重等级进行划分 python 的 logging 提供了一组便利的日志函数，分别是： debug(), info(), warning(), error(), critical()。 12345DEBUG : 详细信息一般只在调试问题时使用INFO : 事情按预期进行WARNNING : 某些没有预料到的事件提示，或者将来可能出现问题的提示。ERROR : 更严重的问题，软件的一部分功能已不能被执行CRITICAL ： 严重错误，表明软件不能继续运行 logging 的四大组件123456日志器 Logger 提供了应用程序一直使用的接口处理器 Handler 将 logger 创建的日志记录发送到合适的目的输出过滤器 Filter 提供更细粒度的控制工具来决定输出哪条日志记录，丢弃哪条日志记录格式器 Formatter 决定日志记录的最终输出格式logger 是入口，真正工作的是 handler, handler 还可以通过 filter 和 formatter 对要输出的日志内容做过滤和格式化处理 日志输出输出到控制台python 中日志的默认等级是 WARNING, DEBUG 和 INFO 级别的日志不会得到显示。12345import logginglogging.info(&apos;info message&apos;)logging.warning(&apos;warning message&apos;)logging.error(&apos;error message&apos;) logging 提供 basciConfig 让使用者可以适时调整默认日志级别1234567import logginglogging.basicConfig(level=logging.DEBUG)logging.info(&apos;info message&apos;)logging.warning(&apos;warning message&apos;)logging.error(&apos;error message&apos;) 输出到文件在 basciConfig 中填写 filename(日志名) ,filemode(写入方式)123456789import logginglogging.basicConfig(level=logging.DEBUG, filename=&apos;test.log&apos;, filemode=&apos;a&apos;)logging.info(&apos;info message&apos;)logging.warning(&apos;warning message&apos;)logging.error(&apos;error message&apos;) 同时输出到文件及控制器对比1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import osimport loggingimport uuidfrom logging import Handler, FileHandler, StreamHandlerclass PathFileHandler(FileHandler): def __init__(self, path, filename, mode = &apos;a&apos;, encoding = None, delay = False): filename = os.fspath(filename) if not os.path.exists(path): os.mkdir(path) self.baseFilename = os.path.join(path, filename) self.mode = mode self.encoding = encoding self.delay =delay if delay: Handler.__init__(self) self.stream = None else: StreamHandler.__init__(self, self._open())class Loggers(): level_relations = &#123; &apos;debug&apos; : logging.DEBUG, &apos;info&apos; : logging.INFO, &apos;warning&apos; : logging.WARNING, &apos;error&apos; : logging.ERROR, &apos;critical&apos; : logging.CRITICAL &#125; uid = uuid.uuid4() def __init__(self, filename = f&apos;&#123;uid&#125;.log&apos;, level = &apos;info&apos;, log_dir = &apos;log&apos;, fmt = &quot;[%(asctime)s] [%(levelname)8s] %(message)s&quot; ): self.logger =logging.getLogger(filename) abspath = os.path.dirname(os.path.abspath(__file__)) self.directory = os.path.join(abspath, log_dir) format_str = logging.Formatter(fmt) self.logger.setLevel(self.level_relations.get(level)) stream_handler = logging.StreamHandler() stream_handler.setFormatter(format_str) file_handler = PathFileHandler(path=self.directory, filename=filename, mode=&apos;a&apos;) file_handler.setFormatter(format_str) self.logger.addHandler(stream_handler) self.logger.addHandler(file_handler)if __name__ == &apos;__main__&apos;: text = &apos;hahaha&apos; log = Loggers(level=&apos;debug&apos;) log.logger.info(4) log.logger.info(5) log.logger.info(text)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python的一些技巧]]></title>
    <url>%2Fpython%2Fpython%E4%B8%80%E4%BA%9B%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[变量有关于变量` 定义 __str__ 方法的对象，可以使用 str() 函数 返回可读名称 定义 __next__ 和 __iter__ 方法的对象，就可以被循环迭代 定义 __bool 方法的对象，进行布尔值的判断时就会使用自定义的逻辑]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[psutil模块]]></title>
    <url>%2Fpython%2Fpsutil%E8%8E%B7%E5%8F%96%E7%B3%BB%E7%BB%9F%E8%BF%90%E8%A1%8C%E7%9A%84%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%B3%BB%E7%BB%9F%E5%88%A9%E7%94%A8%E7%8E%87%2F</url>
    <content type="text"><![CDATA[三大模块 System related function Processes Windows Service 安装方法pip install psutil pip install -user psutil 使用方法123456789101112131415161718192021222324252627import psutil&apos;&apos;&apos;待探索&apos;&apos;&apos;# cpu 节选psutil.cpu_times() # 将系统cpu时间作为命名元组返回psutil.cpu_percent(interval=None, percpu=None) # cpu 使用百分比psutil.cpu_percent(interval=3, percpu=True) # 3秒间隔中，cpu 的占用率psutil.cpu_count() # cpu 逻辑核心数psutil.cpu_count(logical=True) # cpu 物理核心数for i in range(10): psutil.cpu_percent(interval=3, percpu=True) # 3秒间隔中，cpu 的占用率# 内存节选psutil.virtual_memory() # 将系统内存使用情况作为命名元组返回# 当内存不足，发出提示dan = 300 * 1024 * 1024 # 单位为bif psutil.virtual_memory().available &lt;= dan: print(&apos;memory warning&apos;)# 进程信息psutil.pids()[p.info for p in psutil.process_iter(attrs=[&apos;pid&apos;, &apos;name&apos;]) if &apos;python&apos; in p.info[&apos;name&apos;]] 更多单个进程信息1234567891011121314151617181920p = psutil.Process(2423) p.name() #进程名p.exe() #进程的bin路径p.cwd() #进程的工作目录绝对路径p.status() #进程状态p.create_time() #进程创建时间p.uids() #进程uid信息p.gids() #进程的gid信息p.cpu_times() #进程的cpu时间信息,包括user,system两个cpu信息p.cpu_affinity() #get进程cpu亲和度,如果要设置cpu亲和度,将cpu号作为参考就好p.memory_percent() #进程内存利用率p.memory_info() #进程内存rss,vms信息p.io_counters() #进程的IO信息,包括读写IO数字及参数p.connectios() #返回进程列表p.num_threads() #进程开启的线程数听过psutil的Popen方法启动应用程序，可以跟踪程序的相关信息from subprocess import PIPEp = psutil.Popen([&quot;/usr/bin/python&quot;, &quot;-c&quot;, &quot;print(&apos;hello&apos;)&quot;],stdout=PIPE)p.name()p.username() 获取开机时间`psutil.boot_time() # 时间戳 datetime.datetime.fromtimestamp(psutil.boot_time ()).strftime(“%Y-%m-%d %H: %M: %S”) #转换成自然时间格式]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于import]]></title>
    <url>%2Fpython%2F%E5%85%B3%E4%BA%8Eimport%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[12345678import syssys.path.append(&quot;..&quot;) # 将上层目录加入路径.sys.path.append(&quot;/home&quot;) # 将/home 加入路径.## 一个模块只能被导入一次from imp import *reload(sys) # 重新导入某模块]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pathlib模块]]></title>
    <url>%2Fpython%2Fpathlib%E6%9C%89%E5%85%B3%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[面向对象的文件系统路径 pathlib 提供表示文件系统路径的类，适用于不同的操作系统 纯路径提供纯粹的计算操作，具体路径继承纯路径且可以进行 I/O 操作1234567891011import pathlibprint(pathlib.PurePath(__file__)) # 文件路径print(pathlib.PurePath(__file__).match(&apos;*.py&apos;))print(pathlib.Path.cwd()) # 当前路径 （运行路径）print(pathlib.Path.cwd().joinpath(pathlib.PurePath(__file__)))print(pathlib.Path.cwd().parent) # 上一级print(pathlib.Path.cwd().parent.parent) # 上上级parts = [&apos;first&apos;, &apos;second&apos;, &apos;third&apos;]print(pathlib.Path.cwd().parent.joinpath(*parts)) # 在上一级开始拼接路径 更多123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from pathlib import PathPath.iterdir() # 遍历目录的子目录或者文件Path.is_dir() # 判断是否是目录Path.glob() # 过滤目录(返回生成器)Path.resolve() # 返回绝对路径Path.exists() # 判断路径是否存在Path.open() # 打开文件(支持with)Path.unlink() # 删除文件或目录(目录非空触发异常)# 基本属性Path.parts # 分割路径 类似os.path.split(), 不过返回元组Path.drive # 返回驱动器名称Path.root # 返回路径的根目录Path.anchor # 自动判断返回drive或rootPath.parents # 返回所有上级目录的列表# 改变路径Path.with_name() # 更改路径名称, 更改最后一级路径名Path.with_suffix() # 更改路径后缀#拼接路径Path.joinpath() # 拼接路径Path.relative_to() # 计算相对路径# 测试路径Path.match() # 测试路径是否符合patternPath.is_dir() # 是否是文件Path.is_absolute() # 是否是绝对路径Path.is_reserved() # 是否是预留路径Path.exists() # 判断路径是否真实存在# 其他方法Path.cwd() # 返回当前目录的路径对象Path.home() # 返回当前用户的home路径对象Path.stat() # 返回路径信息, 同os.stat()Path.chmod() # 更改路径权限, 类似os.chmod()Path.expanduser() # 展开~返回完整路径对象Path.mkdir() # 创建目录Path.rename() # 重命名路径Path.rglob() # 递归遍历所有子目录的文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import pathlib&apos;&apos;&apos;有关文件路径&apos;&apos;&apos;current_p = pathlib.Path.cwd() # 当前运行路径print(current_p)p = pathlib.Path(__file__)print(p.stat()) # 获取文件信息print(p) # 文件相对运行路径的路径print(p.resolve()) # 返回文件所在的绝对路径print(p.resolve().parent.parent) # 返回文件上上级路径print(pathlib.PurePath(p.resolve()).parts) # 将绝对路径以元组的方式返回print(pathlib.Path.home()) # 家目录 例如: /home/rootprint(pathlib.Path(p).exists() ) # 判断路径或文件是否存在print(p.name) # 获取文件名 path.pyprint(p.stem) # 获取文件名（没后缀）print(p.suffix) # 获取文件的后缀名 .pyprint(p.suffixes) # 获取文件的后缀名 [&apos;.py&apos;], 可能会有 [&apos;.tar&apos;,&apos;.gz&apos;]new_path1 = p.with_name(&apos;test.py&apos;)print(new_path1) # 路径下 + test.pynew_path1.touch() # 创建文件print(new_path1) # 最后文件名改为test.py (仅仅改字符串)new_path2 = new_path1.with_suffix(&apos;.txt&apos;)try: new_path1.rename(pathlib.Path(new_path2)) # 改为 .txtexcept Exception as e: print(f&apos;&#123;e&#125;&apos;) new_path1.replace(pathlib.Path(new_path2))finally: print(&apos;已改名完成&apos;)&apos;&apos;&apos;路径拼接&apos;&apos;&apos;path = pathlib.Path(current_p,&apos;parent_path&apos;,&apos;path&apos;)print(path)path1 = pathlib.Path(path).joinpath(&apos;hahaha&apos;,&apos;path1.py&apos;)print(path1)&apos;&apos;&apos;遍历文件夹&apos;&apos;&apos;print([path for path in current_p.iterdir()]) # 当前路径下所有路径print([path for path in current_p.glob(&apos;*.py&apos;)]) # 找出当前路径下含有 .py 的路径print([path for path in current_p.rglob(&apos;*.py&apos;)]) # 找出当前路径下所有(子，子子...)含有 .py 的路径&apos;&apos;&apos;文件操作open(mode=&apos;r&apos;, bufferiong=-1, encoding=None, errors=None, newline=None)&apos;&apos;&apos;with p.resolve().open(encoding = &apos;utf-8&apos;) as f: print(f.read())# 对于简单文件操作# .read_text(): 以文本模式打开路径并并以字符串形式返回内容。# .read_bytes(): 以二进制/字节模式打开路径并以字节串的形式返回内容。# .write_text(): 打开路径并向其写入字符串数据。# .write_bytes(): 以二进制/字节模式打开路径并向其写入数据。print(p.resolve().read_text(encoding=&apos;utf-8&apos;))&apos;&apos;&apos;文件夹创建及删除&apos;&apos;&apos;ex_path = pathlib.Path(current_p,&apos;parent_path&apos;,&apos;path&apos;)# 创建文件目录，由于parents为True，所以逐级创建出来。ex_path.mkdir(parents = True, exist_ok = True)# 删除路径对象目录，如果要删除的文件夹内包含文件就会报错ex_path = pathlib.Path(current_p,&apos;parent_path&apos;,&apos;path&apos;)ex_path.mkdir(parents = True, exist_ok = True)new_path1 = ex_path.with_name(&apos;test.py&apos;)print(new_path1) # 路径下 + test.pynew_path1.touch() # 创建文件new_path2 = new_path1.with_suffix(&apos;.txt&apos;)print(new_path2) # 最后文件名改为test.py (仅仅改字符串)try: new_path1.rename(pathlib.Path(new_path2)) # 改为 .txtexcept Exception as e: print(f&apos;&#123;e&#125;&apos;) new_path1.replace(pathlib.Path(new_path2)) # 替换文件finally: print(&apos;已改名完成&apos;)try: pathlib.Path(new_path2).unlink() # 删除 test.txt ex_path.parent.rmdir() # 删除文件夹 非空则会报错except Exception as e: print(f&apos;&#123;e&#125;&apos;) import shutil shutil.rmtree(ex_path.parent) # 递归删除 https://blog.csdn.net/itanders/article/details/88754606 pathlib官方文档 去除当前文件夹下歌曲名中的 [music.migu.cn] 1234from pathlib import Pathcurrent_path = Path(__file__).resolve().parentmp3 = [path for path in current_path.glob(&apos;*.mp3&apos;)]result = [i.rename(str(i).replace(&apos;[music.migu.cn]&apos;,&apos;&apos;)) for i in mp3 if &apos;[music.migu.cn]&apos; in str(i)] 1234567891011121314151617181920212223242526from pathlib import Pathfrom mutagen.id3 import ID3, APIC, TIT2, TPE1, TALBdef SetMp3Info(mp3file, info): songFile = ID3(mp3file) songFile[&apos;TIT2&apos;] = TIT2( # 插入歌名 encoding=3, text=info[&apos;title&apos;] ) songFile[&apos;TPE1&apos;] = TPE1( # 插入第一演奏家、歌手、等 encoding=3, text=info[&apos;artist&apos;] ) songFile.save()current_path = Path(__file__).resolve().parentmp3 = [path for path in current_path.glob(&apos;*.mp3&apos;)]for mp3file in mp3: newname = str(mp3file) songtitle = newname.split(&apos;/&apos;)[-1][:12] songtitle = songtitle.replace(&apos;.mp3&apos;,&apos;&apos;) info = &#123;&apos;title&apos;: songtitle, &apos;artist&apos;: &apos;周杰伦&apos; &#125; SetMp3Info(mp3file, info)result = [i.rename(str(i).replace(&apos;-周杰伦&apos;,&apos;&apos;)) for i in mp3 if &apos;-周杰伦&apos; in str(i)] 1234567891011121314151617181920from pathlib import Pathfrom mutagen.flac import FLACdef SetMp3Info(mp3file, info): songFile = FLAC(mp3file) songFile[&apos;TITLE&apos;] = info[&apos;TITLE&apos;] songFile[&apos;ARTIST&apos;] = info[&apos;ARTIST&apos;] songFile.save()current_path = Path(__file__).resolve().parentmp3 = [path for path in current_path.glob(&apos;*.flac&apos;)]for mp3file in mp3: newname = str(mp3file) songtitle = newname.split(&apos;/&apos;)[-1][:12] songtitle = songtitle.replace(&apos;.flac&apos;,&apos;&apos;) print(songtitle) info = &#123;&apos;TITLE&apos;: songtitle, &apos;ARTIST&apos;: &apos;周杰伦&apos; &#125; SetMp3Info(mp3file, info)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[软件安装方式]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[软件安装方式通用二进制格式：直接解压压缩文件，就可以使用。但一定要注意安装平台软件包管理器：如 rpm, deb (由于Linux中的程序大多是小程序。程序与程序之间存在非常复杂的依赖关系。包管理器无法解决软件包的依赖关系。)软件包管理器的前端工具：如 yum,apt ,dnf (建议使用 dnf 替代 yum)源代码编译。 对比包管理器很方便，但有两点劣势 需要提前将包编译好，如果某个包没有发布版本，或者平台上找不到对应的发布版本，则需要编译安装 软件的定制度很高，可能需要在编译阶段传入参数]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zabbix使用]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2Fzabbix%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[原文链接]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux使用者管理]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2Flinux%E4%BD%BF%E7%94%A8%E8%80%85%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[新建用户1234567891011root 权限下：useradd testpasswd testuserdel -r test # 连同文件夹一起删掉addgrop friendsusermod -laddgrop -g/G 例行工作12atcron 程序管理与selinux初探 程序一般放在磁盘中，通过用户的执行来触发，触发后会加载到内存中成为一个个体，就是进程。 &amp; 后台运行 (关掉终端会停止) nohup + cmd + &amp; 或者setsid + cmd + &amp; fg %1 将job 1拿到前台来 vi 下 ctrl + z 可将vi 放到后台。 kill # kill -9 %1 bg 后台暂停的 让 后台运行 top -d 5 -p 12345 free -g uname -a uptime netstat -a SELinuxSecurity Enhanced Linux screen1234screen -dmS test # 创建 test 窗口screen -r test # 连接 test 窗口screen -d test 后 screen -r test # 如果连接不上，这样连接screen -S test -X quit # 删除 test 窗口 rsync 同步 rsync -arv ./ back/ rsync -arv ./ root@107.172.82.37:/root/back/]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[杂]]></title>
    <url>%2Fpython%2Freadme%2F</url>
    <content type="text"><![CDATA[python中变量名 指向的 是 对象的地址，不是对象的值]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基础]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2Fbash_shell%2Freadme%2F</url>
    <content type="text"><![CDATA[基础 .bash_history 历史记录 Tab 补全 alias 命令别名， alias lm = ‘ls -al’ , unalias lm (临时) vi /root/.bashrc （永久） type cd 命令类型 \ 转义 变量 变量未设置时，默认为空 PATH=$PATH:/home/bin 变量累加 export PATH 使变量成为环境变量 一般默认 大写为系统变量 小写为自行设置变量 变量中 单引号’’（纯文本） 与 双引号 “” (保持原本特性) current_path=$(pwd) 接命令赋值给变量。 等同于 123456789101112current_path=`pwd`# 建议都用 $(pwd)``` 7. `unset current_path` 取消变量8. 子进程取消的变量 对 父进程无影响，子进程只继承父进程的环境变量与export。9. `work=/opt/software` 可以`cd $work` 。写入.bash_profile 全局生效。10. `env` 查看环境变量11. `set` 查看所有变量12. `echo $?` 只与上一个命令有关，上一个命令成功返回0## 变量读取，数组与声明 read -s -p “please input root password:” serverPwd # -p 提示 -s 不显示echo $serverPwdecho -e “\n” # -e 启用反斜杠转义 （换行）1**数组** var[1]=’small’var[2]=’big’echo “$var[1],$var[2]”1declare 和 typeset 一样声明变量类型 sum=100+1echo $sun # 100+1declare -i sum=100+1echo $sun # 101 1## $ $0 当前脚本的文件名$n 传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。$# 传递给脚本或函数的参数个数。$* 传递给脚本或函数的所有参数。 # 双引号内，会识别成一个整体$@ 传递给脚本或函数的所有参数。 # 双引号内，还是会识别成一个一个参数$? 上个命令的退出状态，或函数的返回值。一般情况下，大部分命令执行成功会返回 0，失败返回 1。$$ 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID1234567891011121314151617## 与文件系统及程序的限制关系：ulimit## 数据流重定向st:standard1. stdin &lt; &lt;&lt; (代码0)2. stout &gt; &gt;&gt; (代码0)3. stderr 2&gt; 2&gt;&gt; (代码2)4. `&gt;/dev/null ,2&gt;/dev/null` 丢弃输出5. `&gt; list 2&gt;&amp;1 (都输出 list)或 &amp;&gt; list`## 命令执行判断依据1. cmd1,cmd2,cmd3 依次执行2. cmd1 &amp;&amp; cmd2 &amp;&amp; cmd3 前面成功，后面才执行（$# = 0）3. cmd1 || cmd2 || cmd3 前面成功，后面就不执行（$# = 0）## 管道命令（pipe）**将前一个命令的stout(不会处理stderr) 传到下一个命令的stdin中** yes|bash …sh(执行命令输入yes)echo $PATH |cut -d ‘:’ -f 4 # 以 : 分割$PATH ,取出第4个echo $PATH |cut -d ‘:’ -f 3,5 # 以 : 分割$PATH ,取出第3,5个export | cut -c 12- # 取出12到最后的字符last | grep -i root # 找出last中的含root行，忽略大小写last | grep -v root # 不含root行last | grep root|cut -d ‘ ‘ -f 1| sort | uniq -ic # i 忽略大小写 c 计数cat /etc/os-release | wc # 输出 行 字数 字符数wc -l(行) -w(英文单字) -m (多少字符)grep os /etc/os-release -n -i # -n 显示行数， -i 忽略大小写12## 双向重定向（tee）**将数据流同时输出到屏幕和文件中** last |tee -a last.list # -a 累加` shell脚本shell script 是利用shell的功能所写的一个纯文本文件，将一些shell的语法命令写在里面，搭配正则表达式，管道命令与数据流重定向等功能达到我们想要的目的。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[权限目录]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E6%9D%83%E9%99%90%EF%BC%8C%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[用户与用户组 u g o a (user group other all) r:4 w:2 x:1 chgrp chown chmod 目录1234567891011121314151617181920# 一般情况下lrwxrwxrwx. 1 root root 7 Feb 2 14:33 bin -&gt; usr/bin #bin 放用户可用，启动时会用到的命令 l 连接文件 指向 /usr/bin dr-xr-xr-x. 6 root root 4096 Feb 20 10:37 boot # 开机用到的文件，内核，相关设置drwxr-xr-x. 19 root root 3560 Apr 22 16:07 dev # 任何设备与接口设备drwxr-xr-x. 93 root root 12288 May 24 16:05 etc # 配置文件drwxr-xr-x. 6 root root 4096 May 24 14:42 home # 默认用户主文件夹lrwxrwxrwx. 1 root root 7 Feb 2 14:33 lib -&gt; usr/lib #系统函数库lrwxrwxrwx. 1 root root 9 Feb 2 14:33 lib64 -&gt; usr/lib64 drwx------. 2 root root 16384 Feb 2 14:32 lost+found # 文件系统发生错误时，保存的一些丢失片段dr-xr-xr-x. 9 root root 2048 Jan 15 21:24 media # 可删除设备drwxr-xr-x. 2 root root 4096 Jun 25 2018 mnt # 额外挂载设备drwxr-xr-x. 7 root root 4096 May 24 16:16 opt # 第三方软件放置库dr-xr-xr-x. 505 root root 0 Feb 19 17:39 proc #虚拟文件系统，内核进程网络状态等存在于内存中，不占磁盘空间dr-xr-x---. 4 root root 4096 May 24 14:54 root # 系统管理员主文件夹lrwxrwxrwx. 1 root root 8 Feb 2 14:33 sbin -&gt; usr/sbin # 开机过程需要的命令drwxr-xr-x. 3 root root 4096 May 24 14:39 srv # 服务数据目录dr-xr-xr-x. 13 root root 0 Feb 19 17:40 sys # 同proc ，目前已加载的内核模块，与内存监测到的硬件设备信息等。drwxrwxrwt. 25 root root 4096 May 24 16:44 tmp # 临时放置文件drwxr-xr-x. 14 root root 4096 Feb 2 14:33 usr # 可分享不可变动的，所有系统默认软件等drwxr-xr-x. 21 root root 4096 Feb 20 10:37 var # 缓存，登录文件以及某些软件运行所产生的文件等。 可变动的，不可变动的 可分享的，不可分享的]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[日志文件]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[日志文件日志文件记录系统在什么时候由哪个进程做了什么样的行为，发生了何种事件等。 syslogd: 主要登录系统与网络等服务的信息。 klogd: 主要登录内核产生的各项信息。 logrotate: 主要进行日志文件的轮替功能。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[部署]]></title>
    <url>%2Fpython%2Fflask%2F%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[部署流程 自动执行全部任务 把生产环境中的错误写入日志 部署方式 云托管 容器 eg:docker PaaS 平台即服务 使用docker 部署 安装docker 构建容器映像 运行容器 数据库等最好另开容器 容器编排 Docker Compose 定义的所有容器，可以使用 docker-compose 命令一次性全部启动]]></content>
      <categories>
        <category>flask</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[dockerfile]]></title>
    <url>%2Fdocker%2FDockerFile%2F</url>
    <content type="text"><![CDATA[简介Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于操作系统基础镜像并最终创建的一个新镜像； 常用命令FROM image:tag : 使用的基础镜像构建MAINTAINER user_info : 声明镜像维护者信息LABEL value : 镜像描述元信息 (可以多条)ENV key value : 设置环境变量 (可以多条)RUN command : 构建镜像时需要运行的命令 (可以多条)WORKDIR path_dir : 设置终端默认登录进来的工作目录EXPOSE port : 当前容器对外暴露出的端口ADD source_dir/file dest_dir/file : 宿主机内文件复制到容器，压缩文件会解压COPY source_dir/file dest_dir/file : 同 ADD，不过压缩文件不解压VOLUME : 创建一个 可以从本机或其他容器挂载的挂载点，一般用来存放数据库和需要保存的数据CMD : 指定容器启动时要运行的命令，多个CMD，最后一个生效 CMD 或CMD [““,”“,”“,…] CMD [““,”“,…]ENTRYPOINT : 指定容器启动时要运行的命令ONBUILD : 为子镜像服务1234567简单实例：父镜像Dockerfile:FROM centosONBUILD RUN yum -y install vimCMD /bin/bash 子镜像简单点：FROM parent Dockerfile1234567891011121314FROM centosMAINTAINER weilai&lt;imwl@live.com&gt; LABEL name=&quot;imwl CentOS Image&quot; \ build-date=&quot;20180916&quot; ENV WORKPATH /home/WORKDIR $WORKPATH RUN yum -y install net-toolsRUN yum -y install vim EXPOSE 80CMD /bin/bash]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[个人计算机]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E4%B8%AA%E4%BA%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[个人计算机架构与接口设备主板主流 x86 开发商（Intel，AMD）的 cpu 架构并不兼容， 两大主流的 CPU 所需要的主板芯片组设计也不相同。 芯片组 分为两个 桥接器 来控制各组件通信 北桥负责连接速度较快的 CPU 、内存、显卡等组件 南桥负责连接速度较慢的周边接口，包括usb,硬盘，网卡等 tips : AMD 将内存控制组件集成到 CPU 当中，加速 CPU 与内存的传输速度。（AMD 和 INTEL 的架构上的主要区别） CPU 多核 ： 一个 CPU 多个运算内核 频率 ： CPU 每秒可进行的工作次数，等于外频和倍数的乘积（外频：CPU与外部组件进行数据传输/运算时的速度，倍频：CPU内部用来加速工作性能的一个倍速） 32位 与 64位： 主要依据 CPU 解析的字组大小来判定。 32位 CPU 最大只能够支持到 4GB 内存 内存个人计算机的内存主要组件为 动态随机访问内存 （通电使用与记录，断电数据消失） 双通道设计理念 ： 一条内存仅达 64位，两条内存可达128位 BIOS ： Basic input output System , 写死到只读存储器中 （Read Only Memory,rom）,BIOS 系统在开机的时候首先读取的一个程序。（因为升级BIOS，现在BIOS通常写在闪存或EEPROM） 显卡显卡上面有一个 内存的容量，将会影响到最终的屏幕分辨率与色彩深度。运算速度，显卡上面嵌入一个 3D 加速的芯片 ， GPU 的由来。 硬盘PCI适配卡电源操作系统与应用程序操作系统 内核 （kernel）： 是一组程序，重点在于管理计算机的所有活动以及驱动系统中的所有硬件 内核程序所放置到内存当中的区块是受保护的，并且开机常驻内存。主要功能有： 系统调用接口、 程序管理、 内存管理、 文件系统管理、 设备驱动等 系统调用 ： 通常会提供一整组的开发接口给工程师来开发软件应用程序应用程序： 是参考操作系统提供的开发接口所开发出来的软件]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2Fpython%2FDesignPattern%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2Freadme%2F</url>
    <content type="text"><![CDATA[当项目有几个部分不会影响代码的执行时，（例如日志记录）那么使用全局状态是可以接受的 避免使用全局状态的原因之一就是不想使 项目一部分中的代码修改全局状态 logger_class.py123456789101112131415161718192021222324252627282930313233# def log_message(msg):# with open( &apos;filename.log&apos;, &apos;a&apos; ) as log_file:# log_file.write(f&quot;&#123;msg&#125;\n&quot;) # 代替 format，python3新特性## log_message(&apos;save this for later&apos;)class Logger(): def __init__(self, filename): self.filename = filename def _write_log(self, level, msg): with open(self.filename , &apos;a&apos;) as log_file: log_file.write(&apos;&#123;0&#125; &#123;1&#125;\n&apos;.format(level, msg)) def critical(self, msg): self._write_log(&apos;CRUTICAL&apos;,msg) def error(self, msg): self._write_log(&apos;ERROR&apos;,msg) def warn(self, msg): self._write_log(&apos;WARN&apos;,msg) def info(self, msg): self._write_log(&apos;INFO&apos;, msg) def debug(self, msg): self._write_log(&apos;DEBUG&apos;,msg) main_script.py12345678910# import logger### for i in range(4):# logger.log_message(f&apos;log massger &#123;i&#125;&apos;)from logger_class import Loggerlogger_object = Logger(&apos;filename_class&apos;)logger_object.info( &apos;hahahaha&apos;) init函数并不是真正意义上的构造函数，init方法做的事情是在对象创建好之后初始化变量。真正创建实例的是new方法123456789101112131415161718class Singleton(object): &apos;&apos;&apos; 实现__new__方法 并在将一个类的实例绑定到类变量_instance上, 如果cls._instance为None说明该类还没有实例化过,实例化该类,并返回 如果cls._instance不为None,直接返回cls._instance &apos;&apos;&apos; _instance = None def __new__(cls, *args, **kwargs): if cls._instance is None: cls._instance = object.__new__(cls, *args, **kwargs) return cls._instances1 = Singleton()s2 = Singleton()print(s1)print(s2)]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[文件，目录]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E6%96%87%E4%BB%B6%EF%BC%8C%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[目录与路径 cd pwd mkdir rmdir mkdir -m 711 test , mkdir -p -m mkdir -m 711 test/test/test/test1 (仅test1 为711) rmdir -p test/test/test/test1 （递归删除空目录） 查询 file /user/bin/passwd # 查询某文本数据类型 which python # 查询某命令位置 whereis passwd # 查询某目录，文件位置 locate passwd # -i 忽略大小写 -r 接正则表达式 find # 能执行额外的动作 内存交换空间（swap）CPU读取的数据都来自于内存，内存不足时，内存中暂不使用的程序和数据会被移动到swap中 #]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[计算机组成原理]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[计算机组成原理总结计算机系统简介计算机系统由“软件“及”硬件“组成，软件通常分为系统软件和应用软件。系统软件:用来管理整个计算机系统，监视服务，使系统资源得到合理调度，高效运行。应用软件:根据用户任务需求所编制的各种程序。 计算机系统的层次结构通常用户用高级语言编写程序，然后将它和数据一起送入计算机内，再由计算机将其翻译成机器能识别的机器语言程序，然后交由机器运行。 高级语言机器 → → 汇编语言机器 → →机器语言机器 或 高级语言机器 → → 机器语言机器 通常，将高级语言程序翻译成机器语言程序的软件成为翻译程序。翻译程序分为：编译程序，解释程序。编译程序：一次全部翻译成机器语言程序，然后交由机器执行。解释程序：边翻译，边执行。 高级语言机器 → → 汇编语言机器 → →机器语言机器 → →微指令系统 高级语言机器 → → 汇编语言机器 → →操作系统机器→ →机器语言机器 → →微指令系统 第1章：计算机系统概论1、计算机系统由哪两部分组成？计算机系统性能取决于什么？ 计算机系统是由“硬件”和“软件”组成。衡量一台计算机性能的优劣是根据多项技术指标综合确定的，既包括硬件的各种性能指标，又包括软件的各种功能。1）计算机系统由硬件和软件两部分组成。2）计算机系统性能由硬件和软件共同决定。 2、计算机系统5层层次结构从下到上由哪五层组成？哪些是物理机，哪些是虚拟机？ 1）微程序机器、传统机器、操作系统机器、汇编语言机器、高级语言机器2）微程序机器和传统机器是物理机，其他是虚拟机。 3、在计算机系统结构中，什么是翻译？什么是解释？ 1）翻译：将一种语言编写的程序全部翻译成另一种语言，然后再执行；2）解释：将一种语言编写的程序的一条语句翻译成另一种语言的一条或多条语句，然后执行，执行完这条语言后，再解释下一条。 4、什么是计算机体系结构？什么是计算机组成？以乘法指令为例说明二者区别。 1）计算机体系结构是指那些能够被程序员看到的计算机的属性。如指令集、数据类型等；2）计算机组成是指如何实现计算机体系结构所体现出来的属性；3）以乘法指令为例，计算机是否有乘法指令，属于体系结构的问题。乘法指令是采用专用的乘法器，还是使用加法器和移位器构成，属于计算机组成的问题。 5、冯诺依曼机器的主要特点？ 1）计算机由运算器、存储器、控制器、输入设备和输出设备五大部分组成；2）指令和数据存储在存储器中，并可以按地址访问；3）指令和数据均以二进制表示；4）指令由操作码和地址码构成，操作码指明操作的性质，地址码表示操作数在存储器中的位置；5）指令在存储器内按顺序存放，通常按自动的顺序取出执行；6）机器以运算器为中心，I/O设备与存储器交换数据也要通过运算器。（因此，后来有了以存储器为中心的计算机结构） 7、什么是存储单元、存储字、存储字长、存储体？ 存储单元：存储一个存储字并具有特定存储地址的存储单位；存储字：一个存储单元中存放的所有的二进制数据，按照某个地址访问某个存储单元获取的二进制数据。存储字长：存储字中二进制数据的位数，即按照某个地址访问某个存储单元获取的二进制数据的位数；存储体：由多个存储单元构成的存储器件。 8、主存储器中，什么是MAR，什么是MDR，存储器的最大容量由什么决定？ 1）MAR：存储地址寄存器，保存需要访问的存储单元地址。反映存储单元的个数。2）MDR：存储数据寄存器，缓存读出/写入存储单元的数据。反映存储字长。3）存储器的最大容量由MAR寄存器的位数和MDR寄存器的位数决定。 9、什么是机器字长，什么是存储字长长？ 机器字长：CPU一次能够处理的二进制数据的位数。存储字长：按照某个地址访问某个存储单元获取的二进制数据的位数。 10、假设MAR寄存器的位数为16位，MDR寄存器的位数为16位，存储器的最大容量是多少？ 1）MAR寄存器的位数为16位，能表示的地址个数为2的16次方，为64K；2）MDR寄存器的位数为16位，说明存储字长为16位，也即2个字节；3）存储器的最大容量为64K * 2B = 128K Byte 第三章 系统总线1、为什么要使用总线？ 在冯诺依曼结构中，各个部件之间均有单独连线，不仅线多，而且导致扩展I/O设备很不容易。即扩展一个I/O设备，需要连接很多线。因此，引入了总线连接方式，将多个设备连接在同一组总线上，构成设备之间的公共传输通道。 2、总线的两大基本特征是什么？ 1）共享：多个部件连接在同一组总线上，各个部件之间都通过该总线进行数据交换。2）分时：同一时刻，总线上只能传输一个部件发送的信息； 3、系统总线按照传输信息的不同，分成哪几类？是单向的，还是双向的？ 1）分成数据总线、地址总线以及控制总线。2）数据总线：各个功能部件之间传送数据信息，双向传输；3）地址总线：用来指明数据总线上，源数据或目的数据所在的主存单元的地址。单向：由CPU发出4）控制总线：用来发送各种控制信号。对于控制总线中的单根线，是单向的，即只能由一个部件发向另一个部件。而一组控制总线中，有输入也有输出，因此，控制总线也可以看成是双向的。 3、什么是总线宽度、总线带宽、总线复用、信号线数？ 1）总线宽度：数据总线的根数，一般是8的倍数。是衡量计算机系统性能的重要指标；2）总线带宽：即总线数据传输速率，总线上每秒能够传输的最大字节量。3）总线复用：一条信号线上分时传送两种信号。例如数据总线和地址总线的分时复用；4）信号线数：地址总线、数据总线和控制总线三种总线的线数之和。 4、假设总线的工作频率为33MHz，总线宽度为32位，则它最大的传输速率是多少？ 33 * （32/8） = 132 MB/s 5、简要说明单总线结构的概念及缺点？（现代计算机为什么要采用多总线结构？） 在单总线结构中，所有的部件（CPU、主存、I/O设备）都连接在一组总线上。但所有的信息传送都要通过这组总线，同时只能有一个部件向总线上发送信息，导致总线成为系统的瓶颈。因此，发展出来了多总线结构，其基本思想均是将速度相近的设备挂接在同一组总线上，总线之间通过总线控制器相连。例如CPU和Cache之间、I/O设备之间等。 6、集中式总线判优控制有哪三种方式，哪种方式的优先级不能改变？ 1）链式查询、计数器定时查询、以及独立请求。2）链式查询的优先级不能改变，离控制器最近的优先级最高。 8、什么是总线周期，分为哪几个阶段？ 1）总线周期：总线上两个部件完成一次完整且可靠的数据传输时间；2）分为四个阶段：申请分配阶段：申请总线寻址阶段：发出地址及有关命令传数阶段：进行数据交换结束：从总线上撤除信号，让出总线 9、什么是总线通信控制，总线通信控制有哪几种？ 1）总线通信控制：解决通信双方如何获知传输开始和传输结束，以及如何协调配合；2）同步通信、异步通信、半同步通信、分离式通信 10、什么是同步通信？其优点和缺点？ １）同步通信：总线上各个部件由统一的时钟信号控制；在总线周期中，每个时钟周期各个部件如何动作都有明确的规定。２）优点：速度快，各个模块间配合简单３）缺点：以总线上最慢的部件来设计公共时钟，影响总线效率。 11、什么是异步通信？异步通信分为哪几种类型？ 1）异步通信：总线上各部件没有统一的时钟标准，采用应答式通信；（主模块发出请求后，一直等到从模块反馈回来应答信号之后才开始通信）2）不互锁、半互锁、全互锁。（需要了解各种方式的含义） 12、什么是波特率？什么是比特率？（需要掌握如何计算波特率、比特率） 波特率：单位时间内传送的二进制数据数据的位数，单位bps比特率：单位时间内传送的有效的二进制位数。 13、异步通信时，常规需要设置的参数有哪些？ 波特率、停止位（1/2/1.5）、校验位（奇校验、偶校验、无校验） 14、简述半同步通信的基本原理。 半同步通信结合同步通信和异步通信。同步通信：采用统一的时钟，规定了在一定的时钟周期干什么事情；异步通信：如果从模块没有准备好，增加一个“等待响应”信号。 15、简述分离式通信的基本原理。 主模块发出地址和命令之后，放弃总线，在从模块准备数据期间，使得总线可以被其他设备所用。提高总线利用率。但是，这种方式控制比较复杂。 16、奇偶校验可以纠错吗？汉明码可以纠错码？ 1）奇偶校验只能检错，不能纠错。2）汉明码可以纠错。 第四章 存储器1、存储器按存取方式，可以分成哪四类？哪些属于随机访问存储器，哪些属于串行访问存储器？ 1）可以分为随机存储器、只读存储器、顺序存储器和直接存储器；2）随机存储器和只读存储器属于随机存储器，即存取时间与物理地址无关；3）顺序存储器（典型的如磁带）和直接存储器（典型的如磁盘）属于串行存储器，即存取时间与物理地址有关。 2、衡量存储器使用哪三个指标？寄存器、缓存、主存中，哪个速度最快？哪个最便宜？ 1）速度、容量、位价格。2）寄存器速度最快，主存最便宜。 3、常见的存储系统层次结构有哪两种？透明性如何？各自用来解决什么问题的？ 1）缓存-主存层次：用来缓解CPU和主存速度不匹配的问题，由硬件来完成，对所有的程序员完全透明。2）主存-辅存层次：用来解决主存容量不够的问题，由操作系统和硬件共同完成，对应用程序设计者透明，对系统程序设计者不透明。（现在一般存储器都即能按字访问，也能按照字节访问，因此，存储器编址时，每个字节都有一个独立的地址。） 4、字在存储单元中有两种存储方式，大端方式和小端方式。各是什么含义？x86采用的是哪种存储方式？ 1）大端方式：字的低位存在内存的高地址中，而字的高位存在内存的低地址中；2）小端方式：字的低位存在内存的低地址中，而字的高位存在内存的高地址中。3）x86CPU采用的是小端方式。 5、主存的三个主要技术指标 存储容量、存取速度和存储带宽 6、什么是存取时间？什么是存取周期？哪个大？ 1）存取时间：启动一次存储器完成本次操作（读或写）所需的时间；2）存取周期：连续两次启动存储器所需要的最小间隔时间；3）存取周期包含存取时间； 7、什么是存储器带宽？（要了解如何计算存储器带宽） 单位时间内存储器存取的信息量； 8、半导体存储芯片译码驱动包含哪两种方式，请简要说明。 1）线选法：所有的地址芯片通过一个译码器译码，选择一个存储单元的各位，适合于存储容量不大的芯片；2）重合法：将地址分为两组，每组通过一个译码器译码，选择行或列，行、列交叉处就是要访问的存储位。 9、随机存储器包含哪两大类？哪个需要刷新？请从速度、容量、价格等方面进行简要比较。 1）静态RAM：采用锁存器原理实现；2）动态RAM：采用电容原理实现，需要刷新。3）相比于动态RAM，静态RAM的速度快、容量小、价格高，一般用于缓存，而动态RAM一般用于内存。 10、只读存储器有哪几种？ 1）掩模ROM（MROM）：出厂后内容不能被更改。2）PROM：可编程只读存储器，可以进行一次性编程；3）EPROM：可擦除只读ROM，用紫外线照射；4）EEPROM：电可擦除只读ROM。6）FLash Memory：采用EEPROM的非易失性存储器。 11、单片存储器芯片的容量有限，很难满足实际需要，因此必须将若干存储芯片连接在一起才能组成足够容量的存储器。存储器的扩展通常有位扩展和字扩展，什么是字扩展，什么是位扩展？请举例简要说明 1）位扩展：增加存储器的字长，例如两个1K 4位的存储芯片构成1个1K8位的存储器；2）字扩展：增加存储器的字数，例如两个1K 8位的存储芯片构成1个2K 8位的存储器；通常字扩展和位扩展两种方式混合使用。 12、熟虑掌握存储器的扩展，包括地址空间分配、地址线的连接、数据线的连接、片选信号的产生及连接等；参看P94页，例4.1 13、假设欲检测的二进制代码为n位，为了使其具有1位的纠错能力，需添加K位检测位，组成n+k位的代码。问，应添加多少位检测位？ 应添加的检测位位数：2的k次方大于等于n+k+1。因为要使其有1位的检测能力，必须使用k位来说明n+k位到底哪一位出现了错误，k位能表达的数量为2的k次方，而n+k位到底哪一位出现了错误或者是全部正确，共有n+k+1种状况，因此，k的取值需要满足：2的k次方大于等于n+k+1 14、对于汉明码，应熟练掌握汉明码的编码方式（按照配偶或配奇的原则），以及给出汉明码，得到要传送的原始信息（包括纠错过程）。 15、提高访存速度的三种方式。 1）采用高速元器件；2）采用存储层次结构：cache-主存结构；3）调整主存结构：包括单体多字，多体并行两种方式。 16、简述单体多字的存储系统的工作原理，及其优点。 1）单体多字存储系统一次访存取出多个CPU字，即存储字为CPU字的n倍（假设一次访存取出n个cpu字）。2）优点是：显著提高了存储器带宽。 17、多体并行系统有哪两种编址方式？请简要说明其编址方式及其优点。 1）高位交叉编址方式：存储体的编址方式为顺序存储，即一个存储体存满后，再存入下一个；存储单元地址的高位为存储体的编号。高位交叉编址并不能提高单次访存速度，但能使多应用并行访存，提高系统的并发性。2）低位交叉编址方式：存储体的编址方式为交叉存储。即程序连续存放在相邻的存储体之中。存储单元地址的低位为存储体的编号。低位交叉编址能显著提高单次访存速度。 19、在四位低位交叉编址中，假设存取周期为T，总线传输周期为τ，为了实现流水线方式存储，应满足什么条件？如果连续读取四个字，所需要的时间是多少？ 1）T= 4τ2）连续读取四个字，所需要的时间为T + （4-1）τ注意：假设不是低位交叉编址，而是高位交叉编址，连续读取四个字所需要的时间仍然为4T。 20、需要大家掌握多体并行存储器在高位交叉编址（顺序存储）和低位交叉编址（交叉存储）的情况下，存储器带宽的计算方式。 21、在CPU和内存之间引入cache的原因。 1）避免cpu空等I/O访存；2）缓解CPU和主存速度不匹配的问题。 22、什么是程序的局部性原理。 CPU从主存取指令或数据，在一定时间内，只是对主存局部地址区域访问。 23、Cache命中率、平均访问时间以及访问效率的计算。 24、Cache写操作有哪两种方式？ 1）写直达法：写操作既写入Cache又写入主存；2）写回法：只把数据写入Cache而不写入主存，当Cache中数据被替换出去之后才写入主存。 25、将主存地址映射到Cache地址称为地址映射，常见的Cache映射方式有哪几种？ 直接映射、全相联映射、组相联映射。 26、直接映射的优缺点？ 优点：地址变换速度快。缺点：cache利用率不高，块冲突率高； 27、全相联映射的优缺点？ 优点：cache利用率高，块冲突率低。缺点：地址变换复杂，需要较多的硬件。 28、需要大家掌握各种映射方式之下，写出主存地址格式、cache地址格式，以及主存地址向cache地址的转换。 29、Cache常用的替换算法有哪些？哪个命中率最高？ 1）先进先出、近期最少使用算法和随机替换算法；2）命中率最高的是近期最少使用算法； 30、磁盘的三地址结构包括哪些？ 柱面、磁头号和扇区号 第五章 输入输出系统1、I/O系统的发展大致可以分为哪4个阶段？ 1）早期（分散连接、串行工作、程序查询）2）接口模块和DMA阶段（总线连接、并行工作、中断及DMA）3）通道阶段（通道是具有特殊功能的处理器）4）I/O处理机阶段I/O系统的发展实际上是逐步将CPU从繁重的I/O工作中解放出来的过程； 2、I/O设备编址有哪两种方式？各有什么优缺点？ 1）统一编址方式：和存储器统一编址，I/O地址作为存储器地址的一部分；无须用专用的I/O指令，但占用存储器空间。2）独立编址方式：和存储地址分开编址，需用专用的I/O指令。 3、I/O设备与主机的联络方式有哪几种？ I/O设备与主机间交互信息时必须了解彼此的状态。根据I/O设备工作速度的不同，可以分为3类：1）立即响应：不管其状态（认为其时刻准备好），适用于慢速设备。2）应答信号：通过应答信号来进行交互；3）同步时标：采用统一的时钟信号。 4、I/O总线包括哪四类？ 数据线、设备选择线、状态线、命令线 5、I/O设备通常使用D触发器（完成触发器）和B触发器（工作触发器）来标识设备所处的状态。D=0，B=0：暂停状态；D=0，B=1：准备状态D=1，B=0：就绪状态 6、程序查询的基本工作原理。 cpu不断去查询I/O设备状态，导致CPU和I/O设备串行工作。 7、什么是中断？ 计算机在执行程序过程中，当出现异常清空或特殊请求时，计算机停止现行程序的运行，转去处理这些异常清空或特殊请求，处理结束后，再返回现行程序的间断处，继续执行原程序，即为中断。 8、中断服务程序的基本流程包括哪四部分？ 1）保护现场2）中断服务3）恢复现场4）中断返回 9、什么是单重中断和多重中断？ 1）单重中断：不允许中断现行的中断服务程序；2）多重中断：允许级别更高的中断源中断现行的中断服务程序，也称为中断嵌套； 10、CPU响应中断的时机？ 当前指令执行完毕后，cpu发出中断查询信号，也就是说，中断响应一定是在每条指令执行结束之后进行的，不可能在指令执行过程中响应中断。 11、什么是DMA？ DMA：直接内存访问。在主存和I/O设备之间建立独立的总线连接。 12、在DMA方式中，由于DMA接口与CPU共享主存，可能会出现两者争用主存的冲突，为解决冲突，DMA和主存交换数据时，通常采用哪三种工作方式？ 1）停止CPU访问主存：DMA访存优先级高；2）周期挪用（窃取）：DMA挪用存储或窃取总线使用权一个或几个主存存取周期；3）DMA和CPU交替访问：将CPU工作周期分成两部分，一部分供DMA访存，一部分供CPU访存。 13、DMA工作过程包括哪三部分？ 1）预处理2）数据传输2）后处理 第六章 计算机的运算方法1、掌握有符号数的原码计算方法，以及通过原码求真值； 2、掌握补码计算的方法，以及通过补码求原码，然后求真值的方法。 1）通过原码求补码：符号位不变，各位取反，末位加1；2）通过补码求原码：符号位不变，各位取反，末位加1； 3、原码中0有2种表示方法（正零和负零），补码中0只有一种表示方法（正零和负零的表示方法一致） 4、假设有符号数的位数为8（包括符号位），补码能表示的真值的范围？ 补码能表示的真值范围为-128~+127（参见补码定义）5、掌握求反码以及移码的方法。 6、什么是定点表示？什么是浮点表示？ １）定点表示：小数点固定在某一位置的数为定点数；２）浮点表示：小数点位置可以浮动的数。 7、浮点数在机器中的表示形式，由哪几部分组成？ 由尾数、数符、阶码、阶符四部分组成。 8、掌握规格化浮点数的表示范围（最大正数、最小正数、最大负数、最小负数）的计算方法。 9、IEEE754标准规定的浮点数由哪几部分组成？ 由数符、阶码（含阶符）以及尾数组成。 10、IEEE754标准规定的浮点数中，阶码和尾数用什么形式表示？ 阶码用移码表示，其偏移量是2^(n-1)，尾数用原码表示。 11、float占多少位？double占多少位？ float为短实数，占32位，其中阶码8位，尾数23位。double为长实数，占64位，其中阶码占11位，尾数为52位。 12、对正数进行算术移位，当正数采用源码、补码、反码时，左移或右移时，低位或高位添补什么代码？ 对于正数，其源码、补码、反码均等于真值，左移时，低位添补0，右移时，高位添补0。 13、对负数进行算术移位，当负数采用源码、补码、反码时，左移或右移时，低位或高位添补什么代码？ 对于源码，左移或右移时，低位或高位均添补0；对于补码：左移时，低位添补0，右移时高位添补1对于反码：左移或右移时，低位或高位均添补1； 14、什么是逻辑移位？ 逻辑移位是对无符号数的移位，由于无符号数不存在符号位，左移时，高位移丢，低位补零。右移时，低位移丢，高位补零。 15、加法和减法时，什么情况下可能发生溢出？如何简单判断发生溢出？ 1）正数加正数，正数减负数，负数加负数，负数减正数时，可能会发生溢出。2）如果参加操作的两个数符号相同（转换成补码的加法），其结果与源操作数符号不同，即为溢出。3）如果补码采用1位符号位，如果最高有效位的进位和符号位的进位不同，则发生溢出。 16、定点乘法运算可以使用加法和移位来实现吗？ 可以。 17、浮点加减运算基本按照哪几步来进行？ 1）对阶：使小数点对齐；2）尾数求和：将对阶后的两个尾数按照定点加减运算规则求和；3）规格化：尾数规格化；4）舍入：尾数右规时，丢失数值位；5）溢出判断：判断结果是否溢出。 18、如何判断浮点运算结果是否溢出？ 阶码是否超出了其表示范围。（使用2个符号位判溢出） 第七章 指令系统1、什么是机器指令？什么是指令系统？1）机器指令：每一条机器语言的语句；2）指令系统：全部机器指令的集合。 2、一条指令包含哪两个主要部分？请简要说明各部分作用。1）操作码：指明指令要完成的操作；2）地址码：指明指令要操作的数据或数据来源； 3、操作码长度有固定长度和可变长度两种，各自有什么优点？1）固定长度：便于硬件设计，指令译码时间短；2）可变长度：压缩了操作码平均长度； 4、指令中地址码中的地址可以是哪些设备的地址？可以是主存地址、寄存器地址或I/O设备的地址； 5、指令中地址的个数可以有几个？四地址、三地址、二地址、一地址以及零地址。 6、假设指令中有四个地址、三个地址、两个地址以及一个地址，各自需要访存几次？1）四地址：访存4次；2）三地址：访存4次；3）两地址：访存3次；4）一地址：访存2次； 7、当使用寄存器代替指令字中的地址码字段后，有哪些优点？1）扩大指令字的寻址范围；2）缩短指令字长；3）减少访存次数 8、数据在存储器中存储时，为什么要按照边界对齐？减少访存次数。 9、寻址方式包括哪两类？1）指令寻址：下一条将要执行的指令的指令地址；2）数据寻址：确定本指令的操作数地址。 10、什么是形式地址？什么是有效地址？1）形式地址：指令的地址码字段通常都不代表操作数的真实地址，成为形式地址，记为A；2）有效地址：操作数的真实地址，记为EA，由寻址特征和形式地址共同决定； 11、了解各种寻址方式的概念及根据形式地址形成有效地址的方式。立即寻址、直接寻址、隐含寻址、间接寻址、寄存器寻址、寄存器间接寻址、基址寻址（隐式或显式）、变址寻址、相对寻址、堆栈寻址 12、什么是RISC？什么是CISC？RISC：精简指令集；CISC：复杂指令集；]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[常用模块]]></title>
    <url>%2Fpython%2Fflask%2Freadme%2F</url>
    <content type="text"><![CDATA[常用模块 pipenv # 虚拟环境 flask # 主要 路由、调试、web服务器网关接口子系统由 Werkzeug 提供。模板系统 Jinja2提供。 flask-wtf # 对独立的WTForms包进行了封装，用于表单处理 flask-sqlalchemy # 数据库框架，简化flask应用中使用 SQLAlchemy 操作， ORM 也可用其他 flask-migrate # 数据库迁移框架 flask-mail # 电子邮件支持 flask-login # 用于管理用户身份验证系统中的验证状态，且不依赖特定的身份验证机制 调试模式Flask 应用在 调试模式中运行， 默认加载 重载器和调试器， 重载器： 源码文件变动时，自动重启服务器 调试器： 当应用抛出未处理的异常，会出现在浏览器中。 千万不要在生产服务器中启动调试模式，启动调试模式可以要求输入 PIN 应用和请求上下文 变量名 上下文 说 明 current_app 应用上下文 当前应用的应用实例 g 应用上下文 处理请求时用作临时存储的对象，每次请求都会重设这个变量 request 请求上下文 请求对象，封装了客户端发出的 HTTP请求中的内容 session 请求上下文 用户会话，值为一个字典，存储请求之间需要 记住 的值]]></content>
      <categories>
        <category>flask</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[计算机概论]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Flearn_linux%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%A6%82%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[计算机概论计算机五大部分 输入单元 中央处理器 （控制器，运算器） 内存 输出单元 cpu 种类 精简指令集 （RISC） 复杂指令集 （CISC） CPU内部已经含有一小的指令集，我们所使用的软件都要经过 CPU 内部的微指令集来完成 精简指令集RISC比较精简，每个指令执行时间短，完成的操作也很单纯，指令的执行性能比较好，但要做复杂的事情，就要多个指令来完成（ ARM ） 复杂指令集CISC的微指令集中，每个小指令可以执行一些较低阶的硬件操作，指令数目多且复杂，每条指令的长度并不相同。每个指令花费时间长，但每条个别指令可以处理的工作比较丰富。（AMD INTEL 等 x86 架构 CPU ）(64 位的个人计算机CPU 统称为 x86_64 架构) 接口设备最重要的接口设备是主板，主板将所有的设备连接在一起，让它们能够协调通信 主板上最重要的组件 ： 主板芯片组 ，将所有设备汇聚在一起 计算机发展简史 电子管计算机 晶体管计算机 集成电路计算机 （计算机具备进入千家万户条件）IBM 推出兼容的产品 System/360 操作系统的雏形 超大规模集成电路计算机 （当前计算机） 计算机分类 超级计算机 # 天河二号等 大型计算机 # 去’IOE’ 微型计算机 # 小型机，普通服务器, 已经代替了传统大型机，成为大规模企业计算的中枢 工作站 # 比个人计算机更强大的性能 微电脑 （个人 pc ） 计算机上常用的计算单位大小单位理论上只认识0与1，0/1 的单位称为 bit，存储数据时，每份简单的数据都会使用 8 个 bit 来记录，称之为 Byte1Byte = 8 bitk M G T P 用来简化1024写法 速度单位CPU 常用 MHz 和 GHz ，(Hz 秒分之一) 网络上使用的 bit 为单位， 8Mbit/s ,转化为 Byte 为 1024 kB/s 或 1 MB/s 或 8Mbps ##]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IP地址]]></title>
    <url>%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fip%E5%9C%B0%E5%9D%80%2F</url>
    <content type="text"><![CDATA[ip 地址就是 网络中的 地址信息 IPv4 与 IPv6IPv4 格式 A.B.C.D 取值范围 0 ~ 255 2*32 个 IPv6 格式 A:B:C:D:E:F:G:H 十六进制 2*128 个 16*32 公网 ip 和 内网 ip公网内 ip 地址由 inter NIC 负责。公有地址全球唯一私有地址 是非注册地址，用于组织机构内部使用 私有地址范围 A 类 IP 地址 ：1.0.0.0-126.255.255.255 (私有ip 地址 10.0.0.0 ~ 10.255.255.255) B 类 IP 地址 ：128.1.0.1-191.255.255.254 (私有ip 地址 172.16.0.0 ~ 172.31.255.255 ） C 类 IP 地址 ：192.0.1.1-223.255.255.254 (私有ip 地址 192.168.0.0 ~ 192.168.255.255） 私有地址 不是由 internet分配的，不会出现在internet中。需要将私有 ip地址 转为 公网 IP 地址，与外部连接 （NAT）（私网地址访问互联网地址很方便，但互联网地址访问私有地址很困难） 内网的地址都是使用的路由器中的公共的公网ip来连接internet。 局域网内， IP 地址 是唯一的。但不同局域网， IP地址可以重复 localhost， 127.0.0.1 和 0.0.0.0 区别 localhost : 域名， windows默认将 localhost 指向127.0.0.1. 127.0.0.1 : 回环地址，凡是127 开头的 IP地址，都是回环地址（主机上发送给回环地址的数据 会自己接收，根本不传出去） 0.0.0.0 : 并不是一个真实的IP地址，他表示本机中所有的IPV4地址。监听本机所有的ip端口]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[给博客加日期]]></title>
    <url>%2Fpython%2F%E7%BB%99%E5%8D%9A%E5%AE%A2%E5%8A%A0%E6%97%A5%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[之前写文章，一直没有写时间，也没多大问题。后来换了一台电脑后，上传新文章全部乱了顺序。原来之前是按文件的创建时间排序，而我这复制过来的文件，创建时间几乎一样。所以博客乱了套。后来发现文件的修改时间还是以前的，于是给每篇文章，按修改时间添加了date。 代码如下12345678910111213141516171819import osimport sysimport timepath = r&apos;E:\WeiLai\OneDrive\blog\source\_posts&apos;for root, dir, files in os.walk(path): for file in files: full_path = os.path.join(root, file) if &apos;.md&apos; in full_path: mtime = os.stat(full_path).st_mtime file_modify_time = time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;, time.localtime(mtime)) date = &apos;date: &apos;+file_modify_time with open (full_path,&apos;r&apos;, encoding=&apos;UTF-8&apos;) as f: s = f.read() q = s.partition(&apos;tags:&apos;) t = q[0] + date +&apos;\n&apos; + q [1] + q[2] with open (full_path,&apos;w&apos;, encoding=&apos;UTF-8&apos;) as f: f.write(t)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql补充]]></title>
    <url>%2FMySQL%2Fmysql%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[MySQL应用架构的演变过程 单机单库 主从架构 分库分表 云数据库 MySql 体系架构 网络连接层 服务层 存储引擎层 系统文件层 日志文件 (错误日志show variables like ‘%log_error%’；通用查询日志show variables like ‘%general%’; 慢查询日志 show variables like ‘%slow_query%’; ) 数据文件 配置文件(my.conf,my.ini等)， pid 文件 (存放进程 id)， socket 文件 (可以不通过 TCP/IP 网络，而直接使用 unix socket 来连接 MySql) 日志系统 undo log redo log bin log]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用MySQL]]></title>
    <url>%2FMySQL%2F%E4%BD%BF%E7%94%A8MySQL%2F</url>
    <content type="text"><![CDATA[示例数据 https://codeload.github.com/datacharmer/test_db/zip/master导入 eg: mysql -u root -p &lt; employees.sql show variables like &#39;%datadir%&#39;; : 显示配置文件路径 set long_query_time=5; : 慢查询时间设置 连接到 MySQL \g 输出水平显示 \G 输出垂直显示 12mysql -h localhost -P 3306 -u root -p - 连接到mysqlALTER USER `root`@`localhost` IDENTIFIED BY &apos;password&apos;; - 修改密码 创建数据库数据库是许多表的集合，数据库服务器可以容纳许多这样的数据库 数据库服务器 → 数据库 → 表（由列定义） → 行 CREATE/ALTER/DROP/TRUNCATE 数据库对象（数据库和表） 称为 数据定义语言（DDL）操作 INSERT/UPDATE/DELETE /SELECT 称为 数据操作语言（DML） 前三项也称 写，SELECT 也称 读 COMMIT/ROLLBACK 事务控制语句 （TCL） 管理数据库中的事务 GRANT/REVOKE 数据控制语句（DCL） 对数据访问权进行控制的指令 1234567CREATE DATABASE company; - 创建数据库 建议都用 ``CREATE DATABASE `my.contacts`; - 用反标记字符 ``（当数据库和表含特殊字符时） USE `company`; - 使用 company 数据库mysql -u root -p company - 直接连接到 company 数据库SELECT DATABASE(); - 查找连接到的数据库SHOW DATABASES; - 查找有权访问的所有数据库SHOW VARIABLES LIKE &apos;company&apos;; - 获取当前的数据目录 sudo ls -lhtr /usr/lcoal/mysql/data/ 创建表1234567891011CREATE TABLE IF NOT EXISITS `company`.`customers`(`id` int unsigned AUTO_INCREMENT PRIMARY KEY,`first_name` varchar(20),`last_name` varchar(20),`country` varchar(20)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;SHOW TABLES - 查看所有表SHOW CREATE TABLE customers\G - 查看表结构DESC customers;CREATE TABLE new_costomers Like customers - 克隆表结构 增删改查参考 清空表的所有行最快的方式 TRUNCATE TABLE customers DDL操作。无法通过日志恢复delete TABLE customers 慢，但可以恢复 删除表： drop table customers 创建用户除非是localhost的管理任务等，一般不推荐使用root 用户连接到 mysql执行语句]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python操作mysql（增删改查）]]></title>
    <url>%2FMySQL%2Fpython%E6%93%8D%E4%BD%9Cmysql(%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5)%2F</url>
    <content type="text"><![CDATA[使用mysqlclient先安装mysqlclient网址：https://pypi.org/project/mysqlclient/python中可使用pip安装，pip install mysqlclient 也可以使用别的方法，详细可查看之前的文章：爬取百度百科词条写入数据库 python操作mysql查询数据1234567891011121314151617181920import MySQLdb# 获取连接connection = MySQLdb.connect( host = &apos;localhost&apos;, user = &apos;root&apos;, password = &apos;password&apos;, db = &apos;school&apos;, charset = &apos;utf8mb4&apos;, port = 3306 # 默认3306，可不填port)# 获取数据cursor = connection.cursor()cursor.execute(&apos;SELECT * FROM `students`ORDER BY `in_time`DESC;&apos;) result = cursor.fetchone() # 获取第一条数据print (result)# 关闭连接connection.close() 可能会出现异常，所以改写12345678910111213141516171819202122232425import MySQLdbtry:# 获取连接 connection = MySQLdb.connect( host = &apos;localhost&apos;, user = &apos;root&apos;, password = &apos;password&apos;, db = &apos;school&apos;, charset = &apos;utf8mb4&apos;, port = 3306 # 默认3306，可不填port ) # 获取数据 cursor = connection.cursor() cursor.execute(&apos;SELECT * FROM `students`ORDER BY `in_time`DESC;&apos;) result = cursor.fetchone() # 获取第一条数据 print (result)except MySQLdb.Error as e: print(&apos;Error : %s &apos; % e)finally: # 关闭连接 connection.close() 因为这个操作是所有都有的，所以封装成一个对象1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import MySQLdbclass MysqlSearch: def __init__(self): self.get_connection() def get_connection(self): try: self.connection = MySQLdb.connect( host = &apos;localhost&apos;, user = &apos;root&apos;, password = &apos;password&apos;, db = &apos;school&apos;, charset = &apos;utf8mb4&apos;, port = 3306 # 默认3306，可不填port ) except MySQLdb.Error as e: print(&apos;Error : %s &apos; % e) def close_connection(self): try: if self.connection: self.connection.close() except MySQLdb.Error as e: print(&apos;Error : %s &apos; % e) def get_one(self): # 获取会话指针 cursor = self.connection.cursor() # 准备sql sql = &apos;SELECT * FROM `students`WHERE`name`=%s ORDER BY `in_time`DESC;&apos; # 执行sql cursor.execute(sql,(&apos;weilai&apos;,)) # print(cursor.description) ## ((&apos;id&apos;, 3, 1, 11, 11, 0, 0), (&apos;name&apos;, 253, 6, 80, 80, 0, 0), ## (&apos;nickname&apos;, 253, 4, 80, 80, 0, 1), (&apos;sex&apos;, 254, 3, 4, 4, 0, 1), ## (&apos;in_time&apos;, 12, 19, 19, 19, 0, 1)) ## 获得一条结果 # a = [k[0] for k in cursor.description], ## a = [&apos;id&apos;, &apos;name&apos;, &apos;nickname&apos;, &apos;sex&apos;, &apos;in_time&apos;] # b = [k[0] for k in cursor.description],cursor.fetchone() ## ([&apos;id&apos;, &apos;name&apos;, &apos;nickname&apos;, &apos;sex&apos;, &apos;in_time&apos;], ## (7, &apos;weilai&apos;, &apos;imwl&apos;, &apos;男&apos;, datetime.datetime(2018, 12, 27, 22, 5, 41))) result = dict(zip([k[0] for k in cursor.description],cursor.fetchone())) # 关闭 cursor 和连接 cursor.close() self.close_connection() return result def get_more(self): cursor = self.connection.cursor() sql = &apos;SELECT * FROM `students`WHERE`name`=%s ORDER BY `in_time`DESC;&apos; cursor.execute(sql,(&apos;weilai&apos;,)) result = [dict(zip([k[0] for k in cursor.description],row)) for row in cursor.fetchall()] # print(result) # [&#123;&apos;id&apos;: 7, &apos;name&apos;: &apos;weilai&apos;, &apos;nickname&apos;: &apos;imwl&apos;, &apos;sex&apos;: &apos;男&apos;, &apos;in_time&apos;: datetime.datetime(2018, 12, 27, 22, 5, 41)&#125;, # &#123;&apos;id&apos;: 8, &apos;name&apos;:&apos;weilai&apos;, &apos;nickname&apos;: &apos;imwl&apos;, &apos;sex&apos;: &apos;男&apos;, &apos;in_time&apos;: datetime.datetime(2018, 12, 27, 22, 5, 41)&#125;, # &#123;&apos;id&apos;: 9, &apos;name&apos;: &apos;weilai&apos;, &apos;nickname&apos;: &apos;imwl&apos;, &apos;sex&apos;: &apos;男&apos;, &apos;in_time&apos;: datetime.datetime(2018, 12, 27, 22, 5, 41)&#125;] cursor.close() self.close_connection() return resultdef main(): obj = MysqlSearch() # a = obj.get_one() # print(a) # print(a[&apos;id&apos;]) b = obj.get_more() for item in b: print(item)if __name__ == &apos;__main__&apos;: main()# zip函数&apos;&apos;&apos;zip() 将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象，元素个数与最短的一致&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [4,5,6]&gt;&gt;&gt; c = [4,5,6,7,8]&gt;&gt;&gt; zipped = zip(a,b) # 返回一个对象&gt;&gt;&gt; zipped&lt;zip object at 0x103abc288&gt;&gt;&gt;&gt; list(zipped) # list() 转换为列表[(1, 4), (2, 5), (3, 6)]&gt;&gt;&gt; list(zip(a,c)) # 元素个数与最短的列表一致[(1, 4), (2, 5), (3, 6)] &gt;&gt;&gt; a1, a2 = zip(*zip(a,b)) # 与 zip 相反，zip(*) 可理解为解压，返回二维矩阵式&gt;&gt;&gt; list(a1)[1, 2, 3]&gt;&gt;&gt; list(a2)[4, 5, 6]&apos;&apos;&apos; ** 补充(分页查询)：12345678910111213141516def get_more_by_pages(self, page, page_size): # 分页查询数据 offset = (page -1) * page_size cursor = self.connection.cursor() sql = &apos;SELECT * FROM `students`WHERE`name`=%s ORDER BY `in_time`DESC LIMIT %s , %s;&apos; cursor.execute(sql,(&apos;weilai&apos;, offset, page_size)) result = [dict(zip([k[0] for k in cursor.description],row)) for row in cursor.fetchall()] # print(result) # [&#123;&apos;id&apos;: 7, &apos;name&apos;: &apos;weilai&apos;, &apos;nickname&apos;: &apos;imwl&apos;, &apos;sex&apos;: &apos;男&apos;, &apos;in_time&apos;: datetime.datetime(2018, 12, 27, 22, 5, 41)&#125;, # &#123;&apos;id&apos;: 8, &apos;name&apos;:&apos;weilai&apos;, &apos;nickname&apos;: &apos;imwl&apos;, &apos;sex&apos;: &apos;男&apos;, &apos;in_time&apos;: datetime.datetime(2018, 12, 27, 22, 5, 41)&#125;, # &#123;&apos;id&apos;: 9, &apos;name&apos;: &apos;weilai&apos;, &apos;nickname&apos;: &apos;imwl&apos;, &apos;sex&apos;: &apos;男&apos;, &apos;in_time&apos;: datetime.datetime(2018, 12, 27, 22, 5, 41)&#125;] cursor.close() self.close_connection() return result 新增/修改数据到数据库出现问题不应该提交 12345678910111213141516171819202122def add_one(self): # 准备SQL try: sql = ( &quot;INSERT INTO `students` (`name`,`nickname`,`sex`,`in_time`) VALUE&quot; &quot;(%s,%s,%s,%s);&quot; ) cursor = self.connection.cursor() # 可以提交多条 cursor.execute(sql,(&apos;name1&apos;, &apos;nickname1&apos;, &apos;男&apos;, None)) cursor.execute(sql,(&apos;name2&apos;, &apos;nickname2&apos;, &apos;男&apos;, &apos;haha&apos;)) # 提交事务 self.connection.commit() # 关闭cursor和连接 cursor.close() except MySQLdb.Error as e: print(&apos;Error : %s &apos; % e) self.connection.rollback() self.close_connection()]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql基础(1)]]></title>
    <url>%2FMySQL%2Fmysql%E5%9F%BA%E7%A1%80(1)%2F</url>
    <content type="text"><![CDATA[windows安装过程参考之前的文章https://www.jianshu.com/p/e35185ec3294 MySQL语法基础创建表– 为注释，不会被执行 使用查询语句建表12345678910111213141516171819202122232425-- 新建数据库CREATE DATABASE `school`;-- 使用数据库USE `school`;-- 创建表格-- id-- name-- nickname-- sex-- in_timeCREATE TABLE `students`( `id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, `name` VARCHAR(20) NOT NULL, `nickname` VARCHAR(20) NULL, `sex` CHAR(1) NULL, `in_time` DATETIME NULL) DEFAULT CHARSET &apos;UTF8MB4&apos;;-- PRIMARY KEY 主键是用来唯一定位记录的,特殊索引-- 建议不使用任何业务相关的字段作为主键-- 在students表中添加一个class idALTER TABLE `school`.`students`ADD COLUMN `class id` int NULL AFTER `id`; 插入数据12345678910111213-- 插入students表 -- now():mysql中当前时间INSERT INTO `students` VALUE(1,&apos;weilai&apos;,&apos;imwl&apos;,&apos;男&apos;,now());-- 可以选择性插入INSERT INTO `students`(`name`,`nickname`,`sex`,`in_time`) VALUES(&apos;weilai&apos;,&apos;imwl&apos;,&apos;男&apos;,now());-- 插入多行数据INSERT INTO `students`(`name`,`nickname`,`sex`,`in_time`) VALUES(&apos;weilai2&apos;,&apos;imwl&apos;,&apos;男&apos;,now()),(&apos;weilai&apos;,&apos;imwl&apos;,&apos;男&apos;,now()),(&apos;weilai&apos;,&apos;imwl&apos;,&apos;男&apos;,now()),(&apos;weilai&apos;,&apos;imwl&apos;,&apos;男&apos;,now()); 查询数据select * from student where binary name = ‘imwl’; # 加上 binary 区分大小写1234567891011121314151617-- 查询数据库-- * 表示所有的SELECT * FROM `students`;-- 只查询name 和 nicknameSELECT `name`,`nickname` FROM `students`;-- 只查询name 和 nickname,同时性别为男的(查询表中不显示男)SELECT `name`,`nickname` FROM `students` WHERE `sex`=&apos;男&apos;;-- 在上面基础上id倒序SELECT `id`,`name`,`nickname` FROM `students` WHERE `sex`=&apos;男&apos;ORDER BY `id` DESC;-- 在上面基础上分页-- 0，2 : 从第1条数据开始，显示2条SELECT `id`,`name`,`nickname` FROM `students` WHERE `sex`=&apos;男&apos;ORDER BY `id` DESC LIMIT 0,2;-- 1,2 : 从第2条数据开始，显示2条SELECT `id`,`name`,`nickname` FROM `students` WHERE `sex`=&apos;男&apos;ORDER BY `id` DESC LIMIT 1,2; 修改数据where 很重要，不然就是改动整张表的数据123456789-- 修改-- 将所有的性别改女UPDATE `students` SET `sex`=&apos;女&apos;;-- 将name为weilai 的性别回男UPDATE `students` SET `sex`=&apos;男&apos; WHERE `name` = &apos;weilai&apos;;-- 将name为weilai 的性别为男,nickname改为没有昵称UPDATE `students` SET `sex`=&apos;男&apos;,`nickname`=&apos;没有昵称&apos; WHERE `name` = &apos;weilai&apos;;-- 将id &lt;3 的性别改为女UPDATE `students` SET `sex`=&apos;女&apos; WHERE `id` &lt; 3 删除数据 123456-- 删除数据 -- 删除students表中，性别为女的数据DELETE FROM `students` WHERE `sex` = &apos;女&apos;-- 删除students表中全部数据DELETE FROM `students`TRUNCATE TABLE student]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python操作mysql(ORM)]]></title>
    <url>%2FMySQL%2Fpython%E6%93%8D%E4%BD%9Cmysql(ORM)%2F</url>
    <content type="text"><![CDATA[使用SQLAlchemy 安装方法pip install SQLAlchemy 更多内容参考flask鱼书项目 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127from sqlalchemy import create_enginefrom sqlalchemy.ext.declarative import declarative_base from sqlalchemy import Column, Integer, String ,DateTime, Boolean# 连接数据库engine = create_engine(&apos;mysql://root:password@localhost:3306/school?charset=utf8&apos;)## 编码问题# # 获取基类Base = declarative_base()class News(Base): # 继承基类 __tablename__ = &apos;students1&apos; id = Column(Integer, primary_key = True) nickname = Column(String(20)) name = Column(String(20), nullable = False) sex = Column(String(1)) in_time = Column(DateTime) is_vaild = Column(Boolean) idcard = Column(Integer, unique = True) News.metadata.create_all(engine) # 创建表格## 新增数据from sqlalchemy.orm import sessionmakerSession = sessionmaker(bind=engine)class OrmTest(object): def __init__(self): self.session = Session() def add_one(self): new_obj = News( nickname = &apos;123&apos;, name = &apos;321&apos;, sex = &apos;男&apos;, ) self.session.add(new_obj) self.session.commit() return new_obj def add_more(self): new_obj = News( nickname = &apos;123&apos;, name = &apos;321&apos;, sex = &apos;男&apos;, ) new_obj2 = News( nickname = &apos;wei&apos;, name = &apos;lai&apos;, sex = &apos;女&apos;, ) self.session.add_all([new_obj, new_obj2]) self.session.commit() return new_obj## 查询数据 def get_one(self): return self.session.query(News).get(10) # get 是选id为2的 def get_more(self): return self.session.query(News).filter_by(is_vaild=True)## 修改数据## 将一条当作多条的一种情况 def update_data(self): data_list = self.session.query(News).filter(News.id &gt;= 5) for item in data_list: if item: item.is_vaild = 0 self.session.add(item) # 加入 self.session.commit() # 提交## filter 与 filter_by 的区别## 删除数据 def delete_data(self): data = self.session.query(News).get(8) if data: self.session.delete(data) self.session.commit() else: return False def delete_data_more(self): delete_list = self.session.query(News).filter(News.id &lt;= 5) for item in delete_list: if item: self.session.delete(item) else: return False self.session.commit() def main(): obj = OrmTest() obj.add_one() obj.add_more() data = obj.get_one() ## 防止查询失误 if data: print(&apos;ID:&#123;0&#125; &#123;1&#125;&apos;.format(data.id,data.sex)) else: print(&apos;Not exist&apos;) data_more = obj.get_more() print(data_more.count()) # 计数 for new_obj in data_more: print(&apos;ID:&#123;0&#125; &#123;1&#125; &#123;2&#125; &#123;3&#125;&apos;.format(new_obj.id,new_obj.sex,new_obj.name,new_obj.nickname)) obj.update_data() print(&apos;数据修改成功&apos;) obj.delete_data() print(&apos;数据删除成功&apos;) obj.delete_data_more()if __name__ == &apos;__main__&apos;: main()]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql基础(3)]]></title>
    <url>%2FMySQL%2Fmysql%E5%9F%BA%E7%A1%80(3)%2F</url>
    <content type="text"><![CDATA[多表联查 使用多表查询可以获取M x N行记录（M,N为两个表各自的行数）多表查询的结果集可能非常巨大，要小心使用。 内连接123456789101112131415mysql&gt; SELECT s.id, s.name,`s`.`class id`, s.nickname,s.sex,c.name,s.in_time,s.is_vaild FROM students s INNER JOIN class c ON `s`.`class id` = c.id;+----+---------+----------+-----------+------+--------------+---------------------+----------+| id | name | class id | nickname | sex | name | in_time | is_vaild |+----+---------+----------+-----------+------+--------------+---------------------+----------+| 7 | weilai | 202 | imwl | 男 | 二年二班 | 2018-12-27 22:05:41 | 1 || 8 | weilai | 202 | imwl | 男 | 二年二班 | 2018-12-27 22:05:41 | 2 || 9 | weilai | 202 | imwl | 男 | 二年二班 | 2018-12-27 22:05:41 | NULL || 10 | weilai2 | 201 | imwl | 男 | 二年一班 | 2018-12-27 22:05:41 | NULL || 12 | name1 | 201 | nickname1 | 女 | 二年一班 | NULL | NULL || 13 | name2 | 201 | nickname2 | 男 | 二年一班 | NULL | NULL || 19 | 2 | 301 | i | 男 | 三年一班 | 2019-02-27 12:02:04 | NULL || 20 | 3 | 301 | m | 女 | 三年一班 | 2019-02-27 12:02:04 | NULL || 21 | 4 | 302 | w | 男 | 三年二班 | 2019-02-27 12:02:04 | NULL || 22 | 5 | 302 | l | 男 | 三年二班 | 2019-02-27 12:02:04 | NULL |+----+---------+----------+-----------+------+--------------+---------------------+----------+ INNER JOIN查询的写法是： 先确定主表，仍然使用FROM &lt;表1&gt;的语法；再确定需要连接的表，使用INNER JOIN &lt;表2&gt;的语法；然后确定连接条件，使用ON &lt;条件...&gt;，这里的条件是s.class id = c.id，表示students表的class id列与class表的id列相同的行需要连接；可选：加上WHERE子句、ORDER BY等子句。 小结JOIN查询需要先确定主表，然后把另一个表的数据“附加”到结果集上； INNER JOIN是最常用的一种JOIN查询，它的语法是SELECT ... FROM &lt;表1&gt; INNER JOIN &lt;表2&gt; ON &lt;条件...&gt;； JOIN查询仍然可以使用WHERE条件和ORDER BY排序。 补充知识假设查询语句是： 1SELECT ... FROM tableA ??? JOIN tableB ON tableA.column1 = tableB.column2; 我们把tableA看作左表，把tableB看成右表，那么INNER JOIN是选出两张表都存在的记录： LEFT OUTER JOIN是选出左表存在的记录： RIGHT OUTER JOIN是选出右表存在的记录： FULL OUTER JOIN则是选出左右表都存在的记录：]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql基础(2)]]></title>
    <url>%2FMySQL%2Fmysql%E5%9F%BA%E7%A1%80(2)%2F</url>
    <content type="text"><![CDATA[外键在students表中，通过class id的字段，可以把数据与另一张表（class）关联起来，这种列称为外键。 在students表中添加一个class id(id的后一列)12ALTER TABLE `school`.`students`ADD COLUMN `class id` int NULL AFTER `id`; 在数据库school中建立一个班级表1234CREATE TABLE `students`( `class id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, `name` VARCHAR(20) NOT NULL,) DEFAULT CHARSET &apos;UTF8&apos;; 添加/删除 外键12345678910111213ALTER TABLE `students`ADD CONSTRAINT `qe`-- 外键约束名称，随意取值 FOREIGN KEY (`class id`)REFERENCES `class` (`id`);-- ALTER TABLE `school`.`students` -- ADD FOREIGN KEY (`class id`) REFERENCES `school`.`class` (`id`);-- 删除外键ALTER TABLE `students`DROP FOREIGN KEY `qe`;删除外键约束并没有删除外键这一列。删除列是通过DROP COLUMN ...实现的 通过中间表，可以定义了一个“多对多”关系。 一对一：一个表的记录对应到另一个表的唯一一个记录 有一些应用会把一个大表拆成两个一对一的表，目的是把经常读取和不经常读取的字段分开，以获得更高的性能。例如，把一个大的用户表分拆为用户基本信息表user_info和用户详细信息表user_profiles，大部分时候，只需要查询user_info表，并不需要查询user_profiles表，这样就提高了查询速度 索引在查找记录的时候，想要获得非常快的速度，就需要使用索引123456ALTER TABLE `school`.`students` ADD INDEX `sex search`(`sex`); -- 名称为sex search，使用列 sex 的索引-- 也可以多列ALTER TABLE `school`.`students` ADD INDEX `search`(`sex`，`name`); 索引的效率取决于索引列的值是否散列，例如sex列，大约一半的记录值是男，另一半是女，因此，对该列创建索引就没有意义。123ALTER TABLE `school`.`students` DROP INDEX `sex search`;-- 删除索引 **假设name不重复，那么可以创建唯一索引1ADD UNIQUE INDEX `search`(`name`) **没索引，但对is_vaild进行唯一约束12ALTER TABLE studentsADD CONSTRAINT uni_name UNIQUE (is_vaild); 通过对数据库表创建索引，可以提高查询速度。 通过创建唯一索引，可以保证某一列的值具有唯一性。 数据库索引对于用户和应用程序来说都是透明的。 查询补充12345SELECT * FROM `students` WHERE `id` &gt;= 10 AND `sex` != &apos;女&apos; GROUP BY `id` HAVING `in_time` ORDER BY `id` DESC LIMIT 0,3;SELECT COUNT(*) num FROM `students` WHERE NOT `id` &gt;= 10 AND `sex` != &apos;女&apos; ORDER BY `id` DESC LIMIT 0,8 ;SELECT AVG(id) num FROM `students` WHERE NOT `id` &gt;= 10 AND `sex` != &apos;女&apos; ORDER BY `id` DESC LIMIT 0,8 ;]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库]]></title>
    <url>%2FMySQL%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[数据库分类 关系型数据库 （MySQL,SQLServer,MariaDB,ORACLE等） 非关系型数据库 (mongoDB,redis等） 非关系型数据库分类1 . 文档型2 . key-value型3 . 列式数据库4 . 图形数据库]]></content>
      <categories>
        <category>mysql学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2017-2018年总结(初版)]]></title>
    <url>%2F%E9%9A%8F%E7%AC%94%2F2017-2018%20%E6%80%BB%E7%BB%93(%E5%88%9D%E7%89%88)%2F</url>
    <content type="text"><![CDATA[本打算写一个2018年总结，想了一下，觉得还是从学生时代结束后开始写比较好。 从2017-07到现在2019-01，没想到竟然已经18个月了。这18个月，真的算是，对自己一个磨练。所以之前元旦所说的空空如也，并不完全正确，至少在某些方面，确实还有点进步。(2018-10应该算是一个比较重要的分水岭吧) 粗略分为4个方面工作方面准确来说，目前从事过两份工作。 2017-08 至 2017-12。毕业后在某研究所工作。刚开始得到这个工作机会的时候还是挺开心的，毕竟做毕设拿院优，他们的软件占很大成分；同事之间相处也很和睦。主要工作就是给客户解决软件以及设计上的问题，时常需要出差。这工作太闲了，所以当时一直在胡思乱想。后来，我认真思考了一下以后的出路，如果继续这一行，好像只有去做设计了，而我对设计确实没什么兴趣。(一到冬天我就不想呆在济南的原因,可能就是因为雾霾吧。那个地方雾霾比济南还严重，所以就提出了辞职。） 2018-04至2019-01。亲戚介绍了一份工作。当时我其实不想去的，但当时已经在家闲置了快3个月。加上确实很迷茫，不知道以后该干嘛。还有当时说先去看看，然后就过去了。刚开始抱着学习技术的态度去的，后来发现自己多虑了。我从没有想过会从事这么久，期间真的无数次想辞职。刚开始碍于情面，所以不曾开口。后来又因为惰性，习惯了。目前看来，从事这么久的主要原因:一是确实很闲，平常帮师傅们打打下手啥的；二是旅游耗费了太多钱财，弄得经济困难；三是，国庆后，开始认真学习python，有时间学习。 学习方面第一个工作阶段，确实很充实，每天都在自学（职业相关的），即使现在对我而言一点意义都没有了。 第二个工作阶段，到国庆前，即使很闲，但也基本没有主动学习过；国庆后开始感觉自己的学习效率在逐渐提高，也有学习的意识了。在此期间，搭建了自己的个人博客来记录，网址为：https://itswl.github.io 生活方面没有以前那么慵懒了，变得更加的独立。 17年的时候，想着爬华山，看兵马俑，逛陕博，但又因为一个人，懒得行动。心想着不急，终究会去的，结果离开了也未曾去过。 今年得知，张家界离这里不远。（以前外公曾说，等我们初中的时候，就带我们去张家界玩，结果到现在还没带我们去。我都不知道是不是他不记得了，我中秋的时候回去也忘记提这件事了。）然后五一期间，就一个人去了。去了发现凤凰也不远，于是也去了凤凰。算是一个开端吧。 当然还有一个特别重大的事：我从2018-8到现在一滴可乐都没喝过。我并不觉得可乐会带来什么危害，不喝可乐，只是单纯的为了克制一下自己那种欲望。 思想上面我觉得一个人最大的进步就是思想上面的，当然只是我个人现在的想法。挺怀恋刚毕业的时候，自信，洒脱。也享受孤独的感觉，能在元旦的晚上冻成狗，也能在群处怡然自得。更加包容多元，更加心平气和。 总结既然是总结，那么总结一下。不好的地方:浪费了太多时间，当断不断。 好的地方：戒掉了可乐，开始养生，有了学习的意识。变得更加的独立，也不会感到孤独。 期待:2019，能够真的成长吧 补(一)读万卷书，行万里路，真的是很有用的话。行，使我开阔；读书使我静下心。 补(二)今年春运，本着学习爬虫看一下12306，结果还是使用了他人的软件，帮别人买了10多张张春运票，也能算是比较有成就感吧。 补(三)]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫整理（四）多进程分布式与异步]]></title>
    <url>%2Fpython%2F%E7%88%AC%E8%99%AB%E6%95%B4%E7%90%86-(%E5%9B%9B)-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8E%E5%BC%82%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[有的时候，爬取速度不快，就要想一些其他的办法。比如多进程多线程以及异步。不过一般的网站都会对其有限制，所以还得看实际情况具体来选取爬虫方式。爬虫并不复杂。爬虫更关键的是在，爬虫，反爬虫和反反爬虫这一块。 多进程分布式与异步的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960from urllib.request import urlopen, urljoinfrom bs4 import BeautifulSoupimport multiprocessing as mpimport reimport timedef crawl(url): response = urlopen(url) time.sleep(0.1) # slightly delay for downloading return response.read().decode()def parse(html): soup = BeautifulSoup(html, &apos;lxml&apos;) urls = soup.find_all(&apos;a&apos;, &#123;&quot;href&quot;: re.compile(&apos;^/.+?/$&apos;)&#125;) title = soup.find(&apos;h1&apos;).get_text().strip() page_urls = set([urljoin(base_url, url[&apos;href&apos;]) for url in urls]) # remove duplication url = soup.find(&apos;meta&apos;, &#123;&apos;property&apos;: &quot;og:url&quot;&#125;)[&apos;content&apos;] return title, page_urls, urlif __name__ == &apos;__main__&apos;: base_url = &apos;https://morvanzhou.github.io/&apos; # base_url = &quot;http://127.0.0.1:4000/&quot; # DON&apos;T OVER CRAWL THE WEBSITE OR YOU MAY NEVER VISIT AGAIN if base_url != &quot;http://127.0.0.1:4000/&quot;: restricted_crawl = True else: restricted_crawl = False unseen = set([base_url,]) seen = set() pool = mp.Pool(4) # number strongly affected count, t1 = 1, time.time() while len(unseen) != 0: # still get some url to visit if restricted_crawl and len(seen) &gt; 20: break print(&apos;\nDistributed Crawling...&apos;) crawl_jobs = [pool.apply_async(crawl, args=(url,)) for url in unseen] htmls = [j.get() for j in crawl_jobs] # request connection htmls = [h for h in htmls if h is not None] # remove None print(&apos;\nDistributed Parsing...&apos;) parse_jobs = [pool.apply_async(parse, args=(html,)) for html in htmls] results = [j.get() for j in parse_jobs] # parse html print(&apos;\nAnalysing...&apos;) seen.update(unseen) unseen.clear() for title, page_urls, url in results: print(count, title, url) count += 1 unseen.update(page_urls - seen) print(&apos;Total time: %.1f s&apos; % (time.time()-t1, )) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import aiohttpimport asyncioimport timefrom bs4 import BeautifulSoupfrom urllib.request import urljoinimport reimport multiprocessing as mpbase_url = &quot;https://morvanzhou.github.io/&quot;# base_url = &quot;http://127.0.0.1:4000/&quot;# DON&apos;T OVER CRAWL THE WEBSITE OR YOU MAY NEVER VISIT AGAINif base_url != &quot;http://127.0.0.1:4000/&quot;: restricted_crawl = Trueelse: restricted_crawl = Falseseen = set()unseen = set([base_url])def parse(html): soup = BeautifulSoup(html, &apos;lxml&apos;) urls = soup.find_all(&apos;a&apos;, &#123;&quot;href&quot;: re.compile(&apos;^/.+?/$&apos;)&#125;) title = soup.find(&apos;h1&apos;).get_text().strip() page_urls = set([urljoin(base_url, url[&apos;href&apos;]) for url in urls]) url = soup.find(&apos;meta&apos;, &#123;&apos;property&apos;: &quot;og:url&quot;&#125;)[&apos;content&apos;] return title, page_urls, urlasync def crawl(url, session): r = await session.get(url) html = await r.text() await asyncio.sleep(0.1) # slightly delay for downloading return htmlasync def main(loop): pool = mp.Pool(2) # slightly affected async with aiohttp.ClientSession() as session: count = 1 while len(unseen) != 0: if restricted_crawl and len(seen) &gt; 20: break tasks = [loop.create_task(crawl(url, session)) for url in unseen] finished, unfinished = await asyncio.wait(tasks) htmls = [f.result() for f in finished] parse_jobs = [pool.apply_async(parse, args=(html,)) for html in htmls] results = [j.get() for j in parse_jobs] seen.update(unseen) unseen.clear() for title, page_urls, url in results: print(count, title, url) unseen.update(page_urls - seen) count += 1if __name__ == &quot;__main__&quot;: t1 = time.time() loop = asyncio.get_event_loop() loop.run_until_complete(main(loop)) loop.close() print(&quot;Async total time: &quot;, time.time() - t1)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬取百度百科词条写入数据库]]></title>
    <url>%2Fpython%2F%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E7%99%BE%E7%A7%91%E8%AF%8D%E6%9D%A1%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[这是在把百度百科上从一个词条中，随机选择一个关键字，然后从这个关键词的词条中，继续这样一个步骤，同时保存到数据库。如果遇到某词条下没有其他关键字，就会返回到上一个关键字处，目前有一个问题，就是两条关键词都只有一个的话，会进入循环。数据库中可以设置url唯一数据库这一块的操作，得先安装pymysql。直接使用pip安装即可。随机数random是python自带的。 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from bs4 import BeautifulSoupfrom urllib.request import urlopenimport reimport randomimport pymysql.cursors # 数据库base_url = &quot;https://baike.baidu.com&quot;his = [&quot;/item/%E5%8F%B2%E8%AE%B0&quot;]for i in range(1000): # dealing with Chinese symbols url = base_url + his[-1] html = urlopen(url).read().decode(&apos;utf-8&apos;) soup = BeautifulSoup(html, features=&apos;lxml&apos;) print(i, soup.find(&apos;h1&apos;).get_text(), &apos; url: &apos;, url) # find valid urls sub_urls = soup.find_all(&quot;a&quot;, &#123;&quot;target&quot;: &quot;_blank&quot;, &quot;href&quot;: re.compile(&quot;/item/(%.&#123;2&#125;)+$&quot;)&#125;) if len(sub_urls) != 0: his.append(random.sample(sub_urls, 1)[0][&apos;href&apos;]) else: # no valid sub link found his.pop()# 链接数据库 connection = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, password = &apos;password&apos;, db = &apos;baikeurl&apos;, charset = &apos;utf8mb4&apos;, ) try: # 获取会话指针 with connection.cursor() as cursor: # 创建sql 语句 sql = &apos;insert into `urls`(`urlname`,`urlhref`)values(%s,%s)&apos; # 执行sql 语句 cursor.execute(sql,(soup.find(&apos;h1&apos;).get_text(),url)) # 提交 connection.commit() except: pass finally: connection.close() 读取数据库12345678910111213141516171819202122import pymysql.cursorsconnection = pymysql.connect(host = &apos;localhost&apos;, user = &apos;root&apos;, password = &apos;password&apos;, db = &apos;baikeurl&apos;, charset = &apos;utf8mb4&apos;, )try: # 获取会话指针 with connection.cursor() as cursor: # 查询sql 语句 sql = &apos;select `urlname` , `urlhref` from `urls` where `id` is not null&apos; # 执行sql 语句 conut = cursor.execute(sql) print(conut) # result = cursor.fetchall() # print(result)finally: connection.close()]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读取TXT_PDF]]></title>
    <url>%2Fpython%2F%E8%AF%BB%E5%8F%96TXT_PDF%2F</url>
    <content type="text"><![CDATA[这个是我学习爬取TXT和PDF的代码，前半段是读取TXT，后半段是读取PDF，PDF中使用了第三方库，pdfminer3k,使用pip安装即可。pip install pdfminer3k。PDF其中注释掉的为读取网络上的PDF文档。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from urllib import requestfrom pdfminer.pdfdevice import PDFDevicefrom pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManagerfrom pdfminer.pdfparser import PDFDocument, PDFParserfrom pdfminer.converter import PDFPageAggregatorfrom pdfminer.layout import LAParams# html = request.urlopen(# &apos;https://en.wikipedia.org/robots.txt&apos;# ).read().decode(&apos;utf-8&apos;)# print(html) # 读取txt# fp = open(&apos;./practice/byte-of-python-chinese-edition.pdf&apos;,&apos;rb&apos;) # 获取文档对象fp = request.urlopen(&apos;https://q.stock.sohu.com/newpdf/201831703172.pdf&apos;) # 读取网络pdfparser = PDFParser(fp) # 创建一个与文档关联的解释器doc = PDFDocument() # 文档对象# 链接解释器和文档对象parser.set_document(doc)doc.set_parser(parser)# 初始化文档doc.initialize() # 可接收文档密码resource = PDFResourceManager() # 创建PDF资源管理器laparam = LAParams() # 参数分析器device = PDFPageAggregator(resource,laparams=laparam)# 创建一个聚合器interpreter = PDFPageInterpreter(resource,device)# 创建 PDF页面解释器# 使用文档对象得到页面的集合for page in doc.get_pages(): # 使用页面解释器来读取 interpreter.process_page(page) # 使用聚合器来获取内容 layout = device.get_result() for out in layout: if hasattr(out,&apos;get_text&apos;): # 有没有这个属性 print(out.get_text())]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫整理（五）slenium]]></title>
    <url>%2Fpython%2F%E7%88%AC%E8%99%AB%E6%95%B4%E7%90%86-(%E4%BA%94)--slenium%2F</url>
    <content type="text"><![CDATA[首先使用pip安装并加入环境变量123456789101112131415161718192021222324from selenium import webdriverfrom selenium.webdriver.chrome.options import Options# firefox plugin# https://askubuntu.com/questions/870530/how-to-install-geckodriver-in-ubuntu# hide browser windowchrome_options = Options()chrome_options.add_argument(&quot;--headless&quot;) # define headless# add the option when creating driverdriver = webdriver.Chrome(chrome_options=chrome_options)driver.get(&quot;https://morvanzhou.github.io/&quot;)driver.find_element_by_xpath(u&quot;//img[@alt=&apos;强化学习 (Reinforcement Learning)&apos;]&quot;).click()driver.find_element_by_link_text(&quot;About&quot;).click()driver.find_element_by_link_text(u&quot;赞助&quot;).click()driver.find_element_by_link_text(u&quot;教程 ▾&quot;).click()driver.find_element_by_link_text(u&quot;数据处理 ▾&quot;).click()driver.find_element_by_link_text(u&quot;网页爬虫&quot;).click()print(driver.page_source[:200])driver.get_screenshot_as_file(&quot;./img/sreenshot2.png&quot;)driver.close()print(&apos;finish&apos;)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫整理（二）BeautifulSoup]]></title>
    <url>%2Fpython%2F%E7%88%AC%E8%99%AB%E6%95%B4%E7%90%86%EF%BC%88%E4%BA%8C%EF%BC%89BeautifulSoup%2F</url>
    <content type="text"><![CDATA[BeautifulSoup 解析：基础本段完整代码 具体安装过程可自行搜索。beautifulSoup使用过程 选择要爬的网址 (url) 使用 python 打开这个网址 (urlopen等) 读取网页信息 (read() 出来) 将读取的信息放入 BeautifulSoup 使用 BeautifulSoup 选取 tag 信息等 (代替正则表达式)123456from urllib.request import urlopen# if has Chinese, apply decode()html = urlopen(&quot;https://morvanzhou.github.io/static/scraping/basic-structure.html&quot;).read().decode(&apos;utf-8&apos;) 使用BeautifulSoup筛选数据1234from bs4 import BeautifulSoupsoup = BeautifulSoup(html, features=&apos;lxml&apos;) #以 lxml 的这种形式加载print(soup) 12345678print(soup.h1) # 输出&lt;h1&gt; 标题print(soup.p) # 输出&lt;p&gt; 标题all_href = soup.find_all(&apos;a&apos;)print(&apos;\n&apos;,all_href)all_href = [l[&apos;href&apos;] for l in all_href] #像 Python 字典的形式, 用 key 来读取 l[&quot;href&quot;]print(&apos;\n&apos;, all_href) BeautifulSoup 解析网页:CSS本节代码 12345678910111213141516171819202122232425from bs4 import BeautifulSoupfrom urllib.request import urlopen# if has Chinese, apply decode()html = urlopen(&quot;https://morvanzhou.github.io/static/scraping/list.html&quot;).read().decode(&apos;utf-8&apos;)soup = BeautifulSoup(html, features=&apos;lxml&apos;)# use class to narrow searchmonth = soup.find_all(&apos;li&apos;, &#123;&quot;class&quot;: &quot;month&quot;&#125;)print(month)#要找所有 class=month 的信息. 并打印出它们的 tag 内文字for m in month: print(m.get_text()) # 打印tag中的文字jan = soup.find(&apos;ul&apos;, &#123;&quot;class&quot;: &apos;jan&apos;&#125;)print(&apos;\n&apos;,jan)d_jan = jan.find_all(&apos;li&apos;) # use jan as a parentprint(&apos;\n&apos;,d_jan)for d in d_jan: print(&apos;\n&apos;,d.get_text()) BeautifulSoup 解析网页正则表达式本节代码12345678910111213141516html = urlopen(&quot;https://morvanzhou.github.io/static/scraping/table.html&quot;).read().decode(&apos;utf-8&apos;)print(html)soup = BeautifulSoup(html, features=&apos;lxml&apos;)img_links = soup.find_all(&quot;img&quot;, &#123;&quot;src&quot;: re.compile(&apos;.*?\.jpg&apos;)&#125;)for link in img_links: print(link[&apos;src&apos;])print(&apos;\n&apos;)course_links = soup.find_all(&apos;a&apos;, &#123;&apos;href&apos;: re.compile(&apos;https://morvan.*&apos;)&#125;)for link in course_links: print(link[&apos;href&apos;]) 我们发现, 如果是图片, 它们都藏在这样一个 tag 中:123&lt;td&gt; &lt;img src=&quot;https://morvanzhou.github.io/static/img/course_cover/tf.jpg&quot;&gt;&lt;/td&gt; 用 soup 将这些 tag 全部找出来, 但是每一个 img 的链接(src)都可能不同，可能是 jpg 有的是 png, 只挑选 jpg 形式的图片, 用这样一个正则 r’.*?.jpg’ 来选取. 把正则的 compile 形式放到 BeautifulSoup 的功能中, 就能选到符合要求的图片链接了.想要的链接都有统一的形式, 就是开头都会有 https://morvan., 定一个正则, 让 BeautifulSoup 找到符合规则的链接. 一个小练习来熟悉1234567891011121314151617181920212223242526from bs4 import BeautifulSoupfrom urllib.request import urlopenimport reimport randombase_url = &quot;https://baike.baidu.com&quot;his = [&quot;/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/5162711&quot;]for i in range(20): # dealing with Chinese symbols url = base_url + his[-1] html = urlopen(url).read().decode(&apos;utf-8&apos;) soup = BeautifulSoup(html, features=&apos;lxml&apos;) print(i, soup.find(&apos;h1&apos;).get_text(), &apos; url: &apos;, url) # find valid urls sub_urls = soup.find_all( &quot;a&quot;, &#123;&quot;target&quot;: &quot;_blank&quot;, &quot;href&quot;: re.compile(&quot;/item/(%.&#123;2&#125;)+$&quot;)&#125;) if len(sub_urls) != 0: his.append(random.sample(sub_urls, 1)[0][&apos;href&apos;]) else: # no valid sub link found his.pop()]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PandaTV爬取主播人气并排序]]></title>
    <url>%2Fpython%2FPandaTV%E7%88%AC%E5%8F%96%E4%B8%BB%E6%92%AD%E4%BA%BA%E6%B0%94%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[很早前，第一次爬虫，就用的re加urllib原生爬虫。这次重新来爬取一次PandaTV主播人气排名，来练一下手。毕竟看直播嘛，颜值区更喜欢一点。就以颜值区为例，颜值区url = ‘https://www.panda.tv/cate/yzdr&#39;。结果保存在运行目录下的`PandaTV主播人气排名.md`中。代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import refrom urllib import requestimport osimport datetime class Spider(): url = &apos;https://www.panda.tv/all&apos; root_pattern =&apos;&lt;div class=&quot;video-info&quot;&gt;[\s\S]*?&lt;/div&gt;&apos; # 因为number和name均在其下 name_pattern = &apos;&lt;span class=&quot;video-nickname&quot; title=&quot;([\s\S]*?)&quot;&gt;\n&apos; number_pattern = &apos;&lt;span class=&quot;video-number&quot;&gt;&lt;i class=&quot;ricon ricon-eye&quot;&gt;&lt;/i&gt;([\s\S]*?)&lt;/span&gt;\n&apos; # 获取htmls数据 def __fetch_content(self): r = request.Request(Spider.url) r.add_header(&apos;User-Agent&apos;,&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/18.17758&apos;) r = request.urlopen(r) # 打开网页 request 下面的urlopen方法 htmls = r.read() # 读取 htmls = str(htmls, encoding=&apos;utf-8&apos;) # 转为str return htmls # 建立一个list为: [&#123;&apos;name&apos;:name,&apos;number&apos;: number&#125;,&#123;&apos;name&apos;:name,&apos;number&apos;: number&#125;,...] def __analysis(self, htmls): root_html = re.findall(Spider.root_pattern, htmls) # 抓取所有的&lt;div class=&quot;video-info&quot;&gt;[\s\S]*?&lt;/div&gt; anchors = [] for html in root_html: # 将&lt;div class=&quot;video-info&quot;&gt;[\s\S]*?&lt;/div&gt;一个一个提取出来 name = re.findall(Spider.name_pattern, html) # 将一个的name提取出来 ，格式为[str] number = re.findall(Spider.number_pattern, html) # 将一个的number提取出来,格式为[str] anchor = &#123;&apos;name&apos;: name, &apos;number&apos;: number&#125; # 将name 和 number 对应起来，组成一个字典 anchors.append(anchor) # 将这个字典添加到 anchors列表中 return anchors # def __refine(self, anchors): l = lambda anchors: &#123; &apos;name&apos;: anchors[&apos;name&apos;][0], #strip() 内置函数，去掉空格 &apos;number&apos;: anchors[&apos;number&apos;][0] # 取出字符串 &#125; return map(l, anchors) #&#123;[&apos;name&apos;:&apos;xxx&apos;,&apos;number&apos;:&apos;yyy&apos;]&#125;,&#123;[&apos;name&apos;:&apos;xxx1&apos;,&apos;number&apos;:&apos;yyy1&apos;]&#125;... def __sort(self, anchors): #排序 anchors = sorted(anchors, key=self.__sort_seed, reverse=True) #reverse=True表示降序 return anchors #anchor[&apos;number&apos;]中的转为float格式，按转化后的数字大小进行排序 def __sort_seed(self, anchor): # 排序调用的方法 r = anchor[&apos;number&apos;] if &apos;万&apos; in r: r = r.strip(&apos;万&apos;) r = float(r) r *= 10000 number = float(r) return number def __show(self, anchors): # 显示格式 time_stamp = datetime.datetime.now() b = str(time_stamp.strftime(&apos;%Y.%m.%d - %H:%M:%S&apos;) ) with open(&apos;./PandaTV主播人气排名.md&apos;, &apos;a&apos;) as f: f.write(&apos;\n\n&apos;) f.write(b) f.write(&apos;\n\n&apos;) for rank in range(0, len(anchors)): a = str((&apos;rank &apos; + str(rank + 1) + &apos; &apos; #加排名，因为是从0开始 &apos;主播姓名&apos; + &apos;:&apos; + anchors[rank][&apos;name&apos;] + &apos; &apos; + &apos;观看人数:&apos;+anchors[rank][&apos;number&apos;])) with open(&apos;./PandaTV主播人气排名.md&apos;, &apos;a&apos;) as f: f.write(a) f.write(&apos;\n&apos;) def go(self): #主方法 htmls = self.__fetch_content() anchors = self.__analysis(htmls) anchors = list(self.__refine(anchors)) anchors = self.__sort(anchors) self.__show(anchors) spider = Spider()spider.go() 附带本次成果]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫整理（一）使用re和urllib]]></title>
    <url>%2Fpython%2F%E7%88%AC%E8%99%AB%E6%95%B4%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89%E4%BD%BF%E7%94%A8re%E5%92%8Curllib%2F</url>
    <content type="text"><![CDATA[完整代码123456789101112131415161718192021from urllib.request import urlopenhtml = urlopen( &quot;https://morvanzhou.github.io/static/scraping/basic-structure.html&quot;).read( ).decode(&apos;utf-8&apos;)print(html)import reres = re.findall(r&quot;&lt;title&gt;(.+?)&lt;/title&gt;&quot;, html)print(&quot;\nPage title is: &quot;, res[0])res = re.findall(r&quot;&lt;p&gt;(.*?)&lt;/p&gt;&quot;, html, flags=re.DOTALL) print(&quot;\nPage paragraph is: &quot;, res[0])res = re.findall(r&apos;href=&quot;(.*?)&quot;&apos;, html)print(&quot;\nAll links: &quot;, res) 正文使用re和urllib123456from urllib.request import urlopen# if has Chinese, apply decode()html = urlopen( &quot;https://morvanzhou.github.io/static/scraping/basic-structure.html&quot;).read().decode(&apos;utf-8&apos;) print(html) # 打开，读取，转换可显示中文，最后打印出来 结果显示 接下来，使用re筛选数据1234567891011import reres = re.findall(r&quot;&lt;title&gt;(.+?)&lt;/title&gt;&quot;, html) print(res) # [&apos;Scraping tutorial 1 | 莫烦Python&apos;] # 列表print(res[0]) # Scraping tutorial 1 | 莫烦Pythonres = re.findall(r&quot;&lt;p&gt;(.*?)&lt;/p&gt;&quot;, html)print(res) # []res = re.findall(r&quot;&lt;p&gt;(.*?)&lt;/p&gt;&quot;, html, flags=re.DOTALL) # re.DOTALL if multi lineprnt(res)print(res[0]) 12res = re.findall(r&apos;href=&quot;(.*?)&quot;&apos;, html)print(&quot;\nAll links: &quot;, res)]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[慕课网数据采集总结]]></title>
    <url>%2Fpython%2F%E6%85%95%E8%AF%BE%E7%BD%91%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[https://www.imooc.com/video/12637 课程地址]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫整理（三）Requests]]></title>
    <url>%2Fpython%2F%E7%88%AC%E8%99%AB%E6%95%B4%E7%90%86%EF%BC%88%E4%B8%89%EF%BC%89Requests%2F</url>
    <content type="text"><![CDATA[Requests 是一个 Python 的外部模块, 需要手动安装. 使用 pip 安装就好了. 1234567import requestsimport webbrowser # 使用浏览器打开param = &#123;&quot;wd&quot;: &quot;itswl.github&quot;&#125; # 搜索的信息r = requests.get(&apos;https://www.baidu.com/s&apos;, params=param)print(r.url) # 用get 方式webbrowser.open(r.url)# https://www.baidu.com/s?wd=itswl.github 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import requestsimport webbrowser # 使用浏览器打开param = &#123;&quot;wd&quot;: &quot;itswl.github&quot;&#125; # 搜索的信息r = requests.get(&apos;http://www.baidu.com/s&apos;, params=param)print(r.url) # 用get 方式webbrowser.open(r.url)def get(): print(&apos;\nget&apos;) param = &#123;&quot;wd&quot;: &quot;itswl.github&quot;&#125; r = requests.get(&apos;https://www.baidu.com/s&apos;, params=param) print(r.url) print(r.text)# get()def post_name(): print(&apos;\npost name&apos;) # http://pythonscraping.com/pages/files/form.html data = &#123;&apos;firstname&apos;: &apos;laii&apos;, &apos;lastname&apos;: &apos;weii&apos;&#125; r = requests.post(&apos;http://pythonscraping.com/files/processing.php&apos;, data=data) print(r.text)post_name()def post_image(): print(&apos;\npost image&apos;) # http://pythonscraping.com/files/form2.html file = &#123;&apos;uploadFile&apos;: open(&apos;./image.png&apos;, &apos;rb&apos;)&#125; r = requests.post(&apos;http://pythonscraping.com/files/processing2.php&apos;, files=file) print(r.text)def post_login(): print(&apos;\npost login&apos;) # http://pythonscraping.com/pages/cookies/login.html payload = &#123;&apos;username&apos;: &apos;Morvan&apos;, &apos;password&apos;: &apos;password&apos;&#125; r = requests.post(&apos;http://pythonscraping.com/pages/cookies/welcome.php&apos;, data=payload) print(r.cookies.get_dict()) # http://pythonscraping.com/pages/cookies/profile.php r = requests.get(&apos;http://pythonscraping.com/pages/cookies/profile.php&apos;, cookies=r.cookies) print(r.text)def session_login(): # 使用cookie print(&apos;\nsession login&apos;) # http://pythonscraping.com/pages/cookies/login.html session = requests.Session() payload = &#123;&apos;username&apos;: &apos;Morvan&apos;, &apos;password&apos;: &apos;password&apos;&#125; r = session.post(&apos;http://pythonscraping.com/pages/cookies/welcome.php&apos;, data=payload) print(r.cookies.get_dict()) r = session.get(&quot;http://pythonscraping.com/pages/cookies/profile.php&quot;) print(r.text)post_name()post_image()post_login()session_login() 下载文件123456789101112131415161718192021222324252627282930313233import osos.makedirs(&apos;./img/&apos;, exist_ok=True)IMAGE_URL = &quot;https://morvanzhou.github.io/static/img/description/learning_step_flowchart.png&quot;def urllib_download(): from urllib.request import urlretrieve urlretrieve(IMAGE_URL, &apos;./img/image1.png&apos;) # whole documentdef request_download(): import requests r = requests.get(IMAGE_URL) with open(&apos;./img/image2.png&apos;, &apos;wb&apos;) as f: f.write(r.content) # whole documentdef chunk_download(): import requests r = requests.get(IMAGE_URL, stream=True) # stream loading with open(&apos;./img/image3.png&apos;, &apos;wb&apos;) as f: for chunk in r.iter_content(chunk_size=32): f.write(chunk)urllib_download()print(&apos;download image1&apos;)request_download()print(&apos;download image2&apos;)chunk_download()print(&apos;download image3&apos;) 一个小练习，抓取美女吧图片123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100# coding=utf-8import requestsfrom lxml import etreeimport osimport reclass TieBa(object): &quot;&quot;&quot;抓取百度贴吧美女图片&quot;&quot;&quot; def __init__(self, word): self.url = &apos;https://tieba.baidu.com/f?kw=&#123;&#125;&apos;.format(word) # word 美女 self.headers = &#123; &apos;User-Agent&apos;: &apos;Mozilla/4.0 (compatible; MSIE 5.01; Windows NT 5.0; TUCOWS) &apos; &#125; def get_data(self, url): # 构造请求 response = requests.get(url, headers=self.headers) data = response.content # print(data) return data def parse_page(self, data): &quot;&quot;&quot;解析数据&quot;&quot;&quot; # 创建xpath对象 html = etree.HTML(data) # 提取当前页标题，url数据 node_list = html.xpath(&apos;//*[@id=&quot;thread_list&quot;]/li/div/div[2]/div[1]/div[1]/a&apos;) detail_list = [] for node in node_list: temp = dict() temp[&apos;title&apos;] = node.xpath(&apos;./text()&apos;)[0] temp[&apos;url&apos;] = &apos;https://tieba.baidu.com&apos; + node.xpath(&apos;./@href&apos;)[0] detail_list.append(temp) # print(temp) # 提取下一页连接 next_url = html.xpath(&apos;//*[@id=&quot;frs_list_pager&quot;]/a[contains(text(), &quot;下一页&quot;)]/@href&apos;)[0] next_url = &apos;http:&apos; + next_url if len(next_url) &gt; 0 else None # print(next_url) return detail_list, next_url def parse_detail(self, detail_list): &quot;&quot;&quot;提取详情页url&quot;&quot;&quot; data_url = [] for detail in detail_list: data_url.append(detail[&apos;url&apos;]) return data_url def save_data(self, url): &quot;&quot;&quot;保存数据&quot;&quot;&quot; # 请求标题连接地址 data = self.get_data(url) # 创建xpath对象 html = etree.HTML(data) # print(html) # print(url) # 获取图片url try: image_url = html.xpath(&apos;//*[contains(@id,&quot;post_content&quot;)]/img[1]/@src&apos;)[0] except Exception as e: return print(image_url) # 判断图片地址是否已jpg结尾 if re.match(r&apos;.*\.jpg$&apos;, image_url): # 请求图片地址，获取图片 image_data = self.get_data(image_url) filename = &apos;image/&apos; + image_url.split(&apos;/&apos;)[-1] # print(filename) # 保存图片 with open(filename, &apos;wb&apos;) as f: f.write(image_data) def run(self): # 判断是否有image文件夹 if not os.path.exists(&apos;image&apos;): # 创建文件夹 os.mkdir(&apos;image&apos;) next_url = self.url # 请求美女吧首页 data = self.get_data(next_url) # 保存首页文件，观察数据，是否有需要的数据 with open(&apos;tieba.json&apos;, &apos;wb&apos;) as f: f.write(data) # 如果有下一页就执行 while next_url: # 获取每页标题和对应的连接地址 detail_list, next_url = self.parse_page(data) # 提取每页的详情页的url data_url = self.parse_detail(detail_list) # 遍历每个url for url in data_url: # 保存图片 self.save_data(url) # 构造下一页请求 data = self.get_data(next_url)if __name__ == &apos;__main__&apos;: tb = TieBa(&apos;美女&apos;) tb.run()]]></content>
      <categories>
        <category>python练习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(19) 网络编程]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Python进行网络编程，就是在Python程序本身这个进程内，连接别的服务器进程的通信端口进行通信。 TCP/IP 简介互联网上每个计算机的唯一标识就是IP地址，类似123.123.123.123。如果一台计算机同时接入到两个或更多的网络，比如路由器，它就会有两个或多个IP地址，所以，IP地址对应的实际上是计算机的网络接口，通常是网卡。 IP协议负责把数据从一台计算机通过网络发送到另一台计算机。数据被分割成一小块一小块，然后通过IP包发送出去。由于互联网链路复杂，两台计算机之间经常有多条线路，因此，路由器就负责决定如何把一个IP包转发出去。IP包的特点是按块发送，途径多个路由，但不保证能到达，也不保证顺序到达。 IPv4地址实际上是一个32位整数，以字符串表示的。IP地址如192.168.0.1实际上是把32位整数按8位分组后的数字表示，目的是便于阅读IPv6地址全部长度128位(bit)，每16位为一个双字节。 TCP协议则是建立在IP协议之上的。TCP协议负责在两台计算机之间建立可靠连接，保证数据包按顺序到达。TCP协议会通过握手建立连接，然后，对每个IP包编号，确保对方按顺序收到，如果包丢掉了，就自动重发。 socket是电脑网络中进程间数据流的端点 主要分为UDP和TCP两种通信方式 TCP编程Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。 大多数连接都是可靠的TCP连接。创建TCP连接时，主动发起连接的叫客户端，被动响应连接的叫服务器。 创建一个基于TCP连接的Socket，可以这样做：1234567# 导入socket库:import socket# 创建一个socket:s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 建立连接:s.connect((&apos;www.baidu.com&apos;, 80)) 创建Socket时，AF_INET指定使用IPv4协议，如果要用更先进的IPv6，就指定为AF_INET6。SOCK_STREAM指定使用面向流的TCP协议，这样，一个Socket对象就创建成功，但是还没有建立连接。 客户端要主动发起TCP连接，必须知道服务器的IP地址和端口号。新浪网站的IP地址可以用域名www.sina.com.cn自动转换到IP地址。80端口是Web服务的标准端口。其他服务都有对应的标准端口号，例如SMTP服务是25端口，FTP服务是21端口，等等。端口号小于1024的是Internet标准服务的端口，端口号大于1024的，可以任意使用。 因此，连接新浪服务器的代码如下：1s.connect((&apos;www.baidu.com&apos;, 80)) 注意参数是一个tuple，包含地址和端口号。 建立TCP连接后，我们就可以向百度服务器发送请求，要求返回首页的内容：12# 发送数据:s.send(b&apos;GET / HTTP/1.1\r\nHost: www.baidu.com\r\nConnection: close\r\n\r\n&apos;) TCP连接创建的是双向通道，双方都可以同时给对方发数据。但是谁先发谁后发，怎么协调，要根据具体的协议来决定。例如，HTTP协议规定客户端必须先发请求给服务器，服务器收到后才发数据给客户端。 发送的文本格式必须符合HTTP标准，如果格式没问题，接下来就可以接收百度服务器返回的数据了：12345678910# 接收数据:buffer = []while True: # 每次最多接收1k字节: d = s.recv(1024) if d: buffer.append(d) else: breakdata = b&apos;&apos;.join(buffer) 接收数据时，调用recv(max)方法，一次最多接收指定的字节数，因此，在一个while循环中反复接收，直到recv()返回空数据，表示接收完毕，退出循环。 当我们接收完数据后，调用close()方法关闭Socket，这样，一次完整的网络通信就结束了：12# 关闭连接:s.close() 接收到的数据包括HTTP头和网页本身，我们只需要把HTTP头和网页分离一下，把HTTP头打印出来，网页内容保存到文件：123456header, html = data.split(b&apos;\r\n\r\n&apos;, 1)print(header.decode(&apos;utf-8&apos;))# python3.x版本，网络数据的发送接受都是byte类型，需要解码# 把接收的数据写入文件:with open(&apos;baidu.html&apos;, &apos;wb&apos;) as f: f.write(html) 现在，只需要在浏览器中打开这个baidu.html文件，就可以看到百度的首页了。1234567891011121314151617import sockets = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((&apos;www.baidu.com&apos;, 80))s.send(b&apos;GET / HTTP/1.1\r\nHost: www.baidu.com\r\nConnection: close\r\n\r\n&apos;)buffer = []while True: d = s.recv(1024) if d: buffer.append(d) else: breakdata = b&apos;&apos;.join(buffer)s.close()header, html = data.split(b&apos;\r\n\r\n&apos;, 1)print(header.decode(&apos;utf-8&apos;))with open(&apos;baidu.html&apos;, &apos;wb&apos;) as f: f.write(html) 服务器和客户端编程相比，服务器编程就要复杂一些。 服务器进程首先要绑定一个端口并监听来自其他客户端的连接。如果某个客户端连接过来了，服务器就与该客户端建立Socket连接，随后的通信就靠这个Socket连接了。 所以，服务器会打开固定端口（比如80）监听，每来一个客户端连接，就创建该Socket连接。由于服务器会有大量来自客户端的连接，所以，服务器要能够区分一个Socket连接是和哪个客户端绑定的。一个Socket依赖4项：服务器地址、服务器端口、客户端地址、客户端端口来唯一确定一个Socket。 但是服务器还需要同时响应多个客户端的请求，所以，每个连接都需要一个新的进程或者新的线程来处理，否则，服务器一次就只能服务一个客户端了。 我们来编写一个简单的服务器程序，它接收客户端连接，把客户端发过来的字符串加上Hello再发回去。 首先，创建一个基于IPv4和TCP协议的Socket： 1s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) 然后，我们要绑定监听的地址和端口。服务器可能有多块网卡，可以绑定到某一块网卡的IP地址上，也可以用0.0.0.0绑定到所有的网络地址，还可以用127.0.0.1绑定到本机地址。127.0.0.1是一个特殊的IP地址，表示本机地址，如果绑定到这个地址，客户端必须同时在本机运行才能连接，也就是说，外部的计算机无法连接进来。 端口号需要预先指定。因为我们写的这个服务不是标准服务，所以用9999这个端口号。请注意，小于1024的端口号必须要有管理员权限才能绑定： 12# 监听端口:s.bind((&apos;127.0.0.1&apos;, 9999)) 紧接着，调用listen()方法开始监听端口，传入的参数指定等待连接的最大数量： 12s.listen(5)print(&apos;Waiting for connection...&apos;) 接下来，服务器程序通过一个永久循环来接受来自客户端的连接，accept()会等待并返回一个客户端的连接: 1234567# 不断循环，不断接受数据while True: # 接受一个新连接: sock, addr = s.accept() # 创建新线程来处理TCP连接: t = threading.Thread(target=tcplink, args=(sock, addr)) t.start() 每个连接都必须创建新线程（或进程）来处理，否则，单线程在处理连接的过程中，无法接受其他客户端的连接： 12345678910111213def tcplink(sock, addr): print(&apos;Accept new connection from %s:%s...&apos; % addr) sock.send(b&apos;Welcome!&apos;) # 不断接受客服端发来的消息 while True: data = sock.recv(1024) time.sleep(1) if not data or data.decode(&apos;utf-8&apos;) == &apos;exit&apos;: # 退出 break sock.send((&apos;Hello, %s!&apos; % data.decode(&apos;utf-8&apos;)).encode(&apos;utf-8&apos;)) #处理客户端数据 sock.close() print(&apos;Connection from %s:%s closed.&apos; % addr) 连接建立后，服务器首先发一条欢迎消息，然后等待客户端数据，并加上Hello再发送给客户端。如果客户端发送了exit字符串，就直接关闭连接。 要测试这个服务器程序，我们还需要编写一个客户端程序： 123456789101112s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)# 建立连接:s.connect((&apos;127.0.0.1&apos;, 9999))# 接收欢迎消息:print(s.recv(1024).decode(&apos;utf-8&apos;))for data in [b&apos;Michael&apos;, b&apos;Tracy&apos;, b&apos;Sarah&apos;]: # 发送数据: s.send(data) print(s.recv(1024).decode(&apos;utf-8&apos;))s.send(b&apos;exit&apos;)s.close() 我们需要打开两个命令行窗口，一个运行服务器程序，另一个运行客户端程序，就可以看到效果了： 需要注意的是，客户端程序运行完毕就退出了，而服务器程序会永远运行下去，必须按Ctrl+C退出程序。 小结用TCP协议进行Socket编程在Python中十分简单，对于客户端，要主动连接服务器的IP和指定端口，对于服务器，要首先监听指定端口，然后，对每一个新的连接，创建一个线程或进程来处理。通常，服务器程序会无限运行下去。 同一个端口，被一个Socket绑定了以后，就不能被别的Socket绑定了。 #UDP 编程 TCP是建立可靠连接，并且通信双方都可以以流的形式发送数据。相对TCP，UDP则是面向无连接的协议。 使用UDP协议时，不需要建立连接，只需要知道对方的IP地址和端口号，就可以直接发数据包。但是，能不能到达就不知道了。 虽然用UDP传输数据不可靠，但它的优点是和TCP比，速度快，对于不要求可靠到达的数据，就可以使用UDP协议。 我们来看看如何通过UDP协议传输数据。和TCP类似，使用UDP的通信双方也分为客户端和服务器。服务器首先需要绑定端口： 123s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)# 绑定端口:s.bind((&apos;127.0.0.1&apos;, 9999)) 创建Socket时，SOCK_DGRAM指定了这个Socket的类型是UDP。绑定端口和TCP一样，但是不需要调用listen()方法，而是直接接收来自任何客户端的数据： 123456print(&apos;Bind UDP on 9999...&apos;)while True: # 接收数据: data, addr = s.recvfrom(1024) print(&apos;Received from %s:%s.&apos; % addr) s.sendto(b&apos;Hello, %s!&apos; % data, addr) recvfrom()方法返回数据和客户端的地址与端口，这样，服务器收到数据后，直接调用sendto()就可以把数据用UDP发给客户端。 注意这里省掉了多线程，因为这个例子很简单。 客户端使用UDP时，首先仍然创建基于UDP的Socket，然后，不需要调用connect()，直接通过sendto()给服务器发数据： 1234567s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)for data in [b&apos;Michael&apos;, b&apos;Tracy&apos;, b&apos;Sarah&apos;]: # 发送数据: s.sendto(data, (&apos;127.0.0.1&apos;, 9999)) # 接收数据: print(s.recv(1024).decode(&apos;utf-8&apos;))s.close() 从服务器接收数据仍然调用recv()方法。 仍然用两个命令行分别启动服务器和客户端测试，结果如下： 小结UDP的使用与TCP类似，但是不需要建立连接。此外，服务器绑定UDP端口和TCP端口互不冲突，也就是说，UDP的9999端口与TCP的9999端口可以各自绑定。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(18) python异常]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[异常异常的概念 程序在运行时，如果 Python 解释器 遇到 到一个错误，会停止程序的执行，并且提示一些错误信息，这就是 异常 程序停止执行并且提示错误信息 这个动作，我们通常称之为：抛出(raise)异常 程序开发时，很难将 所有的特殊情况 都处理的面面俱到，通过 异常捕获 可以针对突发事件做集中的处理，从而保证程序的 稳定性和健壮性 [图片上传失败…(image-81f29f-1542201966094)] 捕获异常：try except else finally简单的捕获异常语法 在程序开发中，如果 对某些代码的执行不能确定是否正确，可以增加 try(尝试) 来 捕获异常 1234try: 尝试执行的代码except: 出现错误的处理 try 尝试，下方编写要尝试代码，不确定是否能够正常执行的代码 except 如果不是，下方编写尝试失败的代码 简单异常捕获1 —— 要求用户输入整数 12345try: # 提示用户输入一个数字 num = int(input(&quot;请输入数字：&quot;))except: print(&quot;请输入正确的数字&quot;) 错误类型捕获 在程序执行时，可能会遇到 不同类型的异常，并且需要 针对不同类型的异常，做出不同的响应，这个时候，就需要捕获错误类型了 1234567891011try: # 尝试执行的代码 passexcept 错误类型1: # 针对错误类型1，对应的代码处理 passexcept (错误类型2, 错误类型3): # 针对错误类型2 和 3，对应的代码处理 passexcept Exception as result: print(&quot;未知错误 %s&quot; % result) 当 Python 解释器 抛出异常 时，最后一行错误信息的第一个单词，就是错误类型 异常类型捕获2 —— 要求用户输入整数 12345678try: num = int(input(&quot;请输入整数：&quot;)) result = 8 / num print(result)except ValueError: print(&quot;请输入正确的整数&quot;)except ZeroDivisionError: print(&quot;除 0 错误&quot;) 捕获未知错误 在开发时，要预判到所有可能出现的错误，还是有一定难度的 如果希望程序 无论出现任何错误，都不会因为 Python 解释器 抛出异常而被终止，可以再增加一个 except 语法如下： 12except Exception as result: print(&quot;未知错误 %s&quot; % result) 异常捕获完整语法 在实际开发中，为了能够处理复杂的异常情况，完整的异常语法如下： 123456789101112131415161718192021try: # 尝试执行的代码 passexcept 错误类型1: # 针对错误类型1，对应的代码处理 passexcept 错误类型2: # 针对错误类型2，对应的代码处理 passexcept (错误类型3, 错误类型4): # 针对错误类型3 和 4，对应的代码处理 passexcept Exception as result: # 打印错误信息 print(result)else: # 没有异常才会执行的代码 passfinally: # 无论是否有异常，都会执行的代码 print(&quot;无论是否有异常，都会执行的代码&quot;) else 只有在没有异常时才会执行的代码 finally 无论是否有异常，都会执行的代码 之前一个演练的 完整捕获异常 的代码如下： 1234567891011121314try: num = int(input(&quot;请输入整数：&quot;)) result = 8 / num print(result)except ValueError: print(&quot;请输入正确的整数&quot;)except ZeroDivisionError: print(&quot;除 0 错误&quot;)except Exception as result: print(&quot;未知错误 %s&quot; % result)else: print(&quot;正常执行&quot;)finally: print(&quot;执行完成，但是不保证正确&quot;) 异常的传递 异常的传递 —— 当 函数/方法 执行 出现异常，会 将异常传递 给 函数/方法 的 调用一方 如果 传递到主程序，仍然 没有异常处理，程序才会被终止 提示： 在开发中，可以在主函数中增加 异常捕获，而在主函数中调用的其他函数，只要出现异常，都会传递到主函数的异常捕获中 这样就不需要在代码中，增加大量的异常捕获，能够保证代码的整洁 123456789101112131415161718&apos;&apos;&apos;需求:1\. 定义函数 `demo1()` **提示用户输入一个整数并且返回**2\. 定义函数 `demo2()` 调用 `demo1()`3\. 在主程序中调用 `demo2()`&apos;&apos;&apos;def demo1(): return int(input(&quot;请输入一个整数：&quot;))def demo2(): return demo1()try: print(demo2())except ValueError: print(&quot;请输入正确的整数&quot;)except Exception as result: print(&quot;未知错误 %s&quot; % result) 抛出异常： raise应用场景 在开发中，除了 代码执行出错 Python 解释器会 抛出 异常之外 还可以根据 应用程序 特有的业务需求 主动抛出异常 示例 提示用户 输入密码，如果 长度少于 8，抛出 异常 [图片上传失败…(image-3d2a0b-1542201966092)] 抛出异常 Python 中提供了一个 Exception 异常类 在开发时，如果满足 特定业务需求时，希望 抛出异常，由其他需要处理的函数捕获异常，可以： 创建 一个 Exception 的 对象 使用 raise 关键字 抛出 异常对象 12345678910111213141516171819202122232425262728&apos;&apos;&apos;**需求*** 定义 `input_password` 函数，提示用户输入密码* 如果用户输入长度 &lt; 8，抛出异常* 如果用户输入长度 &gt;=8，返回输入的密码&apos;&apos;&apos;def input_password(): # 1\. 提示用户输入密码 pwd = input(&quot;请输入密码：&quot;) # 2\. 判断密码长度，如果长度 &gt;= 8，返回用户输入的密码 if len(pwd) &gt;= 8: return pwd # 3\. 密码长度不够，需要抛出异常 # 1&gt; 创建异常对象 - 使用异常的错误信息字符串作为参数 ex = Exception(&quot;密码长度不够&quot;) # 2&gt; 抛出异常对象 raise extry: user_pwd = input_password() print(user_pwd)except Exception as result: print(&quot;发现错误：%s&quot; % result) 参考文章：https://www.jianshu.com/p/ebc19de7a204]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(17) python文件操作]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[文件文件####文件的概念 计算机的 文件，就是存储在某种 长期储存设备 上的一段 数据 长期存储设备包括：硬盘、U 盘、移动硬盘、光盘… 文件的作用：将数据长期保存下来，在需要的时候使用文件的存储方式：在计算机中，文件是以 二进制 的方式保存在磁盘上的文本文件：可以使用 文本编辑软件 查看，本质上还是二进制文件二进制文件：保存的内容 不是给人直接阅读的，而是 提供给其他软件使用的，例如：图片文件、音频文件、视频文件等等，二进制文件不能使用 文本编辑软件 查看 文件的基本操作操作文件的套路：在 计算机 中要操作文件的套路非常固定，一共包含三个步骤： 打开文件 读、写文件 读 将文件内容读入内存 写 将内存内容写入文件 关闭文件 操作文件的函数/方法在 Python 中要操作文件 序号 函数/方法 说明 01 open 打开文件，并且返回文件操作对象 02 read 将文件内容读取到内存 03 write 将指定内容写入文件 04 close 关闭文件 open 函数负责打开文件，并且返回文件对象read/write/close 三个方法都需要通过 文件对象 来调用 读取文件示例 open 函数的第一个参数是要打开的文件名（文件名区分大小写）如果文件 存在，返回 文件操作对象如果文件 不存在，会 抛出异常 read 方法可以一次性 读入 并 返回 文件的 所有内容 close 方法负责 关闭文件如果 忘记关闭文件，会造成系统资源消耗，而且会影响到后续对文件的访问 注意：read 方法执行后，会把 文件指针 移动到 文件的末尾 123456789# 1\. 打开 - 文件名需要注意大小写file = open(&quot;README&quot;)# 2\. 读取text = file.read()print(text)# 3\. 关闭file.close() 提示 在开发中，通常会先编写 打开 和 关闭 的代码，再编写中间针对文件的 读/写 操作！ &lt;补&gt; 文件指针 文件指针 标记 从哪个位置开始读取数据 第一次打开 文件时，通常 文件指针会指向文件的开始位置 当执行了 read 方法后，文件指针 会移动到 读取内容的末尾 默认情况下会移动到 文件末尾 思考：如果执行了一次 read 方法，读取了所有内容，那么再次调用 read 方法，还能够获得到内容吗？答案：不能！第一次读取之后，文件指针移动到了文件末尾，再次调用不会读取到任何的内容。 &lt;补&gt; 打开文件的方式 open 函数默认以 只读方式 打开文件，并且返回文件对象 1f = open(&quot;文件名&quot;, &quot;访问方式&quot;) 访问方式 说明 r 以只读方式打开文件。文件的指针将会放在文件的开头，这是默认模式。如果文件不存在，抛出异常 w 以只写方式打开文件。如果文件存在会被覆盖。如果文件不存在，创建新文件 a 以追加方式打开文件。如果该文件已存在，文件指针将会放在文件的结尾。如果文件不存在，创建新文件进行写入 r+ 以读写方式打开文件。文件的指针将会放在文件的开头。如果文件不存在，抛出异常 w+ 以读写方式打开文件。如果文件存在会被覆盖。如果文件不存在，创建新文件 a+ 以读写方式打开文件。如果该文件已存在，文件指针将会放在文件的结尾。如果文件不存在，创建新文件进行写入 提示：频繁的移动文件指针，会影响文件的读写效率，开发中更多的时候会以 只读、只写 的方式来操作文件 写入文件示例 12345678# 打开文件f = open(&quot;README&quot;, &quot;w&quot;)f.write(&quot;hello python！\n&quot;)f.write(&quot;今天天气真好&quot;)# 关闭文件f.close() &lt;补&gt; 按行读取文件内容：readline() read 方法默认会把文件的 所有内容 一次性读取到内存 如果文件太大，对内存的占用会非常严重 readline 方法可以一次读取一行内容 方法执行后，会把 文件指针 移动到下一行，准备再次读取 读取大文件的正确姿势 12345678910111213141516# 打开文件file = open(&quot;README&quot;)while True: # 读取一行内容 text = file.readline() # 判断是否读到内容 if not text: break # 每读取一行的末尾已经有了一个 `\n` print(text, end=&quot;&quot;)# 关闭文件file.close() 复制大文件 打开一个已有文件，逐行读取内容，并顺序写入到另外一个文件 123456789101112131415161718# 1\. 打开文件file_read = open(&quot;README&quot;)file_write = open(&quot;README[复件]&quot;, &quot;w&quot;)# 2\. 读取并写入文件while True: # 每次读取一行 text = file_read.readline() # 判断是否读取到内容 if not text: break file_write.write(text)# 3\. 关闭文件file_read.close()file_write.close() 文件/目录的常用管理操作 在 终端 / 文件浏览器、 中可以执行常规的 文件 / 目录 管理操作，例如： 创建、重命名、删除、改变路径、查看目录内容、…… 在 Python 中，如果希望通过程序实现上述功能，需要 import os 模块 文件管理操作 序号 方法名 说明 示例 01 rename 重命名文件 os.rename(源文件名, 目标文件名) 02 remove 删除文件 os.remove(文件名) 目录管理操作 序号 方法名 说明 示例 01 listdir 目录列表 os.listdir(目录名) 02 mkdir 创建目录 os.mkdir(目录名) 03 rmdir 删除目录 os.rmdir(目录名) 04 getcwd 获取当前目录 os.getcwd() 05 chdir 修改工作目录 os.chdir(目标目录) 06 path.isdir 判断是否是文件 os.path.isdir(文件路径) 提示：文件或者目录操作都支持 相对路径 和 绝对路径 文本文件的编码格式 文本文件存储的内容是基于 字符编码 的文件，常见的编码有 ASCII 编码，UNICODE 编码等 Python 2.x 默认使用 ASCII 编码格式Python 3.x 默认使用 UTF-8 编码格式 ASCII 编码 计算机中只有 256 个 ASCII 字符 一个 ASCII 在内存中占用 1 个字节 的空间 8 个 0/1 的排列组合方式一共有 256 种，也就是 2 ** 8 UTF-8 编码格式 计算机中使用 1~6 个字节 来表示一个 UTF-8 字符，涵盖了 地球上几乎所有地区的文字 大多数汉字会使用 3 个字节 表示 UTF-8 是 UNICODE 编码的一种编码格式 123456789# *-* coding:utf8 *-*# 在字符串前，增加一个 `u` 表示这个字符串是一个 utf8 字符串hello_str = u&quot;你好世界&quot;print(hello_str)for c in hello_str: print(c)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(13) python中用字典代替switch]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E7%94%A8%E5%AD%97%E5%85%B8%E4%BB%A3%E6%9B%BFswitch%2F</url>
    <content type="text"><![CDATA[switch语句类型12345678910111213&apos;&apos;&apos;switch(n)&#123;case 1: 执行代码块 1 break;case 2: 执行代码块 2 break;default: n 与 case 1 和 case 2 不同时执行的代码&#125;&apos;&apos;&apos; 例如：12345678910111213141516&apos;&apos;&apos;switch (day)&#123;case 0: x=&quot;Today it&apos;s Sunday&quot;; break;case 1: x=&quot;Today it&apos;s Monday&quot;; break;case 2: x=&quot;Today it&apos;s Tuesday&quot;; break;case 3: x=&quot;unknown&quot;&#125;&apos;&apos;&apos; python中字典方式123456789day = 3switcher = &#123; 0:&apos;Today it\&apos;s Sunday&apos;, 1:&apos;Today it\&apos;s Monday&apos;, 2:&apos;Today it\&apos;s Tuesday&apos;&#125;#day_name =switcher[day] #并不能显示defaultday_name = switcher.get(day,&apos;Unknown&apos;)print(day_name) 函数12345678910111213141516171819202122day = 3def get_monday(): return &apos;Monday&apos;def get_sunday(): return &apos;Sunday&apos;def get_tuesday(): return &apos;Tuesday&apos;def get_default(): return &apos;Unknown&apos;switcher1 = &#123; 0:get_sunday, 1:get_monday, 2:get_tuesday&#125; day_name = switcher1.get(day,get_default)()print(day_name)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(15) python中的None]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E7%9A%84None%2F</url>
    <content type="text"><![CDATA[None 表示空 不同于 空字符串 空的列表 0 False 类型不同，值不同1234567print(type(None)) &lt;class &apos;NoneType&apos;&gt;None是None类a=&apos;&apos;b=Falsec=[]print(a==None) #Falseprint(b==None) #Falseprint(c==None) #False #值不相等 深入123456789101112131415def fun(): return Nonea = fun()if not a: print(&apos;S&apos;)else: print(&apos;F&apos;)if a is None: print(&apos;S&apos;)else: print(&apos;F&apos;)#S#S 123456789101112131415def fun(): return Nonea = []if not a: print(&apos;S&apos;)else: print(&apos;F&apos;)if a is None: print(&apos;S&apos;)else: print(&apos;F&apos;)#S#F 类中默认非空123456789class Test(): passtest = Test()if test: print(&apos;S&apos;)else: print(&apos;F&apos;)#S 类中为空的情况12345678910class Test(): def __len__(self): return 0 #(只能为int类型)test = Test()if test: print(&apos;S&apos;)else: print(&apos;F&apos;)#F 123456789class Test(): def __len__(self): return 0 #(只能为int类型)test = Test()print(bool(None)) #Falseprint(bool(&#123;&#125;))#Falseprint(bool([]))#Falseprint(bool(test))#False 由bool决定True or False,与len无关(即print 只有 bool call True,或者bool call False ))12345678910111213class Test(): def __bool__(self): print(&apos;bool called&apos;) return False#(/True) def __len__(self): print(&apos;len called&apos;) return True #(只能为int类型)print(bool(Test()))#bool called#False#(/True)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(14) python中的列表推导式]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E7%9A%84%E5%88%97%E8%A1%A8%E6%8E%A8%E5%AF%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[#####列表推导式 #####集合字典也可 #####元组也可 1234a=[1,2,3,4,5,6,7,8,9]b=[i**3 for i in a if i &lt;=5]print(b) #b=&#123;....&#125;为集合，b(...)为元组，与a&#123;[(...)]&#125;,什么的无关。#为b()时，是一个对象 也可以map filter表示1234list_a=[1,2,3,4,5,6,7,8,9]r=filter(lambda x:x if x&lt;=5 else 0,list_a)s=map(lambda x:x*x,r)print(list(s)) 12345#同上，不建议list_a=[1,2,3,4,5,6,7,8,9]r=filter(lambda x:x if x&lt;=5 else 0,list_a)s=map(lambda x:x**3,filter(lambda x:x if x&lt;=5 else 0,list_a))print(list(s)) #####当为字典时123456789students =&#123; &apos;wei&apos;:18, &apos;lai&apos;:19, &apos;wan&apos;:20&#125;b = [key for key,value in students.items()]print(b)#[&apos;wei&apos;, &apos;lai&apos;, &apos;wan&apos;]for x in b: print(x)#wei#lai#wan **交换key和value12345678students =&#123; &apos;wei&apos;:18, &apos;lai&apos;:19, &apos;wan&apos;:20&#125;b =&#123;value:key for key,value in students.items()&#125;print(b)#&#123;18: &apos;wei&apos;, 19: &apos;lai&apos;, 20: &apos;wan&apos;&#125;]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(16) python补充]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[1234567num2 = 100sum1 = lambda num1 : num1 + num2 num2 = 10000sum2 = lambda num1 : num1 + num2 print( sum1( 1 ) )#10001print( sum2( 1 ) )#10001 lambda 表达式中的 num2 是一个自由变量，在运行时绑定值，而不是定义时就绑定，这跟函数的默认值参数定义是不同的。打印乘法表占位符12345678910111213#方法1for i in range(1, 10): for j in range(1, i+1): # end=&apos;&apos; 意思是末尾不换行，加空格 print(&apos;&#123;&#125;x&#123;&#125;=&#123;&#125;\t&apos;.format(i, j, i*j), end=&apos;&apos;) print()#方法2for m in range(1, 10): for n in range(1, m+1): print(&apos;%d*%d=%d\t&apos;%(n,m,n*m), end=&apos;&apos;) print() while 与for (待补充) 从键盘获取输入信息：input在 Python 中可以使用 input 函数从键盘等待用户的输入用户输入的 任何内容 Python 都认为是一个 字符串 格式化输出：print如果希望输出文字信息的同时，一起输出 数据，就需要使用到 格式化操作符% 被称为 格式化操作符，专门用于处理字符串中的格式包含 % 的字符串，被称为 格式化字符串% 和不同的 字符 连用，不同类型的数据 需要使用 不同的格式化字符 格式化字符 含义%s 字符串%d 有符号十进制整数，%06d 表示输出的整数显示位数，不足的地方使用 0 补全%f 浮点数，%.2f 表示小数点后只显示两位%% 输出 % 随机数生成1234567import random#导入模块后，可以直接在 模块名称 后面敲一个 . 然后按 Tab 键，会提示该模块中包含的所有函数#random.randint(a, b) ，返回 [a, b] 之间的整数，包含 a 和 brandom.randint(12, 20) # 生成的随机数n: 12 &lt;= n &lt;= 20 random.randint(20, 20) # 结果永远是 20 random.randint(20, 10) # 该语句是错误的，下限必须小于上限。 随机数的小游戏 12345678910111213141516171819202122232425262728import random# 从控制台输入要出的拳 —— 石头（1）／剪刀（2）／布（3）player = int(input(&quot;请输入您要出的拳 石头（1）／剪刀（2）／布（3）：&quot;))# 电脑 随机 出拳 —— 先假定电脑只会出石头，完成整体代码功能computer = random.randint(1, 3)print(&quot;玩家选择的拳头是 %d - 电脑出的拳是 %d&quot; % (player, computer))# 比较胜负# 1 石头 胜 剪刀# 2 剪刀 胜 布# 3 布 胜 石头# if (()# or ()# or ()):if ((player == 1 and computer == 2) or (player == 2 and computer == 3) or (player == 3 and computer == 1)): print(&quot;欧耶，电脑弱爆了！&quot;)# 平局elif player == computer: print(&quot;真是心有灵犀啊，再来一盘&quot;)# 其他的情况就是电脑获胜else: print(&quot;不服气，我们决战到天明！&quot;) 12345678910111213141516import randomguess_list = [&quot;石头&quot;, &quot;剪刀&quot;, &quot;布&quot;]win_combination = [[&quot;布&quot;, &quot;石头&quot;], [&quot;石头&quot;, &quot;剪刀&quot;], [&quot;剪刀&quot;, &quot;布&quot;]]while True: computer = random.choice(guess_list) people = input(&apos;请输入：石头,剪刀,布\n&apos;).strip() if people not in guess_list: continue elif computer == people: print (&quot;平手，再玩一次！&quot;) elif [computer, people] in win_combination: print (&quot;电脑获胜，再玩，人获胜才能退出！&quot;) else: print (&quot;人获胜！&quot;) break 函数1234567891011121314151617181920def print_code(code): print(code) #return Noneprint_code(&apos;python&apos;) # pythondef add(x,y): result=x+y return resulta = add(1,2)print(a) # 3def add1(x,y): result = x + y print(result)add1(1,2) # 3def add2(x,y): result = x + y print(&apos;%d + %d = %d&apos;%(x,y,x+y))add2(1,2) # 1 + 2 = 3 ####多值参数有时可能需要 一个函数 能够处理的参数 个数 是不确定的，这个时候，就可以使用 多值参数。 python 中有 两种 多值参数： 参数名前增加 一个 * 可以接收 元组参数名前增加 两个 ** 可以接收 字典 一般在给多值参数命名时，习惯使用以下两个名字 args —— 存放 元组 参数，前面有一个 kwargs —— 存放 字典 参数，前面有两个 123456789101112131415161718192021def demo(num, *args, **kwargs): print(num) print(args) print(kwargs)demo(1, 2, 3, 4, 5, name=&quot;小明&quot;, age=18, gender=True)#1#(2, 3, 4, 5)#&#123;&apos;name&apos;: &apos;小明&apos;, &apos;age&apos;: 18, &apos;gender&apos;: True&#125;demo(1,(2,3,4,5),&#123;&quot;name&quot;:&quot;小明&quot;, &quot;age&quot;:18, &quot;gender&quot;:True&#125;)#1#((2, 3, 4, 5), &#123;&apos;name&apos;: &apos;小明&apos;, &apos;age&apos;: 18, &apos;gender&apos;: True&#125;)#&#123;&#125;demo(1,(2,3,4,5), name=&quot;小明&quot;, age=18, gender=True)#1#((2, 3, 4, 5),)#&#123;&apos;name&apos;: &apos;小明&apos;, &apos;age&apos;: 18, &apos;gender&apos;: True&#125; 元组和字典的拆包在调用带有多值参数的函数时，如果希望：将一个 元组变量，直接传递给 args将一个 字典变量，直接传递给 kwargs就可以使用 拆包，简化参数的传递，拆包 的方式是：在 元组变量前，增加 一个 在 字典变量前，增加 两个 12345678910111213141516def demo(*args, **kwargs): print(args) print(kwargs)# 需要将一个元组变量/字典变量传递给函数对应的参数gl_nums = (1, 2, 3)gl_xiaoming = &#123;&quot;name&quot;: &quot;小明&quot;, &quot;age&quot;: 18&#125;# 会把 num_tuple 和 xiaoming 作为元组传递个 argsdemo(gl_nums, gl_xiaoming)#((1, 2, 3), &#123;&apos;name&apos;: &apos;小明&apos;, &apos;age&apos;: 18&#125;)#&#123;&#125;demo(*gl_nums, **gl_xiaoming)#(1, 2, 3)#&#123;&apos;name&apos;: &apos;小明&apos;, &apos;age&apos;: 18&#125; 函数的返回值12# Python 专有，利用元组交换两个变量的值a, b = b, a #面向对象(补充)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(11) python之函数式编程]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B9%8B%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[函数式编程是一种思维，闭包只是其一种体现 匿名函数12345678#例如 x+y#普通函数def add(x,y): return x+y#匿名函数lambda x,y:x+y 三元表达式12345678# x,y x大于y，取x 否则，取y# x &gt; y ? x:y (其他语言中)# x if x &gt; y else y #python中#条件为真时返回的结果 if 条件判断 else 条件为假时的返回结果 x = 1y = 4r = x if x &gt; y else yprint(r) #4 map类12345678910111213141516list_a = [1,2,3,4,5,6,7,8]def square(x): return x * xr = map(square,list_a)print(r) #&lt;map object at 0x0000026BCECDE9E8&gt;#map类print(list(r)) #[1, 4, 9, 16, 25, 36, 49, 64]#map:将集合里每个元素传到square里去，并且映射到新的集合中#也可以用fordef square1(x): return x * xfor x in list_a: x = square1(x) print(x)#1, 4, 9, 16, 25, 36, 49, 64 map常用方法1234list_a = [1,2,3,4,5,6,7,8]r = map(lambda x:x * x,list_a)print(list(r))#[1, 4, 9, 16, 25, 36, 49, 64] 12345list_a = [1,2,3,4,5,6,7,8]list_b = [1, 4, 9, 16, 25, 36, 49]s = map(lambda x,y:x * x + y,list_a,list_b) #map中传入多个listprint(list(s)) #[2, 8, 18, 32, 50, 72, 98] 长度取决于列表少的那个 reduce 连续计算，连续计算，连续调用lambda12345from functools import reducelist_a = [1,2,3,4,5,6,7,8]r = reduce(lambda x,y:x + y,list_a,10) #初始值为10 #10+1,得到11，11+2,得到13.....等一系列计算print(r) #46 12345#初始值为50，从0累加到99from functools import reducea = range(0,100)r = reduce(lambda x,y:x+y,a,50)print(r) map/reduce编程模型 映射 归纳并行计算函数式编程 filter 过滤1234list_a = [1,1,0,0,1,1,0,1,0]# r = filter(lambda x: True if x==1 else False, list_a)r = filter(lambda x:x,list_a) #因为0代表Falseprint(list(r))]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(9) python之闭包]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B9%8B%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[闭包闭包 = 函数 + 环境变量(函数定义的时候) 一个最简单的闭包1234567def curve_pre(): def curve(): print(&apos;This is a function&apos;) return curvef = curve_pre()f() #This is a function 闭包不受外部变量影响1234567891011121314def curve_pre1(): a = 25 def curve1(x): return a*x**2 return curve1#闭包 = 函数 + 环境变量(函数定义的时候)a = 20 #全局变量f1 = curve_pre1()print(f1.__closure__) #(&lt;cell at 0x00000216457D06D8: int object at 0x00007FFEF75AD720&gt;,)实质返回了一个闭包print(f1.__closure__[0].cell_contents) #25 取出环境变量f1(2) print(f1(2)) #100 调用时 a 取 25 非闭包1234567891011121314def f2(): a = 10 def f3(): #a(=20)被python 认为是一个局部变量,没有引用上面的a(=10)(环境变量)就不是闭包了 a = 20 print(a) print(a) f3() print(a)f2()#首先运行f2() ,a=10，print(a)即为10#然后运行f3() ,a=20，print(a)即为20，此时a为f3()中的局部变量#最后print(a)即为10 闭包12345678910def f4(): a = 10 def f5(): c = 20 * a #调用了 a=10 return f5f = f4()print(f) #&lt;function f4.&lt;locals&gt;.f5 at 0x0000015AF4F479D8&gt;print(f.__closure__)#(&lt;cell at 0x0000015AF4ED06D8: int object at 0x00007FFC0F54D540&gt;,) 闭包 只是一种思维方式，函数式编程 闭包可以记忆上次调用的状态 例题，origin 最初为0，累加计算12345678910111213141516171819#闭包模式origin = 0def factory(pos): def go(step): nonlocal pos #pos不是本地局部变量 new_pos = pos +step pos = new_pos return new_pos return gotourist = factory(origin) #初始化为 0print(tourist(2)) #即step为2print(tourist.__closure__[0].cell_contents)#取环境变量#2记住了调用的值print(tourist(3))print(tourist.__closure__[0].cell_contents)#5print(tourist(5))print(tourist.__closure__[0].cell_contents)#10print(origin) #0 使用闭包，并没有改变全局变量,所有操作都在函数内部 1234567891011121314#非闭包origin = 0def go(step): global origin #定义一个全局变量 new_pos = origin + step origin = new_pos return new_posprint(go(2))#2print(origin)#2 #改变了全局变量的值print(go(3))#5print(origin)#5print(go(5))#10print(origin)#10 1234567891011121314#面向对象编程class Tourist(): origin = 0 def pos(self,new_pos): self.origin += new_postourist=Tourist()print(tourist.origin)tourist.pos(2)print(tourist.origin)tourist.pos(3)print(tourist.origin)tourist.pos(5)print(tourist.origin)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(10) python中的枚举]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E7%9A%84%E6%9E%9A%E4%B8%BE%2F</url>
    <content type="text"><![CDATA[在python中，枚举的本质是一个类，所有枚举类都是Enum的子类枚举值不能动态更改且标签唯一，标签唯一但是数值不唯一。如果数值不唯一，相当于起别名 表示类型的三种方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101from enum import Enumclass VIP(Enum): #所有枚举类都是Enum的子类 YELLOW = 1 #常量是不能更改的 用大写表示（约定的，python中没有真的常量） GREEN = 2 RED = &apos;str&apos; BLACK = 4 PINK = 1 # 其实就是YELLOW = 1， 可以看作YELLOW 的别名， #YELLOW = 1 #会报错，不能同时有两个YELLOW Attempted to reuse key: &apos;YELLOW&apos; # GREEN = 6 #会报错，不能继续使用GREEN这个标签 Attempted to reuse key: &apos;GREEN&apos;#class Common(): # YELLOW = 1 #VIP.YELLOW =6 #会报错，枚举中的值不能被更改print(VIP.PINK)print(VIP.YELLOW) #VIP.YELLOW (不关心取值)print(VIP.PINK) #VIP.YELLOW 可以看作YELLOW 的别名print(type(VIP.YELLOW)) #&lt;enum &apos;VIP&apos;&gt; 枚举类型print(VIP.YELLOW.name) #YELLOW 获取标签名字print(type(VIP.YELLOW.name)) #&lt;class &apos;str&apos;&gt; 字符串类型print(VIP[&apos;YELLOW&apos;]) #VIP.YELLOWprint(VIP.YELLOW.value) #1 获取值#枚举类型、枚举的名字、枚举的值for v in VIP: #遍历枚举类型(并不会把别名打印出来) print(v) #VIP.YELLOW #VIP.GREEN #VIP.RED #VIP.BLACK #枚举的比较运算#枚举不可以进行大小比较，但可以进行等值比较，身份比较result = VIP.YELLOW == VIP.PINK #枚举之间的等值比较 #Trueresult1 = VIP.YELLOW == 1 #False#result = VIP.YELLOW &gt;= VIP.PINK #枚举不能进行大小比较报错 #&apos;&gt;=&apos; not supported between instances of &apos;VIP&apos; and &apos;VIP&apos;result2 = VIP.YELLOW is VIP.PINK #True 身份比较print(result) print(result1)print(result2) class VIP1(Enum): YELLOW = 1 GREEN = 2 RED = &apos;3&apos; BLACK = 4 PINK = 1result = VIP.YELLOW == VIP1.YELLOW #Fales 虽然值相等，但其实是两个不同的枚举类型print(result) for v in VIP.__members__.items(): #遍历枚举类型(把别名也打印出来) print(v)&apos;&apos;&apos;(&apos;YELLOW&apos;, &lt;VIP.YELLOW: 1&gt;)(&apos;GREEN&apos;, &lt;VIP.GREEN: 2&gt;)(&apos;RED&apos;, &lt;VIP.RED: 3&gt;)(&apos;BLACK&apos;, &lt;VIP.BLACK: 4&gt;)(&apos;PINK&apos;, &lt;VIP.YELLOW: 1&gt;)&apos;&apos;&apos;for v in VIP.__members__: print(v) #枚举的名字（包括别名）&apos;&apos;&apos;YELLOWGREENREDBLACKPINK&apos;&apos;&apos;a = 1a = VIP(a) #把a变成一个枚举类型print(a) #VIP.YELLOW from enum import IntEnum #(枚举的值得是int类型)from enum import IntEnum,unique #(枚举的值得是int类型,且不能重复)class VIP2(IntEnum): YELLOW = 1 GREEN = 2 # RED = &apos;str&apos; #会报错,(枚举的值得是int类型) BLACK = 4 PINK = 1 @uniqueclass VIP3(IntEnum): YELLOW = 1 GREEN = 2 # RED = &apos;str&apos; #会报错,(枚举的值得是int类型) BLACK = 4 # PINK = 1 #会报错,取值重复#枚举 是单例模式 #23种设计模式 实践中]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(12) python中的装饰器]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[对修改是封闭的，对扩展是开放的 ####在原有函数上调用时加时间1234567891011121314import timedef a(): print(&apos;This is a function&apos;) def b(): print(&apos;Hello world&apos;) def print_current_time(abc): print(time.time()) abc()print_current_time(a)print_current_time(b) 等同于12345678910111213141516import timedef a(): print(&apos;This is a function&apos;) def b(): print(&apos;Hello world&apos;) def print_current_time(abc): print(time.time()) abc()print(time.time())a()print(time.time())b() 更改了内部实现，不够优雅 ####装饰器12345678910111213import timedef decorator(func): def wrapper(): print(time.time()) func() return wrapperdef f1(): print(&apos;This is a function&apos;) f = decorator(f1)f() 修改一下 1234567891011121314import timedef decorator(func): def wrapper(): print(time.time()) func() return wrapper@decorator #@装饰器名字def f1(): print(&apos;This is a function&apos;) f1() #并没有改变原有函数的调用方式#这才是装饰器 意义所在 进一步优化，支持不同个数的参数1234567891011121314151617181920import timedef decorator(func): def wrapper(*args): print(time.time()) func(*args) return wrapper@decorator #@装饰器名字def f1(func_name): print(&apos;This is a function&apos;+ func_name) @decoratordef f2(func_name1,func_name2,func_name3): print(&apos;hello world&apos;+ func_name1) print(&apos;hello world&apos;+ func_name2) print(&apos;hello world&apos;+ func_name3) f1(&apos;tset func&apos;) f2(&apos;tset func1&apos;,&apos;tset func2&apos;,&apos;tset func3&apos;) 进一步优化，加入关键字参数12345678910111213141516171819202122232425262728import timedef decorator(func): def wrapper(*args,**kw): print(time.time()) func(*args,**kw) return wrapper@decorator #@装饰器名字def f1(func_name): print(&apos;This is a function&apos;+ func_name) @decoratordef f2(func_name1,func_name2,func_name3): print(&apos;hello world&apos;+ func_name1) print(&apos;hello world&apos;+ func_name2) print(&apos;hello world&apos;+ func_name3) @decoratordef f3(func_name1,func_name2,**kw): print(&apos;hello world&apos;+ func_name1) print(&apos;hello world&apos;+ func_name2) print(kw)f1(&apos;tset func&apos;) f2(&apos;tset func1&apos;,&apos;tset func2&apos;,&apos;tset func3&apos;)f3(&apos;tset func1&apos;,&apos;tset func2&apos;,a = 1,b = 2,c = &apos;123&apos;) 装饰器也可以用来控制访问一个函数上就可以加多个装饰器]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(8) python之初识JSON]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B9%8B%E5%88%9D%E8%AF%86JSON%2F</url>
    <content type="text"><![CDATA[JSON是一种轻量级的数据交换格式JSON 是一种数据格式字符串是 JSON的表现形式符合JSON格式的字符串叫做 JSON字符串json易于阅读，易于解析，网络传输效率高 跨语言交换数据 json.loads()解码(反序列化),json.dumps()编码(序列化)123456789101112131415import json #反序列化json_str = &apos;&#123;&quot;name&quot;:&quot;weilai&quot;,&quot;age&quot;:18,&quot;a&quot;:true&#125;&apos; #JSON字符串格式，双引号json_str1 = &apos;[&#123;&quot;name&quot;:&quot;weilai&quot;,&quot;age&quot;:18,&quot;a&quot;:false&#125;,&#123;&quot;name&quot;:&quot;weilai&quot;,&quot;age&quot;:18&#125;]&apos;student = json.loads(json_str) #将一个JSON编码的字符串转换回一个Python数据结构student1 = json.loads(json_str1) print(type(student)) #字典格式 &#123;&apos;name&apos;: &apos;weilai&apos;, &apos;age&apos;: 18, &apos;a&apos;: True&#125;print(type(student1)) #列表形式 [&#123;&apos;name&apos;: &apos;weilai&apos;, &apos;age&apos;: 18, &apos;a&apos;: False&#125;, &#123;&apos;name&apos;: &apos;weilai&apos;, &apos;age&apos;: 18&#125;]print(student) print(student1)print(student[&apos;age&apos;]) print(student[&apos;name&apos;]) 序列化12345678910import jsonstudent = [ &#123;&apos;name&apos;: &apos;weilai&apos;, &apos;age&apos;: 18,&apos;a&apos;: False&#125;, &#123;&apos;name&apos;: &apos;weilai&apos;, &apos;age&apos;: 18&#125; ]json_str = json.dumps(student)print(type(json_str)) #&lt;class &apos;str&apos;&gt;print(json_str) #[&#123;&quot;name&quot;: &quot;weilai&quot;, &quot;age&quot;: 18, &quot;a&quot;: false&#125;, &#123;&quot;name&quot;: &quot;weilai&quot;, &quot;age&quot;: 18&#125;] JSON对象，json, json字符串 在python中没有JSON对象 json 是对ecmascript的一种实现 与Javascript相同 json 是一种中间数据类型，有自己的数据类型，与JavaScript相似 rest 服务的标准格式]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(7) python正则表达式的学习过程]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[12345 #优先使用内置函数a = 'C|C++|Java|C#|Python|Javascript'print(a.index('Python')&gt;-1)print('Python' in a) #利用内置函数判断字符串'python'是否在a中 正则表达式是一个特殊的字符序列，帮助检测一个字符串是否与所设定字符序列相匹配。.可快速检索文本、实现一些替换文本的操作。例如:1、检查一串数字是否是电话号码.2、检测一个字符串是否符合email3、把一个文本里指定的单词替换为另外一个单词。 #用正则表达式123456789101112131415161718192021import re # 引入re 模块 a = 'C|C++|Java|C#|Python|Javascript'r = re.findall('Python',a) #findall 方法 print(r)if len(r) &gt; 0: print('字符串中包含Python')else: print('No') ``` 正则表达式不仅可以用来检测字符串，也可以用来替换字符串。```pythonimport re a = 'C0C++7Java12C#9Python67\nJavascript8' #用r来提取a中的数字r = re.findall('\d',a) #\d 来表示数字（0-9）print(r)#用s来提取a中的非数字s = re.findall('\D',a) #\D 来表示非数字的字符print(s) 上面’python’是普通字符，’\d’,’\D’属于元字符正则表达式就是由普通字符和元字符等组合在一起的。 字符集虽然可以提取字符串，但提取出来的都是一个一个字符。只能匹配单一的字符（单个字母，数字）12345import rea = 'abc,acc,adc,aec,adfc,ahc,afc'r = re.findall('a[cf]c',s) #提取afc 或acc,普通字符a,c定界，元字符c，f#[]里表示或。[cf] c或f.[cdf] c或d或f [^cfd]取反，不是c和d和f。[c-f]取c到f。print(r) 概括字符集 \d即 [0-9]\D所有的非数字\w单词字符 ‘[A-Za-z0-9]和下划线_\W 非单词字符，\s 空白字符(空格/制表符/换行符)\S 非空白字符. 匹配除换行符之外其他所有的字符12345import rea = 'C0C++7Java12C#9Python67Javascript8\n\r &amp;^'r = re.findall('\d',a) print(r)#可自行验证 数量词,贪婪与非贪婪123456789101112import rea = 'C0C++7Java12C#9Python67Javascript8\n\r &amp;^'r = re.findall('\w&#123;3&#125;',a) #提取出来的\w 3个一组s = re.findall('[A-Za-z]&#123;3&#125;',a)t = re.findall('[A-Za-z]&#123;3,7&#125;',a)#3到7个一组，优先选择7个#贪婪 与 非贪婪#python默认使用贪婪 按最大的匹配u = re.findall('[A-Za-z]&#123;3,7&#125;?',a)#非贪婪 按最小的匹配，即3个一组print(r) print(s)print(t)print(u) 问号，星号，加号的使用方法123456789import rea = 'pytho0python1pythonn2'r = re.findall('python*',a) #['pytho', 'python', 'pythonn']s = re.findall('python+',a)t = re.findall('python?',a)print(r)print(s)print(t) 1、 对前的字符匹配0次或无限多次2、+ 对+前的字符匹配1次或无限多次3、 ? 对?前的字符匹配0次或1次 与贪婪中的?是不同的 边界匹配123456import re qq = '100001'#qq位数4-10位数r = re.findall('^\d&#123;4,10&#125;$',qq) #^从字符串开头匹配 ， $从字符串末尾匹配#即开头到结尾得在4-10之间print(r) 组1234import rea = 'PythonPythonPythonPythonPythonPython'r = re.findall('(Python)&#123;2&#125;',a)print(r)#['Python', 'Python', 'Python'] 匹配模式 （函数中的第三个参数）re.I 忽略匹配中的大小写re.S 匹配所有的字符，包括换行符123456import rea = &apos;C0C++7Java12C#\n9Python67Javascript#8&apos;r = re.findall(&apos;c#&apos;,a,re.I)r = re.findall(&apos;c#.&#123;1&#125;&apos;,a,re.I|re.S) # | 且print(r)#[&apos;C#&apos;]print(r1)#[&apos;C#\n&apos;] re.sub简单用法12345678import rea = 'C0C++C#7Java12C#\n9Python6C#7JavascriptC#8'r = re.sub('C#','GO',a,0) #无限次替换s = re.sub('C#','GO',a,1) #只替换一次t = a.replace('C#','GO') #python内置函数print(r)print(s)print(t) re.sub高阶用法123456789101112131415import rea = &apos;C0C++C#7Java12C#\n9Python6C#7JavascriptC#8&apos;def convert(value): print(value)#&lt;re.Match object; span=(5, 7), match=&apos;C#&apos;&gt;#&lt;re.Match object; span=(14, 16), match=&apos;C#&apos;&gt;#&lt;re.Match object; span=(25, 27), match=&apos;C#&apos;&gt;#&lt;re.Match object; span=(38, 40), match=&apos;C#&apos;&gt;#所以用value.group() matched = value.group() return &apos;!!&apos; + matched +&apos;!!&apos;r = re.sub(&apos;C#&apos;,convert,a)print(r) 把函数作为传递参数12345678910111213import res = &apos;A1b2c3d4e5f6g7h8i9&apos;def convert1(value): print(value) matched1 = value.group() if int(matched1) &gt;=6: return &apos;9&apos; else: return &apos;0&apos;s = re.sub( r&apos;\d&apos;,convert1,s)print(s) match和searchmatch和search方法类似, 但有些许区别, 顾明思议match是匹配的意思, 从第一个字符开始匹配, 匹配不到就返回search是搜索的意思, 如果第一个字符匹配不到, 会继续往后匹配, 直到字符结束1234567import res = &apos;A1b2c3d4e5f6g7h8i9&apos;r = re.match(r&apos;\d&apos;,s) r1 = re.search(r&apos;\d&apos;,s)print(r) #Noneprint(r1)#&lt;re.Match object; span=(1, 2), match=&apos;1&apos;&gt; group()的用法123456789101112import res = &apos;life is short,i use python&apos;r = re.search(&apos;life.*python&apos;,s)r1 = re.search((&apos;life.*python&apos;),s) #与上行一样r2 = re.search(&apos;life(.*)python&apos;,s)print(r.group())print(r1.group())print(r2.group(0)) #全文匹配print(r2.group(1)) #括号内匹配r3 = re.findall(&apos;life(.*)python&apos;,s)print(r3) 12345678910import res = &apos;life is short,i use python,I love python&apos;r = re.search(&apos;life(.*)python(.*)python&apos;,s)print(r.group())#life is short,i use python,I love pythonprint(r.group(0))#life is short,i use python,I love pythonprint(r.group(1))# is short,i use (第一组)print(r.group(2))#,I love（第二组）print(r.group(0,1,2)) #用元组的方式表达出来#(&apos;life is short,i use python,I love python&apos;, &apos; is short,i use &apos;, &apos;,I love &apos;)print(r.groups()) #只会表示出（.*）的内容#(&apos; is short,i use &apos;, &apos;,I love &apos;)]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(6) python中面向对象]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[有意义的面向对象的代码类 是面向对象最核心的观念类、对象实例化类最基本的作用：封装一定要用self,引用 self.类只负责定义，不会去运行类和对象。数据成员构造函数可以让模板生成不同的对象 类是现实世界或思维世界中的实体在计算机中的反馈它将数据以及这些数据上的操作封装在一起 类 被 实例化后 就成了一个具体的对象类就像是一个模板，通过类 就可以产生很多对象。123456789101112131415#比如这段代码为 1.pyclass Human(): sum = 0 #在class内部定义变量 类变量 （和类相关联在一起的） def __init__(self,name,age):#构造函数 ， #文件夹中得含有 _init_.py 模块才会被认为是一个包。包 导入时会优先运行. #初始化对象属性 self.name = name # 定义实例时需要self，调用实例不需要给self赋参 self.age = age #定义实例变量，实例变量只和对象相关 self. #return NONE (构造函数只能返回NONE) (补充知识) def get_name(self): print(self.name) def do_homework(self): print(&apos;This is a parent method&apos;) 12345678910111213141516171819202122232425from 1.py import Human class Student(Human): #Human是Student的父类，Student是Human的子类 def __init__(self,school,name,age): self.school = school super(Student,self).__init__(name,age) #建议以此方式调用父类 #super 不仅仅可用于构造函数，也可以用于普通的实例方法 # Human.__init__(self,name,age) #子类里调用父类构造函数 #self 用类调用实例方法没意义，所以加self # self.age = age def do_homework(self): #子类和父类同名的话，不会报错，先使用子类 #super(Student,self).do_homework() #This is a parent method print(&apos;English homework&apos;) student1 = Student(&apos;jinan university&apos;,&apos;wei&apos;,18) #实例化student1.do_homework() #English homeworkprint(student1.name) #weiprint(student1.age)#18#继承 单继承 多继承 定义一个类1234567891011121314151617181920class Student(): name = &apos;&apos; #在class内部定义变量 类变量 （和类相关联在一起的） age = 0 #行为 与 特征 def __init__(self,age,name): #构造函数(实例化后，会自动调用) #初始化对象属性 self.neme = name self.age = age #定义实例变量，实例变量只和对象相关 self. # #return NONE (构造函数只能返回NONE) (补充知识) def print_files(self): #在class内部定义函数 print(&apos;name:&apos;+ self.name) print(&apos;age:&apos;+ str(self.age))student = Student() #类的实例化student.print_files() #类下面方法的调用# 建议 类的实例化以及类下面方法的调用 与类的定义放在不同的模块。# 定义实例时需要self，调用实例不需要给self赋参 详解123456789101112# 模块c = 50def add(x, y): c= x+y print(c)add(1,2) #3 函数中局部变量的值print(c) #50 全局变量的值 # 两个print(c)的区别 # 局部变量不会改变全局变量的值 类和模块要区别对待 ‘类变量’ 和 类 关联在一起的######’实例变量’ 和 对象 关联在一起的123456789101112131415161718class Student(): sum=0 name = &apos;weilai&apos; age = 0 def __init__(self,name,age): self.name = name self.age = age def marking(self,sorce): #内部访问 if sorce &lt; 0: #建议通过方法 对 类变量赋值 # sorce =0 return &apos;不能给同学打负分&apos; self.__sorce = sorce print(self.name + &apos;同学本次的考试分数为：&apos; + str(self.__sorce)) return &apos;hello&apos;result = student1.marking(80)#wang同学本次的考试分数为：80print(result) #hello 12345678910111213141516class Student(): sum=0 # 类变量 和类相关 name = &apos;weilai&apos; #在class内部定义变量 类变量 age = 0 # 类中赋值没有意义的。 #21 ，22 其实是与对象相关，不应出现在这 # 行为 与 特征 def __init__(self,name,age): #构造函数(实例化后，会自动调用),是一个特殊的方法 #主要是被用来初始化对象属性 self.name = name #实例方法操控实例变量 self.age = age print(self.__class__.sum) print(Student.sum) self.__class__.sum +=1 #实例方法访问类变量中的sum print(Student.sum)student1 = Student(&apos;wang&apos;,18)student2 = Student(&apos;li&apos;,19) 类方法主要操作和类相关的变量用类调用类方法123456789101112131415161718class Student(): sum=0 name = &apos;weilai&apos; age = 0 def __init__(self,name,age): self.name = name self.age = age @classmethod #让其成为类方法 def plus_sum(cls): #sum每运行一次就+1 cls.sum+=1 print(cls.sum)student1 = Student(&apos;wang&apos;,18)Student.plus_sum() #用类调用类方法student2 = Student(&apos;li&apos;,19)Student.plus_sum() 对象调用类方法(python可用但最好不要用)123456789101112131415161718class Student(): sum=0 name = &apos;weilai&apos; age = 0 def __init__(self,name,age): self.name = name self.age = age @classmethod #让其成为类方法 def plus_sum(cls): #sum每运行一次就+1 cls.sum+=1 print(cls.sum)student1 = Student(&apos;wang&apos;,18)student1.plus_sum() #用对象调用类方法student2 = Student(&apos;li&apos;,19)student2.plus_sum() 静态方法12345678910111213class Student(): sum=0 name = &apos;weilai&apos; age = 0 def __init__(self,name,age): self.name = name self.age = age @staticmethod #静态方法 def add(x): print(Student.sum) print(&apos;this is a static method&apos;) 静态方法 能用的地方 基本可以用 类方法替代(最好用类方法)当和类和对象没多大关系的时候,可以使用静态方法静态方法和类方法 均不能访问 实例变量 类中赋值没有意义的。1234567891011121314151617class Student(): name = &apos;weilai&apos; age = 0 def __init__(self,name,age): name = name age = age student1 = Student(&apos;wang&apos;,18)print(student1.name) #weilaiprint(student1.age) #0print(student1.__dict__) #&#123;&#125; #__dict__显示student1下所有的变量，即没有变量# python 会先在 实列变量上寻找 ，寻找不到就会到类变量里寻找，（然后再到父类里寻找）# 所以即使student1为空，也显示了类变量下的值#公开的 public 私有的（外部不能访问）private 在方法或变量前加__ 表示私有的#__init__ 构造函数是python特有的，可以从外部访问#print(student1._Student__sorce) 表明python中私有只是改了一个名字]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(5) python项目的组织结构]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E9%A1%B9%E7%9B%AE%E7%9A%84%E7%BB%84%E7%BB%87%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[包、模块、类→函数、变量 序列解包1234# a=1# b=2# c=3# d,e,f=4,5,6 定义一个函数12345678def damage(skill1,skill2): damage1 = skill1*3 damage2 = skill2*2+10 return damage1,damage2 (不return，就是返回none)skill1s,skill2s=damage(2,3)print(skill1s,skill2s) 1234567891011def add(x,y): result=x+y return result def print_code(code): print(code) returna=add(1,2)print_code(&apos;python&apos;)print(a) 函数参数1234567891011121314151617181920212223def print_student_files(name, gender,age,adress): print(&quot;I&apos;m &quot;+name) print(&quot;I&apos;m &quot;+age+&apos;years old&apos;) print(&quot;I&apos;m &quot;+ gender) print(&quot;I&apos;m living in &quot;+adress)print_student_files(&apos;weilai&apos;,&apos;man&apos;,&apos;18&apos;,&apos;hubei&apos;)def print_student_files1(name, gender=&apos;man&apos;,age=18,adress=&apos;hubei&apos;): print(&quot;I&apos;m &quot;+name) print(&quot;I&apos;m &quot;+str(age)+ &apos;years old&apos;) print(&quot;I&apos;m &quot;+gender) print(&quot;I&apos;m living in &quot;+adress)print_student_files1(&apos;weilai&apos;,&apos;woman&apos;,18,&apos;hubei&apos;)#重点：#1）必须参数:形参(例如name)，实参(&apos;weilai&apos;,&apos;man&apos;,18,&apos;hubei&apos;)#2）关键字参数#3)默认参数：大多数情况下，函数的参数选取的的是一种默认值，可选用默认参数# 注意事项:1、形参没有给默认值的，函数调用时得给一个实参# 2、非默认参数不能放在默认参数之后（调用时，同理）# 3、参数顺序得与默认参数顺序相同（关键字参数有时，可不遵守顺序）# 4、给了默认参数，函数调用时优先使用实参 import1234567891011121314import _init_print(_init_.b)# 注意事项：import 与 from import# 1）如 print t包C7.py中的a# import t.c7 ~ print（t.c7.a） 等价于from t.c7 import a ~print（a）# 等价于from t import c7.a ~print（c7.a）# 2)import t.c7 ~ print（t.c7.a） 等价于import t.c7 as m ~print（m.a）# 3）包和模块不会被重复导入 # 4）避免循环导入 # 5）from t.c7 import * (导入C7中所有的变量) # 6）from t.c7 impor _all_=[&apos;a&apos;,&apos;c&apos;] (导入C7中&apos;a&apos;,&apos;c&apos;两个变量） if12345mood=True if mood: print(&apos;go to left&apos;)else : print(&apos;go to right&apos;) 123456789101112a=1b=2c=3d,e,f=4,5,6 #序列解包if d&lt;a: print(&apos;go to left&apos;)elif d&lt;b: print(&apos;go to left&apos;)elif d&lt;c: print(&apos;go to left&apos;)elif d&lt;e: print(&apos;go to left&apos;) for1234567891011121314151617181920a=[1,2,3,4,5]for x in a: if x==3: break print(x) # continue # print(x)a = [[&apos;apple&apos;,&apos;orange&apos;,&apos;banana&apos;],(1,2,3)]for x in a: for y in x: print(y) print(x)for x in range(0,10): print(x)for x in range(0,10,2): print(x) 注意事项： 1)break和continue区别：break到3就停止，continue跳过3继续 2）注意print()函数的位置，对结果的影响 3）递归用while，遍历用for]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(4) python中流程控制语句]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[条件语句if elif else都是关键字，需要能读和写 基本格式：123456if 条件语句1： 执行语句块1elif 条件语句2： 执行语句块2else： 执行语句块3 执行过程：12a.先判断条件语句1是否为True，如果为True就执行冒号后边的执行语句块1，整个条件结构就执行完了;如果是False，就去判断条件语句2是否为True。b.如果是True就执行执行语句块2，再执行其他语句;如果是False,就直接执行语句块3，再执行其他语句。 注意：冒号后边语句块和冒号所在得语句要保持一个缩进。 if判断条件语句的值是否为True，如果为True，就只执行执行语句块。否则就直接执行if语句后面的其他语句。123456789101112if 条件语句： 执行语句块age=20要求判断年龄是否大于18，如果大于18就输出&apos;成年人&apos;if age&gt;18: print(&apos;成年人&apos;)练习：判断一个数是否是偶数，如果是就打印&apos;xxx是偶数&apos;n=18if n%2==0: print(&apos;%d是偶数&apos;%(n)) 2.if-else判断条件语句是否为True，如果为True，就执行语句块1;否则就执行语句块2.12345678910111213141516171819202122if 条件语句： 执行语句块1else： 执行语句块2n=17if n%2==0: print(&apos;%d是偶数&apos;%(n))else: print(&apos;%d是奇数&apos;%(n))练习：输入一个数，如果这个数大于10，就输出他的2倍值。否 则输出这个数的2次幂。input():从控制台获取键盘输入的一个字符串，以回车结束。inputvalue=input(&apos;请输入一个数：&apos;)print(inputvalue)n=int(inputvalue)比较运算符和+以及*，在运算的时候，两边可以都是字符串，也可以都是数字，但是不可以一样一个。if n&gt;10:num=n*2 print(num)else:num=n**2 print(num) 3.if-elif-elif-else总结: a.如果要求中需要多个判断，可以使用多个elif的if语句。b.一个if/elif/else语句中可以嵌套其他的if语句。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354（1）给一个成绩，判断成绩是优秀(90-100)、良好(80-89)、 中等(60-79)、不及格(60以下)方法一：grade=96if grade&gt;=90: if grade&gt;100: print(&apos;成绩有误&apos;) else: print(&apos;优秀&apos;)elif grade&gt;=80: print(&apos;良好&apos;)elif grade&gt;=60: print(&apos;中等&apos;)elif grade&gt;=0: print(&apos;不及格&apos;)else: print(&apos;成绩有误&apos;)方法二：grade=67if 100&gt;=grade&gt;=90: print(&apos;优秀&apos;)elif 90&gt;grade&gt;=80: print(&apos;良好&apos;)elif 80&gt;grade&gt;=60: print(&apos;中等&apos;)elif 60&gt;grade&gt;=0: print(&apos;不及格&apos;)else: print(&apos;成绩有误&apos;) （2）给个年龄，判断年龄处于：婴儿（0-1岁）、儿童（2-4 岁）、少年（5-12岁）、青年（13-18岁）、成年（19-40）、 中年（41-60）、老年（60以上）age=1if age&lt;2: if age&lt;=0: print(&apos;年龄输入错误&apos;) else: print(&apos;婴儿&apos;)elif age&lt;5: print(&apos;儿童&apos;)elif age&lt;13: print(&apos;少年&apos;)elif age&lt;19: print(&apos;青年&apos;)elif age&lt;41: print(&apos;成年&apos;)elif age&lt;61: print(&apos;中年&apos;)else: print(&apos;老年&apos;)说明：Python中没有switch语法。pass：占位，防止因为没有写块结构而出现语法错误。if n==10: pass 转换函数 1.int()int():将其他的数据转换成int类型的数据123456num=12.56print(int(num)) # 12 将浮点数转换成整数（直接去掉小数部分）bool1=Trueprint(int(bool1)) # 1 将布尔值转换成整数，True-&gt;1 False-&gt;0str1=&apos;123&apos;print(int(str1)) # 123 只有纯数字字符串或者纯数字字符串前有正负号的字符串才能转换成相应的整数。 2.flot()flot():将其他数据转换成浮点型3.bool()bool()：将其他的数据转换成布尔值 数字转换成布尔，非0是True，0是False。1234567print(bool(12)) # Trueprint(bool(-12.3)) # Trueprint(bool(0)) # False字符串转换成布尔，除了空串是False，其他的都是True。print(bool(&apos;abc&apos;)) # Trueprint(bool(&apos;&apos;)) # False 注意：在if或者while循环后的条件语句，可以不是结果为True/False的表达式，也可以是值是其他类型的表达式.判断的是时候就看这个值转换成bool后的结果是True还是False。1234if 10: print(&apos;aaa&apos;) # aaa （10转换成bool后是True) if 0: print(&apos;aaa&apos;) # （0转换成bool后是False） 练习：判断一个字符串是否是空串，如果不是就直接打印这个字符 串，否则打印“空串”123456789101112方法1：str1=&apos;&apos;if str1: print(str1)else: print(&apos;空串&apos;)方法2：str1=&apos;abc&apos;if str1!=&apos;&apos;: print(str1)else: print(&apos;空串&apos;) 4.str()str()：将其他的数据转换成字符串。所有的数据类型都可以转换成字符串。循环python中循环：for循环、while循环（一个操作需要重复执行多次，这个时候就要考虑使用循环）for循环python中的for循环只有for-in循环：123456789101112131415161718192021格式：for 变量名 in 列表： 循环体执行过程：使用变量去依次获取列表中的数据直到获取完为止;没获取一个数据，执行一次循环体。循环次数：由列表中的数据的个数决定。去获取字符串中的每一个字符str1=&apos;abcdef&apos;for char in str1: print(char)去统计字符串中&apos;a&apos;出现的次数str1=&apos;avaadafvaavafaaa&apos;n=0for char in str1: if char==&apos;a&apos;: n=n+1 print(n)range（）函数：可以生成一个数值范围` 1234567打印1-100for n in range(1,101): print(n)用法1：range(n),生成0~n-1的值for x in range(9): print(x)` 用法2：range(m,n),生成m~n-1的数123456for n in range(5,9): print(n)打印0-100之间所有的偶数for x in range(101): if x%2==0: print(x) 用法3：range(m,n,step):从m开始每step取一个数，取到n前 一个数为止。123456for x in range(1,8,2): print(x) # 1,3,5,7 不通过字符串相乘，打印10次“=”,并且打印在同一行。for _ in range(10): print(&apos;=&apos;,end=&apos; &apos;) 求1+2+3…+1001234n=0for x in range(1,101): n=n+xprint(n) 注意：如果循环中的变量取到的值没有意义，循环只是单纯的控制次数，这个时候for后面的变量名一般用“_”代替。 while循环123格式： while 条件语句： 循环体 执行过程：判断条件语句结果是否为True，如果为True就执行一次循环体。执行完循环体后再判断条件语句是否为True，如果为True继续执行循环体。重复这个过程，直到条件语句结果为False for循环可以实现的操作，while循环都可以 打印1-10012345678910方法1：x=0while x&lt;100: x+=1 print(x) 方法2：x=1while x&lt;=100: print(x) x+=1 计算1+2+3+…+100123456x=0n=0while n&lt;100: n+=1 x+=n print(x) 求1-100中所有偶数的和123456789101112131415方法1：n=0x=0while n&lt;=100: if n%2==0: x=x+n n=n+1 print(x)方法2：n=0x=0while n&lt;100: n+=2 x=x+nprint(x) break和continue1、breakbreak是一个让循环提前结束的关键字 如果在for循环或者while循环中遇到了break，那么循环就在break的位置直接结束。结束后程序执行循环后边的代码。 练习:找到1000~9999中第一个能够被13整除的数，打印出来123456789for x in range(1000,10000): if x%13==0: print(x) break for x in range(1,100): if x==50: break print(x) # 1 2 3 ... 49 用while循环实现：不断的让用户去输入数字，直到用户输入的数字是0为止。最后在打印之前输入的数的和。 input()函数：程序执行到input()函数的时候，程序就会停下来，等待用户从键盘输入并且以回车结束，然后才会往下执行。 注意：break只能写在循环中12345678sum1=0while True:num=int(input(&quot;&gt;&gt;&gt;&quot;)) # 获取键盘输入的内容，并且转换成int类型 sum1+=num # 将当次输入的数字加起来 if num==0: # 判断输入的数字是否是0，如果是就让循环结束 break print(num)print(sum1) for循环的特点：次数确定，可以在序列中取数据 while循环：循环次数不确定的（while True + break） randint(m,n):产生一个m到n的随机整数 产生随机数：random模块是python内置用来产生随机数的模块，里面提供了很多产生随机数的函数。 猜数字：随机生成一个整数。用户输入数字。如果用户输入的数字大于这个随机数就提示：“大了”;如果用户输入的数小于随机数就提示：“小了”。直到用户输入的数和这个随机数大小一样游戏结束。123456789101112131415161718import randomnum=random.randint(0,100) # 产生一个0到100的随机数n=0while True:num1=int(input(&quot;请输入你猜的数字：&quot;))n=n+1if num1&gt;num: print(&apos;大了&apos;)elif num1&lt;num: print(&apos;小了&apos;)else: print(&apos;恭喜你，猜对了！&apos;) print(&apos;一共猜了：%d次&apos;%(n),end=&apos; &apos;) if n&lt;=5: print(&apos;你太棒了，只猜了%d次就猜对了&apos;%(n)) else: print(&apos;下次加油！&apos;) break 2、continuecontinue:结束当次循环，进入下次循环12345for x in range(1,10): print(&apos;=&apos;) continue # 遇到continue就不再执行循环体后面的内容，直接进入下一次循环的判断 print(x)` 求1~100中所有奇数的和123456sum=0for x in range(1,100): if x%2==0: continue sum=sum+xprint(sum) 打印100~999中十位数上不是3的所有数：123456 for x in range(100,1000): if x//10%10==3: continue print(x) ``` 统计输入的数字中，偶数的个数。如果输入0，就结束。（必须使用continue） flag=True n=0 while True: num=int(input(‘请输入一个数：’)) # 输入数据 if num%2==1: # 判断是否是奇数 continue if num==0: flag=False n=n+1 print(n)12**else**python中循环语句后面可以加else语句。这个else语句会在循环结束后执行。 for 变量 in 序列： 循环体 else： 循环结束后会执行的语句块 1234567``` 1*2*3...*10 sum1=1 for x in range(1,11): sum1*=x else: print(sum1) 注意：如果再循环语句中使用break，那么else语句不会执行。（continue不存在这个问题） 123…*10，当乘积大于10000就不在执行12345678sum1=1for x in range(1,11): if sum1*x&gt;10000: break sum1*=xprint(sum1)else: print(sum1) # 如果在循环中执行了break，那么else中的语句不会执行 多重循环在循环体里面可以有其他的循环语句，结构为：123456789101112131415for 变量 in 序列： for 变量1 in 序列2： 循环体2 其它的循环语句for 变量 in 序列： 其他的循环语句1 while 条件语句： 循环体2 其他的循环语句2while 条件语句1： while 条件语句2： 循环体2 其他的循环语句2 例如：1234567891011121314151617181920212223242526272829如果n=5 打印112123123412345n=5for x in range(1,n+1): # 控制行数 for b in range(1,x+1): # 控制当前行的数值 print(b,end=&apos;&apos;) print() # 一行结束换行***************n=5for x in range(1,n+1): for b in range(x,n+1): print(&apos;*&apos;,end=&apos;&apos;) print()n=10for x in range(1,n+1): for b in range(x,n+1): print(&apos;*&apos;,end=&apos;&apos;) print() 参考了简书中某人的记录，但找不到具体是谁了。侵删。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(3) python中变量与运算符]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E4%B8%AD%E5%8F%98%E9%87%8F%E4%B8%8E%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[变量的命名规则字母，数字，下划线_和他们的组合注意：12345671、首字母不能为数字2、只有下划线_这一种特殊字符3、系统关键字不能作为变量名#True = 1 #报错can&apos;t assign to keyword4、变量是区分大小写的cat_name=1catName=1 #变量的两种命名方式 运算符python运算符有：算术运算符、比较运算符、赋值运算符、逻辑运算符、位运算符、成员运算符、身份运算符、运算符优先级 Python算术运算符1234567+ 加 - 两个对象相加 a + b 输出结果 31- 减 - 得到负数或是一个数减去另一个数 a - b 输出结果 -11* 乘 - 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 210/ 除 - x 除以 y b / a 输出结果 2.1% 取模 - 返回除法的余数 b % a 输出结果 1** 幂 - 返回x的y次幂 a**b 为10的21次方// 取整除 - 返回商的整数部分 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 Python比较运算符123456== 等于 - 比较对象是否相等 (a == b) 返回 False。!= 不等于 - 比较两个对象是否不相等 (a != b) 返回 True。&gt; 大于 - 返回x是否大于y (a &gt; b) 返回 False。&lt; 小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价。注意，这些变量名的大写。 (a &lt; b) 返回 True。&gt;= 大于等于 - 返回x是否大于等于y。 (a &gt;= b) 返回 False。&lt;= 小于等于 - 返回x是否小于等于y。 (a &lt;= b) 返回 True。 Python赋值运算符12345678= 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值为 c+= 加法赋值运算符 c += a 等效于 c = c + a-= 减法赋值运算符 c -= a 等效于 c = c - a*= 乘法赋值运算符 c *= a 等效于 c = c * a/= 除法赋值运算符 c /= a 等效于 c = c / a%= 取模赋值运算符 c %= a 等效于 c = c % a**= 幂赋值运算符 c **= a 等效于 c = c ** a//= 取整除赋值运算符 c //= a 等效于 c = c // a Python位运算符 按位运算符是把数字看作二进制来进行计算的。Python中的按位运算法则如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657下表中变量 a 为 60，b 为 13二进制格式如下：a = 0011 1100b = 0000 1101-----------------a&amp;b = 0000 1100a|b = 0011 1101a^b = 0011 0001~a = 1100 0011运算符 &amp; 按位与运算符：参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0 (a &amp; b) 输出结果 12 ，二进制解释： 0000 1100| 按位或运算符：只要对应的二个二进位有一个为1时，结果位就为1。 (a | b) 输出结果 61 ，二进制解释： 0011 1101^ 按位异或运算符：当两对应的二进位相异时，结果为1 (a ^ b) 输出结果 49 ，二进制解释： 0011 0001~ 按位取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1。~x 类似于 -x-1 (~a ) 输出结果 -61 ，二进制解释： 1100 0011， 在一个有符号二进制数的补码形式。&lt;&lt; 左移动运算符：运算数的各二进位全部左移若干位，由&quot;&lt;&lt;&quot;右边的数指定移动的位数，高位丢弃，低位补0。 a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000&gt;&gt; 右移动运算符：把&quot;&gt;&gt;&quot;左边的运算数的各二进位全部右移若干位，&quot;&gt;&gt;&quot;右边的数指定移动的位数 a &gt;&gt; 2 输出结果 15 ，二进制解释： 0000 1111以下实例演示了Python所有位运算符的操作：实例(Python 3.0+) #!/usr/bin/python3 a = 60 # 60 = 0011 1100 b = 13 # 13 = 0000 1101 c = 0 c = a &amp; b; # 12 = 0000 1100print (&quot;1 - c 的值为：&quot;, c) c = a | b; # 61 = 0011 1101 print (&quot;2 - c 的值为：&quot;, c) c = a ^ b; # 49 = 0011 0001print (&quot;3 - c 的值为：&quot;, c) c = ~a; # -61 = 1100 0011print (&quot;4 - c 的值为：&quot;, c) c = a &lt;&lt; 2; # 240 = 1111 0000print (&quot;5 - c 的值为：&quot;, c) c = a &gt;&gt; 2; # 15 = 0000 1111print (&quot;6 - c 的值为：&quot;, c)以上实例输出结果：1 - c 的值为： 122 - c 的值为： 613 - c 的值为： 494 - c 的值为： -615 - c 的值为： 2406 - c 的值为： 15 Python逻辑运算符123and x and y 布尔&quot;与&quot; - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。or x or y 布尔&quot;或&quot; - 如果 x 是 True，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。not not x 布尔&quot;非&quot; - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False Python成员运算符除了以上的一些运算符之外，Python还支持成员运算符，测试实例中包含了一系列的成员，包括字符串，列表或元组。12in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True。 Python身份运算符身份运算符用于比较两个对象的存储单元123456789is is 是判断两个标识符是不是引用自一个对象 x is y, 类似 id(x) == id(y) , 如果引用的是同一个对象则返回 True，否则返回 Falseis not is not 是判断两个标识符是不是引用自不同对象 x is not y ， 类似 id(a) != id(b)。如果引用的不是同一个对象则返回结果 True，否则返回 False。注： id() 函数用于获取对象内存地址。is 与 == 区别：is 用于判断两个变量引用对象是否为同一个， == 用于判断引用变量的值是否相等。&gt;&gt;&gt;a = [1, 2, 3] &gt;&gt;&gt; b = a &gt;&gt;&gt; b is a True &gt;&gt;&gt; b == a True &gt;&gt;&gt; b = a[:] &gt;&gt;&gt; b is a False &gt;&gt;&gt; b == a True Python运算符优先级以下表格列出了从最高到最低优先级的所有运算符：12345678910111213** 指数 (最高优先级)~ + - 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@)* / % // 乘，除，取模和取整除+ - 加法减法&gt;&gt; &lt;&lt; 右移，左移运算符&amp; 位 &apos;AND&apos;^ | 位运算符&lt;= &lt; &gt; &gt;= 比较运算符&lt;&gt; == != 等于运算符= %= /= //= -= += *= **= 赋值运算符is is not 身份运算符in not in 成员运算符and or not 逻辑运算符 一些杂项 `3+2-1 #4 同优先级 左集合c=a+b #先算a+b然后赋值给c 右集合not (1 or 2)+2==3 #True 建议括号只用来改变优先级关系]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(2) python基本数据类型总结]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[整数int与浮点数float整数运算永远是精确的，浮点数的运算可能会有四舍五入。2/2结果为1.0// 表示整除 2//2结果为13//2也是1 并不是四舍五入，而是只保留整数部分1.23x10^9和 12.3x10^8相等1.23x10^9就是1.23e9，或者12.3e8，0.000012可以写成1.2e-5进制python中默认为10进制。2进制用0b表示，例如0b10即为2。8进制用0o表示，例如0o10即为8。16进制用0x表示，例如0x10即为16。（8,9,a,b,c,d,e,f,0x10)1234bin() #转化为2进制oct() #转化为8进制int() #转化为10进制hex() #转化为16进制 布尔值bool123456bool()bool(0)bool(&apos;&apos;)bool([])bool(&#123;&#125;)bool(None) 只有bool(0)和bool()括号中为空才表示Fasle。bool(’0‘)等表示True 序列字符串 str 可用单引号，双引号或者三引号表示例如’str’ 或”str “或者’’’str’’’ 其中三引号常用方式如下123456&apos;&apos;&apos;line1line2 . .&apos;&apos;&apos; 在字符串前面加一个R/r 表示原始字符串1print(r&apos;\t\r&apos;) # \t\r 一些转义字符（特殊的字符）123456\n #换行 无法“看见”的字符\&apos; #单引号 与语言本身有冲突的字符\t #横向制表符\r #回车\n #换行\\ #表示\ 元组 tuple ( )与列表list [ ] 元组与列表在python中的唯一区别就是：元组是不可变的，列表是可变的。(元组和字符串是不可变的)12345678910111213141516a = &apos;hello&apos;a=a+&apos;world&apos;print(a) #&apos;helloworld&apos; a变成了一个新的字符串，而不是改变了字符串#列表可变b=[1,2,3]b.append(4)print(b) #[1,2,3,4]#改变的是列表不是元组c = (1,2,3,[4,5,[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;]])c[3][2][1] = &apos;d&apos;c[3][0]=&apos;6&apos;c[3][1]=7#c[2]=8 #会报错，因为元组不能被改变&apos;tuple&apos; object does not support item assignmentprint(c) #(1, 2, 3, [&apos;6&apos;, 7, [&apos;a&apos;, &apos;d&apos;, &apos;c&apos;]]) 改变的是列表 而不是 元组 在你有一些不确定长度的相同类型队列的时候使用列表；在你提前知道元素数量的情况下使用元组，因为元素的位置很重要。123456789#元组(1,2,3) ((1,2,3),(4,&apos;hello&apos;,True))(1,2,[3,4],&#123;5,6&#125;,&#123;(1,2,3):10,&apos;hello&apos;:11,100:&apos;hello&apos;&#125;)() #空元组(1,) #一个元素的元组#列表[1,2,3][[1,2,3],[4,&apos;hello&apos;,True],(1,2,3),&#123;7,8&#125;&#123;(1,2,3):10,&apos;hello&apos;:11,100:&apos;hello&apos;&#125;] 序列可以进行加法，与整数相乘，切片操作123456789101112131415161718#与整数相乘&apos;python&apos;*3 # &apos;pythonpythonpython&apos;((1,2,3),(4,&apos;hello&apos;,True))*2 # ((1, 2, 3), (4, &apos;hello&apos;, True), (1, 2, 3), (4, &apos;hello&apos;, True))[[1,2,3],[4,&apos;hello&apos;,True],(1,2,3)]*2 #[[1, 2, 3], [4, &apos;hello&apos;, True], (1, 2, 3), [1, 2, 3], [4, &apos;hello&apos;, True], (1, 2, 3)]#同类型相加&apos;hello&apos;+&apos;world&apos; # &apos;helloword&apos;((1,2,3),(4,&apos;hello&apos;,True))+(7,8,9) #((1, 2, 3), (4, &apos;hello&apos;, True), 7, 8, 9)[[1,2,3],[4,&apos;hello&apos;,True],(1,2,3)]+[4,5,6] #[[1, 2, 3], [4, &apos;hello&apos;, True], (1, 2, 3), 4, 5, 6]#切片&apos;hello world&apos;[0] # &apos;h&apos; 从0开始&apos;hello world&apos;[-1] # &apos;d&apos; 从末尾往前数1&apos;hello world&apos;[1:4] # &apos;ell&apos; 从1开始，4前一位结束&apos;hello world&apos;[0:-2] # &apos;hello wor&apos; 从开头到末尾减去2位&apos;hello world&apos;[:-5] # &apos;hello &apos; 从开头到末尾减去5个字符 &apos;hello world&apos;[1:-2] #&apos;ello wor&apos; 从1到末尾减去2位&apos;hello world&apos;[6:100] # &apos;world&apos; 超过，从第6位取到末尾&apos;hello world&apos;[6:] # &apos;world&apos; 从第6位取得末尾&apos;hello world&apos;[-1:2] #&apos;’‘ 空字符串，不能这样做 集合set {}和字典dict {}集合和字典的特点是 无序，不重复set()表示空集合{} 表示空字典123- #可以用来求两个集合的差集+ #可以用来求两个集合的交集| #可以用来求两个集合的合集 字典是通过key访问value{key1:value1,key2:value2}key不能重复,类型为int,str，tuplevalue可以为任意数据]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[(1) python]]></title>
    <url>%2Fpython%E5%9F%BA%E7%A1%80%2Fpython%2F</url>
    <content type="text"><![CDATA[编译型语言在程序执行之前，先会通过编译器对程序执行一个编译的过程，把程序转变成机器语言。运行时就不需要翻译，而直接执行就可以了。最典型的例子就是 C 语言。 解释型语言就没有这个编译的过程，而是在程序运行的时候，通过解释器对程序逐行作出解释，然后直接运行，最典型的例子是 Ruby。 Python 是一门先编译后解释的语言。 当 Python 程序运行时，编译的结果则是保存在位于内存中的 PyCodeObject 中，当 Python 程序运行结束时，Python 解释器则将 PyCodeObject 写回到 pyc 文件中。 当 Python 程序第二次运行时，首先程序会在硬盘中寻找 pyc 文件，如果找到，则直接载入，否则就重复上面的过程。 pyc 文件其实是 PyCodeObject 的一种持久化保存方式。 执行 Python 程序的三种方式：解释器、交互式运行、IDE运行]]></content>
      <categories>
        <category>python基础</category>
      </categories>
  </entry>
</search>
